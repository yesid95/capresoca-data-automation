{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proceso de Identificaci√≥n y Gesti√≥n de Cartera de Afiliados - Capresoca EPS\n",
    "\n",
    "**Normatividad:**  \n",
    "- *Decreto 780 de 2016*: Es la ley macro que dice qu√© se debe hacer (pagar) y qu√© pasa si no se hace (mora y suspensi√≥n). \n",
    "- *Resoluci√≥n 1702 de 2021*: Fue el primer manual de instrucciones detallado sobre c√≥mo cobrar.\n",
    "- *Resoluci√≥n 2082 de 2016*: Es el manual de instrucciones vigente y mejorado sobre c√≥mo deben las EPS cobrar la cartera hoy (2025).  \n",
    "\n",
    "**Contexto:**  \n",
    "Este notebook tiene como objetivo agilizar la identificaci√≥n de afiliados en estado de Mora, Aviso o Sin Pagos, para que el √°rea de Aseguramiento de Capresoca EPS realice la gesti√≥n de cobro y notificaci√≥n a afiliados y empresas, conforme a la normatividad vigente.\n",
    "\n",
    "**Fuentes de datos principales:**  \n",
    "- PILA entregada por el operador a la EPS \"Pila I y Pila IP\" \n",
    "- PILA conciliada por ADRES  \"Pila 3047\"\n",
    "- Maestro contributivo de afiliados de la EPS  \n",
    "\n",
    "**Fuentes de datos secundarias:**  \n",
    "- Informaci√≥n interna de la EPS ;\n",
    "    * relaciones laborales del sistema interno.\n",
    "    * Maestro del sitema interno de la EPS.\n",
    "    \n",
    "\n",
    "El proceso permite consolidar y analizar la informaci√≥n para facilitar la gesti√≥n y el recaudo de cartera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Carga de librer√≠as y configuraci√≥n inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import openpyxl  # Motor recomendado para escribir archivos Excel (.xlsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_Periodo_Actual = \"2025-06-01\"\n",
    "Dia = \"2025-06-01\"\n",
    "Mora = \"2025-05-01\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fuentes de datos y rutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rutas Capresoca \n",
    "R_MaestroAdres = r\"\\\\Servernas\\AYC2\\ASEGURAMIENTO\\eps_data_management\\Procesos BDUA\\Contributivo\\Maestro\\2025-2\\EPSC25MC0014072025.TXT\" # Cambiar nombre\n",
    "R_Relaciones_Laborales_SIE = r\"\\\\Servernas\\AYC2\\ASEGURAMIENTO\\eps_data_management\\SIE\\Aseguramiento\\relaciones laborales\\Reporte_Afiliados Contributivo Relaciones Laborales_2025_07_16.csv\" # Cambiar nombre\n",
    "R_Ms_SIE =r\"\\\\Servernas\\AYC2\\ASEGURAMIENTO\\eps_data_management\\SIE\\Aseguramiento\\ms_sie\\Reporte_Validaci√≥n Archivos Maestro_2025_07_15.csv\" # Cambiar nombre\n",
    "\n",
    "R_Pila3047 = r\"\\\\Servernas\\AYC2\\ASEGURAMIENTO\\eps_data_management\\Procesos BDUA\\Contributivo\\Compensaci√≥n\\Pila consiliada ADRES\\Pila_Unificado_Con_Aportante_2018_2025.TXT\"\n",
    "R_Pila_I_SIE = r\"\\\\Servernas\\AYC2\\ASEGURAMIENTO\\eps_data_management\\SIE\\Pila_SIE\\Pila I\"\n",
    "R_Pila_IP_SIE = r\"\\\\Servernas\\AYC2\\ASEGURAMIENTO\\eps_data_management\\SIE\\Pila_SIE\\Pila IP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas de salida Capresoca \n",
    "R_Salida_Pila_SIE_i = r\"C:\\Users\\osmarrincon\\Downloads\\Proceso.xlsx\"\n",
    "#R_Salida_Relaciones_Laborales = r\"C:\\Users\\osmarrincon\\OneDrive - uniminuto.edu\\Capresoca\\AlmostClear\\Procesos BDUA\\Contributivo\\Compensaci√≥n\\_Pila_SIE\\SIE\\Relaciones laborales.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Obtener la lista de archivos .txt en la ruta especificada\n",
    "file_list = glob.glob(R_Pila_I_SIE + \"/*.TXT\")\n",
    "file_list_IP = glob.glob(R_Pila_IP_SIE + \"/*.TXT\")\n",
    "\n",
    "# Leer y concatenar todos los archivos .txt en un solo dataframe\n",
    "df_pila_i_sie = pd.concat((pd.read_csv(file, sep='|', encoding='ANSI') for file in file_list), ignore_index=True)\n",
    "df_pila_iP_sie = pd.concat((pd.read_csv(file, sep='|', encoding='ANSI', header=None) for file in file_list_IP), ignore_index=True)\n",
    "DF_MC_Adres = pd.read_csv(R_MaestroAdres, sep=',', encoding='ansi', header=None)\n",
    "df_Pila_3047 = pd.read_csv(R_Pila3047, sep=',', encoding='UTF-16')\n",
    "df_Relaciones_Laborales_SIE = pd.read_csv(R_Relaciones_Laborales_SIE, sep=';', encoding='ansi')\n",
    "Df_SIE = pd.read_csv(R_Ms_SIE, sep=';', dtype=str, encoding='ANSI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. üßæ Registro de Logs de Entrada (Trazabilidad de Fuentes)\n",
    "\n",
    "Para garantizar la trazabilidad, reproducibilidad y control de calidad del proceso automatizado, se implementa un mecanismo de auditor√≠a que registra las fuentes de informaci√≥n que alimentan el proceso de cartera.\n",
    "\n",
    "**Objetivo:**  \n",
    "Generar estructuras de resumen (`logs_3047` y `logs_pila`) que permitan identificar con precisi√≥n qu√© archivos o fechas alimentaron el modelo actual. Esto facilita detectar inconsistencias, regresiones en la calidad de datos, o depurar resultados hist√≥ricos.\n",
    "\n",
    "### a) **Logs de df_Pila_3047**  \n",
    "El DataFrame `df_Pila_3047` (fuente ADRES) incluye una columna `nombre_Archivo`, que contiene el nombre del archivo de origen.  \n",
    "- Se extraen los nombres √∫nicos de archivo.\n",
    "- Se infiere la fecha del archivo a partir del patr√≥n `PILA_EPSC2520241001.TXT`, reconociendo el fragmento `20241001` como la fecha `01/10/2024`.\n",
    "- El resultado es un DataFrame `logs_3047` con las columnas:\n",
    "  - `nombre_Archivo`\n",
    "  - `Fecha` (convertida a formato datetime)\n",
    "\n",
    "### b) **Logs de PILA Interna (`Pila_I` y `Pila_IP`)**\n",
    "Los DataFrames `df_pila_i_sie` y `df_pila_iP_sie` provienen de archivos `.TXT` internos, que no incluyen el nombre del archivo como columna.  \n",
    "Como a√∫n no se han asignado nombres de columnas a estas estructuras, se toma la **columna n√∫mero 18** (`√≠ndice 17`, correspondiente a la `Fecha Pago` en la estructura esperada) para inferir la √∫ltima fecha de actualizaci√≥n de cada fuente.\n",
    "\n",
    "- `Pila_I` ‚Üí Datos principales (`df_pila_i_sie`)\n",
    "- `Pila_IP` ‚Üí Datos adicionales (`df_pila_iP_sie`)\n",
    "\n",
    "El resultado es un DataFrame `logs_pila` con:\n",
    "- `Origen` (Pila_I o Pila_IP)\n",
    "- `Fecha M√°xima` (m√°xima fecha de pago detectada en cada fuente)\n",
    "\n",
    "**Resultado:**  \n",
    "Ambos registros se exportan en hojas separadas dentro del archivo final (`Logs_3047`, `Logs_PILA`) para facilitar su trazabilidad, validaci√≥n o comparaci√≥n entre ejecuciones del modelo de cartera.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Logs para df_Pila_3047 ---\n",
    "logs_3047 = (\n",
    "    df_Pila_3047[[\"nombre_Archivo\"]]\n",
    "    .dropna()\n",
    "    .drop_duplicates()\n",
    "    .assign(\n",
    "        Fecha=lambda df: pd.to_datetime(\n",
    "            df[\"nombre_Archivo\"].str.extract(r'EPSC25(\\d{8})')[0],\n",
    "            format='%Y%m%d',\n",
    "            errors='coerce'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# --- Logs para fuentes internas PILA_I y PILA_IP (usando la columna 17 = Fecha Pago) ---\n",
    "logs_pila = pd.concat([\n",
    "    pd.DataFrame({\n",
    "        \"Origen\": \"Pila_I\",\n",
    "        \"Fecha\": pd.to_datetime(df_pila_i_sie.iloc[:, 17], errors='coerce')\n",
    "    }),\n",
    "    pd.DataFrame({\n",
    "        \"Origen\": \"Pila_IP\",\n",
    "        \"Fecha\": pd.to_datetime(df_pila_iP_sie.iloc[:, 17], errors='coerce')\n",
    "    })\n",
    "], ignore_index=True)\n",
    "\n",
    "logs_pila = (\n",
    "    logs_pila\n",
    "    .groupby(\"Origen\")[\"Fecha\"]\n",
    "    .max()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"Fecha\": \"Fecha M√°xima\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Limpieza y normalizaci√≥n de datos\n",
    "## 3.1 Limpieza de PILA IP y PILA 3047\n",
    "- Reemplazo de valores\n",
    "- Definic√≥n del origen de los datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar los valores 'X' por 1 en todo el dataframe df_pila_iP_sie\n",
    "df_pila_iP_sie = df_pila_iP_sie.replace('X', 1)\n",
    "df_Pila_3047 = df_Pila_3047.replace('X', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pila_i_sie['origen'] = 'Pila_I'\n",
    "df_pila_iP_sie['origen'] = 'Pila_IP'\n",
    "df_Pila_3047['origen'] = 'Pila_3047'\n",
    "print(f\"N√∫mero de columnas en df_pila_i_sie: {df_pila_i_sie.shape[1]}\")\n",
    "print(f\"N√∫mero de columnas en df_pila_iP_sie: {df_pila_iP_sie.shape[1]}\")\n",
    "print(f\"N√∫mero de columnas en df_Pila_3047: {df_Pila_3047.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. üîó Unificaci√≥n de Fuentes de PILA Interna\n",
    "\n",
    "En esta celda se realiza la unificaci√≥n de dos fuentes internas relacionadas con los pagos PILA (`df_pila_i_sie` y `df_pila_iP_sie`). El prop√≥sito es consolidar la informaci√≥n de pagos reportados desde distintas instancias internas del sistema SIE, manteniendo una √∫nica base de an√°lisis.\n",
    "\n",
    "**Pasos realizados:**\n",
    "1. Se valida que ambos DataFrames tengan la misma cantidad de columnas.\n",
    "2. Se renombra `df_pila_iP_sie` para asegurar consistencia en los nombres de columnas.\n",
    "3. Se concatenan ambos DataFrames en `df_pila_i_sie`.\n",
    "4. Se verifica que la unificaci√≥n se haya realizado correctamente.\n",
    "5. Se elimina `df_pila_iP_sie` para liberar memoria.\n",
    "\n",
    "Este proceso asegura que toda la informaci√≥n de pagos desde diferentes m√≥dulos del sistema quede unificada para su posterior an√°lisis de cartera.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar la cantidad de registros antes de la unificaci√≥n\n",
    "print(f\"Cantidad de registros en df_pila_i_sie antes de la unificaci√≥n: {len(df_pila_i_sie)}\")\n",
    "print(f\"Cantidad de registros en df_pila_iP_sie antes de la unificaci√≥n: {len(df_pila_iP_sie)}\")\n",
    "\n",
    "# Validar que ambos dataframes tengan la misma cantidad de columnas\n",
    "if df_pila_iP_sie.shape[1] == df_pila_i_sie.shape[1]:\n",
    "    # Asignar el mismo nombre de columnas de df_pila_i_sie a df_pila_iP_sie\n",
    "    df_pila_iP_sie.columns = df_pila_i_sie.columns\n",
    "    \n",
    "    # Unificar ambos dataframes\n",
    "    df_pila_i_sie = pd.concat([df_pila_i_sie, df_pila_iP_sie], ignore_index=True)\n",
    "    \n",
    "    # Validar que la unificaci√≥n se haya realizado correctamente\n",
    "    if len(df_pila_i_sie) > len(df_pila_i_sie) - len(df_pila_iP_sie):\n",
    "        print(\"Unificaci√≥n realizada correctamente.\")\n",
    "    else:\n",
    "        print(\"Error en la unificaci√≥n de los dataframes.\")\n",
    "    \n",
    "    # Eliminar el dataframe df_pila_iP_sie\n",
    "    del df_pila_iP_sie\n",
    "else:\n",
    "    print(\"Los dataframes no tienen la misma cantidad de columnas. No se puede realizar la unificaci√≥n.\")\n",
    "\n",
    "# Mostrar la cantidad de registros despu√©s de la unificaci√≥n\n",
    "print(f\"Cantidad de registros despu√©s de la unificaci√≥n: {len(df_pila_i_sie)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3üîç Filtrado del √öltimo Per√≠odo de Pago por Aportante\n",
    "\n",
    "Esta celda tiene como objetivo conservar √∫nicamente el registro m√°s reciente de cada aportante (empresa o entidad) con base en la columna `Perido Pago`. Para ello:\n",
    "\n",
    "1. Se convierte la columna `Perido Pago` al tipo `datetime` usando el formato `%Y-%m`.\n",
    "2. Se ordenan los registros por `Raz√≥n Social Aportante`, `N¬∞ Identificaci√≥n Aportante` y `Perido Pago` en orden descendente.\n",
    "3. Se eliminan los duplicados por aportante, manteniendo solo el per√≠odo de pago m√°s reciente.\n",
    "\n",
    "Este paso es clave para consolidar la informaci√≥n y evitar duplicidades en el an√°lisis de cartera, permitiendo identificar la √∫ltima vez que cada empresa realiz√≥ aportes en PILA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Datos_Complementarios = df_pila_i_sie\n",
    "\n",
    "# Mostrar la cantidad de registros antes de filtrar\n",
    "print(f\"Cantidad de registros antes de filtrar: {len(df_Datos_Complementarios)}\")\n",
    "\n",
    "# Convertir la columna 'Perido Pago' a tipo datetime\n",
    "df_Datos_Complementarios['Perido Pago'] = pd.to_datetime(df_Datos_Complementarios['Perido Pago'], format='%Y-%m')\n",
    "\n",
    "# Ordenar el dataframe por las columnas especificadas y por 'Perido Pago' en orden descendente\n",
    "df_pila_df_Datos_Complementariosi_sie = df_Datos_Complementarios.sort_values(by=['Raz√≥n Social Aportante', 'N¬∞ Identificaci√≥n Aportante', 'Perido Pago'], ascending=[True, True, False])\n",
    "\n",
    "# Eliminar duplicados manteniendo solo los registros con el periodo m√°ximo\n",
    "df_Datos_Complementarios = df_Datos_Complementarios.drop_duplicates(subset=['Raz√≥n Social Aportante', 'N¬∞ Identificaci√≥n Aportante'], keep='first')\n",
    "\n",
    "# Mostrar la cantidad de registros despu√©s de filtrar\n",
    "print(f\"Cantidad de registros despu√©s de filtrar: {len(df_Datos_Complementarios)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar las primeras filas del dataframe\n",
    "print(f\"Cantidad de registros Pila SIE: {len(df_pila_i_sie)}\")\n",
    "\n",
    "print(DF_MC_Adres.columns)\n",
    "print(f\"Cantidad de registros MC ADRES: {len(DF_MC_Adres)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. üßæ Depuraci√≥n y Selecci√≥n de Variables del Maestro Contributivo ADRES\n",
    "\n",
    "Esta celda realiza la depuraci√≥n inicial del archivo maestro contributivo proveniente de ADRES (`DF_MC_Adres`). El objetivo es conservar √∫nicamente las columnas relevantes para la identificaci√≥n del afiliado y su clasificaci√≥n en el r√©gimen contributivo.\n",
    "\n",
    "**Pasos realizados:**\n",
    "1. Se seleccionan 11 columnas clave mediante √≠ndices posicionales (`columns_to_keep`), asegurando eficiencia en el manejo de estructuras de archivos sin encabezado estandarizado.\n",
    "2. Se filtran los registros excluyendo aquellos con tipo de afiliado `\"AF\"` (Afiliado Fallecido) o con ese campo vac√≠o.\n",
    "3. Se renombran las columnas seleccionadas para facilitar la interpretaci√≥n y an√°lisis.\n",
    "4. Se imprimen las columnas resultantes y la cantidad total de registros filtrados.\n",
    "\n",
    "Esta depuraci√≥n permite trabajar con una versi√≥n optimizada del maestro contributivo, √∫til para cruces con PILA y detecci√≥n de inconsistencias en estado y afiliaci√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar solo las columnas especificadas\n",
    "columns_to_keep = [\n",
    "    4, 5, 6, 7, 8, 9, 17, 23, 24, 33, 41 \n",
    "]\n",
    "\n",
    "# Filtrar el dataframe para mantener solo las columnas especificadas\n",
    "DF_MC_Adres = DF_MC_Adres[columns_to_keep]\n",
    "DF_MC_Adres = DF_MC_Adres[\n",
    "    (DF_MC_Adres[33] != \"AF\") | (DF_MC_Adres[33].isna())\n",
    "]\n",
    "\n",
    "# Asignar nombres a las columnas seleccionadas\n",
    "DF_MC_Adres.columns = [\n",
    "    'Tp_Do', 'No_Do', '1A', '2A', '1N', '2N', 'Tp_Afiliado', 'Departamento', 'Municipio', 'Estado_ADRES', 'Sisben'\n",
    "]\n",
    "\n",
    "\n",
    "# Mostrar las primeras filas del dataframe resultante\n",
    "print(DF_MC_Adres.columns)\n",
    "print(f\"Cantidad de registros: {len(DF_MC_Adres)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. üßπ Eliminaci√≥n de Planillas Corregidas y Selecci√≥n de Variables Relevantes ‚Äì PILA Interna\n",
    "\n",
    "Esta celda tiene como objetivo depurar los registros del DataFrame `df_pila_i_sie` eliminando las planillas que fueron corregidas por los afiliados, ya que estas pueden generar duplicidad o sesgos en el an√°lisis de cotizaciones y mora.\n",
    "\n",
    "**Contexto t√©cnico:**\n",
    "Cuando un afiliado realiza una correcci√≥n sobre su planilla (por ejemplo, modifica los d√≠as cotizados o retira una novedad err√≥nea), el sistema PILA genera dos planillas: la original y la corregida. Es fundamental conservar solo la √∫ltima (v√°lida), eliminando aquellas con indicador de correcci√≥n `\"A\"` en la columna `Correcciones`.\n",
    "\n",
    "**Pasos realizados:**\n",
    "1. Se eliminan los registros marcados como correcciones (`Correcciones = \"A\"`), conservando √∫nicamente planillas v√°lidas o sin marca.\n",
    "2. Se seleccionan las columnas clave para el an√°lisis de aportes, afiliaci√≥n y origen de los datos:\n",
    "   - Datos del aportante y cotizante.\n",
    "   - Per√≠odo y fecha de pago.\n",
    "   - Ingresos y valores cotizados.\n",
    "   - Indicador de origen de la informaci√≥n (fuente de carga).\n",
    "\n",
    "Este paso asegura que el an√°lisis posterior no se vea afectado por registros corregidos que podr√≠an duplicar o distorsionar la informaci√≥n real de aportes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pila_i_sie = df_pila_i_sie[\n",
    "    (df_pila_i_sie['Correcciones'] != \"A\") | (df_pila_i_sie['Correcciones'].isna())\n",
    "]\n",
    "\n",
    "# Seleccionar solo las columnas especificadas\n",
    "columns_to_keep = [\n",
    "    'Raz√≥n Social Aportante', 'N¬∞ Identificaci√≥n Aportante', 'Perido Pago', 'Fecha Pago',\n",
    "    'Tipo Documento Cotizante', 'N¬∞ Identificaci√≥n Cotizante', 'Tipo Cotizante', 'ING', 'RET', 'D√≠as Cotizados', \n",
    "    'Ingreso Base Cotizaci√≥n', 'Cotizaci√≥n Obligatoria', 'N√∫mero Planilla', 'origen'\n",
    "]\n",
    "# Filtrar el dataframe para mantener solo las columnas especificadas\n",
    "df_pila_i_sie = df_pila_i_sie[columns_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6. üßæ Estandarizaci√≥n de Columnas del Archivo PILA 3047 ‚Äì Conciliada ADRES\n",
    "\n",
    "Esta celda tiene como objetivo estandarizar la estructura del archivo `df_Pila_3047`, correspondiente a la planilla PILA conciliada por ADRES, con el fin de unificar su an√°lisis con otras fuentes de informaci√≥n interna (como PILA SIE).\n",
    "\n",
    "**Pasos realizados:**\n",
    "1. Se renombran las columnas originales para adoptar la misma nomenclatura utilizada en el an√°lisis interno de PILA (`df_pila_i_sie`), garantizando compatibilidad estructural.\n",
    "2. Se reorganizan las columnas en un orden l√≥gico que facilita su comparaci√≥n, consolidaci√≥n y posterior cruce de datos con otras fuentes como:\n",
    "   - Maestro contributivo EPS.\n",
    "   - Relaci√≥n laboral SIE.\n",
    "   - PILA del operador.\n",
    "\n",
    "La estandarizaci√≥n de esta fuente es fundamental para evitar ambig√ºedades, asegurar trazabilidad en los campos clave y permitir un an√°lisis integral de la informaci√≥n de aportes y cartera, conforme a los lineamientos normativos de Capresoca EPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Pila_3047 = df_Pila_3047.rename(columns={\n",
    "    'Num_rad_planilla': 'N√∫mero Planilla',\n",
    "    'perido_pago_del_aportante': 'Perido Pago',\n",
    "    'fecha_pago': 'Fecha Pago',\n",
    "    'Tipo_doc_cotizante': 'Tipo Documento Cotizante',\n",
    "    'doc_cotizante' : 'N¬∞ Identificaci√≥n Cotizante',\n",
    "    'Tipo_cotizante': 'Tipo Cotizante',\n",
    "    'ingreso': 'ING',\n",
    "    'retiro': 'RET',\n",
    "    'dias_cotizados': 'D√≠as Cotizados',\n",
    "    'ibc': 'Ingreso Base Cotizaci√≥n',\n",
    "    'cotizacion_obligatoria':'Cotizaci√≥n Obligatoria',\n",
    "    'Nit': 'N¬∞ Identificaci√≥n Aportante',\n",
    "    'Razon_Soacial': 'Raz√≥n Social Aportante'\n",
    "})\n",
    "print(df_Pila_3047.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order = [\n",
    "    'Raz√≥n Social Aportante', 'N¬∞ Identificaci√≥n Aportante', 'Perido Pago', 'Fecha Pago',\n",
    "    'Tipo Documento Cotizante', 'N¬∞ Identificaci√≥n Cotizante', 'Tipo Cotizante', 'ING', 'RET', 'D√≠as Cotizados', \n",
    "    'Ingreso Base Cotizaci√≥n', 'Cotizaci√≥n Obligatoria', 'N√∫mero Planilla', 'origen'\n",
    "    ]\n",
    "df_Pila_3047 = df_Pila_3047[column_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7. üß™ Normalizaci√≥n de Tipos de Datos en PILA Interna y PILA Conciliada ADRES\n",
    "\n",
    "Esta celda realiza la conversi√≥n y estandarizaci√≥n de tipos de datos num√©ricos clave en los DataFrames `df_pila_i_sie` (fuente interna de Capresoca EPS) y `df_Pila_3047` (planilla PILA conciliada por ADRES). Esta normalizaci√≥n es esencial para garantizar que operaciones como filtros, comparaciones y agregaciones puedan ejecutarse sin errores de tipo o coerci√≥n.\n",
    "\n",
    "**Campos transformados:**\n",
    "\n",
    "- `Tipo Cotizante`: convertido a entero (`int64`) y valores nulos reemplazados por 0.\n",
    "- `Ingreso Base Cotizaci√≥n`: convertido a n√∫mero decimal (`float64`) para permitir operaciones aritm√©ticas.\n",
    "- `N¬∞ Identificaci√≥n Aportante`: asegurado como n√∫mero entero, reemplazando errores o vac√≠os.\n",
    "- Indicadores de novedad (`ING`, `RET`) y `D√≠as Cotizados`: completados con 0 y convertidos a `int64`.\n",
    "\n",
    "**Importancia operativa:**\n",
    "Esta limpieza evita errores en procesos como:\n",
    "- Uniones (`merge`) basadas en identificadores.\n",
    "- C√°lculo de mora y d√≠as cotizados.\n",
    "- Generaci√≥n de reportes consolidados por empresa o afiliado.\n",
    "\n",
    "Al aplicar esta estandarizaci√≥n, se fortalece la calidad y confiabilidad del an√°lisis de cartera de acuerdo con los lineamientos t√©cnicos de Capresoca EPS.\n",
    "\n",
    "Finalmente, se realiza la uni√≥n vertical (`concat`) de ambas fuentes (`df_pila_i_sie` y `df_Pila_3047`), consolidando as√≠ la base de datos completa de aportes reportados tanto por el sistema interno como por la conciliaci√≥n ADRES. Esta consolidaci√≥n permite un an√°lisis integral y depurado de los registros de cotizaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new columns to df_sin_pagos\n",
    "df_pila_i_sie['Tipo Cotizante'] = df_pila_i_sie['Tipo Cotizante'].fillna(0).astype('int64')\n",
    "\n",
    "\n",
    "df_Pila_3047['Ingreso Base Cotizaci√≥n'] = df_Pila_3047['Ingreso Base Cotizaci√≥n'].astype('float64')\n",
    "df_Pila_3047['N¬∞ Identificaci√≥n Aportante'] = pd.to_numeric(df_Pila_3047['N¬∞ Identificaci√≥n Aportante'], errors='coerce').fillna(0).astype('int64')\n",
    "df_Pila_3047['Tipo Cotizante'] = df_Pila_3047['Tipo Cotizante'].astype('int64')\n",
    "df_Pila_3047['ING'] = df_Pila_3047['ING'].fillna(0).astype('int64')\n",
    "df_Pila_3047['RET'] = df_Pila_3047['RET'].fillna(0).astype('int64')\n",
    "df_Pila_3047['D√≠as Cotizados'] = df_Pila_3047['D√≠as Cotizados'].fillna(0).astype('int64')\n",
    "df_pila_i_sie['ING'] = df_pila_i_sie['ING'].fillna(0).astype('int64')\n",
    "df_pila_i_sie['RET'] = df_pila_i_sie['RET'].fillna(0).astype('int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar la cantidad de registros antes de la uni√≥n\n",
    "print(f\"Cantidad de registros en df_Pila_3047 antes de la uni√≥n: {len(df_Pila_3047)}\")\n",
    "print(f\"Cantidad de registros en df_pila_i_sie antes de la uni√≥n: {len(df_pila_i_sie)}\")\n",
    "\n",
    "# Unir los dataframes uno debajo del otro\n",
    "df_pila_i_sie = pd.concat([df_pila_i_sie, df_Pila_3047], ignore_index=True)\n",
    "\n",
    "# Mostrar la cantidad de registros despu√©s de la uni√≥n\n",
    "print(f\"Cantidad de registros en df_pila_i_sie despu√©s de la uni√≥n: {len(df_pila_i_sie)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8. üîÑ Cruce con Maestro Contributivo ADRES y Filtro por Estado Activo\n",
    "\n",
    "Esta celda tiene como objetivo enriquecer y depurar la base de PILA consolidada (`df_pila_i_sie`) mediante el cruce con el Maestro Contributivo ADRES (`DF_MC_Adres`). Se busca garantizar que los registros analizados correspondan √∫nicamente a afiliados activos en ADRES y que cuenten con informaci√≥n complementaria √∫til para la segmentaci√≥n futura.\n",
    "\n",
    "**Pasos realizados:**\n",
    "1. Se estandarizan los nombres de las columnas de identificaci√≥n (`Tipo Documento Cotizante` y `N¬∞ Identificaci√≥n Cotizante`) para permitir la uni√≥n.\n",
    "2. Se cruza la informaci√≥n con `DF_MC_Adres`, incorporando:\n",
    "   - Apellidos y nombres.\n",
    "   - Ubicaci√≥n geogr√°fica (Departamento y Municipio).\n",
    "   - Estado del afiliado y puntaje Sisben.\n",
    "3. Se filtran √∫nicamente los registros cuyo estado sea `\"AC\"` (Activo), asegurando que el an√°lisis posterior no incluya afiliados suspendidos, retirados o sin validaci√≥n ante ADRES.\n",
    "\n",
    "Este paso cierra el proceso de limpieza y normalizaci√≥n, dejando los datos listos para la identificaci√≥n de afiliados en mora, aviso o sin pagos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar el nombre de las columnas especificadas\n",
    "df_pila_i_sie = df_pila_i_sie.rename(columns={\n",
    "    'Tipo Documento Cotizante': 'Tp_Do', \n",
    "    'N¬∞ Identificaci√≥n Cotizante': 'No_Do'\n",
    "})\n",
    "\n",
    "print(f\"Cantidad de registros Pila: {len(df_pila_i_sie)}\")\n",
    "# Realizar la uni√≥n de los dataframes\n",
    "df_pila_i_sie = df_pila_i_sie.merge(DF_MC_Adres[['Tp_Do', 'No_Do', '1A', '2A', '1N', '2N', 'Tp_Afiliado', 'Departamento', 'Municipio', 'Estado_ADRES', 'Sisben']], on=['Tp_Do', 'No_Do'], how='left')\n",
    "df_pila_i_sie = df_pila_i_sie[df_pila_i_sie['Estado_ADRES'].notna() & (df_pila_i_sie['Estado_ADRES'] == \"AC\")]\n",
    "\n",
    "\n",
    "print(f\"Cantidad de registros Pila: {len(df_pila_i_sie)}\")\n",
    "print(f\"Cantidad de registros df_pila_i_sie: {len(df_pila_i_sie)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9. üßÆ Normalizaci√≥n por Agrupaci√≥n: D√≠as Cotizados, ING y RET\n",
    "\n",
    "Este paso aplica reglas de consolidaci√≥n y estandarizaci√≥n sobre los registros de PILA (`df_pila_i_sie`), agrupando por empresa, afiliado y per√≠odo de pago. El objetivo es asegurar la consistencia interna de los indicadores antes de aplicar filtros anal√≠ticos.\n",
    "\n",
    "**Pasos realizados:**\n",
    "1. Se convierte la columna `D√≠as Cotizados` a tipo num√©rico para permitir su agregaci√≥n.\n",
    "2. Se agrupan los registros por:\n",
    "   - N¬∞ de identificaci√≥n del aportante.\n",
    "   - Tipo y n√∫mero de documento del afiliado.\n",
    "   - Per√≠odo de pago.\n",
    "3. Se aplica:\n",
    "   - Suma total de d√≠as cotizados dentro del grupo.\n",
    "   - M√°ximo valor para las columnas `ING` y `RET` (si alguno en el grupo tiene novedad, se refleja en todos).\n",
    "\n",
    "**Resultado:**\n",
    "Una estructura depurada donde cada grupo representa de forma homog√©nea la totalidad de los d√≠as cotizados y las novedades reportadas, eliminando discrepancias dentro del mismo conjunto de identificaci√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar la cantidad de registros antes de filtrar\n",
    "print(f\"Cantidad de registros antes de filtrar: {len(df_pila_i_sie)}\")\n",
    "\n",
    "# Convertir la columna 'D√≠as Cotizados' a tipo num√©rico\n",
    "df_pila_i_sie['D√≠as Cotizados'] = pd.to_numeric(df_pila_i_sie['D√≠as Cotizados'], errors='coerce')\n",
    "\n",
    "# Sumar los d√≠as cotizados por cada ID1\n",
    "df_pila_i_sie['D√≠as Cotizados'] = df_pila_i_sie.groupby(\n",
    "    [\"N¬∞ Identificaci√≥n Aportante\", \"Tp_Do\", \"No_Do\", 'Perido Pago']\n",
    ")['D√≠as Cotizados'].transform('sum')\n",
    "\n",
    "# Si en la columna ING hay un 1, todos los registros del mismo grupo quedan con 1\n",
    "df_pila_i_sie['ING'] = df_pila_i_sie.groupby(\n",
    "    [\"N¬∞ Identificaci√≥n Aportante\", \"Tp_Do\", \"No_Do\", 'Perido Pago']\n",
    ")['ING'].transform('max')\n",
    "\n",
    "# Si en la columna RET hay un 1, todos los registros del mismo grupo quedan con 1\n",
    "df_pila_i_sie['RET'] = df_pila_i_sie.groupby(\n",
    "    [\"N¬∞ Identificaci√≥n Aportante\", \"Tp_Do\", \"No_Do\", 'Perido Pago']\n",
    ")['RET'].transform('max')\n",
    "\n",
    "# Mostrar las primeras filas del dataframe resultante\n",
    "print(f\"Cantidad de registros despu√©s de la agregaci√≥n: {len(df_pila_i_sie)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.10. üìÖ Filtrado del √öltimo Per√≠odo Reportado por Afiliado y Aportante\n",
    "\n",
    "Esta celda tiene como objetivo conservar √∫nicamente el registro correspondiente al √∫ltimo per√≠odo de pago disponible para cada afiliado, dentro de cada empresa (aportante).\n",
    "\n",
    "**Pasos realizados:**\n",
    "1. Se convierte la columna `Perido Pago` a formato fecha (`datetime`), con formato `YYYY-MM`.\n",
    "2. Se agrupa por:\n",
    "   - N¬∞ de identificaci√≥n del aportante.\n",
    "   - Tipo y n√∫mero de documento del afiliado.\n",
    "3. Para cada grupo, se selecciona autom√°ticamente el registro con la fecha m√°xima de per√≠odo reportado.\n",
    "4. El DataFrame resultante contiene un solo registro por afiliado y aportante, correspondiente al per√≠odo m√°s reciente.\n",
    "\n",
    "**Resultado:**\n",
    "Una base depurada, donde se mantiene el registro m√°s actual de cotizaci√≥n por afiliado. Esto evita duplicidades y garantiza que los an√°lisis se basen en el dato m√°s vigente del sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna 'Perido Pago' a datetime\n",
    "df_pila_i_sie['Perido Pago'] = pd.to_datetime(df_pila_i_sie['Perido Pago'], format='%Y-%m', errors='coerce')\n",
    "\n",
    "# Para cada grupo, obtener el √≠ndice del registro con la fecha m√°xima\n",
    "idx_max = df_pila_i_sie.groupby(['N¬∞ Identificaci√≥n Aportante', 'Tp_Do', 'No_Do'])['Perido Pago'].idxmax()\n",
    "\n",
    "# Seleccionar √∫nicamente esos registros\n",
    "df_pila_i_sie = df_pila_i_sie.loc[idx_max].reset_index(drop=True)\n",
    "\n",
    "# Mostrar la cantidad de registros despu√©s de filtrar\n",
    "print(f\"Cantidad de registros despu√©s de filtrar: {len(df_pila_i_sie)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.11. üì¨ Enriquecimiento con Informaci√≥n de Contacto del Aportante\n",
    "\n",
    "Esta celda tiene como objetivo complementar el DataFrame depurado de PILA (`df_pila_i_sie`) con informaci√≥n de contacto proveniente de los datos internos de la EPS (`df_Datos_Complementarios`), para facilitar la posterior gesti√≥n de cobro, notificaci√≥n o seguimiento por parte del √°rea de Aseguramiento.\n",
    "\n",
    "**Pasos realizados:**\n",
    "1. Se extraen del DataFrame `df_Datos_Complementarios` las columnas:\n",
    "   - `Direcci√≥n de Correspondencia`\n",
    "   - `Tel√©fono`\n",
    "   - `Correo Electr√≥nico`\n",
    "2. Se realiza un cruce (`merge`) con `df_pila_i_sie`, utilizando como clave el `N¬∞ Identificaci√≥n Aportante`.\n",
    "\n",
    "**Resultado:**\n",
    "Cada registro de afiliado en PILA ahora incluye datos clave de contacto de la empresa aportante, permitiendo que los procesos de gesti√≥n de cartera puedan ejecutarse de forma m√°s eficiente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar solo las columnas necesarias de df_Datos_Complementarios\n",
    "df_Datos_Complementarios_subset = df_Datos_Complementarios[['N¬∞ Identificaci√≥n Aportante', 'Direcci√≥n de Correspondencia', 'Tel√©fono', 'Correo Electr√≥nico']]\n",
    "\n",
    "# Realizar el merge para traer las columnas a df_pila_i_sie\n",
    "df_pila_i_sie = df_pila_i_sie.merge(df_Datos_Complementarios_subset, on='N¬∞ Identificaci√≥n Aportante', how='left')\n",
    "\n",
    "print(df_pila_i_sie.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.12. üßæ Extracci√≥n de Afiliados √önicos para An√°lisis\n",
    "\n",
    "Esta celda extrae un subconjunto con los afiliados √∫nicos a partir del DataFrame `df_pila_i_sie`, utilizando las columnas de identificaci√≥n (`Tp_Do` y `No_Do`). Este paso permite construir una vista depurada para an√°lisis posteriores, sin duplicidad de registros por afiliado.\n",
    "\n",
    "**Pasos realizados:**\n",
    "1. Se seleccionan √∫nicamente las columnas `Tp_Do` y `No_Do` del DataFrame de PILA.\n",
    "2. Se eliminan duplicados para obtener una lista √∫nica de afiliados presentes en el consolidado.\n",
    "\n",
    "**Resultado:**\n",
    "Un DataFrame (`df_unique_aportantes`) con un registro por afiliado, que puede usarse como base para an√°lisis posteriores de mora, avisos o estado de pagos en ADRES y SIE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un nuevo dataframe con los valores √∫nicos de las columnas especificadas\n",
    "df_unique_aportantes = df_pila_i_sie[[\"Tp_Do\", \"No_Do\"]].drop_duplicates()\n",
    "\n",
    "# Mostrar las primeras filas del nuevo dataframe\n",
    "print(f\"Cantidad de registros √∫nicos: {len(df_unique_aportantes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.13. üßπ Depuraci√≥n de la Base de Relaciones Laborales del SIE\n",
    "\n",
    "Esta celda tiene como objetivo limpiar y consolidar la base de relaciones laborales internas (`df_Relaciones_Laborales_SIE`) para asegurar que cada afiliado quede representado con su v√≠nculo laboral m√°s reciente por empresa aportante.\n",
    "\n",
    "**Pasos realizados:**\n",
    "1. Se convierte la columna `fecha_ingreso` al tipo de dato `datetime`, con el formato est√°ndar `%Y-%m-%d`.\n",
    "2. Se agrupan los registros por documento del afiliado y del aportante (`tipo_documento`, `numero_identificacion`, etc.).\n",
    "3. Para cada grupo, se conserva √∫nicamente la fecha m√°xima de ingreso (`fecha_ingreso` m√°s reciente).\n",
    "4. Se eliminan los registros duplicados, conservando un √∫nico v√≠nculo laboral vigente por afiliado y aportante.\n",
    "\n",
    "**Resultado:**\n",
    "Una base de relaciones laborales limpia y lista para ser cruzada con la PILA, que garantiza integridad temporal y unicidad de los v√≠nculos activos para an√°lisis posteriores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Cantidad de registros realcionaes laborales #1: {len(df_Relaciones_Laborales_SIE)}\")\n",
    "# Convertir la columna 'fecha_ingreso' a tipo datetime\n",
    "df_Relaciones_Laborales_SIE['fecha_ingreso'] = pd.to_datetime(df_Relaciones_Laborales_SIE['fecha_ingreso'], format='%Y-%m-%d')\n",
    "\n",
    "# Asignar la fecha m√°xima de 'fecha_ingreso' a todo el grupo\n",
    "df_Relaciones_Laborales_SIE['fecha_ingreso'] = df_Relaciones_Laborales_SIE.groupby(\n",
    "    ['tipo_documento', 'numero_identificacion', 'tipo_documento_aportante', 'numero_identificacion_aportante']\n",
    ")['fecha_ingreso'].transform('max')\n",
    "\n",
    "# Eliminar duplicados manteniendo solo un registro por grupo\n",
    "df_Relaciones_Laborales_SIE = df_Relaciones_Laborales_SIE.drop_duplicates(\n",
    "    subset=['tipo_documento', 'numero_identificacion', 'tipo_documento_aportante', 'numero_identificacion_aportante']\n",
    ")\n",
    "\n",
    "# Mostrar las primeras filas del dataframe resultante\n",
    "print(f\"Cantidad de registros realcionaes laborales #2: {len(df_Relaciones_Laborales_SIE)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.14. üîß Estandarizaci√≥n Final y Enriquecimiento de la Base de Relaciones Laborales (SIE)\n",
    "\n",
    "En este paso se finaliza la preparaci√≥n de la base de relaciones laborales del sistema SIE (`df_Relaciones_Laborales_SIE`), alineando su estructura con el resto de fuentes y a√±adiendo informaci√≥n de contacto relevante.\n",
    "\n",
    "**Pasos realizados:**\n",
    "1. Se renombran columnas clave para homogeneizar la estructura con la base de PILA.\n",
    "2. Se convierten los identificadores del aportante (`N¬∞ Identificaci√≥n Aportante`) a tipo `str` para asegurar la correcta uni√≥n de DataFrames.\n",
    "3. Se realiza un cruce con la PILA (`df_pila_i_sie`) para a√±adir la columna `Correo Electr√≥nico` del aportante a cada relaci√≥n laboral.\n",
    "\n",
    "**Resultado:**\n",
    "Una base de relaciones laborales con estructura estandarizada, identificadores consistentes y campos de contacto listos para facilitar futuras notificaciones o validaciones de v√≠nculo laboral.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Relaciones_Laborales_SIE = df_Relaciones_Laborales_SIE.rename(columns={\n",
    "    'tipo_documento': 'Tp_Do',\n",
    "    'numero_identificacion': 'No_Do',\n",
    "    'tipo_documento_aportante': 'Tipo Documento Aportante',\n",
    "    'numero_identificacion_aportante': 'N¬∞ Identificaci√≥n Aportante',\n",
    "    'razon_social': 'Raz√≥n Social Aportante'\n",
    "})\n",
    "print(df_Relaciones_Laborales_SIE.columns)\n",
    "df_Relaciones_Laborales_SIE['N¬∞ Identificaci√≥n Aportante'] = df_Relaciones_Laborales_SIE['N¬∞ Identificaci√≥n Aportante'].astype(str)\n",
    "df_pila_i_sie['N¬∞ Identificaci√≥n Aportante'] = df_pila_i_sie['N¬∞ Identificaci√≥n Aportante'].astype(str)\n",
    "\n",
    "df_Relaciones_Laborales_SIE = df_Relaciones_Laborales_SIE.merge(df_pila_i_sie[['N¬∞ Identificaci√≥n Aportante', 'Correo Electr√≥nico']], on=['N¬∞ Identificaci√≥n Aportante'], how='left')\n",
    "print(df_Relaciones_Laborales_SIE.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Clasificaci√≥n de Afiliados: Mora, Aviso y Sin Pagos\n",
    "En esta secci√≥n se identifican y clasifican los afiliados que presentan riesgo de recaudo o interrupci√≥n de cotizaciones, seg√∫n los datos cruzados entre PILA, Maestro Contributivo ADRES y el sistema interno de la EPS. Esta clasificaci√≥n responde a los lineamientos del Decreto 780 de 2016 y busca facilitar la gesti√≥n oportuna de cobro por parte del √°rea de Aseguramiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. ‚ùå Identificaci√≥n de Afiliados Sin Pagos Reportados\n",
    "\n",
    "En este paso se identifican los afiliados activos en el Maestro Contributivo ADRES que no presentan ning√∫n registro de cotizaci√≥n en la base de PILA consolidada (`df_pila_i_sie`).\n",
    "\n",
    "**Criterios aplicados:**\n",
    "1. Se cruzan las c√©dulas (`Tp_Do`, `No_Do`) de `DF_MC_Adres` contra los afiliados presentes en PILA (`df_unique_aportantes`).\n",
    "2. Se seleccionan los registros que **no est√°n en PILA** (`_merge = \"left_only\"`).\n",
    "3. Se filtran solo los afiliados tipo `\"C\"` (Cotizante) y con estado `\"AC\"` (activo) en ADRES.\n",
    "\n",
    "**Resultado:**\n",
    "Una lista de afiliados activos y sin evidencia de pago, que puede ser usada para alertar, notificar o priorizar en la gesti√≥n de cartera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar los registros en DF_MC_Adres que no est√°n en df_unique_aportantes\n",
    "df_sin_pagos = DF_MC_Adres.merge(df_unique_aportantes, on=[\"Tp_Do\", \"No_Do\"], how=\"left\", indicator=True)\n",
    "df_sin_pagos = df_sin_pagos[df_sin_pagos[\"_merge\"] == \"left_only\"].drop(columns=[\"_merge\"])\n",
    "\n",
    "# Filtrar las columnas [Tp_Afiliado= 'C' y Estado_ADRES= 'AC']\n",
    "df_sin_pagos = df_sin_pagos[(df_sin_pagos['Tp_Afiliado'] == 'C') & (df_sin_pagos['Estado_ADRES'] == 'AC')]\n",
    "\n",
    "# Mostrar la cantidad de registros filtrados\n",
    "print(f\"Cantidad de registros sin pagos: {len(df_sin_pagos)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1. üîó Enriquecimiento de Afiliados Sin Pagos con Datos del SIE\n",
    "\n",
    "Este paso complementa la base de afiliados sin pagos (`df_sin_pagos`) con informaci√≥n adicional proveniente de las relaciones laborales internas (`df_Relaciones_Laborales_SIE`), con el fin de mejorar la trazabilidad del v√≠nculo laboral y la capacidad operativa de contacto para acciones de cobranza.\n",
    "\n",
    "**Pasos realizados:**\n",
    "1. Se asegura que los documentos (`No_Do`) est√©n en formato `str` en ambas fuentes para permitir una uni√≥n sin errores.\n",
    "2. Se cruzan los datos usando como claves `Tp_Do` y `No_Do`.\n",
    "3. Se a√±aden los siguientes campos:\n",
    "   - `Tipo Documento Aportante`\n",
    "   - `N¬∞ Identificaci√≥n Aportante`\n",
    "   - `Raz√≥n Social Aportante`\n",
    "   - `fecha_ingreso` del v√≠nculo laboral\n",
    "   - `Correo Electr√≥nico` del aportante\n",
    "\n",
    "**Resultado:**\n",
    "Una vista de afiliados sin pagos con contexto empresarial y laboral, √∫til para procesos de contacto, priorizaci√≥n y validaci√≥n de posibles omisiones de pago o mora en el sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir 'No_Do' en df_Relaciones_Laborales_SIE a str para que coincida con df_sin_pagos\n",
    "df_Relaciones_Laborales_SIE['No_Do'] = df_Relaciones_Laborales_SIE['No_Do'].astype(str)\n",
    "df_sin_pagos['No_Do'] = df_sin_pagos['No_Do'].astype(str)\n",
    "\n",
    "# Realizar el merge para traer la columna 'fecha_ingreso' a df_sin_pagos\n",
    "df_sin_pagos = df_sin_pagos.merge(df_Relaciones_Laborales_SIE[['Tp_Do', 'No_Do', 'Tipo Documento Aportante', 'N¬∞ Identificaci√≥n Aportante', 'Raz√≥n Social Aportante', 'fecha_ingreso', 'Correo Electr√≥nico']], on=['Tp_Do', 'No_Do'], how='left')\n",
    "print(df_sin_pagos.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2. üßÆ Consolidaci√≥n √önica de Afiliados Sin Pagos\n",
    "\n",
    "Una vez enriquecida la base `df_sin_pagos` con informaci√≥n laboral y de contacto, este paso tiene como objetivo asegurar que cada afiliado aparezca una sola vez en el listado, independientemente de cu√°ntas relaciones laborales tenga registradas.\n",
    "\n",
    "**Pasos realizados:**\n",
    "1. Se eliminan duplicados utilizando como clave de unicidad la combinaci√≥n `Tp_Do` + `No_Do` (tipo y n√∫mero de documento del afiliado).\n",
    "2. Se conserva √∫nicamente un registro por afiliado para evitar alertas o notificaciones duplicadas.\n",
    "\n",
    "**Resultado:**\n",
    "Una base de afiliados sin pagos depurada y consolidada, con un registro √∫nico por persona, lista para priorizaci√≥n operativa o generaci√≥n de reportes para el √°rea de Aseguramiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Cantidad de registros sin pagos: {len(df_sin_pagos)}\")\n",
    "# Dejar valores √∫nicos en df_sin_pagos seg√∫n las columnas ['Tp_Do', 'No_Do']\n",
    "df_sin_pagos = df_sin_pagos.drop_duplicates(subset=['Tp_Do', 'No_Do'])\n",
    "\n",
    "# Mostrar las primeras filas del dataframe resultante para verificar\n",
    "print(f\"Cantidad de registros √∫nicos en df_sin_pagos: {len(df_sin_pagos)}\")\n",
    "print(df_sin_pagos.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3. üîÅ Revalidaci√≥n Final de Afiliados Sin Pagos\n",
    "\n",
    "Luego del proceso de enriquecimiento y consolidaci√≥n de `df_sin_pagos`, se realiza una revalidaci√≥n cruzando nuevamente con `df_unique_aportantes` para asegurar que los afiliados seleccionados no hayan sido incorporados por error durante etapas intermedias del an√°lisis.\n",
    "\n",
    "**Pasos realizados:**\n",
    "1. Se aseguran los formatos de las columnas `No_Do` como `string` para evitar errores de uni√≥n.\n",
    "2. Se vuelve a cruzar la base de sin pagos con los afiliados presentes en PILA consolidada (`df_unique_aportantes`) para garantizar exclusividad.\n",
    "3. Se aplica nuevamente el filtro de afiliados tipo `\"C\"` y con estado `\"AC\"` en ADRES.\n",
    "\n",
    "**Resultado:**\n",
    "Una validaci√≥n final que garantiza que los afiliados listados en `df_sin_pagos` no tienen registros en PILA, est√°n activos ante ADRES, y pertenecen al r√©gimen contributivo, con un √∫nico registro por persona.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert No_Do to string type in both dataframes\n",
    "df_sin_pagos['No_Do'] = df_sin_pagos['No_Do'].astype(str)\n",
    "df_unique_aportantes['No_Do'] = df_unique_aportantes['No_Do'].astype(str)\n",
    "\n",
    "# Now perform the merge\n",
    "df_sin_pagos = df_sin_pagos.merge(df_unique_aportantes, on=[\"Tp_Do\", \"No_Do\"], how=\"left\", indicator=True)\n",
    "df_sin_pagos = df_sin_pagos[df_sin_pagos[\"_merge\"] == \"left_only\"].drop(columns=[\"_merge\"])\n",
    "\n",
    "# Filter records with required conditions\n",
    "df_sin_pagos = df_sin_pagos[(df_sin_pagos['Tp_Afiliado'] == 'C') & (df_sin_pagos['Estado_ADRES'] == 'AC')]\n",
    "\n",
    "# Show results\n",
    "print(f\"Cantidad de registros sin pagos: {len(df_sin_pagos)}\")\n",
    "print(df_sin_pagos.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.4. üß± Estandarizaci√≥n Estructural y Reorganizaci√≥n de Afiliados Sin Pagos\n",
    "\n",
    "Con el fin de permitir una futura concatenaci√≥n o an√°lisis conjunto entre `df_sin_pagos` y `df_pila_i_sie`, este paso ajusta la estructura del DataFrame `df_sin_pagos` para que coincida exactamente con el esquema de columnas, tipos y orden de la base consolidada de PILA.\n",
    "\n",
    "**Pasos realizados:**\n",
    "\n",
    "1. **Creaci√≥n de columnas faltantes**: Se agregan campos que no existen en `df_sin_pagos`, asignando valores por defecto:\n",
    "   - Num√©ricos: `Tipo Cotizante`, `D√≠as Cotizados`, `Ingreso Base Cotizaci√≥n`, `N√∫mero Planilla`, etc.\n",
    "   - Categ√≥ricos: `Direcci√≥n de Correspondencia`, `Correcciones`, `origen` (establecido como `\"MC_ADRES\"`).\n",
    "   - Fechas: `Perido Pago` y `fecha_ingreso` se inicializan como vac√≠as (`datetime`).\n",
    "\n",
    "2. **Conversi√≥n de tipos de datos**: Se aseguran tipos consistentes con `df_pila_i_sie`:\n",
    "   - `int64` para campos num√©ricos.\n",
    "   - `float64` para ingresos base.\n",
    "   - `str` con relleno (`zfill`) para c√≥digos de `Departamento` (2 d√≠gitos) y `Municipio` (3 d√≠gitos).\n",
    "\n",
    "3. **Reorganizaci√≥n de columnas**: Se reordena el DataFrame `df_sin_pagos` para que el orden de las columnas sea id√©ntico al de `df_pila_i_sie`, facilitando la uni√≥n vertical (`concat`) o an√°lisis conjunto.\n",
    "\n",
    "**Resultado:**\n",
    "Una versi√≥n totalmente estructurada de los afiliados sin pagos, con la misma forma, tipos y orden que la base de PILA consolidada, lista para integraci√≥n, visualizaci√≥n o exportaci√≥n operativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new columns to df_sin_pagos\n",
    "df_sin_pagos['No_Do'] = df_sin_pagos['No_Do'].astype('int64')\n",
    "df_sin_pagos['N¬∞ Identificaci√≥n Aportante'] = df_sin_pagos['N¬∞ Identificaci√≥n Aportante'].fillna(0).astype('int64')\n",
    "df_sin_pagos['Tipo Cotizante'] = 0\n",
    "df_sin_pagos['Tipo Cotizante'] = df_sin_pagos['Tipo Cotizante'].astype('int64')\n",
    "df_sin_pagos['Direcci√≥n de Correspondencia'] = \"\"\n",
    "df_sin_pagos['Perido Pago'] = pd.to_datetime(\"\")\n",
    "df_sin_pagos['Fecha Pago'] = \"\"\n",
    "\n",
    "df_sin_pagos['ING'] = 0\n",
    "df_sin_pagos['ING'] = df_sin_pagos['ING'].astype('int64')\n",
    "df_sin_pagos['RET'] = 0\n",
    "df_sin_pagos['RET'] = df_sin_pagos['RET'].astype('int64')\n",
    "df_sin_pagos['D√≠as Cotizados'] = 0\n",
    "df_sin_pagos['D√≠as Cotizados'] = df_sin_pagos['D√≠as Cotizados'].astype('int64')\n",
    "df_sin_pagos['Ingreso Base Cotizaci√≥n'] = 0\n",
    "df_sin_pagos['Ingreso Base Cotizaci√≥n'] = df_sin_pagos['Ingreso Base Cotizaci√≥n'].astype('float64')\n",
    "df_sin_pagos['Correcciones'] = \"\"\n",
    "df_sin_pagos['N√∫mero Planilla'] = 0\n",
    "df_sin_pagos['N√∫mero Planilla'] = df_sin_pagos['N√∫mero Planilla'].astype('int64')\n",
    "df_sin_pagos['Departamento'] = df_sin_pagos['Departamento'].astype('int64')\n",
    "df_sin_pagos['Departamento'] = df_sin_pagos['Departamento'].astype(str).str.zfill(2)\n",
    "df_sin_pagos['Municipio'] = df_sin_pagos['Municipio'].astype('int64')\n",
    "df_sin_pagos['Municipio'] = df_sin_pagos['Municipio'].astype(str).str.zfill(3)\n",
    "df_sin_pagos['origen'] = \"MC_ADRES\"\n",
    "\n",
    "df_pila_i_sie['Tipo Cotizante'] = df_pila_i_sie['Tipo Cotizante'].fillna(0).astype('int64')\n",
    "df_pila_i_sie['ING'] = df_pila_i_sie['ING'].fillna(0).astype('int64')\n",
    "df_pila_i_sie['RET'] = df_pila_i_sie['RET'].fillna(0).astype('int64')\n",
    "df_pila_i_sie['Departamento'] = df_pila_i_sie['Departamento'].astype('int64')\n",
    "df_pila_i_sie['Departamento'] = df_pila_i_sie['Departamento'].astype(str).str.zfill(2)\n",
    "df_pila_i_sie['Municipio'] = df_pila_i_sie['Municipio'].astype('int64')\n",
    "df_pila_i_sie['Municipio'] = df_pila_i_sie['Municipio'].astype(str).str.zfill(3)\n",
    "df_pila_i_sie['fecha_ingreso'] = pd.to_datetime(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganizar las columnas de df_sin_pagos en el orden especificado\n",
    "column_order = ['Raz√≥n Social Aportante', 'Tipo Documento Aportante', 'N¬∞ Identificaci√≥n Aportante', 'Direcci√≥n de Correspondencia', 'Correo Electr√≥nico', 'Perido Pago', 'Fecha Pago', 'Tp_Do', 'No_Do', 'Tipo Cotizante', 'ING', 'RET', 'D√≠as Cotizados', 'Ingreso Base Cotizaci√≥n', 'Correcciones', 'N√∫mero Planilla', 'origen', '1A', '2A', '1N', '2N', 'Tp_Afiliado', 'Departamento', 'Municipio', 'Estado_ADRES', 'Sisben', 'fecha_ingreso']\n",
    "df_sin_pagos = df_sin_pagos[column_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.5. üß© Integraci√≥n Final: Uni√≥n de Afiliados con Pagos y Sin Pagos\n",
    "\n",
    "Una vez estructuradas ambas fuentes (`df_pila_i_sie` y `df_sin_pagos`) con el mismo esquema de columnas, se realiza la concatenaci√≥n vertical de los registros, unificando en un √∫nico DataFrame todos los afiliados del r√©gimen contributivo que se encuentran en estado activo seg√∫n ADRES.\n",
    "\n",
    "**Pasos realizados:**\n",
    "\n",
    "1. Se imprime la cantidad de registros en cada base antes de la uni√≥n:\n",
    "   - `df_pila_i_sie`: Afiliados con pagos registrados en PILA (operador o ADRES).\n",
    "   - `df_sin_pagos`: Afiliados activos en ADRES sin evidencia de pagos.\n",
    "\n",
    "2. Se concatenan ambos DataFrames utilizando `pd.concat([...], ignore_index=True)` para generar un √≠ndice limpio.\n",
    "\n",
    "3. Se imprime la cantidad total de registros resultantes tras la integraci√≥n.\n",
    "\n",
    "**Resultado:**\n",
    "Una √∫nica base maestra (`df_pila_i_sie`) que contiene:\n",
    "- Afiliados con v√≠nculo laboral y pagos identificables.\n",
    "- Afiliados sin pagos, pero con v√≠nculo y estado activo en ADRES.\n",
    "\n",
    "Esta integraci√≥n servir√° de insumo para reportes finales y estrategias de intervenci√≥n por parte del √°rea de Aseguramiento de Capresoca EPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Cantidad de registros sin pagos: {len(df_sin_pagos)}\")\n",
    "print(f\"Cantidad de registros PAgos SIE pagos: {len(df_pila_i_sie)}\")\n",
    "df_pila_i_sie = pd.concat([df_pila_i_sie, df_sin_pagos], ignore_index=True)\n",
    "print(f\"Cantidad de registros Total: {len(df_pila_i_sie)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. üßØ Depuraci√≥n Final: Exclusi√≥n de Registros Retirados y Fuera de Periodo\n",
    "\n",
    "Despu√©s de unificar la base de afiliados con y sin pagos, se realiza un nuevo filtrado para excluir los registros que corresponden a afiliados retirados o cuya cotizaci√≥n pertenece al per√≠odo actual (en curso), ya que estos no requieren intervenci√≥n inmediata.\n",
    "\n",
    "**Pasos realizados:**\n",
    "\n",
    "1. Se asegura que la columna `Perido Pago` est√© en formato `datetime`.\n",
    "2. Se eliminan los registros con novedad de retiro (`RET = 1`), ya que estos afiliados ya no hacen parte activa del sistema.\n",
    "3. Se restringe el an√°lisis a registros con `Perido Pago` **anterior al mes actual**, o sin informaci√≥n en esa columna (`NaT`), asumiendo que estas omisiones tambi√©n podr√≠an representar casos sin cotizaci√≥n reciente.\n",
    "\n",
    "**Variable utilizada:**\n",
    "- `V_Periodo_Actual`: variable definida previamente que representa el primer d√≠a del mes actual.\n",
    "\n",
    "**Resultado:**\n",
    "Una base m√°s precisa para an√°lisis operativo, centrada en afiliados activos sin retiro reciente y con cotizaciones omitidas o desactualizadas, lista para priorizaci√≥n o intervenci√≥n por parte del √°rea de Aseguramiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'Perido Pago' is datetime\n",
    "print(f\"Cantidad de registros df_pila_i_sie: {len(df_pila_i_sie)}\")\n",
    "\n",
    "df_pila_i_sie['Perido Pago'] = pd.to_datetime(df_pila_i_sie['Perido Pago'], errors='coerce')\n",
    "\n",
    "# Filter out records where RET = 1\n",
    "df_pila_i_sie = df_pila_i_sie[\n",
    "    (df_pila_i_sie['RET'] != 1) &\n",
    "    ((df_pila_i_sie['Perido Pago'] < pd.to_datetime(V_Periodo_Actual)) | (df_pila_i_sie['Perido Pago'].isna()))\n",
    "]\n",
    "print(f\"Cantidad de registros despu√©s de filtrar RET != 1: {len(df_pila_i_sie)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. üìä Clasificaci√≥n de Afiliados seg√∫n Estado de Cartera\n",
    "\n",
    "En este paso se asigna a cada afiliado un estado de cartera (`Sin Pagos`, `Mora`, `Aviso`, `Al D√≠a`) en funci√≥n de la fecha de su √∫ltimo per√≠odo cotizado (`Perido Pago`), comparada con los umbrales definidos por la EPS.\n",
    "\n",
    "**Variables utilizadas:**\n",
    "- `Mora`: fecha l√≠mite para considerar que un afiliado ha ca√≠do en mora.\n",
    "- `Dia`: fecha a partir de la cual un afiliado puede considerarse al d√≠a.\n",
    "\n",
    "**Clasificaci√≥n aplicada:**\n",
    "1. Se crea la columna `Cartera` con valor por defecto `\"Sin Pagos\"`, para casos sin `Perido Pago`.\n",
    "2. Para afiliados con fecha v√°lida:\n",
    "   - Si `Perido Pago` < `Mora`: se clasifica como `\"mora\"`.\n",
    "   - Si `Mora` ‚â§ `Perido Pago` < `Dia`: se clasifica como `\"Aviso\"`.\n",
    "   - Si `Perido Pago` ‚â• `Dia`: se clasifica como `\"Al D√≠a\"`.\n",
    "\n",
    "**Resultado:**\n",
    "Cada afiliado queda clasificado seg√∫n su nivel de riesgo de cartera, permitiendo priorizar acciones correctivas, preventivas o informativas desde el √°rea de Aseguramiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column 'Cartera' based on conditions\n",
    "df_pila_i_sie['Cartera'] = 'Sin Pagos'  # Default value\n",
    "\n",
    "# Convert Mora to datetime\n",
    "mora_date = pd.to_datetime(Mora)\n",
    "Dia_date = pd.to_datetime(Dia)\n",
    "\n",
    "# Update values based on conditions for non-null Perido Pago\n",
    "mask = df_pila_i_sie['Perido Pago'].notna()\n",
    "df_pila_i_sie.loc[mask & (df_pila_i_sie['Perido Pago'] < mora_date), 'Cartera'] = 'mora'\n",
    "df_pila_i_sie.loc[mask & (df_pila_i_sie['Perido Pago'] >= mora_date), 'Cartera'] = 'Aviso'\n",
    "df_pila_i_sie.loc[mask & (df_pila_i_sie['Perido Pago'] >= Dia_date), 'Cartera'] = 'Al Dia'\n",
    "print(f\"Cantidad de registros df_pila_i_sie: {len(df_pila_i_sie)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. üß∑ Consolidaci√≥n del V√≠nculo Laboral Vigente por Afiliado\n",
    "\n",
    "Como preparaci√≥n para reportes o an√°lisis posteriores, se depura la base de relaciones laborales internas (`df_Relaciones_Laborales_SIE`) para conservar √∫nicamente un registro por afiliado, correspondiente a su v√≠nculo laboral m√°s reciente.\n",
    "\n",
    "**Pasos realizados:**\n",
    "\n",
    "1. Se ordena la base por:\n",
    "   - Tipo y n√∫mero de documento (`Tp_Do`, `No_Do`).\n",
    "   - Fecha de ingreso (`fecha_ingreso`), en orden descendente (del m√°s reciente al m√°s antiguo).\n",
    "2. Se eliminan duplicados, conservando solo el primer registro de cada afiliado (que ser√° el m√°s reciente por el orden aplicado).\n",
    "3. Se reinicia el √≠ndice del DataFrame resultante.\n",
    "\n",
    "**Resultado:**\n",
    "Una base consolidada con un √∫nico v√≠nculo laboral vigente por afiliado, √∫til para reportes operativos, validaci√≥n de empresas activas, o an√°lisis de posibles evasores reincidentes por empresa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by date in descending order and keep first record for each ID\n",
    "df_Relaciones_Laborales_SIE = df_Relaciones_Laborales_SIE.sort_values(\n",
    "    by=['Tp_Do', 'No_Do', 'fecha_ingreso'], \n",
    "    ascending=[True, True, False]\n",
    ")\n",
    "\n",
    "# Drop duplicates keeping first record (which will be the one with max date due to sort)\n",
    "df_Relaciones_Laborales_SIE = df_Relaciones_Laborales_SIE.drop_duplicates(\n",
    "    subset=['Tp_Do', 'No_Do'], \n",
    "    keep='first'\n",
    ")\n",
    "\n",
    "# Reset the index if needed\n",
    "df_Relaciones_Laborales_SIE = df_Relaciones_Laborales_SIE.reset_index(drop=True)\n",
    "\n",
    "print(f\"Cantidad de registros despu√©s de eliminar duplicados: {len(df_Relaciones_Laborales_SIE)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5. üìÖ Validaci√≥n del Rango Temporal del Per√≠odo de Pago\n",
    "\n",
    "Para asegurar que el an√°lisis de cartera y los reportes se concentren en datos v√°lidos y coherentes, se realiza un filtrado final sobre la columna `Perido Pago` para excluir fechas fuera de rango o err√≥neas.\n",
    "\n",
    "**Pasos realizados:**\n",
    "\n",
    "1. Se convierte la columna `Perido Pago` al formato `datetime` con estructura `dd/mm/yyyy`.\n",
    "2. Se define un rango v√°lido entre:\n",
    "   - `2024-01-01` (inicio del an√°lisis operativo).\n",
    "   - `2050-12-31` (l√≠mite preventivo ante errores de digitaci√≥n).\n",
    "3. Se conserva:\n",
    "   - Registros cuyo `Perido Pago` est√© dentro del rango definido.\n",
    "   - Registros con `Perido Pago` vac√≠o (`NaT`), v√°lidos para clasificaciones como \"Sin Pagos\".\n",
    "\n",
    "**Resultado:**\n",
    "Una base libre de errores por fechas an√≥malas, con periodos de pago consistentes y apta para reportes operativos, priorizaci√≥n o generaci√≥n de alertas autom√°ticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna 'Perido Pago' al formato datetime con el formato dd/mm/yyyy\n",
    "df_pila_i_sie['Perido Pago'] = pd.to_datetime(df_pila_i_sie['Perido Pago'], format='%d/%m/%Y', errors='coerce')\n",
    "\n",
    "# Definir el rango de fechas deseado\n",
    "start_date = pd.to_datetime('2024-01-01')\n",
    "end_date   = pd.to_datetime('2050-12-31')\n",
    "\n",
    "# Filtrar: conservar los registros cuyo 'Perido Pago' est√© vac√≠o o est√© entre las fechas definidas\n",
    "mask = df_pila_i_sie['Perido Pago'].isna() | ((df_pila_i_sie['Perido Pago'] >= start_date) & (df_pila_i_sie['Perido Pago'] <= end_date))\n",
    "df_pila_i_sie = df_pila_i_sie[mask]\n",
    "\n",
    "print(f\"Cantidad de registros despu√©s del filtrado: {len(df_pila_i_sie)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6. üóìÔ∏è Formateo Final de Fechas para Reportes y Exportaci√≥n\n",
    "\n",
    "Para facilitar la interpretaci√≥n de los datos y cumplir con los est√°ndares visuales de presentaci√≥n de reportes, se convierten las columnas de tipo fecha al formato `DD/MM/YYYY`, tradicionalmente utilizado en documentos administrativos en Colombia.\n",
    "\n",
    "**Pasos realizados:**\n",
    "1. Se define la lista `columnas_fecha` con las columnas que contienen fechas relevantes:\n",
    "   - `Perido Pago`\n",
    "   - `fecha_ingreso`\n",
    "2. Para cada columna en esa lista:\n",
    "   - Se convierte su contenido al tipo `datetime` (con manejo de errores).\n",
    "   - Se transforma al formato `d√≠a/mes/a√±o` usando `.dt.strftime('%d/%m/%Y')`.\n",
    "\n",
    "**Resultado:**\n",
    "Un DataFrame `df_pila_i_sie` con todas las fechas visibles en formato amigable para lectura humana, listo para ser exportado a Excel o utilizado en informes del √°rea de Aseguramiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de columnas que contienen fechas (ajusta seg√∫n tu DataFrame)\n",
    "columnas_fecha = ['Perido Pago', 'fecha_ingreso']  # Reempl√°zalas con los nombres reales\n",
    "\n",
    "# Convertir las columnas de fecha al formato DD/MM/YYYY\n",
    "for col in columnas_fecha:\n",
    "    df_pila_i_sie[col] = pd.to_datetime(df_pila_i_sie[col], errors='coerce').dt.strftime('%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7. üß¨ Normalizaci√≥n del NIT del Aportante para Consolidaci√≥n Empresarial\n",
    "\n",
    "En este paso se corrigen variaciones del n√∫mero de identificaci√≥n del aportante (`N¬∞ Identificaci√≥n Aportante`) que podr√≠an representar a una misma empresa, pero con extensiones, errores o sufijos que afectan el an√°lisis agrupado.\n",
    "\n",
    "**Objetivo:**  \n",
    "Consolidar planillas o relaciones laborales bajo un √∫nico identificador base por empresa, especialmente cuando existen NITs como `800123456`, `800123456-1`, `800123456001`, etc.\n",
    "\n",
    "**Pasos realizados:**\n",
    "\n",
    "1. Se convierten todos los NITs a tipo `str` para manipulaci√≥n segura.\n",
    "2. Se ordena la lista √∫nica de identificaciones por longitud creciente, asumiendo que el ID base es el m√°s corto.\n",
    "3. Se crea un diccionario `id_map` que relaciona cada ID extendido con su versi√≥n base, si comparte el prefijo.\n",
    "4. Se genera una nueva columna auxiliar `Id_Normalizado` aplicando ese mapeo.\n",
    "5. Se eliminan duplicados por aportante y afiliado (`Id_Normalizado`, `Tp_Do`, `No_Do`), conservando el primer registro.\n",
    "6. Finalmente, se elimina la columna auxiliar para dejar limpia la estructura.\n",
    "\n",
    "**Resultado:**\n",
    "Una base consolidada por empresa aportante, libre de fragmentaciones causadas por NITs con sufijos o inconsistencias, lista para an√°lisis agregados, generaci√≥n de reportes o agrupamientos confiables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Convertir todos los ID a string para evitar errores\n",
    "df_pila_i_sie[\"N¬∞ Identificaci√≥n Aportante\"] = df_pila_i_sie[\"N¬∞ Identificaci√≥n Aportante\"].astype(str)\n",
    "\n",
    "# Paso 2: Obtener lista √∫nica de identificaciones ordenadas por longitud ascendente\n",
    "ids_unicos = sorted(df_pila_i_sie[\"N¬∞ Identificaci√≥n Aportante\"].unique(), key=len)\n",
    "\n",
    "# Paso 3: Crear un diccionario para mapear los IDs con sus equivalentes base (m√°s cortos)\n",
    "id_map = {}\n",
    "\n",
    "for i, base_id in enumerate(ids_unicos):\n",
    "    for other_id in ids_unicos[i+1:]:\n",
    "        if other_id.startswith(base_id):\n",
    "            id_map[other_id] = base_id\n",
    "\n",
    "# Paso 4: Aplicar el mapeo al DataFrame\n",
    "def mapear_id(ident):\n",
    "    return id_map.get(ident, ident)\n",
    "\n",
    "df_pila_i_sie[\"Id_Normalizado\"] = df_pila_i_sie[\"N¬∞ Identificaci√≥n Aportante\"].apply(mapear_id)\n",
    "\n",
    "# Paso 5: Eliminar duplicados\n",
    "df_pila_i_sie = df_pila_i_sie.drop_duplicates(subset=[\"Id_Normalizado\", \"Tp_Do\", \"No_Do\"], keep='first')\n",
    "\n",
    "# (Opcional) Eliminar la columna auxiliar\n",
    "df_pila_i_sie = df_pila_i_sie.drop(columns=[\"Id_Normalizado\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.8. üß© Enriquecimiento de Contacto desde el Maestro SIE\n",
    "\n",
    "Despu√©s de consolidar y normalizar los registros, se identificaron afiliados cuyos campos de contacto (`Direcci√≥n de Correspondencia`, `Tel√©fono`, `Correo Electr√≥nico`) estaban vac√≠os. Para complementar esta informaci√≥n, se utiliz√≥ el maestro de datos del sistema interno SIE (`Df_SIE`), cruzado por tipo y n√∫mero de documento.\n",
    "\n",
    "**Pasos realizados:**\n",
    "\n",
    "1. Se seleccionaron los campos relevantes del archivo maestro: `tipo_documento`, `numero_identificacion`, `direccion`, `celular`, `correo_electronico`.\n",
    "2. Se renombraron para facilitar la uni√≥n con `df_pila_i_sie`.\n",
    "3. Se aplic√≥ un `merge` por `Tp_Do` y `No_Do`.\n",
    "4. Se actualizaron los campos vac√≠os del DataFrame principal √∫nicamente cuando los valores originales estaban en blanco (`\"\"` o `NaN`).\n",
    "\n",
    "**Resultado:**\n",
    "Una base enriquecida con mayor cobertura de informaci√≥n de contacto para los afiliados, lo cual facilita la **notificaci√≥n oportuna** y la **gesti√≥n proactiva de cartera** por parte del √°rea de Aseguramiento de Capresoca EPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Paso 1: Asegurar que los IDs est√©n en el mismo formato ---\n",
    "df_pila_i_sie[\"Tp_Do\"] = df_pila_i_sie[\"Tp_Do\"].astype(str)\n",
    "df_pila_i_sie[\"No_Do\"] = df_pila_i_sie[\"No_Do\"].astype(str)\n",
    "Df_SIE[\"tipo_documento\"] = Df_SIE[\"tipo_documento\"].astype(str)\n",
    "Df_SIE[\"numero_identificacion\"] = Df_SIE[\"numero_identificacion\"].astype(str)\n",
    "\n",
    "# --- Paso 2: Seleccionar columnas relevantes del maestro del SIE ---\n",
    "Df_SIE_contacto = Df_SIE[[\"tipo_documento\", \"numero_identificacion\", \"direccion\", \"celular\", \"correo_electronico\"]].copy()\n",
    "\n",
    "# --- Paso 3: Renombrar columnas para facilitar el merge ---\n",
    "Df_SIE_contacto = Df_SIE_contacto.rename(columns={\n",
    "    \"tipo_documento\": \"Tp_Do\",\n",
    "    \"numero_identificacion\": \"No_Do\",\n",
    "    \"direccion\": \"Direcci√≥n de Correspondencia\",\n",
    "    \"celular\": \"Tel√©fono\",\n",
    "    \"correo_electronico\": \"Correo Electr√≥nico\"\n",
    "})\n",
    "\n",
    "# --- Paso 4: Realizar el merge solo si las columnas est√°n vac√≠as ---\n",
    "campos_contacto = [\"Direcci√≥n de Correspondencia\", \"Tel√©fono\", \"Correo Electr√≥nico\"]\n",
    "\n",
    "for campo in campos_contacto:\n",
    "    df_pila_i_sie[campo] = df_pila_i_sie[campo].fillna(\"\")\n",
    "\n",
    "df_pila_i_sie = df_pila_i_sie.merge(\n",
    "    Df_SIE_contacto,\n",
    "    on=[\"Tp_Do\", \"No_Do\"],\n",
    "    how=\"left\",\n",
    "    suffixes=('', '_SIE')\n",
    ")\n",
    "\n",
    "# --- Paso 5: Completar campos faltantes con valores del SIE ---\n",
    "for campo in campos_contacto:\n",
    "    df_pila_i_sie[campo] = df_pila_i_sie[campo].mask(df_pila_i_sie[campo] == \"\", df_pila_i_sie[f\"{campo}_SIE\"])\n",
    "    df_pila_i_sie = df_pila_i_sie.drop(columns=[f\"{campo}_SIE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.9. ‚úâÔ∏è Validaci√≥n de Correos Electr√≥nicos\n",
    "\n",
    "Con el fin de garantizar que las estrategias de notificaci√≥n y comunicaci√≥n con los afiliados sean efectivas, se implementa una funci√≥n de validaci√≥n que detecta correos electr√≥nicos **inv√°lidos operativamente**, aunque sean t√©cnicamente v√°lidos en cuanto a su formato.\n",
    "\n",
    "**Motivaci√≥n:**\n",
    "Muchos registros contienen correos gen√©ricos, falsos o placeholders, como:\n",
    "- `actualizar@actualizar.com`\n",
    "- `notiene@gmail.com`\n",
    "- `a@a.com`\n",
    "- `correo@correo.com`\n",
    "- Correos de prueba (`ejemplo@...`, `test@...`, etc.)\n",
    "\n",
    "Este tipo de valores impide contactar al afiliado y generan falsos positivos en indicadores de cobertura de contacto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Lista exacta de correos inv√°lidos comunes\n",
    "CORREOS_INVALIDOS_EXACTOS = {\n",
    "    \"a@a.com\", \"email@email.com\", \"correo@correo.com\", \"correo@noexiste.com\", \"notiene@gmail.com\"\n",
    "}\n",
    "\n",
    "# Palabras clave que invalidan si aparecen solas o son parte de un patr√≥n corto\n",
    "CORREOS_PALABRAS_INVALIDAS = [\n",
    "    \"sincorreo\", \"sin_correo\", \"NOTINE\", \"no_tiene\", \"notiene\", \"actualizar\", \"ejemplo\", \"test\", \"prueba\", \"aaa\", \"xxxx\", \" \"\n",
    "]\n",
    "\n",
    "# Expresi√≥n regular para validar la estructura del correo\n",
    "regex_valido = re.compile(r\"^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$\")\n",
    "\n",
    "def validar_correo_operativo(correo):\n",
    "    if pd.isna(correo):\n",
    "        return False\n",
    "\n",
    "    correo = str(correo).strip().lower()\n",
    "\n",
    "    # Validaci√≥n 1: estructura b√°sica v√°lida\n",
    "    if not regex_valido.match(correo):\n",
    "        return False\n",
    "\n",
    "    # Validaci√≥n 2: coincidencia exacta con correos inv√°lidos\n",
    "    if correo in CORREOS_INVALIDOS_EXACTOS:\n",
    "        return False\n",
    "\n",
    "    # Validaci√≥n 3: patrones sospechosos en la parte local del correo\n",
    "    local_part = correo.split('@')[0]\n",
    "    for palabra in CORREOS_PALABRAS_INVALIDAS:\n",
    "        if palabra in local_part:\n",
    "            return False\n",
    "\n",
    "    # Validaci√≥n 4: longitud m√≠nima total\n",
    "    if len(correo) < 10:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "# Aplicar validaci√≥n al dataframe\n",
    "df_pila_i_sie[\"Correo_V√°lido\"] = df_pila_i_sie[\"Correo Electr√≥nico\"].apply(validar_correo_operativo)\n",
    "\n",
    "# (Opcional) Crear subconjunto con solo los v√°lidos\n",
    "df_correos_validos = df_pila_i_sie[df_pila_i_sie[\"Correo_V√°lido\"] == True]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.10. üì± Validaci√≥n y Normalizaci√≥n de N√∫meros Telef√≥nicos seg√∫n Normativa Colombiana\n",
    "\n",
    "Con el objetivo de asegurar la calidad y operatividad de los n√∫meros telef√≥nicos registrados en la base `df_pila_i_sie`, se implementa una funci√≥n que **limpia, valida y clasifica** los datos de contacto con base en la normativa actual de marcaci√≥n telef√≥nica en Colombia.\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Motivaci√≥n\n",
    "\n",
    "Durante el proceso de an√°lisis se identificaron m√∫ltiples problemas como:\n",
    "\n",
    "- Formatos inconsistentes: `310-2267612` ‚Üí `3102267612`\n",
    "- Entradas gen√©ricas o inv√°lidas: `\"actualizar\"`, `\"ninguno\"`, `\"no tiene\"`, `\"0000000000\"`, `\"99999999\"`\n",
    "- N√∫meros con longitud incorrecta (menos de 10 d√≠gitos o no normativos)\n",
    "\n",
    "Estos errores dificultan las estrategias de **contacto, cobranza y seguimiento de cartera**.\n",
    "\n",
    "---\n",
    "\n",
    "### üõ†Ô∏è Reglas de Validaci√≥n Aplicadas\n",
    "\n",
    "| Tipo de L√≠nea              | Longitud esperada | Prefijo requerido          | Ejemplo v√°lido       |\n",
    "|---------------------------|-------------------|-----------------------------|-----------------------|\n",
    "| **Tel√©fono m√≥vil**        | 10 d√≠gitos        | Inicia con `3`              | `3102267612`         |\n",
    "| **L√≠nea fija nacional**   | 10 d√≠gitos        | Inicia con `60` + indicativo (`1`, `2`, `4`, `5`, `6`, `7`, `8`) | `6012345678` |\n",
    "| **L√≠nea gratuita (toll-free)** | 11 d√≠gitos    | Inicia con `01800`          | `018005556789`        |\n",
    "| ‚ùå **L√≠neas de emergencia** | 3 d√≠gitos         | `123`, `112`, etc. ‚Üí **no v√°lidas** | ‚Äî                   |\n",
    "\n",
    "---\n",
    "\n",
    "### üßπ Proceso de Limpieza y Validaci√≥n\n",
    "\n",
    "1. Se eliminan todos los caracteres no num√©ricos (como `-`, espacios, par√©ntesis).\n",
    "2. Se descartan entradas con palabras clave como `\"sin\"`, `\"no tiene\"`, `\"actualizar\"`, etc.\n",
    "3. Se eval√∫a si el n√∫mero cumple con las reglas de longitud y prefijo seg√∫n la tabla anterior.\n",
    "4. Se generan dos nuevas columnas:\n",
    "   - `Tel√©fono_Normalizado`: n√∫mero limpio, solo con d√≠gitos.\n",
    "   - `Tel√©fono_V√°lido`: indicador booleano (`True`/`False`) seg√∫n las reglas anteriores.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Resultado\n",
    "\n",
    "Este control de calidad permite **focalizar las estrategias de contacto** en n√∫meros verificados, operativos y √∫tiles para procesos de notificaci√≥n, cobranza o contacto institucional, mejorando la eficiencia y reduciendo reprocesos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TELEFONOS_INVALIDOS = [\n",
    "    \"actualizar\", \"sin\", \"ninguno\", \"no tiene\", \"desconocido\", \"no registra\", \"prueba\"\n",
    "]\n",
    "\n",
    "EMERGENCY_NUMBERS = {'123', '112', '119', '132', '144', '155'}\n",
    "\n",
    "def validar_telefono_co(tel):\n",
    "    if pd.isna(tel):\n",
    "        return \"\", False\n",
    "\n",
    "    tel_raw = str(tel).strip().lower()\n",
    "    for palabra in TELEFONOS_INVALIDOS:\n",
    "        if palabra in tel_raw:\n",
    "            return \"\", False\n",
    "\n",
    "    tel_num = re.sub(r'\\D', '', tel_raw)\n",
    "\n",
    "    if len(tel_num) == 3 and tel_num in EMERGENCY_NUMBERS:\n",
    "        return tel_num, False\n",
    "\n",
    "    if len(tel_num) == 11 and tel_num.startswith('01800'):\n",
    "        return tel_num, True\n",
    "\n",
    "    if len(tel_num) == 10:\n",
    "        if tel_num.startswith('3'):\n",
    "            return tel_num, True\n",
    "        if tel_num.startswith('60') and tel_num[2] in {'1','2','4','5','6','7','8'}:\n",
    "            return tel_num, True\n",
    "        return tel_num, False\n",
    "\n",
    "    return tel_num, False\n",
    "\n",
    "df_pila_i_sie[['Tel_Normalizado', 'Tel√©fono_V√°lido']] = df_pila_i_sie['Tel√©fono'].apply(\n",
    "    lambda x: pd.Series(validar_telefono_co(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. üìä Indicadores Clave de Desempe√±o (KPIs) del Proceso de Cartera\n",
    "\n",
    "Con el objetivo de medir la efectividad y cobertura del proceso de generaci√≥n de cartera, se calculan KPIs estrat√©gicos por cada ejecuci√≥n del modelo.\n",
    "\n",
    "Estos indicadores permiten realizar seguimiento a la evoluci√≥n del comportamiento de pagos, la calidad de los datos de contacto y la cobertura institucional del sistema de aseguramiento.\n",
    "\n",
    "**M√©tricas calculadas:**\n",
    "\n",
    "- `Fecha Generaci√≥n`: Fecha en que se ejecut√≥ el proceso.\n",
    "- `Total Registros`: Total de registros analizados.\n",
    "- `Sin Pagos`: Afiliados sin ning√∫n registro de pago.\n",
    "- `En Mora`: Afiliados con √∫ltimo pago anterior a la fecha de corte.\n",
    "- `En Aviso`: Afiliados que requieren seguimiento (pero no est√°n en mora).\n",
    "- `Empresas Aportantes`: N√∫mero de empleadores distintos en la base.\n",
    "- `Afiliados √önicos`: N√∫mero de afiliados identificados por documento.\n",
    "- `Correos V√°lidos`: Afiliados con correos operativos verificados.\n",
    "- `Tel√©fonos V√°lidos`: Afiliados con tel√©fonos operativos verificados.\n",
    "\n",
    "El resultado se guarda en un DataFrame (`resumen_kpis`) para su posterior exportaci√≥n y an√°lisis comparativo en el tiempo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. KPIs Operativos de Cartera\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Fecha de generaci√≥n del reporte ---\n",
    "fecha_generacion = pd.to_datetime(\"today\").strftime('%Y-%m-%d')\n",
    "\n",
    "# --- Total general de registros ---\n",
    "total_registros = len(df_pila_i_sie)\n",
    "\n",
    "# --- Registros por tipo de cartera ---\n",
    "conteo_cartera = df_pila_i_sie[\"Cartera\"].value_counts().to_dict()\n",
    "mora = conteo_cartera.get(\"mora\", 0)\n",
    "aviso = conteo_cartera.get(\"Aviso\", 0)\n",
    "sin_pagos = conteo_cartera.get(\"Sin Pagos\", 0)\n",
    "\n",
    "# --- N√∫mero de empresas distintas (aportantes) ---\n",
    "empresas = df_pila_i_sie[\"N¬∞ Identificaci√≥n Aportante\"].nunique()\n",
    "\n",
    "# --- N√∫mero de afiliados √∫nicos ---\n",
    "afiliados = df_pila_i_sie[\"No_Do\"].nunique()\n",
    "\n",
    "# --- Correos v√°lidos ---\n",
    "correos_validos = df_pila_i_sie[\"Correo_V√°lido\"].sum()\n",
    "\n",
    "# --- Tel√©fonos v√°lidos ---\n",
    "telefonos_validos = df_pila_i_sie[\"Tel√©fono_V√°lido\"].sum()\n",
    "\n",
    "# --- Crear DataFrame resumen ---\n",
    "resumen_kpis = pd.DataFrame([{\n",
    "    \"Fecha Generaci√≥n\": fecha_generacion,\n",
    "    \"Total Registros\": total_registros,\n",
    "    \"Sin Pagos\": sin_pagos,\n",
    "    \"En Mora\": mora,\n",
    "    \"En Aviso\": aviso,\n",
    "    \"Empresas Aportantes\": empresas,\n",
    "    \"Afiliados √önicos\": afiliados,\n",
    "    \"Correos V√°lidos\": correos_validos,\n",
    "    \"Tel√©fonos V√°lidos\": telefonos_validos\n",
    "}])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Generaci√≥n de reportes para aseguramiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pila_i_sie.to_excel(R_Salida_Pila_SIE_i, index=False, engine='openpyxl')\n",
    "#df_Relaciones_Laborales_SIE.to_csv(R_Salida_Relaciones_Laborales, sep=',', index=False, encoding='ANSI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pila_i_sie.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "\n",
    "with pd.ExcelWriter(R_Salida_Pila_SIE_i, engine='xlsxwriter') as writer:\n",
    "    # Exportar las hojas normales\n",
    "    df_pila_i_sie.to_excel(writer, sheet_name='Cartera Consolidada', index=False)\n",
    "    logs_3047.to_excel(writer, sheet_name='Logs_3047', index=False)\n",
    "    logs_pila.to_excel(writer, sheet_name='Logs_PILA', index=False)\n",
    "\n",
    "    # Escribir KPIs\n",
    "    resumen_kpis.to_excel(writer, sheet_name='Resumen_KPIs', index=False)\n",
    "\n",
    "    # Obtener el libro y la hoja de KPIs\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets['Resumen_KPIs']\n",
    "\n",
    "    # --- Formatos personalizados ---\n",
    "    header_format = workbook.add_format({\n",
    "        'bold': True,\n",
    "        'text_wrap': True,\n",
    "        'valign': 'center',\n",
    "        'align': 'center',\n",
    "        'border': 1,\n",
    "        'bg_color': '#004C97',  # Azul institucional\n",
    "        'font_color': 'white'\n",
    "    })\n",
    "\n",
    "    body_format = workbook.add_format({\n",
    "        'valign': 'center',\n",
    "        'align': 'center',\n",
    "        'border': 1,\n",
    "        'bg_color': '#E9EDF5'  # Gris muy claro\n",
    "    })\n",
    "\n",
    "    number_format = workbook.add_format({\n",
    "        'num_format': '#,##0',\n",
    "        'valign': 'center',\n",
    "        'align': 'center',\n",
    "        'border': 1,\n",
    "        'bg_color': '#E9EDF5'\n",
    "    })\n",
    "\n",
    "    date_format = workbook.add_format({\n",
    "        'num_format': 'dd/mm/yyyy',\n",
    "        'valign': 'center',\n",
    "        'align': 'center',\n",
    "        'border': 1,\n",
    "        'bg_color': '#E9EDF5'\n",
    "    })\n",
    "\n",
    "    # --- Aplicar formato a cada celda ---\n",
    "    for col_num, value in enumerate(resumen_kpis.columns):\n",
    "        # Escribir encabezado con formato\n",
    "        worksheet.write(0, col_num, value, header_format)\n",
    "\n",
    "        # Aplicar formatos por tipo de dato\n",
    "        if \"Fecha\" in value:\n",
    "            fmt = date_format\n",
    "        elif resumen_kpis.dtypes[value] in ['int64', 'float64']:\n",
    "            fmt = number_format\n",
    "        else:\n",
    "            fmt = body_format\n",
    "\n",
    "        # Aplicar a la(s) fila(s) de datos (asumiendo una sola fila de KPIs)\n",
    "        worksheet.write(1, col_num, resumen_kpis.iloc[0, col_num], fmt)\n",
    "\n",
    "        # Autoajustar ancho de columna\n",
    "        col_width = max(len(str(value)), len(str(resumen_kpis.iloc[0, col_num]))) + 2\n",
    "        worksheet.set_column(col_num, col_num, col_width)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
