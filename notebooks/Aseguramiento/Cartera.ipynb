{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import openpyxl  # Motor recomendado para escribir archivos Excel (.xlsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_Periodo_Actual = \"2025-04-01\"\n",
    "Dia = \"2025-03-01\"\n",
    "Mora = \"2025-02-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rutas Capresoca \n",
    "R_MaestroAdres = r\"C:\\DIANAB\\ASEGURAMIENTO 2025\\3. GESTION DE CARTERA\\Automatización\\Adicionales\\EPSC25MC0027032025.TXT\" # Cambiar nombre\n",
    "R_Relaciones_Laborales_SIE = r\"C:\\DIANAB\\ASEGURAMIENTO 2025\\3. GESTION DE CARTERA\\Automatización\\Adicionales\\Reporte_Afiliados Contributivo Relaciones Laborales_2025_04_02.csv\" # Cambiar nombre\n",
    "\n",
    "R_Pila3047 = r\"C:\\DIANAB\\ASEGURAMIENTO 2025\\3. GESTION DE CARTERA\\Automatización\\Pila consiliada ADRES\\Pila_Unificado_Con_Aportante_2018_2025.TXT\"\n",
    "R_Pila_I_SIE = r\"C:\\DIANAB\\ASEGURAMIENTO 2025\\3. GESTION DE CARTERA\\Automatización\\Pila I\"\n",
    "R_Pila_IP_SIE = r\"C:\\DIANAB\\ASEGURAMIENTO 2025\\3. GESTION DE CARTERA\\Automatización\\Pila IP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas de salida Capresoca \n",
    "R_Salida_Pila_SIE_i = r\"C:\\DIANAB\\ASEGURAMIENTO 2025\\3. GESTION DE CARTERA\\Automatización\\df_pila_i_sie.xlsx\"\n",
    "#R_Salida_Relaciones_Laborales = r\"C:\\Users\\osmarrincon\\OneDrive - uniminuto.edu\\Capresoca\\AlmostClear\\Procesos BDUA\\Contributivo\\Compensación\\_Pila_SIE\\SIE\\Relaciones laborales.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dianaborda\\AppData\\Local\\Temp\\ipykernel_22384\\3879205004.py:8: DtypeWarning: Columns (79,80,81,82) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_pila_i_sie = pd.concat((pd.read_csv(file, sep='|', encoding='ANSI') for file in file_list), ignore_index=True)\n",
      "C:\\Users\\dianaborda\\AppData\\Local\\Temp\\ipykernel_22384\\3879205004.py:8: DtypeWarning: Columns (79,80) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_pila_i_sie = pd.concat((pd.read_csv(file, sep='|', encoding='ANSI') for file in file_list), ignore_index=True)\n",
      "C:\\Users\\dianaborda\\AppData\\Local\\Temp\\ipykernel_22384\\3879205004.py:8: DtypeWarning: Columns (43,44,79,80) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_pila_i_sie = pd.concat((pd.read_csv(file, sep='|', encoding='ANSI') for file in file_list), ignore_index=True)\n",
      "C:\\Users\\dianaborda\\AppData\\Local\\Temp\\ipykernel_22384\\3879205004.py:8: DtypeWarning: Columns (29,43,44,79,80) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_pila_i_sie = pd.concat((pd.read_csv(file, sep='|', encoding='ANSI') for file in file_list), ignore_index=True)\n",
      "C:\\Users\\dianaborda\\AppData\\Local\\Temp\\ipykernel_22384\\3879205004.py:8: DtypeWarning: Columns (43,44,79,80) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_pila_i_sie = pd.concat((pd.read_csv(file, sep='|', encoding='ANSI') for file in file_list), ignore_index=True)\n",
      "C:\\Users\\dianaborda\\AppData\\Local\\Temp\\ipykernel_22384\\3879205004.py:8: DtypeWarning: Columns (29,43,44,79,80) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_pila_i_sie = pd.concat((pd.read_csv(file, sep='|', encoding='ANSI') for file in file_list), ignore_index=True)\n",
      "C:\\Users\\dianaborda\\AppData\\Local\\Temp\\ipykernel_22384\\3879205004.py:9: DtypeWarning: Columns (50,51,53,69,70) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_pila_iP_sie = pd.concat((pd.read_csv(file, sep='|', encoding='ANSI', header=None) for file in file_list_IP), ignore_index=True)\n",
      "C:\\Users\\dianaborda\\AppData\\Local\\Temp\\ipykernel_22384\\3879205004.py:11: DtypeWarning: Columns (9,16,17,26,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_Pila_3047 = pd.read_csv(R_Pila3047, sep=',', encoding='UTF-16')\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# Obtener la lista de archivos .txt en la ruta especificada\n",
    "file_list = glob.glob(R_Pila_I_SIE + \"/*.TXT\")\n",
    "file_list_IP = glob.glob(R_Pila_IP_SIE + \"/*.TXT\")\n",
    "\n",
    "# Leer y concatenar todos los archivos .txt en un solo dataframe\n",
    "df_pila_i_sie = pd.concat((pd.read_csv(file, sep='|', encoding='ANSI') for file in file_list), ignore_index=True)\n",
    "df_pila_iP_sie = pd.concat((pd.read_csv(file, sep='|', encoding='ANSI', header=None) for file in file_list_IP), ignore_index=True)\n",
    "DF_MC_Adres = pd.read_csv(R_MaestroAdres, sep=',', encoding='ansi', header=None)\n",
    "df_Pila_3047 = pd.read_csv(R_Pila3047, sep=',', encoding='UTF-16')\n",
    "df_Relaciones_Laborales_SIE = pd.read_csv(R_Relaciones_Laborales_SIE, sep=';', encoding='ansi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dianaborda\\AppData\\Local\\Temp\\ipykernel_22384\\1628223100.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_pila_iP_sie = df_pila_iP_sie.replace('X', 1)\n",
      "C:\\Users\\dianaborda\\AppData\\Local\\Temp\\ipykernel_22384\\1628223100.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_Pila_3047 = df_Pila_3047.replace('X', 1)\n"
     ]
    }
   ],
   "source": [
    "# Reemplazar los valores 'X' por 1 en todo el dataframe df_pila_iP_sie\n",
    "df_pila_iP_sie = df_pila_iP_sie.replace('X', 1)\n",
    "df_Pila_3047 = df_Pila_3047.replace('X', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de columnas en df_pila_i_sie: 92\n",
      "Número de columnas en df_pila_iP_sie: 92\n",
      "Número de columnas en df_Pila_3047: 45\n"
     ]
    }
   ],
   "source": [
    "df_pila_i_sie['origen'] = 'Pila_I'\n",
    "df_pila_iP_sie['origen'] = 'Pila_IP'\n",
    "df_Pila_3047['origen'] = 'Pila_3047'\n",
    "print(f\"Número de columnas en df_pila_i_sie: {df_pila_i_sie.shape[1]}\")\n",
    "print(f\"Número de columnas en df_pila_iP_sie: {df_pila_iP_sie.shape[1]}\")\n",
    "print(f\"Número de columnas en df_Pila_3047: {df_Pila_3047.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros en df_pila_i_sie antes de la unificación: 812502\n",
      "Cantidad de registros en df_pila_iP_sie antes de la unificación: 18176\n",
      "Unificación realizada correctamente.\n",
      "Cantidad de registros después de la unificación: 830678\n"
     ]
    }
   ],
   "source": [
    "# Mostrar la cantidad de registros antes de la unificación\n",
    "print(f\"Cantidad de registros en df_pila_i_sie antes de la unificación: {len(df_pila_i_sie)}\")\n",
    "print(f\"Cantidad de registros en df_pila_iP_sie antes de la unificación: {len(df_pila_iP_sie)}\")\n",
    "\n",
    "# Validar que ambos dataframes tengan la misma cantidad de columnas\n",
    "if df_pila_iP_sie.shape[1] == df_pila_i_sie.shape[1]:\n",
    "    # Asignar el mismo nombre de columnas de df_pila_i_sie a df_pila_iP_sie\n",
    "    df_pila_iP_sie.columns = df_pila_i_sie.columns\n",
    "    \n",
    "    # Unificar ambos dataframes\n",
    "    df_pila_i_sie = pd.concat([df_pila_i_sie, df_pila_iP_sie], ignore_index=True)\n",
    "    \n",
    "    # Validar que la unificación se haya realizado correctamente\n",
    "    if len(df_pila_i_sie) > len(df_pila_i_sie) - len(df_pila_iP_sie):\n",
    "        print(\"Unificación realizada correctamente.\")\n",
    "    else:\n",
    "        print(\"Error en la unificación de los dataframes.\")\n",
    "    \n",
    "    # Eliminar el dataframe df_pila_iP_sie\n",
    "    del df_pila_iP_sie\n",
    "else:\n",
    "    print(\"Los dataframes no tienen la misma cantidad de columnas. No se puede realizar la unificación.\")\n",
    "\n",
    "# Mostrar la cantidad de registros después de la unificación\n",
    "print(f\"Cantidad de registros después de la unificación: {len(df_pila_i_sie)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros antes de filtrar: 830678\n",
      "Cantidad de registros después de filtrar: 28651\n"
     ]
    }
   ],
   "source": [
    "df_Datos_Complementarios = df_pila_i_sie\n",
    "\n",
    "# Mostrar la cantidad de registros antes de filtrar\n",
    "print(f\"Cantidad de registros antes de filtrar: {len(df_Datos_Complementarios)}\")\n",
    "\n",
    "# Convertir la columna 'Perido Pago' a tipo datetime\n",
    "df_Datos_Complementarios['Perido Pago'] = pd.to_datetime(df_Datos_Complementarios['Perido Pago'], format='%Y-%m')\n",
    "\n",
    "# Ordenar el dataframe por las columnas especificadas y por 'Perido Pago' en orden descendente\n",
    "df_pila_df_Datos_Complementariosi_sie = df_Datos_Complementarios.sort_values(by=['Razón Social Aportante', 'N° Identificación Aportante', 'Perido Pago'], ascending=[True, True, False])\n",
    "\n",
    "# Eliminar duplicados manteniendo solo los registros con el periodo máximo\n",
    "df_Datos_Complementarios = df_Datos_Complementarios.drop_duplicates(subset=['Razón Social Aportante', 'N° Identificación Aportante'], keep='first')\n",
    "\n",
    "# Mostrar la cantidad de registros después de filtrar\n",
    "print(f\"Cantidad de registros después de filtrar: {len(df_Datos_Complementarios)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros Pila SIE: 830678\n",
      "Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "       36, 37],\n",
      "      dtype='int64')\n",
      "Cantidad de registros MC ADRES: 21535\n"
     ]
    }
   ],
   "source": [
    "# Mostrar las primeras filas del dataframe\n",
    "print(f\"Cantidad de registros Pila SIE: {len(df_pila_i_sie)}\")\n",
    "\n",
    "print(DF_MC_Adres.columns)\n",
    "print(f\"Cantidad de registros MC ADRES: {len(DF_MC_Adres)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Tp_Do', 'No_Do', '1A', '2A', '1N', '2N', 'Tp_Afiliado', 'Departamento',\n",
      "       'Municipio', 'Estado_ADRES', 'Sisben'],\n",
      "      dtype='object')\n",
      "Cantidad de registros: 21251\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar solo las columnas especificadas\n",
    "columns_to_keep = [\n",
    "    4, 5, 6, 7, 8, 9, 12, 18, 19, 28, 36 \n",
    "]\n",
    "\n",
    "# Filtrar el dataframe para mantener solo las columnas especificadas\n",
    "DF_MC_Adres = DF_MC_Adres[columns_to_keep]\n",
    "DF_MC_Adres = DF_MC_Adres[\n",
    "    (DF_MC_Adres[28] != \"AF\") | (DF_MC_Adres[28].isna())\n",
    "]\n",
    "\n",
    "# Asignar nombres a las columnas seleccionadas\n",
    "DF_MC_Adres.columns = [\n",
    "    'Tp_Do', 'No_Do', '1A', '2A', '1N', '2N', 'Tp_Afiliado', 'Departamento', 'Municipio', 'Estado_ADRES', 'Sisben'\n",
    "]\n",
    "\n",
    "\n",
    "# Mostrar las primeras filas del dataframe resultante\n",
    "print(DF_MC_Adres.columns)\n",
    "print(f\"Cantidad de registros: {len(DF_MC_Adres)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pila_i_sie = df_pila_i_sie[\n",
    "    (df_pila_i_sie['Correcciones'] != \"A\") | (df_pila_i_sie['Correcciones'].isna())\n",
    "]\n",
    "\n",
    "# Seleccionar solo las columnas especificadas\n",
    "columns_to_keep = [\n",
    "    'Razón Social Aportante', 'N° Identificación Aportante', 'Perido Pago', 'Fecha Pago',\n",
    "    'Tipo Documento Cotizante', 'N° Identificación Cotizante', 'Tipo Cotizante', 'ING', 'RET', 'Días Cotizados', \n",
    "    'Ingreso Base Cotización', 'Cotización Obligatoria', 'Número Planilla', 'origen'\n",
    "]\n",
    "# Filtrar el dataframe para mantener solo las columnas especificadas\n",
    "df_pila_i_sie = df_pila_i_sie[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['codigo_operador', 'Número Planilla', 'Perido Pago', 'Fecha Pago',\n",
      "       'cod_eps', 'digito_nit', 'Tipo Documento Cotizante',\n",
      "       'N° Identificación Cotizante', 'serial_benef_upc_adicional',\n",
      "       'tipo_doc_benef_upc_adicional', 'Doc_benef_adicional', 'Tipo Cotizante',\n",
      "       'subtipo_cotizante', 'tipo_pensionado', 'tipo_pension',\n",
      "       'pension_compartida', 'extranjero_no_obligado_compensar',\n",
      "       'colombiano_residente_eterior', 'cod_dept_ubicacion_laboral',\n",
      "       'mun_ubicacion_laboral', 'apel_1', 'apel_2', 'nom_1', 'nom_2', 'ING',\n",
      "       'RET', 'traslado-otra_administradora', 'traslado_a_otra_adminstradora',\n",
      "       'variacion_permanente_salario', 'variacion_trnsitoria_salario',\n",
      "       'suspension_temporal_de_contrato', 'vacaciones', 'Días Cotizados',\n",
      "       'salario_basico', 'Ingreso Base Cotización', 'tarifa',\n",
      "       'Cotización Obligatoria', 'valor_upc_adcional', 'Campo39', 'Campo40',\n",
      "       'nombre_Archivo', 'Fecha_Archivo', 'N° Identificación Aportante',\n",
      "       'Razón Social Aportante', 'origen'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_Pila_3047 = df_Pila_3047.rename(columns={\n",
    "    'Num_rad_planilla': 'Número Planilla',\n",
    "    'perido_pago_del_aportante': 'Perido Pago',\n",
    "    'fecha_pago': 'Fecha Pago',\n",
    "    'Tipo_doc_cotizante': 'Tipo Documento Cotizante',\n",
    "    'doc_cotizante' : 'N° Identificación Cotizante',\n",
    "    'Tipo_cotizante': 'Tipo Cotizante',\n",
    "    'ingreso': 'ING',\n",
    "    'retiro': 'RET',\n",
    "    'dias_cotizados': 'Días Cotizados',\n",
    "    'ibc': 'Ingreso Base Cotización',\n",
    "    'cotizacion_obligatoria':'Cotización Obligatoria',\n",
    "    'Nit': 'N° Identificación Aportante',\n",
    "    'Razon_Soacial': 'Razón Social Aportante'\n",
    "})\n",
    "print(df_Pila_3047.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order = [\n",
    "    'Razón Social Aportante', 'N° Identificación Aportante', 'Perido Pago', 'Fecha Pago',\n",
    "    'Tipo Documento Cotizante', 'N° Identificación Cotizante', 'Tipo Cotizante', 'ING', 'RET', 'Días Cotizados', \n",
    "    'Ingreso Base Cotización', 'Cotización Obligatoria', 'Número Planilla', 'origen'\n",
    "    ]\n",
    "df_Pila_3047 = df_Pila_3047[column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new columns to df_sin_pagos\n",
    "df_pila_i_sie['Tipo Cotizante'] = df_pila_i_sie['Tipo Cotizante'].fillna(0).astype('int64')\n",
    "\n",
    "\n",
    "df_Pila_3047['Ingreso Base Cotización'] = df_Pila_3047['Ingreso Base Cotización'].astype('float64')\n",
    "df_Pila_3047['N° Identificación Aportante'] = pd.to_numeric(df_Pila_3047['N° Identificación Aportante'], errors='coerce').fillna(0).astype('int64')\n",
    "df_Pila_3047['Tipo Cotizante'] = df_Pila_3047['Tipo Cotizante'].astype('int64')\n",
    "df_Pila_3047['ING'] = df_Pila_3047['ING'].fillna(0).astype('int64')\n",
    "df_Pila_3047['RET'] = df_Pila_3047['RET'].fillna(0).astype('int64')\n",
    "df_Pila_3047['Días Cotizados'] = df_Pila_3047['Días Cotizados'].fillna(0).astype('int64')\n",
    "df_pila_i_sie['ING'] = df_pila_i_sie['ING'].fillna(0).astype('int64')\n",
    "df_pila_i_sie['RET'] = df_pila_i_sie['RET'].fillna(0).astype('int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros en df_Pila_3047 antes de la unión: 1350627\n",
      "Cantidad de registros en df_pila_i_sie antes de la unión: 817450\n",
      "Cantidad de registros en df_pila_i_sie después de la unión: 2168077\n"
     ]
    }
   ],
   "source": [
    "# Mostrar la cantidad de registros antes de la unión\n",
    "print(f\"Cantidad de registros en df_Pila_3047 antes de la unión: {len(df_Pila_3047)}\")\n",
    "print(f\"Cantidad de registros en df_pila_i_sie antes de la unión: {len(df_pila_i_sie)}\")\n",
    "\n",
    "# Unir los dataframes uno debajo del otro\n",
    "df_pila_i_sie = pd.concat([df_pila_i_sie, df_Pila_3047], ignore_index=True)\n",
    "\n",
    "# Mostrar la cantidad de registros después de la unión\n",
    "print(f\"Cantidad de registros en df_pila_i_sie después de la unión: {len(df_pila_i_sie)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros Pila: 2168077\n",
      "Cantidad de registros Pila: 1000622\n",
      "Cantidad de registros df_pila_i_sie: 1000622\n"
     ]
    }
   ],
   "source": [
    "# Cambiar el nombre de las columnas especificadas\n",
    "df_pila_i_sie = df_pila_i_sie.rename(columns={\n",
    "    'Tipo Documento Cotizante': 'Tp_Do', \n",
    "    'N° Identificación Cotizante': 'No_Do'\n",
    "})\n",
    "\n",
    "print(f\"Cantidad de registros Pila: {len(df_pila_i_sie)}\")\n",
    "# Realizar la unión de los dataframes\n",
    "df_pila_i_sie = df_pila_i_sie.merge(DF_MC_Adres[['Tp_Do', 'No_Do', '1A', '2A', '1N', '2N', 'Tp_Afiliado', 'Departamento', 'Municipio', 'Estado_ADRES', 'Sisben']], on=['Tp_Do', 'No_Do'], how='left')\n",
    "df_pila_i_sie = df_pila_i_sie[df_pila_i_sie['Estado_ADRES'].notna() & (df_pila_i_sie['Estado_ADRES'] == \"AC\")]\n",
    "\n",
    "\n",
    "print(f\"Cantidad de registros Pila: {len(df_pila_i_sie)}\")\n",
    "print(f\"Cantidad de registros df_pila_i_sie: {len(df_pila_i_sie)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros antes de filtrar: 1000622\n",
      "Cantidad de registros después de la agregación: 1000622\n"
     ]
    }
   ],
   "source": [
    "# Mostrar la cantidad de registros antes de filtrar\n",
    "print(f\"Cantidad de registros antes de filtrar: {len(df_pila_i_sie)}\")\n",
    "\n",
    "# Convertir la columna 'Días Cotizados' a tipo numérico\n",
    "df_pila_i_sie['Días Cotizados'] = pd.to_numeric(df_pila_i_sie['Días Cotizados'], errors='coerce')\n",
    "\n",
    "# Sumar los días cotizados por cada ID1\n",
    "df_pila_i_sie['Días Cotizados'] = df_pila_i_sie.groupby(\n",
    "    [\"N° Identificación Aportante\", \"Tp_Do\", \"No_Do\", 'Perido Pago']\n",
    ")['Días Cotizados'].transform('sum')\n",
    "\n",
    "# Si en la columna ING hay un 1, todos los registros del mismo grupo quedan con 1\n",
    "df_pila_i_sie['ING'] = df_pila_i_sie.groupby(\n",
    "    [\"N° Identificación Aportante\", \"Tp_Do\", \"No_Do\", 'Perido Pago']\n",
    ")['ING'].transform('max')\n",
    "\n",
    "# Si en la columna RET hay un 1, todos los registros del mismo grupo quedan con 1\n",
    "df_pila_i_sie['RET'] = df_pila_i_sie.groupby(\n",
    "    [\"N° Identificación Aportante\", \"Tp_Do\", \"No_Do\", 'Perido Pago']\n",
    ")['RET'].transform('max')\n",
    "\n",
    "\n",
    "\n",
    "# Mostrar las primeras filas del dataframe resultante\n",
    "print(f\"Cantidad de registros después de la agregación: {len(df_pila_i_sie)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros después de filtrar: 66031\n"
     ]
    }
   ],
   "source": [
    "# Convertir la columna 'Perido Pago' a datetime\n",
    "df_pila_i_sie['Perido Pago'] = pd.to_datetime(df_pila_i_sie['Perido Pago'], format='%Y-%m', errors='coerce')\n",
    "\n",
    "# Para cada grupo, obtener el índice del registro con la fecha máxima\n",
    "idx_max = df_pila_i_sie.groupby(['N° Identificación Aportante', 'Tp_Do', 'No_Do'])['Perido Pago'].idxmax()\n",
    "\n",
    "# Seleccionar únicamente esos registros\n",
    "df_pila_i_sie = df_pila_i_sie.loc[idx_max].reset_index(drop=True)\n",
    "\n",
    "# Mostrar la cantidad de registros después de filtrar\n",
    "print(f\"Cantidad de registros después de filtrar: {len(df_pila_i_sie)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Razón Social Aportante', 'N° Identificación Aportante', 'Perido Pago',\n",
      "       'Fecha Pago', 'Tp_Do', 'No_Do', 'Tipo Cotizante', 'ING', 'RET',\n",
      "       'Días Cotizados', 'Ingreso Base Cotización', 'Cotización Obligatoria',\n",
      "       'Número Planilla', 'origen', '1A', '2A', '1N', '2N', 'Tp_Afiliado',\n",
      "       'Departamento', 'Municipio', 'Estado_ADRES', 'Sisben',\n",
      "       'Dirección de Correspondencia', 'Teléfono', 'Correo Electrónico'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar solo las columnas necesarias de df_Datos_Complementarios\n",
    "df_Datos_Complementarios_subset = df_Datos_Complementarios[['N° Identificación Aportante', 'Dirección de Correspondencia', 'Teléfono', 'Correo Electrónico']]\n",
    "\n",
    "# Realizar el merge para traer las columnas a df_pila_i_sie\n",
    "df_pila_i_sie = df_pila_i_sie.merge(df_Datos_Complementarios_subset, on='N° Identificación Aportante', how='left')\n",
    "\n",
    "print(df_pila_i_sie.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros únicos: 15868\n"
     ]
    }
   ],
   "source": [
    "# Crear un nuevo dataframe con los valores únicos de las columnas especificadas\n",
    "df_unique_aportantes = df_pila_i_sie[[\"Tp_Do\", \"No_Do\"]].drop_duplicates()\n",
    "\n",
    "# Mostrar las primeras filas del nuevo dataframe\n",
    "print(f\"Cantidad de registros únicos: {len(df_unique_aportantes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros realcionaes laborales #1: 24724\n",
      "Cantidad de registros realcionaes laborales #2: 24367\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cantidad de registros realcionaes laborales #1: {len(df_Relaciones_Laborales_SIE)}\")\n",
    "# Convertir la columna 'fecha_ingreso' a tipo datetime\n",
    "df_Relaciones_Laborales_SIE['fecha_ingreso'] = pd.to_datetime(df_Relaciones_Laborales_SIE['fecha_ingreso'], format='%Y-%m-%d')\n",
    "\n",
    "# Asignar la fecha máxima de 'fecha_ingreso' a todo el grupo\n",
    "df_Relaciones_Laborales_SIE['fecha_ingreso'] = df_Relaciones_Laborales_SIE.groupby(\n",
    "    ['tipo_documento', 'numero_identificacion', 'tipo_documento_aportante', 'numero_identificacion_aportante']\n",
    ")['fecha_ingreso'].transform('max')\n",
    "\n",
    "# Eliminar duplicados manteniendo solo un registro por grupo\n",
    "df_Relaciones_Laborales_SIE = df_Relaciones_Laborales_SIE.drop_duplicates(\n",
    "    subset=['tipo_documento', 'numero_identificacion', 'tipo_documento_aportante', 'numero_identificacion_aportante']\n",
    ")\n",
    "\n",
    "# Mostrar las primeras filas del dataframe resultante\n",
    "print(f\"Cantidad de registros realcionaes laborales #2: {len(df_Relaciones_Laborales_SIE)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros sin pagos: 95\n"
     ]
    }
   ],
   "source": [
    "# Filtrar los registros en DF_MC_Adres que no están en df_unique_aportantes\n",
    "df_sin_pagos = DF_MC_Adres.merge(df_unique_aportantes, on=[\"Tp_Do\", \"No_Do\"], how=\"left\", indicator=True)\n",
    "df_sin_pagos = df_sin_pagos[df_sin_pagos[\"_merge\"] == \"left_only\"].drop(columns=[\"_merge\"])\n",
    "\n",
    "# Filtrar las columnas [Tp_Afiliado= 'C' y Estado_ADRES= 'AC']\n",
    "df_sin_pagos = df_sin_pagos[(df_sin_pagos['Tp_Afiliado'] == 'C') & (df_sin_pagos['Estado_ADRES'] == 'AC')]\n",
    "\n",
    "# Mostrar la cantidad de registros filtrados\n",
    "print(f\"Cantidad de registros sin pagos: {len(df_sin_pagos)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Razón Social Aportante', 'N° Identificación Aportante', 'Perido Pago',\n",
      "       'Fecha Pago', 'Tp_Do', 'No_Do', 'Tipo Cotizante', 'ING', 'RET',\n",
      "       'Días Cotizados', 'Ingreso Base Cotización', 'Cotización Obligatoria',\n",
      "       'Número Planilla', 'origen', '1A', '2A', '1N', '2N', 'Tp_Afiliado',\n",
      "       'Departamento', 'Municipio', 'Estado_ADRES', 'Sisben',\n",
      "       'Dirección de Correspondencia', 'Teléfono', 'Correo Electrónico'],\n",
      "      dtype='object')\n",
      "Index(['tipo_documento', 'numero_identificacion', 'tipo_documento_aportante',\n",
      "       'numero_identificacion_aportante', 'razon_social', 'fecha_ingreso',\n",
      "       'Unnamed: 6'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_pila_i_sie.columns)\n",
    "print(df_Relaciones_Laborales_SIE.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Tp_Do', 'No_Do', 'Tipo Documento Aportante',\n",
      "       'N° Identificación Aportante', 'Razón Social Aportante',\n",
      "       'fecha_ingreso', 'Unnamed: 6'],\n",
      "      dtype='object')\n",
      "Index(['Tp_Do', 'No_Do', 'Tipo Documento Aportante',\n",
      "       'N° Identificación Aportante', 'Razón Social Aportante',\n",
      "       'fecha_ingreso', 'Unnamed: 6', 'Correo Electrónico'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_Relaciones_Laborales_SIE = df_Relaciones_Laborales_SIE.rename(columns={\n",
    "    'tipo_documento': 'Tp_Do',\n",
    "    'numero_identificacion': 'No_Do',\n",
    "    'tipo_documento_aportante': 'Tipo Documento Aportante',\n",
    "    'numero_identificacion_aportante': 'N° Identificación Aportante',\n",
    "    'razon_social': 'Razón Social Aportante'\n",
    "})\n",
    "print(df_Relaciones_Laborales_SIE.columns)\n",
    "df_Relaciones_Laborales_SIE['N° Identificación Aportante'] = df_Relaciones_Laborales_SIE['N° Identificación Aportante'].astype(str)\n",
    "df_pila_i_sie['N° Identificación Aportante'] = df_pila_i_sie['N° Identificación Aportante'].astype(str)\n",
    "\n",
    "df_Relaciones_Laborales_SIE = df_Relaciones_Laborales_SIE.merge(df_pila_i_sie[['N° Identificación Aportante', 'Correo Electrónico']], on=['N° Identificación Aportante'], how='left')\n",
    "print(df_Relaciones_Laborales_SIE.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Tp_Do', 'No_Do', '1A', '2A', '1N', '2N', 'Tp_Afiliado', 'Departamento',\n",
      "       'Municipio', 'Estado_ADRES', 'Sisben', 'Tipo Documento Aportante',\n",
      "       'N° Identificación Aportante', 'Razón Social Aportante',\n",
      "       'fecha_ingreso', 'Correo Electrónico'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Convertir 'No_Do' en df_Relaciones_Laborales_SIE a str para que coincida con df_sin_pagos\n",
    "df_Relaciones_Laborales_SIE['No_Do'] = df_Relaciones_Laborales_SIE['No_Do'].astype(str)\n",
    "df_sin_pagos['No_Do'] = df_sin_pagos['No_Do'].astype(str)\n",
    "\n",
    "# Realizar el merge para traer la columna 'fecha_ingreso' a df_sin_pagos\n",
    "df_sin_pagos = df_sin_pagos.merge(df_Relaciones_Laborales_SIE[['Tp_Do', 'No_Do', 'Tipo Documento Aportante', 'N° Identificación Aportante', 'Razón Social Aportante', 'fecha_ingreso', 'Correo Electrónico']], on=['Tp_Do', 'No_Do'], how='left')\n",
    "print(df_sin_pagos.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros sin pagos: 4184\n",
      "Cantidad de registros únicos en df_sin_pagos: 95\n",
      "Index(['Tp_Do', 'No_Do', '1A', '2A', '1N', '2N', 'Tp_Afiliado', 'Departamento',\n",
      "       'Municipio', 'Estado_ADRES', 'Sisben', 'Tipo Documento Aportante',\n",
      "       'N° Identificación Aportante', 'Razón Social Aportante',\n",
      "       'fecha_ingreso', 'Correo Electrónico'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cantidad de registros sin pagos: {len(df_sin_pagos)}\")\n",
    "# Dejar valores únicos en df_sin_pagos según las columnas ['Tp_Do', 'No_Do']\n",
    "df_sin_pagos = df_sin_pagos.drop_duplicates(subset=['Tp_Do', 'No_Do'])\n",
    "\n",
    "# Mostrar las primeras filas del dataframe resultante para verificar\n",
    "print(f\"Cantidad de registros únicos en df_sin_pagos: {len(df_sin_pagos)}\")\n",
    "print(df_sin_pagos.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros sin pagos: 95\n",
      "Index(['Tp_Do', 'No_Do', '1A', '2A', '1N', '2N', 'Tp_Afiliado', 'Departamento',\n",
      "       'Municipio', 'Estado_ADRES', 'Sisben', 'Tipo Documento Aportante',\n",
      "       'N° Identificación Aportante', 'Razón Social Aportante',\n",
      "       'fecha_ingreso', 'Correo Electrónico'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Convert No_Do to string type in both dataframes\n",
    "df_sin_pagos['No_Do'] = df_sin_pagos['No_Do'].astype(str)\n",
    "df_unique_aportantes['No_Do'] = df_unique_aportantes['No_Do'].astype(str)\n",
    "\n",
    "# Now perform the merge\n",
    "df_sin_pagos = df_sin_pagos.merge(df_unique_aportantes, on=[\"Tp_Do\", \"No_Do\"], how=\"left\", indicator=True)\n",
    "df_sin_pagos = df_sin_pagos[df_sin_pagos[\"_merge\"] == \"left_only\"].drop(columns=[\"_merge\"])\n",
    "\n",
    "# Filter records with required conditions\n",
    "df_sin_pagos = df_sin_pagos[(df_sin_pagos['Tp_Afiliado'] == 'C') & (df_sin_pagos['Estado_ADRES'] == 'AC')]\n",
    "\n",
    "# Show results\n",
    "print(f\"Cantidad de registros sin pagos: {len(df_sin_pagos)}\")\n",
    "print(df_sin_pagos.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new columns to df_sin_pagos\n",
    "df_sin_pagos['No_Do'] = df_sin_pagos['No_Do'].astype('int64')\n",
    "df_sin_pagos['N° Identificación Aportante'] = df_sin_pagos['N° Identificación Aportante'].fillna(0).astype('int64')\n",
    "df_sin_pagos['Tipo Cotizante'] = 0\n",
    "df_sin_pagos['Tipo Cotizante'] = df_sin_pagos['Tipo Cotizante'].astype('int64')\n",
    "df_sin_pagos['Dirección de Correspondencia'] = \"\"\n",
    "df_sin_pagos['Perido Pago'] = pd.to_datetime(\"\")\n",
    "df_sin_pagos['Fecha Pago'] = \"\"\n",
    "\n",
    "df_sin_pagos['ING'] = 0\n",
    "df_sin_pagos['ING'] = df_sin_pagos['ING'].astype('int64')\n",
    "df_sin_pagos['RET'] = 0\n",
    "df_sin_pagos['RET'] = df_sin_pagos['RET'].astype('int64')\n",
    "df_sin_pagos['Días Cotizados'] = 0\n",
    "df_sin_pagos['Días Cotizados'] = df_sin_pagos['Días Cotizados'].astype('int64')\n",
    "df_sin_pagos['Ingreso Base Cotización'] = 0\n",
    "df_sin_pagos['Ingreso Base Cotización'] = df_sin_pagos['Ingreso Base Cotización'].astype('float64')\n",
    "df_sin_pagos['Correcciones'] = \"\"\n",
    "df_sin_pagos['Número Planilla'] = 0\n",
    "df_sin_pagos['Número Planilla'] = df_sin_pagos['Número Planilla'].astype('int64')\n",
    "df_sin_pagos['Departamento'] = df_sin_pagos['Departamento'].astype('int64')\n",
    "df_sin_pagos['Departamento'] = df_sin_pagos['Departamento'].astype(str).str.zfill(2)\n",
    "df_sin_pagos['Municipio'] = df_sin_pagos['Municipio'].astype('int64')\n",
    "df_sin_pagos['Municipio'] = df_sin_pagos['Municipio'].astype(str).str.zfill(3)\n",
    "df_sin_pagos['origen'] = \"MC_ADRES\"\n",
    "\n",
    "df_pila_i_sie['Tipo Cotizante'] = df_pila_i_sie['Tipo Cotizante'].fillna(0).astype('int64')\n",
    "df_pila_i_sie['ING'] = df_pila_i_sie['ING'].fillna(0).astype('int64')\n",
    "df_pila_i_sie['RET'] = df_pila_i_sie['RET'].fillna(0).astype('int64')\n",
    "df_pila_i_sie['Departamento'] = df_pila_i_sie['Departamento'].astype('int64')\n",
    "df_pila_i_sie['Departamento'] = df_pila_i_sie['Departamento'].astype(str).str.zfill(2)\n",
    "df_pila_i_sie['Municipio'] = df_pila_i_sie['Municipio'].astype('int64')\n",
    "df_pila_i_sie['Municipio'] = df_pila_i_sie['Municipio'].astype(str).str.zfill(3)\n",
    "df_pila_i_sie['fecha_ingreso'] = pd.to_datetime(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganizar las columnas de df_sin_pagos en el orden especificado\n",
    "column_order = ['Razón Social Aportante', 'Tipo Documento Aportante', 'N° Identificación Aportante', 'Dirección de Correspondencia', 'Correo Electrónico', 'Perido Pago', 'Fecha Pago', 'Tp_Do', 'No_Do', 'Tipo Cotizante', 'ING', 'RET', 'Días Cotizados', 'Ingreso Base Cotización', 'Correcciones', 'Número Planilla', 'origen', '1A', '2A', '1N', '2N', 'Tp_Afiliado', 'Departamento', 'Municipio', 'Estado_ADRES', 'Sisben', 'fecha_ingreso']\n",
    "df_sin_pagos = df_sin_pagos[column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros sin pagos: 95\n",
      "Cantidad de registros PAgos SIE pagos: 80096\n",
      "Cantidad de registros Total: 80191\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cantidad de registros sin pagos: {len(df_sin_pagos)}\")\n",
    "print(f\"Cantidad de registros PAgos SIE pagos: {len(df_pila_i_sie)}\")\n",
    "df_pila_i_sie = pd.concat([df_pila_i_sie, df_sin_pagos], ignore_index=True)\n",
    "print(f\"Cantidad de registros Total: {len(df_pila_i_sie)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros df_pila_i_sie: 80191\n",
      "Cantidad de registros después de filtrar RET != 1: 22731\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'Perido Pago' is datetime\n",
    "print(f\"Cantidad de registros df_pila_i_sie: {len(df_pila_i_sie)}\")\n",
    "\n",
    "df_pila_i_sie['Perido Pago'] = pd.to_datetime(df_pila_i_sie['Perido Pago'], errors='coerce')\n",
    "\n",
    "# Filter out records where RET = 1\n",
    "df_pila_i_sie = df_pila_i_sie[\n",
    "    (df_pila_i_sie['RET'] != 1) &\n",
    "    ((df_pila_i_sie['Perido Pago'] < pd.to_datetime(V_Periodo_Actual)) | (df_pila_i_sie['Perido Pago'].isna()))\n",
    "]\n",
    "print(f\"Cantidad de registros después de filtrar RET != 1: {len(df_pila_i_sie)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros df_pila_i_sie: 22731\n"
     ]
    }
   ],
   "source": [
    "# Create new column 'Cartera' based on conditions\n",
    "df_pila_i_sie['Cartera'] = 'Sin Pagos'  # Default value\n",
    "\n",
    "# Convert Mora to datetime\n",
    "mora_date = pd.to_datetime(Mora)\n",
    "Dia_date = pd.to_datetime(Dia)\n",
    "\n",
    "# Update values based on conditions for non-null Perido Pago\n",
    "mask = df_pila_i_sie['Perido Pago'].notna()\n",
    "df_pila_i_sie.loc[mask & (df_pila_i_sie['Perido Pago'] < mora_date), 'Cartera'] = 'mora'\n",
    "df_pila_i_sie.loc[mask & (df_pila_i_sie['Perido Pago'] >= mora_date), 'Cartera'] = 'Aviso'\n",
    "df_pila_i_sie.loc[mask & (df_pila_i_sie['Perido Pago'] >= Dia_date), 'Cartera'] = 'Al Dia'\n",
    "print(f\"Cantidad de registros df_pila_i_sie: {len(df_pila_i_sie)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert column 31 to datetime format\n",
    "#DF_Automatico_R1[\"Fecha_Efectiva\"] = pd.to_datetime(DF_Automatico_R1[34], format='%d/%m/%Y')\n",
    "\n",
    "# Sort by date in descending order and keep first record for each ID\n",
    "#DF_Automatico_R1 = DF_Automatico_R1.sort_values(by=[2, 3, 34], ascending=[True, True, False])\n",
    "#DF_Automatico_R1 = DF_Automatico_R1.drop_duplicates(subset=[2, 3], keep='first')\n",
    "\n",
    "# Reset the index if needed\n",
    "#DF_Automatico_R1 = DF_Automatico_R1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of column names where column 31 is 'Fecha_R1' and others are 'col#'\n",
    "#column_names = [f'col{i}' for i in range(len(DF_Automatico_R1.columns))]\n",
    "#column_names[34] = 'Fecha_R1'\n",
    "#column_names[2] = 'Tp_Do'\n",
    "#column_names[3] = 'No_Do'\n",
    "\n",
    "# Assign column names to dataframe\n",
    "#DF_Automatico_R1.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_pila_i_sie with DF_Automatico_R1 to get Fecha_R1\n",
    "#df_pila_i_sie = df_pila_i_sie.merge(\n",
    "#    DF_Automatico_R1[['Tp_Do', 'No_Do', 'Fecha_R1']], \n",
    "#    on=['Tp_Do', 'No_Do'], \n",
    "#    how='left'\n",
    "#)\n",
    "#print(f\"Cantidad de registros df_pila_i_sie: {len(df_pila_i_sie)}\")\n",
    "#print(df_pila_i_sie.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros después de eliminar duplicados: 21594\n"
     ]
    }
   ],
   "source": [
    "# Sort by date in descending order and keep first record for each ID\n",
    "df_Relaciones_Laborales_SIE = df_Relaciones_Laborales_SIE.sort_values(\n",
    "    by=['Tp_Do', 'No_Do', 'fecha_ingreso'], \n",
    "    ascending=[True, True, False]\n",
    ")\n",
    "\n",
    "# Drop duplicates keeping first record (which will be the one with max date due to sort)\n",
    "df_Relaciones_Laborales_SIE = df_Relaciones_Laborales_SIE.drop_duplicates(\n",
    "    subset=['Tp_Do', 'No_Do'], \n",
    "    keep='first'\n",
    ")\n",
    "\n",
    "# Reset the index if needed\n",
    "df_Relaciones_Laborales_SIE = df_Relaciones_Laborales_SIE.reset_index(drop=True)\n",
    "\n",
    "print(f\"Cantidad de registros después de eliminar duplicados: {len(df_Relaciones_Laborales_SIE)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros después del filtrado: 20324\n"
     ]
    }
   ],
   "source": [
    "# Convertir la columna 'Perido Pago' al formato datetime con el formato dd/mm/yyyy\n",
    "df_pila_i_sie['Perido Pago'] = pd.to_datetime(df_pila_i_sie['Perido Pago'], format='%d/%m/%Y', errors='coerce')\n",
    "\n",
    "# Definir el rango de fechas deseado\n",
    "start_date = pd.to_datetime('2023-01-01')\n",
    "end_date   = pd.to_datetime('2026-12-31')\n",
    "\n",
    "# Filtrar: conservar los registros cuyo 'Perido Pago' esté vacío o esté entre las fechas definidas\n",
    "mask = df_pila_i_sie['Perido Pago'].isna() | ((df_pila_i_sie['Perido Pago'] >= start_date) & (df_pila_i_sie['Perido Pago'] <= end_date))\n",
    "df_pila_i_sie = df_pila_i_sie[mask]\n",
    "\n",
    "print(f\"Cantidad de registros después del filtrado: {len(df_pila_i_sie)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Lista de columnas que contienen fechas (ajusta según tu DataFrame)\n",
    "columnas_fecha = ['Perido Pago', 'fecha_ingreso']  # Reemplázalas con los nombres reales\n",
    "\n",
    "# Convertir las columnas de fecha al formato DD/MM/YYYY\n",
    "for col in columnas_fecha:\n",
    "    df_pila_i_sie[col] = pd.to_datetime(df_pila_i_sie[col], errors='coerce').dt.strftime('%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pila_i_sie.to_excel(R_Salida_Pila_SIE_i, index=False, engine='openpyxl')\n",
    "#df_Relaciones_Laborales_SIE.to_csv(R_Salida_Relaciones_Laborales, sep=',', index=False, encoding='ANSI')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
