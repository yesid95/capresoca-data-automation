{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Concluciones del proceso\n",
    "\n",
    "Durante el tercer cuatrimestre de 2025 (septiembre a diciembre), se llevaron a cabo 12 ciclos de envío semanales de MS a ADRES. A nivel mensual, la efectividad presentó una alta volatilidad: se alcanzó un 38% en septiembre, repuntando a un notable 71% en octubre, para luego caer al 35% en noviembre y cerrar con un 36% en diciembre. Esta tendencia irregular contrasta con la estabilidad del periodo anterior.\n",
    "\n",
    "Desglosando por envío, la tasa de corrección osciló drásticamente desde un mínimo del 0% (presente en tres cortes: 19 de sep, 12 y 19 de dic) hasta un máximo del 69% el 17 de octubre. Este patrón evidencia que, aunque octubre logró consolidar una limpieza de glosas superior al objetivo (con picos de 60% y 69%), el cierre de año fue crítico, acumulando dos semanas consecutivas con nula efectividad en diciembre. Adicionalmente, se identifica una concentración severa en la causal GN0013, que por sí sola representa el 53.0% de los casos sin reenvío exitoso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# 1. Modulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import letter\n",
    "import openpyxl\n",
    "import xlsxwriter\n",
    "from docx import Document\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import squarify\n",
    "import subprocess\n",
    "import os\n",
    "import dataframe_image as dfi\n",
    "import kaleido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# 2. Rutas y contantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_Glosas = r\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\Constantes\\Glosas ADRES 2025.xlsx\"\n",
    "R_MS_Neg = r\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\Procesos BDUA\\Subsidiados\\Procesos BDUA EPS\\MS\\MS Negado\\All_MS_NEG.TXT\"\n",
    "R_MS_Val = r\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\Procesos BDUA\\Subsidiados\\Procesos BDUA EPS\\MS\\MS Validados\\All_MS_VAL.TXT\"\n",
    "\n",
    "R_Salida = r\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Escritorio\\Yesid Rincón Z\\informes\\2025\\CTO135.2025 Informe  #13\\ACTIVIDAD 14\\Analisis detallado MS negados\"\n",
    "\n",
    "# ——————————————————————————————\n",
    "# 0) Prepara rutas y carpetas\n",
    "# ——————————————————————————————\n",
    "graficas_dir = os.path.join(R_Salida, \"Graficas\")\n",
    "os.makedirs(graficas_dir, exist_ok=True)\n",
    "\n",
    "ruta_excel   = os.path.join(R_Salida, \"Metricas_Glosas_MS_entrega.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las constantes a objetos datetime\n",
    "Mes_Ini = datetime.strptime('01/09/2025', '%d/%m/%Y')\n",
    "Mes_Fin = datetime.strptime('31/12/2025', '%d/%m/%Y')\n",
    "\n",
    "# ajusta a tu nombre real\n",
    "notebook = r\"C:\\Users\\osmarrincon\\Documents\\capresoca-data-automation\\notebooks\\Aseguramiento\\Inf_Ejec_MS_NEG.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Mes_Fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# 3. Cargue de Dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glosas = pd.read_excel(R_Glosas, sheet_name=\"Glosas de Negocio_BDUA\", usecols=\"A:B\", header=0, dtype=str)\n",
    "\n",
    "Df_MS_Neg = pd.read_csv(R_MS_Neg, sep=',', header=0, dtype=str, encoding='ANSI')\n",
    "Df_MS_Val = pd.read_csv(R_MS_Val, sep=',', header=0, dtype=str, encoding='ANSI')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# 4. Limpieza de dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 4.1 dicionario de Glosas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glosas.columns = df_glosas.columns.str.strip()\n",
    "# Reemplazar cadenas vacías que contienen solo espacios por NaN\n",
    "df_glosas[['Glosa', 'Descripción']] = df_glosas[['Glosa', 'Descripción']].replace(r'^\\s*$', np.nan, regex=True)\n",
    "# Eliminar las filas donde ambas columnas son NaN\n",
    "df_glosas = df_glosas.dropna(subset=['Glosa', 'Descripción'], how='all')\n",
    "\n",
    "# Número de registros antes de eliminar duplicados\n",
    "n_registros_antes = len(df_glosas)\n",
    "print(\"Número de registros antes de eliminar duplicados:\", n_registros_antes)\n",
    "\n",
    "# Eliminar duplicados de la columna \"Glosa\"\n",
    "df_glosas = df_glosas.drop_duplicates(subset=\"Glosa\")\n",
    "\n",
    "# Número de registros después de eliminar duplicados\n",
    "n_registros_despues = len(df_glosas)\n",
    "print(\"Número de registros después de eliminar duplicados:\", n_registros_despues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la longitud de cada valor de la columna 'Glosa'\n",
    "lengths = df_glosas['Glosa'].astype(str).str.len()\n",
    "\n",
    "# Determinar la longitud más frecuente (la modalidad)\n",
    "majority_length = lengths.mode()[0]\n",
    "print(\"Longitud mayoritaria:\", majority_length)\n",
    "\n",
    "# Filtrar las filas donde la longitud es diferente a la mayoritaria\n",
    "different_rows = df_glosas[lengths != majority_length]\n",
    "print(\"Filas con una longitud diferente a la mayoría:\")\n",
    "print(different_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## 4.2. MS negado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las columnas a formato datetime\n",
    "Df_MS_Neg['AFL_FECHA_NACIMIENTO'] = pd.to_datetime(Df_MS_Neg['AFL_FECHA_NACIMIENTO'], format='%d/%m/%Y')\n",
    "Df_MS_Neg['CND_AFL_FECHA_INICIO'] = pd.to_datetime(Df_MS_Neg['CND_AFL_FECHA_INICIO'], format='%d/%m/%Y')\n",
    "Df_MS_Neg['Fecha_Proceso'] = pd.to_datetime(Df_MS_Neg['Fecha_Proceso'], format='%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Número de registros antes de filtrar Fecha proceso:\", len(Df_MS_Neg))\n",
    "# Filtrar registros dentro del rango de fechas\n",
    "Df_MS_Neg = Df_MS_Neg[(Df_MS_Neg['Fecha_Proceso'] >= Mes_Ini) & (Df_MS_Neg['Fecha_Proceso'] <= Mes_Fin)]\n",
    "print(\"Número de registros despues de filtrar fecha proceso:\", len(Df_MS_Neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 4.3 MS validados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las columnas a formato datetime\n",
    "Df_MS_Val['AFL_FECHA_NACIMIENTO'] = pd.to_datetime(Df_MS_Val['AFL_FECHA_NACIMIENTO'], format='%d/%m/%Y')\n",
    "Df_MS_Val['CND_AFL_FECHA_INICIO'] = pd.to_datetime(Df_MS_Val['CND_AFL_FECHA_INICIO'], format='%d/%m/%Y')\n",
    "Df_MS_Val['Fecha_Proceso'] = pd.to_datetime(Df_MS_Val['Fecha_Proceso'], format='%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Número de registros antes de filtrar Fecha proceso:\", len(Df_MS_Val))\n",
    "# Filtrar registros dentro del rango de fechas\n",
    "Df_MS_Val = Df_MS_Val[(Df_MS_Val['Fecha_Proceso'] >= Mes_Ini) & (Df_MS_Val['Fecha_Proceso'] <= Mes_Fin)]\n",
    "print(\"Número de registros despues de filtrar fecha proceso:\", len(Df_MS_Val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "# 5. Analisis de los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## 5.1. métricas inicales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### 5.1 Cálculo de glosas reales por registro\n",
    "¿Por qué agrupamos por llave “total” y no por fecha de reporte?\n",
    "\n",
    "Llave de negocio constante\n",
    "\n",
    "(ENT_ID, TPS_IDN_ID, HST_IDN_NUMERO_IDENTIFICACION) identifica única e invariablemente a cada afiliado.\n",
    "\n",
    "Incluir Fecha_Proceso en la llave creararía claves distintas para un mismo usuario en cada envío, rompiendo la trazabilidad.\n",
    "\n",
    "Fecha_Proceso como dimensión temporal\n",
    "\n",
    "La usamos fuera de la llave para:\n",
    "\n",
    "Ordenar cronológicamente las glosas.\n",
    "\n",
    "Filtrar por cortes (cuatrimestrales, últimos envíos, etc.).\n",
    "\n",
    "Determinar la “última glosa” de cada afiliado y quién queda pendiente.\n",
    "\n",
    "Beneficio\n",
    "\n",
    "Obtenemos métricas globales (total de glosas, promedio de reintentos, registros pendientes) sin fragmentar la identidad.\n",
    "\n",
    "Podemos profundizar por período sin comprometer la agregación histórica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —————————————————————————————————————\n",
    "# 1) Definir la llave única de afiliado\n",
    "# —————————————————————————————————————\n",
    "keys = [\"ENT_ID\", \"TPS_IDN_ID\", \"HST_IDN_NUMERO_IDENTIFICACION\"]\n",
    "\n",
    "Df_MS_Neg[\"_key\"] = (\n",
    "    Df_MS_Neg[keys]\n",
    "      .astype(str)\n",
    "      .agg('|'.join, axis=1)\n",
    ")\n",
    "Df_MS_Val[\"_key\"] = (\n",
    "    Df_MS_Val[keys]\n",
    "      .astype(str)\n",
    "      .agg('|'.join, axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### 5.1.2. Contar cuántas glosas tuvo cada registro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —————————————————————————————————————\n",
    "# 2) Contar “glosas reales” en cada fila\n",
    "# —————————————————————————————————————\n",
    "def contar_glosas(texto: str) -> int:\n",
    "    # cada glosa está separada por ';'\n",
    "    trozos = texto.strip(';').split(';')\n",
    "    return sum(1 for g in trozos if g)\n",
    "\n",
    "Df_MS_Neg[\"n_glosas\"] = Df_MS_Neg[\"GLOSA\"].apply(contar_glosas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### 5.1.3. ¿Cuántos registros terminaron validados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —————————————————————————————————————\n",
    "# 3) Agregar total de glosas por registro\n",
    "# —————————————————————————————————————\n",
    "neg_count = (\n",
    "    Df_MS_Neg\n",
    "      .groupby(\"_key\")[\"n_glosas\"]\n",
    "      .sum()\n",
    "      .rename(\"total_glosas\")\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# Distribución de glosas\n",
    "print(neg_count[\"total_glosas\"].value_counts().sort_index())\n",
    "\n",
    "# Promedio de glosas por registro\n",
    "print(\"Promedio de glosas por registro:\",\n",
    "      neg_count[\"total_glosas\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### 5.1.4. ¿Cuántas veces, en promedio, se glosó un registro antes de validarse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —————————————————————————————————————\n",
    "# 4) ¿Cuántos registros terminaron validados?\n",
    "# —————————————————————————————————————\n",
    "val_keys = set(Df_MS_Val[\"_key\"])\n",
    "neg_count[\"fue_validado\"] = neg_count[\"_key\"].isin(val_keys)\n",
    "\n",
    "print(f\"De {len(neg_count)} registros negados, \"\n",
    "      f\"{neg_count['fue_validado'].sum()} acabaron validados.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### 5.1.5 Promedio de glosas antes de validar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —————————————————————————————————————\n",
    "# 5) Promedio de glosas antes de validar\n",
    "# —————————————————————————————————————\n",
    "promedio_antes = neg_count.loc[\n",
    "    neg_count[\"fue_validado\"], \"total_glosas\"\n",
    "].mean()\n",
    "print(\"Promedio de glosas antes de validar:\", promedio_antes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### 5.1.6 Registros glosados en el último envío\n",
    "Entendemos que el “último reporte” es la fecha máxima de Fecha_Proceso (ultimo reporte del mes). Los registros glosados en esa fecha son los que pasan al siguiente cuatrimestre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —————————————————————————————————————\n",
    "# 6) Registros glosados en el último envío\n",
    "#    (pendientes para el próximo cuatrimestre)\n",
    "# —————————————————————————————————————\n",
    "ultima_fecha = Df_MS_Neg[\"Fecha_Proceso\"].max()\n",
    "quedan_para_siguiente = (\n",
    "    Df_MS_Neg\n",
    "      .loc[Df_MS_Neg[\"Fecha_Proceso\"] == ultima_fecha, \"_key\"]\n",
    "      .nunique()\n",
    ")\n",
    "print(\"Registros glosados en el último envío (pendientes):\",\n",
    "      quedan_para_siguiente)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### 5.1.7 Identificar registros glosados sin re-envío"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —————————————————————————————————————\n",
    "# 7) Identificar registros glosados sin re-envío\n",
    "# —————————————————————————————————————\n",
    "\n",
    "# a) Obtengo la última fecha de glosa de cada afiliado\n",
    "last_neg = (\n",
    "    Df_MS_Neg\n",
    "      .groupby(\"_key\")[\"Fecha_Proceso\"]\n",
    "      .max()\n",
    "      .reset_index()\n",
    "      .rename(columns={\"Fecha_Proceso\":\"last_neg_date\"})\n",
    ")\n",
    "\n",
    "# b) Marco si hubo re-envío posterior a esa fecha\n",
    "#    uniendo con el mismo Df_MS_Neg y comprobando fechas\n",
    "tmp = Df_MS_Neg.merge(last_neg, on=\"_key\", how=\"inner\")\n",
    "tiene_reenvio = (\n",
    "    tmp\n",
    "      .assign(flag = tmp[\"Fecha_Proceso\"] > tmp[\"last_neg_date\"])\n",
    "      .groupby(\"_key\")[\"flag\"]\n",
    "      .any()\n",
    "      .reset_index()\n",
    "      .rename(columns={\"flag\":\"tiene_reenvio\"})\n",
    ")\n",
    "\n",
    "last_neg = last_neg.merge(tiene_reenvio, on=\"_key\")\n",
    "\n",
    "# c) Filtrar los que NO tuvieron re-envío y además NO están en validados\n",
    "val_keys = set(Df_MS_Val[\"_key\"])\n",
    "no_reenviado = last_neg[\n",
    "    (~ last_neg[\"tiene_reenvio\"]) &\n",
    "    (~ last_neg[\"_key\"].isin(val_keys))\n",
    "]\n",
    "\n",
    "print(\"Registros glosados que no volvieron a enviarse:\", len(no_reenviado))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "## 5.2. diagnóstico de los registros glosados que no se volvieron a enviar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "### 5..2.1 Identificar los afiliados sin re-envío\n",
    "Partimos del DataFrame last_neg (o de no_reenviado) que ya contiene la llave _key de quienes no tuvieron un envío posterior y no fueron validados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asumiendo que ya tienes `no_reenviado` con la lista de keys:\n",
    "keys_no_re = set(no_reenviado[\"_key\"])\n",
    "\n",
    "# Filtramos todas las filas originales de Df_MS_Neg de estos keys:\n",
    "df_nr = Df_MS_Neg[ Df_MS_Neg[\"_key\"].isin(keys_no_re) ].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "### 5.2.2 “Explotar” cada glosa en una fila\n",
    "Convertimos la columna 'Glosa' (con uno o varios GNxxxx(...) separados por ;) en filas independientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Separamos por `;`\n",
    "df_nr[\"lst_glosa\"] = df_nr[\"GLOSA\"].str.strip(\";\").str.split(\";\")\n",
    "\n",
    "# 2) Explode para tener una fila por cada glosa\n",
    "df_expl = df_nr.explode(\"lst_glosa\").rename(columns={\"lst_glosa\":\"glosa_raw\"})\n",
    "\n",
    "# 3) Extraemos el código (primeros 6 caracteres: GN + 4 dígitos)\n",
    "df_expl[\"GN\"] = df_expl[\"glosa_raw\"].str[:6]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "### 5.2.3 Unir con el diccionario de glosas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expl = (\n",
    "    df_expl\n",
    "      .merge(\n",
    "         df_glosas,\n",
    "         left_on=\"GN\",\n",
    "         right_on=\"Glosa\",    # suponiendo que en df_glosas la columna de código se llama \"Glosa\"\n",
    "         how=\"left\"\n",
    "      )\n",
    "      .rename(columns={\"Descripción\":\"descr_glosa\"})\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "### 5.2.4 Contar y visualizar las causas\n",
    "1. Top códigos que no se re-envían:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_glosas = df_expl[\"GN\"].value_counts().head(10)\n",
    "print(top_glosas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "2. Tabla con descripción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Permitir mostrar texto completo en las celdas\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "# 2) Armar la tabla de glosas con descripción\n",
    "top_tabla = (\n",
    "    df_expl[[\"GN\", \"descr_glosa\"]]\n",
    "      .drop_duplicates(subset=[\"GN\"])\n",
    "      .set_index(\"GN\")\n",
    "      .loc[top_glosas.index]\n",
    ")\n",
    "\n",
    "# 3) Quitar el nombre del índice (para que solo haya un encabezado)\n",
    "top_tabla.index.name = None\n",
    "\n",
    "datos = top_glosas.sort_values()\n",
    "# ---------------------------------------------------\n",
    "# datos = top_glosas  # Serie index=GN, values=conteo\n",
    "top_tabla[\"Frecuencia\"] = datos.reindex(top_tabla.index).fillna(0).astype(int)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2) Reordenar columnas: Frecuencia primero\n",
    "# ---------------------------------------------------\n",
    "top_tabla = top_tabla[[\"Frecuencia\", \"descr_glosa\"]]\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3) Preparar estilos con pandas Styler\n",
    "# ---------------------------------------------------\n",
    "pd.set_option(\"display.max_colwidth\", None)    # que no trunque el texto\n",
    "\n",
    "# Definimos estilos CSS para la tabla\n",
    "styles = [\n",
    "    # Encabezado\n",
    "    {\n",
    "      \"selector\": \"th\",\n",
    "      \"props\": [\n",
    "        (\"background-color\", \"#4F81BD\"),\n",
    "        (\"color\", \"white\"),\n",
    "        (\"font-weight\", \"bold\"),\n",
    "        (\"text-align\", \"center\"),\n",
    "        (\"padding\", \"8px\")\n",
    "      ]\n",
    "    },\n",
    "    # Celdas de datos\n",
    "    {\n",
    "      \"selector\": \"td\",\n",
    "      \"props\": [\n",
    "        (\"padding\",        \"6px\"),\n",
    "        (\"border\",         \"1px solid #dddddd\")\n",
    "      ]\n",
    "    },\n",
    "    # Alineamos la columna Frecuencia al centro\n",
    "    {\n",
    "      \"selector\": \"td.row0.col0, td.row1.col0, td.row2.col0, td.row3.col0, td.row4.col0, td.row5.col0, td.row6.col0\",\n",
    "      \"props\": [(\"text-align\", \"center\")]\n",
    "    },\n",
    "    # Celda de índice (GN) con negrita\n",
    "    {\n",
    "      \"selector\": \"th.row_heading\",\n",
    "      \"props\": [(\"font-weight\", \"bold\")]\n",
    "    }\n",
    "]\n",
    "\n",
    "styled = (\n",
    "    top_tabla.style\n",
    "      .set_table_styles(styles)\n",
    "      .format({\"Frecuencia\": \"{:d}\"})    # formateo entero sin decimales\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# 1) Limitar ancho de tabla y permitir wrap\n",
    "# ---------------------------------------------------\n",
    "styled = (\n",
    "    top_tabla.style\n",
    "\n",
    "      # 1.1) Ancho total y fixed layout\n",
    "      .set_table_attributes(\n",
    "          'style=\"width:500px; table-layout: fixed; margin-left: auto; margin-right: auto;\"'\n",
    "      )\n",
    "\n",
    "      # 1.2) Estilos generales y de header (como ya tenías)\n",
    "      .set_table_styles(styles)\n",
    "\n",
    "      # 1.3) Para TODAS las celdas: envolver texto y permitir break-word\n",
    "      .set_properties(\n",
    "          **{\n",
    "             \"white-space\": \"normal\", \n",
    "             \"word-wrap\":   \"break-word\",\n",
    "             \"overflow\":    \"hidden\"\n",
    "          }\n",
    "      )\n",
    "\n",
    "      # 1.4) Formato de la frecuencia\n",
    "      .format({\"Frecuencia\": \"{:d}\"})\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2) Mostrar en el notebook\n",
    "# ---------------------------------------------------\n",
    "display(styled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "3. Usar un treemap\n",
    "Un treemap condensa proporción + etiquetas (códigos) en rectángulos de distinto tamaño. Con squarify queda así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar de menor a mayor para barras horizontales\n",
    "datos = top_glosas.sort_values()\n",
    "top3 = datos.nlargest(3)\n",
    "other = datos.iloc[3:].sum()\n",
    "# Crear una nueva serie con \"Otros\"\n",
    "otros_serie = pd.Series({\"Otros\": other})\n",
    "# Usar pd.concat para combinar las series\n",
    "resumen = pd.concat([top3, otros_serie])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import squarify\n",
    "\n",
    "# 1) Configuración de directorios\n",
    "graficas_dir = os.path.join(R_Salida, \"Graficas\")\n",
    "os.makedirs(graficas_dir, exist_ok=True)\n",
    "\n",
    "# 2) Preparación de Datos\n",
    "sizes = datos.values\n",
    "total = sizes.sum()\n",
    "codigos = datos.index # Guardamos los índices para usarlos en el bucle\n",
    "\n",
    "# Colores Pastel (Set3)\n",
    "cmap = plt.cm.Set3\n",
    "colors = [cmap(i/len(sizes)) for i in range(len(sizes))]\n",
    "\n",
    "# 3) Generación de la gráfica (SIN ETIQUETAS AUTOMÁTICAS)\n",
    "fig = plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Dibujamos solo los rectángulos primero. Ponemos label=None para hacerlo manual después.\n",
    "ax = squarify.plot(\n",
    "    sizes=sizes,\n",
    "    label=None, \n",
    "    color=colors,\n",
    "    alpha=1,\n",
    "    pad=True\n",
    ")\n",
    "\n",
    "# 4) Lógica de Etiquetado Manual (La parte mágica)\n",
    "# Iteramos sobre cada rectángulo (patch) generado por squarify\n",
    "for i, rect in enumerate(ax.patches):\n",
    "    # Obtenemos los datos correspondientes al rectángulo actual\n",
    "    count = sizes[i]\n",
    "    percent = (count / total) * 100\n",
    "    code = codigos[i]\n",
    "    \n",
    "    # Texto a mostrar (Completo)\n",
    "    label_text = f\"{code}\\n{count} ({percent:.1f}%)\"\n",
    "    \n",
    "    # --- LÓGICA DE TAMAÑO DINÁMICO ---\n",
    "    # Calculamos el centro del rectángulo para poner el texto\n",
    "    x = rect.get_x() + rect.get_width() / 2\n",
    "    y = rect.get_y() + rect.get_height() / 2\n",
    "    \n",
    "    # Decidimos el tamaño de la letra según el porcentaje\n",
    "    if percent > 5:\n",
    "        font_size = 11\n",
    "        font_weight = 'bold'\n",
    "    elif percent > 2.5:\n",
    "        font_size = 9   # Mediano para cajas medianas\n",
    "        font_weight = 'bold'\n",
    "    else:\n",
    "        font_size = 6   # Pequeño para que quepa todo en cajas chicas\n",
    "        font_weight = 'normal' # Quitamos negrita para que sea más legible en tamaño 6\n",
    "\n",
    "    # Insertamos el texto manualmente en las coordenadas calculadas\n",
    "    ax.text(\n",
    "        x, y, \n",
    "        label_text, \n",
    "        fontsize=font_size, \n",
    "        weight=font_weight, \n",
    "        color='black',\n",
    "        ha='center', # Alineación horizontal centrada\n",
    "        va='center'  # Alineación vertical centrada\n",
    "    )\n",
    "\n",
    "# 5) Detalles finales\n",
    "plt.axis('off')\n",
    "plt.title(\"Distribución de Glosas sin Reenvío (Top Glosas)\", fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "ruta_png = os.path.join(graficas_dir, \"treemap_glosas_dinamico.png\")\n",
    "fig.savefig(ruta_png, bbox_inches=\"tight\", dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "## 5.3 Tiempo de resolución\n",
    "* ¿Cuánto tarda, en promedio, desde la primera glosa de un registro hasta que finalmente se valida (o queda pendiente)?\n",
    "* Cálculo: para cada _key,\n",
    "\n",
    "En esta sección calculamos el tiempo (en días) que transcurre desde la **primera glosa** de cada afiliado hasta que finalmente aparece **validado** en ADRES.  \n",
    "Este indicador nos ayudará a identificar cuellos de botella en el proceso de corrección y reenvío.\n",
    "\n",
    "**Pasos**:   \n",
    "1. Para cada afiliado (`_key`), obtener las fechas de primera glosa y primera validación.  \n",
    "2. Calcular la diferencia en días.  \n",
    "3. Generar estadísticas descriptivas y visualizar la distribución.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3.1 Fecha de primera glosa por afiliado\n",
    "primera_neg = (\n",
    "    Df_MS_Neg\n",
    "      .groupby(\"_key\")[\"Fecha_Proceso\"]\n",
    "      .min()\n",
    "      .rename(\"fecha_primera_glosa\")\n",
    ")\n",
    "\n",
    "# Fecha de primera validación por afiliado\n",
    "primera_val = (\n",
    "    Df_MS_Val\n",
    "      .groupby(\"_key\")[\"Fecha_Proceso\"]\n",
    "      .min()\n",
    "      .rename(\"fecha_primera_validacion\")\n",
    ")\n",
    "\n",
    "# Unir en un único DataFrame\n",
    "df_tiempo = pd.concat([primera_neg, primera_val], axis=1).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "### 5.3.1. Medir resolución en “ciclos de envío” en vez de días\n",
    "En lugar de contar días, calculemos cuántos envíos tardó cada registro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3.4 Añadir columna de días de resolución\n",
    "df_tiempo[\"dias_resolucion\"] = (\n",
    "    df_tiempo[\"fecha_primera_validacion\"] - \n",
    "    df_tiempo[\"fecha_primera_glosa\"]\n",
    ").dt.days\n",
    "\n",
    "# Estadísticas descriptivas\n",
    "stats = df_tiempo[\"dias_resolucion\"].describe().round(1)\n",
    "print(\"Estadísticas de tiempo de resolución (días):\\n\", stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "### 5.3.2 Visualización de la distribución\n",
    "\n",
    "– **Histograma** para ver la forma de la distribución.  \n",
    "– **Boxplot** para identificar posibles valores atípicos (outliers).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Asegúrate de tener definida tu carpeta de gráficas\n",
    "graficas_dir = os.path.join(R_Salida, \"Graficas\")\n",
    "os.makedirs(graficas_dir, exist_ok=True)\n",
    "\n",
    "# 2) Crea la figura y los ejes\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,4))\n",
    "\n",
    "# Histograma\n",
    "ax1.hist(df_tiempo[\"dias_resolucion\"], bins=20, edgecolor='k')\n",
    "ax1.set_xlabel(\"Días para validación\")\n",
    "ax1.set_ylabel(\"Número de registros\")\n",
    "ax1.set_title(\"Histograma de tiempo de resolución\")\n",
    "\n",
    "# Boxplot\n",
    "ax2.boxplot(df_tiempo[\"dias_resolucion\"], vert=False)\n",
    "ax2.set_xlabel(\"Días para validación\")\n",
    "ax2.set_title(\"Boxplot de tiempo de resolución\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# 3) Guardar la figura completa\n",
    "ruta_png = os.path.join(graficas_dir, \"tiempo_resolucion.png\")\n",
    "fig.savefig(ruta_png, bbox_inches=\"tight\")\n",
    "\n",
    "# 4) Mostrar en el notebook (opcional)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "**Interpretación rápida**:  \n",
    "- La media y mediana nos indican el tiempo típico de resolución.  \n",
    "- El histograma muestra si hay sesgos o concentraciones en rangos de días.  \n",
    "- El boxplot revela outliers que podrían requerir un tratamiento especial (casos que tardan demasiado).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "### 5.3.3. Medir resolución en “ciclos de envío” en vez de días\n",
    "En lugar de contar días, calculemos cuántos envíos tardó cada registro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Generar la serie de fechas de envío (viernes hábiles según ADRES)\n",
    "#    Aquí simplificamos a todos los viernes; en producción podrías ajustar feriados.\n",
    "envios = pd.date_range(\n",
    "    start= Df_MS_Neg[\"Fecha_Proceso\"].min().floor('D'),\n",
    "    end= Df_MS_Val[\"Fecha_Proceso\"].max().ceil('D'),\n",
    "    freq='W-FRI'\n",
    ")\n",
    "\n",
    "# 2. Función para contar envíos entre dos fechas\n",
    "def ciclos_entre(fecha_ini, fecha_val):\n",
    "    return ((envios > fecha_ini) & (envios <= fecha_val)).sum()\n",
    "\n",
    "# 3. Aplicar al DataFrame de tiempos\n",
    "df_tiempo[\"ciclos_resolucion\"] = df_tiempo.apply(\n",
    "    lambda row: ciclos_entre(\n",
    "        row[\"fecha_primera_glosa\"], \n",
    "        row[\"fecha_primera_validacion\"]\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# 4. Estadísticas de ciclos\n",
    "print(\"Distribución de ciclos de resolución:\\n\",\n",
    "      df_tiempo[\"ciclos_resolucion\"].value_counts().sort_index())\n",
    "print(\"\\nPromedio de ciclos:\", df_tiempo[\"ciclos_resolucion\"].mean().round(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "### 5.3.4 Visualizar ciclos de resolución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Df_MS_Neg['Fecha_Proceso'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Asegúrate de que exista la carpeta de gráficas\n",
    "graficas_dir = os.path.join(R_Salida, \"Graficas\")\n",
    "os.makedirs(graficas_dir, exist_ok=True)\n",
    "\n",
    "# 2) Crear la figura y el eje\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "\n",
    "# 3) Dibujar el bar plot\n",
    "df_tiempo[\"ciclos_resolucion\"]\\\n",
    "    .value_counts()\\\n",
    "    .sort_index()\\\n",
    "    .plot.bar(ax=ax)\n",
    "\n",
    "ax.set_xlabel(\"Número de envíos para resolución\")\n",
    "ax.set_ylabel(\"Número de registros\")\n",
    "ax.set_title(\"Ciclos de envío necesarios para corregir glosa\")\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# 4) Guardar la figura\n",
    "ruta_png = os.path.join(graficas_dir, \"ciclos_resolucion.png\")\n",
    "fig.savefig(ruta_png, bbox_inches=\"tight\")\n",
    "\n",
    "# 5) Mostrar (opcional)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "## 5.4 Análisis de combinaciones de glosas\n",
    "\n",
    "En muchos casos un **mismo registro** recibe **varias glosas** en un solo envío.  \n",
    "Detectar patrones de **co-ocurrencia** de códigos nos ayuda a identificar combinaciones frecuentes que podrían tener causas comunes o requerir un mismo proceso de corrección.  \n",
    "\n",
    "**Pasos**:  \n",
    "1. Para cada fila de `Df_MS_Neg`, parsear la lista de códigos GN.  \n",
    "2. Generar todas las **parejas** posibles de códigos dentro de cada fila.  \n",
    "3. Contar cuántas veces aparece cada **par** en todo el conjunto.  \n",
    "4. Mostrar los **top 10 pares** más frecuentes y un **heatmap** de co-ocurrencia para los principales códigos.\n",
    "### 5.5.1 Extraer lista de códigos por fila y generar pares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.5.1 Extraer lista de códigos por fila y generar pares\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "\n",
    "# Asegurarnos de tener df_expl/df_nr o volver a parsear desde Df_MS_Neg\n",
    "# Aquí volvemos a extraer de Df_MS_Neg\n",
    "def lista_gn(glosa_str):\n",
    "    return [g[:6] for g in glosa_str.strip(\";\").split(\";\") if g]\n",
    "\n",
    "# Generate pairs counter\n",
    "pair_counter = Counter()\n",
    "for lst in Df_MS_Neg[\"GLOSA\"].dropna().apply(lista_gn):\n",
    "    # solo filas con al menos 2 glosas\n",
    "    if len(lst) > 1:\n",
    "        for a,b in combinations(sorted(set(lst)), 2):\n",
    "            pair_counter[(a,b)] += 1\n",
    "\n",
    "# Top 10 pares más frecuentes\n",
    "top_pairs = pair_counter.most_common(10)\n",
    "top_pairs_df = pd.DataFrame(top_pairs, columns=[\"Par\", \"Frecuencia\"])\n",
    "top_pairs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "### 5.4.2 Visualizar los 10 pares más frecuentes\n",
    "\n",
    "La tabla anterior muestra los pares de GN que más aparecen juntos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Asegurarnos de que exista la carpeta Graficas\n",
    "graficas_dir = os.path.join(R_Salida, \"Graficas\")\n",
    "os.makedirs(graficas_dir, exist_ok=True)\n",
    "\n",
    "# 2) Preparar datos\n",
    "pairs = [\" & \".join(p) for p,_ in top_pairs]\n",
    "freqs = [f for _,f in top_pairs]\n",
    "\n",
    "# 3) Crear figura y eje\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "ax.barh(pairs[::-1], freqs[::-1])\n",
    "ax.set_xlabel(\"Frecuencia de co-ocurrencia\")\n",
    "ax.set_title(\"Top 10 pares de glosas que ocurren juntos\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# 4) Guardar la figura\n",
    "ruta_png = os.path.join(graficas_dir, \"top_pares_glosas.png\")\n",
    "fig.savefig(ruta_png, bbox_inches=\"tight\")\n",
    "\n",
    "# 5) Mostrar en notebook (opcional)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "### 5.4.3 Heatmap de co-ocurrencia para los principales códigos\n",
    "\n",
    "Para un vistazo más amplio, construimos una matriz de co-ocurrencia para los **top 6** códigos individuales y la mostramos como heatmap.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Asegurar carpeta de gráficas\n",
    "graficas_dir = os.path.join(R_Salida, \"Graficas\")\n",
    "os.makedirs(graficas_dir, exist_ok=True)\n",
    "\n",
    "# 2) Preparar datos para el heatmap\n",
    "top_codes = pd.Series(pair_counter).explode().value_counts().head(6).index.tolist()\n",
    "mat = pd.DataFrame(0, index=top_codes, columns=top_codes)\n",
    "for (a,b), cnt in pair_counter.items():\n",
    "    if a in top_codes and b in top_codes:\n",
    "        mat.loc[a,b] = cnt\n",
    "        mat.loc[b,a] = cnt\n",
    "\n",
    "# 3) Crear figura y dibujar heatmap\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "sns.heatmap(mat, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax)\n",
    "ax.set_title(\"Heatmap de co-ocurrencia de glosas (top 6 códigos)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# 4) Guardar en archivo PNG\n",
    "ruta_png = os.path.join(graficas_dir, \"heatmap_coocurrencia.png\")\n",
    "fig.savefig(ruta_png, bbox_inches=\"tight\")\n",
    "\n",
    "# 5) Mostrar en el notebook\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "**Interpretación**:  \n",
    "- El bar chart revela qué combinaciones de glosas suelen aparecer juntas, sugiriendo procesos de corrección simultáneos.  \n",
    "- El heatmap muestra la relación entre los **códigos más críticos**, ayudándote a priorizar validaciones conjuntas o flujos de trabajo mixtos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "## 5.5. Efectividad de Corrección\n",
    "\n",
    "En esta sección calculamos la **efectividad** de nuestro flujo de glosas, entendida como el porcentaje de registros glosados que finalmente quedan **validados**:\n",
    "\n",
    "1. **Por envío**: del total de registros glosados en un envío, ¿qué % se valida en el envío siguiente?  \n",
    "2. **Por mes**: del total de glosados en un mes, ¿qué % se valida en el mismo mes?  \n",
    "3. **Por cuatrimestre** (cuando tengamos más data): del total de glosados en un cuatrimestre, ¿qué % se valida antes de cerrar el periodo?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "### 5.5.1 Preparación: lista de envíos ordenados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Lista completa de envíos\n",
    "envios = sorted(Df_MS_Neg[\"Fecha_Proceso\"].unique())\n",
    "\n",
    "efic_envio = []\n",
    "for i, fecha in enumerate(envios):\n",
    "    # claves glosadas en este envío\n",
    "    neg_keys = set(\n",
    "        Df_MS_Neg.loc[Df_MS_Neg[\"Fecha_Proceso\"] == fecha, \"_key\"]\n",
    "    )\n",
    "    # si hay un siguiente envío, contamos validados; si no, 0\n",
    "    if i < len(envios) - 1:\n",
    "        next_fecha = envios[i+1]\n",
    "        val_next = set(\n",
    "            Df_MS_Val.loc[Df_MS_Val[\"Fecha_Proceso\"] == next_fecha, \"_key\"]\n",
    "        )\n",
    "        n_val = len(neg_keys & val_next)\n",
    "    else:\n",
    "        n_val = 0\n",
    "\n",
    "    n_tot = len(neg_keys)\n",
    "    efect = (n_val / n_tot * 100) if n_tot else None\n",
    "\n",
    "    efic_envio.append({\n",
    "        \"envio\": fecha,\n",
    "        \"glosados\": n_tot,\n",
    "        \"validados_next\": n_val,\n",
    "        \"efectividad\": round(efect,1) if efect is not None else None\n",
    "    })\n",
    "\n",
    "# 2) Crear el DataFrame final y mostrarlo\n",
    "df_efic_envio = pd.DataFrame(efic_envio).set_index(\"envio\")\n",
    "display(df_efic_envio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "### 5.5.2 Resultados por envío\n",
    "\n",
    "| Envío      | Glosados | Validados en próximo envío | Efectividad (%) |\n",
    "|:----------:|:--------:|:--------------------------:|:---------------:|\n",
    "{{ aquí ya no necesitas nada, porque la tabla la genera el display() }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Creamos el DataFrame y redondeamos\n",
    "df_efic_envio = pd.DataFrame(efic_envio).set_index(\"envio\").round(1)\n",
    "\n",
    "# 2. Reordenamos las columnas en el orden que queremos ver\n",
    "df_efic_envio = df_efic_envio[[\"glosados\", \"validados_next\", \"efectividad\"]]\n",
    "\n",
    "# 3. Renombramos para que coincidan con tu tabla de Markdown\n",
    "df_efic_envio = df_efic_envio.rename(\n",
    "    columns={\n",
    "        \"glosados\": \"Glosados\",\n",
    "        \"validados_next\": \"Validados en próximo envío\",\n",
    "        \"efectividad\": \"Efectividad (%)\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# 4. Opcional: convertimos el índice a string para que no salga con Timestamp\n",
    "df_efic_envio.index = df_efic_envio.index.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 5. Mostramos el resultado\n",
    "from IPython.display import display\n",
    "display(df_efic_envio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "### 5.5.3 Gráfico de efectividad por envío"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "1. Gráfico combinado: volumen + eficacia\n",
    "\n",
    "Comparación de volumen de glosados y tasa de corrección por envío"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Asegúrate de tener definida la carpeta de salida de gráficas\n",
    "graficas_dir = os.path.join(R_Salida, \"Graficas\")\n",
    "os.makedirs(graficas_dir, exist_ok=True)\n",
    "\n",
    "# 2) Crea la figura y los ejes\n",
    "fig, ax1 = plt.subplots(figsize=(8,4))\n",
    "\n",
    "# Barras de glosados\n",
    "ax1.bar(\n",
    "    df_efic_envio.index,\n",
    "    df_efic_envio[\"Glosados\"],\n",
    "    alpha=0.6,\n",
    "    label=\"Glosados por envío\"\n",
    ")\n",
    "ax1.set_ylabel(\"Glosados\", color=\"tab:blue\")\n",
    "ax1.tick_params(axis=\"y\", labelcolor=\"tab:blue\")\n",
    "\n",
    "# Línea de efectividad en eje derecho\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(\n",
    "    df_efic_envio.index,\n",
    "    df_efic_envio[\"Efectividad (%)\"],\n",
    "    color=\"tab:orange\",\n",
    "    marker=\"o\",\n",
    "    label=\"Efectividad (%)\"\n",
    ")\n",
    "ax2.set_ylabel(\"Efectividad (%)\", color=\"tab:orange\")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=\"tab:orange\")\n",
    "ax2.set_ylim(0, 100)\n",
    "\n",
    "# Anotar valores de eficacia sobre cada punto\n",
    "for x, y in zip(df_efic_envio.index, df_efic_envio[\"Efectividad (%)\"]):\n",
    "    ax2.text(x, y + 3, f\"{y:.0f}%\", ha=\"center\", color=\"tab:orange\")\n",
    "\n",
    "# Estética\n",
    "ax1.set_title(\"Volumen de glosados vs Efectividad por envío\")\n",
    "ax1.set_xticklabels(df_efic_envio.index, rotation=45, ha=\"right\")\n",
    "ax1.legend(loc=\"upper left\")\n",
    "ax2.legend(loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# 3) Guardar la figura en PNG\n",
    "ruta_png = os.path.join(graficas_dir, \"volumen_vs_efectividad_envio.png\")\n",
    "fig.savefig(ruta_png, bbox_inches=\"tight\")\n",
    "\n",
    "# 4) Mostrarla en pantalla (opcional)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "2. Barras horizontales con umbral\n",
    "\n",
    "Cumplimiento del 50 % de efectividad — envíos fuera de SLA en rojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Asegura que exista la carpeta de gráficas\n",
    "graficas_dir = os.path.join(R_Salida, \"Graficas\")\n",
    "os.makedirs(graficas_dir, exist_ok=True)\n",
    "\n",
    "# 1) Definimos constantes\n",
    "THRESHOLD = 50\n",
    "COLOR_OK   = \"tab:green\"\n",
    "COLOR_FAIL = \"tab:red\"\n",
    "\n",
    "# 2) Preparamos los datos y la máscara\n",
    "efic = df_efic_envio[\"Efectividad (%)\"]\n",
    "idx  = df_efic_envio.index\n",
    "mask_ok   = efic >= THRESHOLD\n",
    "mask_fail = ~mask_ok\n",
    "\n",
    "# 3) Dibujamos\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "\n",
    "# Barras de los que cumplen\n",
    "ax.barh(\n",
    "    idx[mask_ok],\n",
    "    efic[mask_ok],\n",
    "    color=COLOR_OK,\n",
    "    label=f\">= {THRESHOLD}%\"\n",
    ")\n",
    "\n",
    "# Barras de los que no cumplen\n",
    "ax.barh(\n",
    "    idx[mask_fail],\n",
    "    efic[mask_fail],\n",
    "    color=COLOR_FAIL,\n",
    "    label=f\"< {THRESHOLD}%\"\n",
    ")\n",
    "\n",
    "# 4) Línea de umbral y anotaciones\n",
    "ax.axvline(THRESHOLD, color=\"gray\", linestyle=\"--\")\n",
    "ax.text(\n",
    "    THRESHOLD, -0.5,\n",
    "    f\"Objetivo {THRESHOLD}%\",\n",
    "    ha=\"center\", va=\"bottom\", color=\"gray\"\n",
    ")\n",
    "\n",
    "for i, v in enumerate(efic):\n",
    "    ax.text(\n",
    "        v + 1,\n",
    "        i,\n",
    "        f\"{v:.0f}%\",\n",
    "        va=\"center\"\n",
    "    )\n",
    "\n",
    "# 5) Ejes y leyenda\n",
    "ax.set_xlabel(\"Efectividad (%)\")\n",
    "ax.set_title(\"Efectividad de corrección por envío\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# 6) Guardar la figura\n",
    "ruta_png = os.path.join(graficas_dir, \"efectividad_envio_horizontal.png\")\n",
    "fig.savefig(ruta_png, bbox_inches=\"tight\")\n",
    "\n",
    "# 7) Mostrarla en pantalla\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {},
   "source": [
    "### 5.5.4 Efectividad mensual\n",
    "\n",
    "Para el indicador mensual definimos:\n",
    "- **Denominador**: todos los registros glosados en el mes “M”.  \n",
    "- **Numerador**: de esos, los que quedaron validados **en ese mismo mes** “M”.\n",
    "\n",
    "Esto simula tu reporte mensual de efectividad, que excluye validaciones que caen en meses posteriores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar mes de proceso\n",
    "Df_MS_Neg[\"mes\"] = Df_MS_Neg[\"Fecha_Proceso\"].dt.to_period(\"M\")\n",
    "Df_MS_Val[\"mes\"] = Df_MS_Val[\"Fecha_Proceso\"].dt.to_period(\"M\")\n",
    "\n",
    "# Calcular efectividad por mes\n",
    "meses = sorted(Df_MS_Neg[\"mes\"].unique())\n",
    "efic_mes = []\n",
    "\n",
    "for mes in meses:\n",
    "    neg_keys = set(Df_MS_Neg.loc[ Df_MS_Neg[\"mes\"]==mes, \"_key\" ])\n",
    "    val_keys = set(Df_MS_Val.loc[ Df_MS_Val[\"mes\"]==mes, \"_key\" ])\n",
    "    n_tot = len(neg_keys)\n",
    "    n_val = len(neg_keys & val_keys)\n",
    "    efic = n_val / n_tot * 100 if n_tot else None\n",
    "    efic_mes.append({\"mes\": str(mes), \"glosados\":n_tot, \"val_mes\":n_val, \"efectividad\":round(efic,1)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "### 5.5.5 Resultados mensuales\n",
    "\n",
    "| Mes     | Glosados | Validados en mes | Efectividad (%) |\n",
    "|:-------:|---------:|-----------------:|----------------:|\n",
    "{{ muestra `df_efic_mes` }}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partiendo de tu df_efic_mes ya renombrado\n",
    "df_efic_mes = pd.DataFrame(efic_mes).set_index(\"mes\")\n",
    "\n",
    "# Renombrar índice y columnas\n",
    "df_efic_mes.index.name = \"Mes\"\n",
    "df_efic_mes = df_efic_mes.rename(columns={\n",
    "    \"glosados\": \"Glosados\",\n",
    "    \"val_mes\":  \"Validados en mes\",\n",
    "    \"efectividad\": \"Efectividad (%)\"\n",
    "})\n",
    "\n",
    "# Convertir la columna a string con '%'\n",
    "df_efic_mes[\"Efectividad (%)\"] = (\n",
    "    df_efic_mes[\"Efectividad (%)\"]\n",
    "      .map(lambda x: f\"{x:.1f}%\")\n",
    ")\n",
    "\n",
    "# Mostrar\n",
    "from IPython.display import display\n",
    "display(df_efic_mes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83",
   "metadata": {},
   "source": [
    "### 5.5.6 Gráfico de efectividad mensual\n",
    "\n",
    "En este gráfico mostramos, para cada mes:\n",
    "- Una barra con la **efectividad (%)** de corrección.\n",
    "- Color verde si ≥ 50 % y rojo si < 50 %.\n",
    "- Línea discontinua al 50 % como objetivo.\n",
    "\n",
    "Esto te permitirá ver rápidamente qué meses cumplen tu SLA mensual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 1) Asegúrate de que exista la carpeta de gráficas\n",
    "graficas_dir = os.path.join(R_Salida, \"Graficas\")\n",
    "os.makedirs(graficas_dir, exist_ok=True)\n",
    "\n",
    "# 2) Crear la figura y el gráfico de efectividad mensual\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "THRESHOLD = 50\n",
    "COLOR_OK   = \"tab:green\"\n",
    "COLOR_FAIL = \"tab:red\"\n",
    "\n",
    "efic_mes   = df_efic_mes.copy()\n",
    "efic_vals  = efic_mes[\"Efectividad (%)\"].str.rstrip(\"%\").astype(float)\n",
    "mask_ok    = efic_vals >= THRESHOLD\n",
    "mask_fail  = ~mask_ok\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.bar(efic_mes.index[mask_ok],   efic_vals[mask_ok],   color=COLOR_OK,   label=f\">= {THRESHOLD}%\")\n",
    "ax.bar(efic_mes.index[mask_fail], efic_vals[mask_fail], color=COLOR_FAIL, label=f\"< {THRESHOLD}%\")\n",
    "\n",
    "ax.axhline(THRESHOLD, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "ax.text(efic_mes.index[0], THRESHOLD + 2, f\"Objetivo {THRESHOLD}%\", color=\"gray\", va=\"bottom\")\n",
    "\n",
    "for x, v in zip(efic_mes.index, efic_vals):\n",
    "    ax.text(x, v + 2, f\"{v:.0f}%\", ha=\"center\")\n",
    "\n",
    "ax.set_ylabel(\"Efectividad (%)\")\n",
    "ax.set_title(\"Efectividad de corrección mensual\")\n",
    "ax.set_ylim(0, 100)\n",
    "ax.legend(loc=\"upper right\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "# 3) Guardar la figura\n",
    "ruta_png = os.path.join(graficas_dir, \"efectividad_mensual.png\")\n",
    "fig.savefig(ruta_png, bbox_inches=\"tight\")\n",
    "\n",
    "# 4) Mostrarla en el notebook\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {},
   "source": [
    "> **Utilidad de estos indicadores**  \n",
    "> - Saber si en cada envío estamos resolviendo la mayor parte de las glosas en el siguiente ciclo.  \n",
    "> - Detectar si algún mes (por festivos, puentes o volúmenes atípicos) baja dramáticamente la efectividad.  \n",
    "> - Reportar a Planeación no solo volúmenes absolutos, sino la **calidad y rapidez** de la corrección."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86",
   "metadata": {},
   "source": [
    "## 5.6 KPIs\n",
    "\n",
    "A continuación, se definen los indicadores clave de desempeño (KPIs) recomendados para evaluar el proceso de gestión de glosas en el notebook:\n",
    "\n",
    "### 5.6.1. Tasa de cierre integral\n",
    "**Definición:** Proporción de glosas que se consideran cerradas, ya sea mediante validación o por no requerir reenvío.\n",
    "**Fórmula:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la columna '_key' en ambos DataFrames si no existen\n",
    "if '_key' not in Df_MS_Neg.columns:\n",
    "    Df_MS_Neg[\"_key\"] = Df_MS_Neg[[\"ENT_ID\", \"TPS_IDN_ID\", \"HST_IDN_NUMERO_IDENTIFICACION\"]].astype(str).agg('|'.join, axis=1)\n",
    "if '_key' not in Df_MS_Val.columns:\n",
    "    Df_MS_Val[\"_key\"] = Df_MS_Val[[\"ENT_ID\", \"TPS_IDN_ID\", \"HST_IDN_NUMERO_IDENTIFICACION\"]].astype(str).agg('|'.join, axis=1)\n",
    "\n",
    "# Identificar registros no reenviados (código de la celda anterior, que es correcto)\n",
    "last_neg = Df_MS_Neg.groupby(\"_key\")[\"Fecha_Proceso\"].max().reset_index().rename(columns={\"Fecha_Proceso\": \"last_neg_date\"})\n",
    "tmp = Df_MS_Neg.merge(last_neg, on=\"_key\", how=\"inner\")\n",
    "# CORRECCIÓN LÓGICA: Un reenvío existe si hay más de una fecha de proceso\n",
    "submission_counts = Df_MS_Neg.groupby('_key')['Fecha_Proceso'].nunique()\n",
    "keys_con_reenvio = submission_counts[submission_counts > 1].index\n",
    "last_neg['tiene_reenvio'] = last_neg['_key'].isin(keys_con_reenvio)\n",
    "no_reenviado = last_neg[\n",
    "    (~last_neg[\"tiene_reenvio\"]) & (~last_neg[\"_key\"].isin(Df_MS_Val[\"_key\"]))\n",
    "]\n",
    "\n",
    "# --- CÁLCULO CORRECTO DE LA TASA DE CIERRE ---\n",
    "\n",
    "# 1. Total de afiliados únicos con glosas\n",
    "total_glosas_unicas = Df_MS_Neg['_key'].nunique()\n",
    "\n",
    "# 2. Afiliados únicos que fueron validados (y que previamente fueron negados)\n",
    "keys_negadas = set(Df_MS_Neg['_key'])\n",
    "keys_validas = set(Df_MS_Val['_key'])\n",
    "afiliados_validados = len(keys_negadas.intersection(keys_validas))\n",
    "\n",
    "# 3. Afiliados únicos que se cerraron por no requerir reenvío\n",
    "afiliados_no_reenviados = no_reenviado['_key'].nunique()\n",
    "\n",
    "# 4. Tasa de cierre\n",
    "tasa_cierre = (afiliados_validados + afiliados_no_reenviados) / total_glosas_unicas * 100\n",
    "\n",
    "print(f\"Tasa de cierre integral: {tasa_cierre:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88",
   "metadata": {},
   "source": [
    "**Instrucciones:** Documentar los códigos de glosa incluidos en `no_reenviado` (por ejemplo, GN0013).\n",
    "\n",
    "### 5.6.2. First-Pass Yield\n",
    "\n",
    "**Definición:** Porcentaje de glosas resueltas en el primer ciclo de envío.\n",
    "**Fórmula:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Calcular el ciclo de cada glosa para cada afiliado\n",
    "Df_MS_Neg['ciclo'] = Df_MS_Neg.groupby('_key')['Fecha_Proceso'].rank(method='dense', ascending=True).astype(int)\n",
    "\n",
    "# Filtrar solo los registros que fueron glosados en su primer ciclo (primer intento)\n",
    "glosas_primer_ciclo = Df_MS_Neg[Df_MS_Neg['ciclo'] == 1]\n",
    "\n",
    "# De esos registros del primer ciclo, ver cuántos fueron validados eventualmente\n",
    "validado_en_primer_intento = glosas_primer_ciclo['_key'].isin(Df_MS_Val['_key'])\n",
    "\n",
    "# Calcular el porcentaje de éxito en el primer intento\n",
    "first_pass_yield = (validado_en_primer_intento.sum() / len(glosas_primer_ciclo)) * 100\n",
    "\n",
    "print(f\"First-Pass Yield (Tasa de éxito al primer envío): {first_pass_yield:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90",
   "metadata": {},
   "source": [
    "### 5.6.3. Backlog de pendientes\n",
    "\n",
    "**Definición:** Volumen y antigüedad promedio de glosas aún pendientes de resolución.\n",
    "**Cálculo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Identificar las llaves (_key) de los registros que aún están pendientes\n",
    "keys_negadas = set(Df_MS_Neg['_key'])\n",
    "keys_validas = set(Df_MS_Val['_key'])\n",
    "keys_pendientes = keys_negadas - keys_validas\n",
    "\n",
    "# 2. Filtrar el DataFrame de negados para obtener solo los registros pendientes\n",
    "pendientes_df = Df_MS_Neg[Df_MS_Neg['_key'].isin(keys_pendientes)]\n",
    "\n",
    "# 3. Para cada afiliado pendiente, encontrar la fecha de su última glosa\n",
    "ultima_glosa_pendientes = pendientes_df.groupby('_key')['Fecha_Proceso'].max().reset_index()\n",
    "\n",
    "# 4. Calcular la antigüedad en días desde la última glosa hasta hoy\n",
    "ultima_glosa_pendientes['antiguedad'] = (pd.Timestamp.today() - ultima_glosa_pendientes['Fecha_Proceso']).dt.days\n",
    "\n",
    "# 5. Calcular el volumen del backlog y la antigüedad promedio\n",
    "backlog_volumen = len(ultima_glosa_pendientes)\n",
    "antiguedad_media = ultima_glosa_pendientes['antiguedad'].mean()\n",
    "\n",
    "print(f\"Backlog de pendientes (volumen): {backlog_volumen} registros\")\n",
    "print(f\"Antigüedad promedio de pendientes: {antiguedad_media:.2f} días\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92",
   "metadata": {},
   "source": [
    "**Instrucciones:** Segmentar los pendientes por mes de `fecha_glosa` para detectar cuellos de botella.\n",
    "\n",
    "### 5.6.4. Glosas vs. volumen total\n",
    "\n",
    "**Definición:** Relación entre el número de glosas y el total de registros MS procesados.\n",
    "**Fórmula:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTA: El valor de total_ms_procesados debe ser suministrado externamente.\n",
    "# Por ejemplo, si en el periodo se procesaron 25,000 registros en total:\n",
    "total_ms_procesados = 25000  # <-- REEMPLAZA ESTE VALOR con el total real de MS procesados\n",
    "\n",
    "# Total de afiliados únicos con glosas\n",
    "total_glosas_unicas = Df_MS_Neg['_key'].nunique()\n",
    "\n",
    "# Calcular la proporción\n",
    "glosas_vs_volumen = (total_glosas_unicas / total_ms_procesados) * 100\n",
    "\n",
    "print(f\"Proporción de Glosas vs. Volumen Total: {glosas_vs_volumen:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94",
   "metadata": {},
   "source": [
    "### 5.6.5. SLA de resolución\n",
    "\n",
    "**Definición:** Porcentaje de glosas resueltas dentro del plazo objetivo (7 días).\n",
    "**Fórmula:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos el dataframe df_tiempo que ya tiene los días de resolución calculados\n",
    "# para cada registro que fue validado.\n",
    "\n",
    "# Contar cuántos registros se resolvieron en 7 días o menos\n",
    "dentro_sla = (df_tiempo['dias_resolucion'] <= 7).sum()\n",
    "\n",
    "# Contar el total de registros que se resolvieron\n",
    "total_resueltas = len(df_tiempo)\n",
    "\n",
    "# Calcular el porcentaje de cumplimiento del SLA\n",
    "sla_resolucion = (dentro_sla / total_resueltas) * 100\n",
    "\n",
    "print(f\"Cumplimiento de SLA de Resolución (<= 7 días): {sla_resolucion:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96",
   "metadata": {},
   "source": [
    "**Notas finales:**\n",
    "\n",
    "* Incluir gráficos (líneas de tendencia, barras comparativas) y tablas resumen en el notebook para cada KPI.\n",
    "* Permitir filtros dinámicos por mes y por código de glosa para análisis detallado.\n",
    "* Documentar claramente las reglas de inclusión para cada KPI y revisar posibles outliers en fechas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97",
   "metadata": {},
   "source": [
    "# 6. Exportación del Informe\n",
    "\n",
    "En esta sección veremos cómo generar automáticamente:\n",
    "\n",
    "1. **PDF** del notebook completo (incluyendo texto, código y gráficas).  \n",
    "2. **Excel** con los resúmenes de métricas (opcional, para acompañar el PDF)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98",
   "metadata": {},
   "source": [
    "## 6.1 Exportar el notebook a PDF\n",
    "\n",
    "Usaremos `nbconvert` de Jupyter. Solo necesitas ejecutar:\n",
    "\n",
    "```bash\n",
    "!jupyter nbconvert --to pdf \"TuNotebook.ipynb\" \\\n",
    "    --output \"Informe_Glosas_MS.pdf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from weasyprint import HTML\n",
    "\n",
    "# 0) Variables\n",
    "base_name = \"Informe_Glosas_MS\"\n",
    "\n",
    "# 1) Asegurar que exista la carpeta\n",
    "os.makedirs(R_Salida, exist_ok=True)\n",
    "\n",
    "# 2) Convertir a HTML\n",
    "cmd = [\n",
    "    \"python\", \"-m\", \"nbconvert\",\n",
    "    \"--to\", \"html\",\n",
    "    notebook,\n",
    "    \"--output-dir\", R_Salida,\n",
    "    \"--output\", base_name\n",
    "]\n",
    "proc = subprocess.run(cmd, capture_output=True, text=True)\n",
    "if proc.returncode != 0:\n",
    "    print(\"❌ nbconvert falló:\\n\", proc.stderr)\n",
    "else:\n",
    "    print(\"✅ HTML generado en:\", os.path.join(R_Salida, f\"{base_name}.html\"))\n",
    "\n",
    "    # 3) Convertir HTML a PDF con WeasyPrint\n",
    "    html_path = os.path.join(R_Salida, f\"{base_name}.html\")\n",
    "    pdf_path  = os.path.join(R_Salida, f\"{base_name}.pdf\")\n",
    "    HTML(html_path).write_pdf(pdf_path)\n",
    "    print(\"✅ PDF generado en:\", pdf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100",
   "metadata": {},
   "source": [
    "## 6.2 Exportar métricas clave a Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Preparar df_env con la tasa en fracción\n",
    "df_env = df_efic_envio.copy()\n",
    "df_env[\"Efectividad (%)\"] = df_env[\"Efectividad (%)\"] / 100\n",
    "# Ahora df_env[\"Efectividad (%)\"] va de 0 a 1\n",
    "\n",
    "# 2) Preparar df_mes sin columna extra\n",
    "# Partimos del df_efic_mes (que era strings “31.2%”) y lo convertimos a fracción\n",
    "df_mes = df_efic_mes.copy()\n",
    "df_mes[\"Efectividad (%)\"] = (\n",
    "    df_mes[\"Efectividad (%)\"]\n",
    "      .str.rstrip(\"%\")\n",
    "      .astype(float) / 100\n",
    ")\n",
    "# df_mes ya no lleva columna extra, sólo ésta con valores 0–1\n",
    "\n",
    "# 3) Escribir todo en Excel\n",
    "with pd.ExcelWriter(ruta_excel, engine=\"xlsxwriter\") as writer:\n",
    "    wb = writer.book\n",
    "\n",
    "    #### Hoja Envios ####\n",
    "    df_env.to_excel(\n",
    "        writer,\n",
    "        sheet_name=\"Envios\",\n",
    "        startrow=2,\n",
    "        index_label=\"Envío\",\n",
    "        columns=[\"Glosados\", \"Validados en próximo envío\", \"Efectividad (%)\"]\n",
    "    )\n",
    "    ws1 = writer.sheets[\"Envios\"]\n",
    "\n",
    "    # Formatos\n",
    "    hdr = wb.add_format({\"bold\":True, \"bg_color\":\"#4F81BD\",\n",
    "                         \"font_color\":\"white\", \"align\":\"center\", \"border\":1})\n",
    "    i_fmt = wb.add_format({\"num_format\":\"0\",    \"border\":1})\n",
    "    p_fmt = wb.add_format({\"num_format\":\"0.0%\", \"border\":1})\n",
    "    bad_fmt = wb.add_format({\"bg_color\":\"#FFC7CE\"})\n",
    "\n",
    "    # Encabezados\n",
    "    for col, title in enumerate([\"Envío\",\"Glosados\",\"Validados en próximo envío\",\"Efectividad (%)\"]):\n",
    "        ws1.write(1, col, title, hdr)\n",
    "\n",
    "    # Anchos\n",
    "    ws1.set_column(0,0,15)\n",
    "    ws1.set_column(1,1,10, i_fmt)\n",
    "    ws1.set_column(2,2,18, i_fmt)\n",
    "    ws1.set_column(3,3,15, p_fmt)\n",
    "\n",
    "    ws1.freeze_panes(2,1)\n",
    "    ws1.autofilter(1,0, 1+len(df_env), 3)\n",
    "\n",
    "    # Resaltar <50%\n",
    "    ws1.conditional_format(\n",
    "        2, 3,\n",
    "        1+len(df_env), 3,\n",
    "        {\"type\":\"cell\",\"criteria\":\"<\",\"value\":0.5,\"format\":bad_fmt}\n",
    "    )\n",
    "\n",
    "    #### Hoja Mensual ####\n",
    "    df_mes.to_excel(\n",
    "        writer,\n",
    "        sheet_name=\"Mensual\",\n",
    "        startrow=2,\n",
    "        index_label=\"Mes\",\n",
    "        columns=[\"Glosados\",\"Validados en mes\",\"Efectividad (%)\"]\n",
    "    )\n",
    "    ws2 = writer.sheets[\"Mensual\"]\n",
    "\n",
    "    # Encabezados\n",
    "    for col, title in enumerate([\"Mes\",\"Glosados\",\"Validados en mes\",\"Efectividad (%)\"]):\n",
    "        ws2.write(1, col, title, hdr)\n",
    "\n",
    "    # Anchos\n",
    "    ws2.set_column(0,0,12)\n",
    "    ws2.set_column(1,1,10, i_fmt)\n",
    "    ws2.set_column(2,2,15, i_fmt)\n",
    "    ws2.set_column(3,3,15, p_fmt)\n",
    "\n",
    "    ws2.freeze_panes(2,1)\n",
    "    ws2.autofilter(1,0, 1+len(df_mes), 3)\n",
    "    ws2.conditional_format(\n",
    "        2,3, 1+len(df_mes), 3,\n",
    "        {\"type\":\"cell\",\"criteria\":\"<\",\"value\":0.5,\"format\":bad_fmt}\n",
    "    )\n",
    "\n",
    "    #### Hojas crudas ###\n",
    "    Df_MS_Neg.to_excel(writer, sheet_name=\"MS_Negados\", index=False)\n",
    "    Df_MS_Val.to_excel(writer, sheet_name=\"MS_Validados\", index=False)\n",
    "\n",
    "print(\"✅ Excel corregido exportado en:\", ruta_excel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102",
   "metadata": {},
   "source": [
    "## 6.3. Hoja Resumen del Excel con las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.drawing.image import Image as XLImage\n",
    "from openpyxl.styles import Font, Alignment, PatternFill\n",
    "\n",
    "\n",
    "# —————————————————————\n",
    "# 1) Abrir y borrar Resumen viejo\n",
    "# —————————————————————\n",
    "wb = load_workbook(ruta_excel)\n",
    "if \"Resumen\" in wb.sheetnames:\n",
    "    wb.remove(wb[\"Resumen\"])\n",
    "ws = wb.create_sheet(\"Resumen\", 0)\n",
    "\n",
    "# —————————————————————\n",
    "# 2) Columnas y filas compactas\n",
    "# —————————————————————\n",
    "# Sólo usamos A–K y alturas de fila reducidas\n",
    "#for col in \"ABCDEFGHIJK\":\n",
    "#    ws.column_dimensions[col].width = 8\n",
    "\n",
    "#for r in range(4, 14):   ws.row_dimensions[r].height = 60\n",
    "#for r in range(14, 24):  ws.row_dimensions[r].height = 60\n",
    "\n",
    "# —————————————————————\n",
    "# 3) Título\n",
    "# —————————————————————\n",
    "ws.merge_cells(\"A1:N2\")\n",
    "c = ws[\"A1\"]\n",
    "c.value     = \"Informe Glosas MS Negados – Resumen\"\n",
    "c.font      = Font(bold=True, size=16)\n",
    "c.alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "c.fill      = PatternFill(\"solid\", fgColor=\"D9E1F2\")\n",
    "\n",
    "# —————————————————————\n",
    "# 4) Insertar y escalar imágenes\n",
    "# —————————————————————\n",
    "imgs = [\n",
    "    (\"volumen_vs_efectividad_envio.png\",   \"A3\", 0.5, 0.5),\n",
    "    (\"efectividad_envio_horizontal.png\",   \"H3\", 0.5, 0.5),\n",
    "    (\"treemap_glosas.png\",                 \"A16\",0.5, 0.5),\n",
    "    (\"top_pares_glosas.png\",               \"H16\",0.5, 0.5),\n",
    "]\n",
    "for fname, anchor, xs, ys in imgs:\n",
    "    img = XLImage(os.path.join(graficas_dir, fname))\n",
    "    img.anchor = anchor\n",
    "    img.width  = img.width  * xs\n",
    "    img.height = img.height * ys\n",
    "    ws.add_image(img)\n",
    "\n",
    "# —————————————————————\n",
    "# 5) Descripciones compactas\n",
    "# —————————————————————\n",
    "desc_fmt = Alignment(wrap_text=True, vertical=\"top\")\n",
    "desc = [\n",
    "    (\"A13:F14\",\n",
    "     \"1) Volumen glosados vs efectividad por envío.\"),\n",
    "    (\"H13:L14\",\n",
    "     \"2) Efectividad con umbral 50 % (verde cumple, rojo no).\"),\n",
    "    (\"A29:F30\",\n",
    "     \"3) Treemap: GN0013 = 60,3 % de no reenvíos.\"),\n",
    "    (\"H29:L30\",\n",
    "     \"4) Pares top de glosas juntas.\"),\n",
    "]\n",
    "for rng, text in desc:\n",
    "    ws.merge_cells(rng)\n",
    "    cell = ws[rng.split(\":\")[0]]\n",
    "    cell.value     = text\n",
    "    cell.alignment = desc_fmt\n",
    "\n",
    "# —————————————————————\n",
    "# 6) Guardar\n",
    "# —————————————————————\n",
    "wb.save(ruta_excel)\n",
    "print(\"✅ Resumen compacto listo en:\", ruta_excel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104",
   "metadata": {},
   "source": [
    "## 7. Conclusión\n",
    "\n",
    "### **Conclusión**\n",
    "\n",
    "Durante el tercer cuatrimestre de 2025 (septiembre a diciembre), se llevaron a cabo **12 ciclos de envío** semanales de Maestro de Servicios (MS) a ADRES. La dinámica de corrección presentó una alta volatilidad, con un comportamiento heterogéneo entre meses.\n",
    "\n",
    "Las glosas **GN0013 (53.0%)** y **GN0169 (22.7%)** dominaron masivamente los rechazos, desplazando a otras causales históricas. A nivel mensual, la efectividad mostró un repunte significativo en octubre, pero una caída preocupante hacia el cierre de año:\n",
    "\n",
    "| Mes | Efectividad | Estado |\n",
    "|:---|:---:|:---|\n",
    "| **2025-09** | 38% | < 50% (Crítico) |\n",
    "| **2025-10** | 71% | >= 50% (Óptimo) |\n",
    "| **2025-11** | 35% | < 50% (Crítico) |\n",
    "| **2025-12** | 36% | < 50% (Crítico) |\n",
    "\n",
    "Si bien octubre demostró que el proceso puede superar el objetivo del 50%, el cierre de diciembre fue técnicamente complejo: aunque se registró una efectividad mensual del 36%, las dos últimas semanas del año (12 y 19 de diciembre) cerraron con una **tasa de recuperación de ciclo del 0%**, dejando esos registros pendientes de gestión para el siguiente periodo.\n",
    "\n",
    "---\n",
    "\n",
    "### **Puntos clave y recomendaciones**\n",
    "\n",
    "1.  **Concentración crítica en GN0013**: Esta glosa (\"Afiliado ya existe en la BDUA\") representa ahora más de la mitad del problema (**53.0%**). Esto ya no sugiere un error operativo de digitación, sino un fallo estructural en la pre-validación de la base de datos contra la BDUA antes de generar el archivo plano.\n",
    "2.  **Inestabilidad del proceso**: A diferencia de la estabilidad del cuatrimestre anterior, aquí vemos picos extremos: de un éxito del 71% en octubre caemos a un 35% en noviembre. Esto indica que la limpieza de datos no está automatizada, sino que depende de esfuerzos manuales que varían mes a mes.\n",
    "3.  **Nuevos patrones de co-ocurrencia**: La combinación más frecuente cambió. Ahora el par dominante es **(GN0011 & GN0146)**, seguido por **(GN0018 & GN0361)**. Es imperativo ajustar las reglas de negocio para validar la consistencia de *Tipo de Documento* y *Afiliado Principal* simultáneamente para evitar este doble rechazo.\n",
    "4.  **Gestión de cierre de año**: El backlog generado en las últimas dos semanas de diciembre (con efectividad de ciclo 0%) requiere atención inmediata en enero. Se recomienda implementar un reporte de **\"Saldos de Glosas Pendientes\"** que no dependa del ciclo de envío, para no perder de vista estos casos \"abiertos\" entre años fiscales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105",
   "metadata": {},
   "source": [
    "## 📊 Análisis de Glosas MS Negados\n",
    "\n",
    "Este notebook (`notebooks/Aseguramiento/Inf_Ejec_MS_NEG.ipynb`) contiene el análisis completo de los registros negados en el Maestro de ingresos (MS) que reporta Capresoca EPS a ADRES.  \n",
    "\n",
    "🔍 **Autoría**  \n",
    "Este estudio y los algoritmos de extracción de métricas fueron diseñados y desarrollados por **Yesid Rincón**.  \n",
    "\n",
    "### Contenido principal\n",
    "1. **Métricas iniciales**: volumen y frecuencia de glosas.  \n",
    "2. **Tiempo de resolución**: distribución de días y ciclos de envío.  \n",
    "3. **Efectividad**: porcentaje de glosas corregidas por envío y por mes.  \n",
    "4. **Co-ocurrencia de glosas**: patrones de glosas múltiples en un mismo registro.  \n",
    "5. **Dashboard y exportación**: generación automática de gráficos y Excel.\n",
    "\n",
    "> Para ver los resultados completos, abre el notebook y revisa la sección **7. Conclusión**, donde se recogen los principales hallazgos y próximas acciones.\n",
    "\n",
    "---\n",
    "\n",
    "*Puedes clonar este proyecto y ejecutar el notebook con*  \n",
    "```bash\n",
    "git clone https://github.com/yesid95/capresoca-data-automation.git\n",
    "cd capresoca-data-automation/notebooks/Aseguramiento\n",
    "jupyter lab\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
