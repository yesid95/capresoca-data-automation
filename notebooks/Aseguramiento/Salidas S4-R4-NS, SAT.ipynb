{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Modulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import openpyxl\n",
    "from openpyxl.styles import Font, PatternFill, Alignment\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Módulo para trabajar con archivos de texto\n",
    "\n",
    "# Módulo para trabajar con fechas y tiempos\n",
    "\n",
    "# Módulo para leer y escribir archivos Excel\n",
    "\n",
    "# Módulo para crear gráficas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Módulo para trabajar con rutas del sistema de forma multiplataforma\n",
    "\n",
    "# Módulo para crear reportes en Excel con más funcionalidades\n",
    "\n",
    "# Módulo adicional para manipular datos tabulares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Rutas y varaibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_S4 = r\"C:\\Users\\crist\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\Procesos BDUA\\Subsidiados\\Procesos BDUA EPS\\S4\\S4_consolidado_total.txt\"\n",
    "R_R4 = r\"C:\\Users\\crist\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\Procesos BDUA\\Subsidiados\\Procesos BDUA EPS\\R4\\R4_consolidado_total.txt\"\n",
    "R_NS = r\"C:\\Users\\crist\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\Procesos BDUA\\Subsidiados\\Procesos BDUA EPS\\NS\\NS validado\\all-NS-VAL.txt\"\n",
    "\n",
    "R_SAT = r\"C:\\Users\\crist\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\SAT\\SUBSIDIADO\\Consolidado_Sat_EP025.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo R_SAT en un dataframe\n",
    "df_traslados_SAT = pd.read_csv(R_SAT, sep='|', dtype=str, encoding='ANSI')\n",
    "\n",
    "print(f\"Total de registros en SAT: {len(df_traslados_SAT)}\")\n",
    "print(f\"\\nPrimeras filas del dataframe:\")\n",
    "print(f\"\\nColumnas disponibles:\")\n",
    "print(df_traslados_SAT.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo R_R4 en un dataframe\n",
    "df_traslados_R4 = pd.read_csv(R_R4, sep=',', dtype=str, encoding='utf-8')\n",
    "\n",
    "print(f\"Total de registros en R4: {len(df_traslados_R4)}\")\n",
    "print(f\"\\nPrimeras filas del dataframe:\")\n",
    "print(f\"\\nColumnas disponibles:\")\n",
    "print(df_traslados_R4.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo R_S4 en un dataframe\n",
    "df_traslados_S4 = pd.read_csv(R_S4, sep=',', dtype=str, encoding='utf-8')\n",
    "\n",
    "print(f\"Total de registros en S4: {len(df_traslados_S4)}\")\n",
    "print(f\"\\nPrimeras filas del dataframe:\")\n",
    "print(f\"\\nColumnas disponibles:\")\n",
    "print(df_traslados_S4.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo R_NS en un dataframe\n",
    "df_ns_BDUA = pd.read_csv(R_NS, sep=',', dtype=str, encoding='latin-1')\n",
    "\n",
    "print(f\"Total de registros en NS BDUA: {len(df_ns_BDUA)}\")\n",
    "print(f\"\\nPrimeras filas del dataframe:\")\n",
    "print(f\"\\nColumnas disponibles:\")\n",
    "print(df_ns_BDUA.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## df resultadosEspeciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta base donde están los archivos .VAL\n",
    "ruta_val = r\"C:\\Users\\crist\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\Procesos BDUA\\Subsidiados\\RESULTADOS ESPECIALES\\VAL\"\n",
    "\n",
    "# Lista para almacenar todos los dataframes\n",
    "lista_dfs = []\n",
    "\n",
    "# Recorrer la carpeta y subcarpetas buscando archivos .VAL\n",
    "for archivo in Path(ruta_val).rglob(\"*.VAL\"):\n",
    "    # Leer el archivo como texto separado por comas, todo como string\n",
    "    df_temp = pd.read_csv(archivo, sep=',', dtype=str, encoding='latin-1', header=None)\n",
    "    \n",
    "    # Obtener el nombre del archivo sin extensión\n",
    "    nombre_archivo = archivo.stem\n",
    "    \n",
    "    # Extraer la fecha de los últimos 8 dígitos del nombre del archivo\n",
    "    fecha_str = nombre_archivo[-8:]  # Últimos 8 caracteres: ddmmyyyy\n",
    "    # Convertir a formato dd/mm/yyyy\n",
    "    fecha_formateada = f\"{fecha_str[0:2]}/{fecha_str[2:4]}/{fecha_str[4:8]}\"\n",
    "    \n",
    "    # Agregar columna con el nombre del archivo\n",
    "    df_temp['nombre_archivo'] = nombre_archivo\n",
    "    \n",
    "    # Agregar columna con la fecha\n",
    "    df_temp['fecha_archivo'] = fecha_formateada\n",
    "    \n",
    "    # Agregar a la lista\n",
    "    lista_dfs.append(df_temp)\n",
    "\n",
    "# Consolidar todos los dataframes en uno solo\n",
    "df_resultadosEspeciales = pd.concat(lista_dfs, ignore_index=True)\n",
    "\n",
    "print(f\"Total de archivos cargados: {len(lista_dfs)}\")\n",
    "print(f\"Total de registros: {len(df_resultadosEspeciales)}\")\n",
    "print(f\"\\nPrimeras filas del dataframe consolidado:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## df novedades municipios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas base donde están los archivos .VAL de novedades municipios\n",
    "rutas_ns_municipios = [\n",
    "    r\"C:\\Users\\crist\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\Procesos BDUA\\Subsidiados\\Novedades municipios\\2025\",\n",
    "    r\"C:\\Users\\crist\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\Procesos BDUA\\Subsidiados\\Novedades municipios\\2026\"\n",
    "]\n",
    "\n",
    "# Lista para almacenar todos los dataframes\n",
    "lista_dfs_municipios = []\n",
    "\n",
    "# Recorrer ambas carpetas y subcarpetas buscando archivos .VAL\n",
    "for ruta in rutas_ns_municipios:\n",
    "    for archivo in Path(ruta).rglob(\"*.VAL\"):\n",
    "        # Leer el archivo como texto separado por comas, todo como string\n",
    "        df_temp = pd.read_csv(archivo, sep=',', dtype=str, encoding='latin-1', header=None)\n",
    "        \n",
    "        # Obtener el nombre del archivo sin extensión\n",
    "        nombre_archivo = archivo.stem\n",
    "        \n",
    "        # Extraer la fecha de los últimos 8 dígitos del nombre del archivo\n",
    "        fecha_str = nombre_archivo[-8:]  # Últimos 8 caracteres: ddmmyyyy\n",
    "        # Convertir a formato dd/mm/yyyy\n",
    "        fecha_formateada = f\"{fecha_str[0:2]}/{fecha_str[2:4]}/{fecha_str[4:8]}\"\n",
    "        \n",
    "        # Agregar columna con el nombre del archivo\n",
    "        df_temp['nombre_archivo'] = nombre_archivo\n",
    "        \n",
    "        # Agregar columna con la fecha\n",
    "        df_temp['fecha_archivo'] = fecha_formateada\n",
    "        \n",
    "        # Agregar a la lista\n",
    "        lista_dfs_municipios.append(df_temp)\n",
    "\n",
    "# Consolidar todos los dataframes en uno solo\n",
    "df_ns_municipios = pd.concat(lista_dfs_municipios, ignore_index=True)\n",
    "\n",
    "print(f\"Total de archivos cargados: {len(lista_dfs_municipios)}\")\n",
    "print(f\"Total de registros: {len(df_ns_municipios)}\")\n",
    "print(f\"\\nPrimeras filas del dataframe consolidado:\")\n",
    "print(df_ns_municipios.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# Depurar Resultados Especiales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la cantidad de registros antes del filtro\n",
    "registros_antes = len(df_resultadosEspeciales)\n",
    "\n",
    "# Filtrar solo los registros donde la columna 11 es \"N09\"\n",
    "df_resultadosEspeciales = df_resultadosEspeciales[df_resultadosEspeciales[11] == \"N09\"]\n",
    "\n",
    "# Obtener la cantidad de registros después del filtro\n",
    "registros_despues = len(df_resultadosEspeciales)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"Registros antes del filtro: {registros_antes}\")\n",
    "print(f\"Registros después del filtro: {registros_despues}\")\n",
    "print(f\"Registros eliminados: {registros_antes - registros_despues}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las categorías y cantidad de registros de la columna 11\n",
    "print(df_resultadosEspeciales[11].value_counts())\n",
    "print(f\"\\nTotal de categorías: {df_resultadosEspeciales[11].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# Depurar novedades municipios "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la cantidad de registros antes del filtro\n",
    "registros_antes = len(df_ns_municipios)\n",
    "\n",
    "# Filtrar solo los registros donde la columna 11 es \"N09\" o \"N13\"\n",
    "df_ns_municipios = df_ns_municipios[df_ns_municipios[11].isin([\"N09\", \"N13\"])]\n",
    "\n",
    "# Obtener la cantidad de registros después del filtro\n",
    "registros_despues = len(df_ns_municipios)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"Registros antes del filtro: {registros_antes}\")\n",
    "print(f\"Registros después del filtro: {registros_despues}\")\n",
    "print(f\"Registros eliminados: {registros_antes - registros_despues}\")\n",
    "print(f\"\\nDistribución de novedades:\")\n",
    "print(df_ns_municipios[11].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las categorías y cantidad de registros de la columna 11\n",
    "print(df_ns_municipios[11].value_counts())\n",
    "print(f\"\\nTotal de categorías: {df_ns_municipios[11].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# Depurar NS proceso BDUA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la cantidad de registros antes del filtro\n",
    "registros_antes = len(df_ns_BDUA)\n",
    "\n",
    "# Paso 1: Filtrar por novedades N09 y N14\n",
    "df_ns_BDUA = df_ns_BDUA[df_ns_BDUA['NOVEDAD'].isin(['N09', 'N14'])]\n",
    "\n",
    "# Paso 2: Convertir Fecha_Proceso a datetime y filtrar por años 2025 y 2026\n",
    "df_ns_BDUA['fecha_dt'] = pd.to_datetime(df_ns_BDUA['Fecha_Proceso'], format='%d/%m/%Y')\n",
    "df_ns_BDUA['año'] = df_ns_BDUA['fecha_dt'].dt.year\n",
    "df_ns_BDUA = df_ns_BDUA[df_ns_BDUA['año'].isin([2025, 2026])]\n",
    "\n",
    "# Obtener la cantidad de registros después del filtro\n",
    "registros_despues = len(df_ns_BDUA)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"========== FILTRADO DE df_ns_BDUA ==========\")\n",
    "print(f\"\\nRegistros antes del filtro: {registros_antes:,}\")\n",
    "print(f\"Registros después del filtro: {registros_despues:,}\")\n",
    "print(f\"Registros eliminados: {(registros_antes - registros_despues):,}\")\n",
    "print(f\"\\n{'='*45}\")\n",
    "\n",
    "print(f\"\\nDistribución por NOVEDAD:\")\n",
    "print(df_ns_BDUA['NOVEDAD'].value_counts())\n",
    "print(f\"\\nTotal de categorías de novedad: {df_ns_BDUA['NOVEDAD'].nunique()}\")\n",
    "\n",
    "print(f\"\\nDistribución por AÑO:\")\n",
    "print(df_ns_BDUA['año'].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\nDistribución cruzada (NOVEDAD x AÑO):\")\n",
    "print(pd.crosstab(df_ns_BDUA['NOVEDAD'], df_ns_BDUA['año'], margins=True, margins_name='TOTAL'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las categorías y cantidad de registros de la columna 'NOVEDAD'\n",
    "print(df_ns_BDUA['NOVEDAD'].value_counts())\n",
    "print(f\"\\nTotal de categorías: {df_ns_BDUA['NOVEDAD'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "# Depurar S4 proceso BDUA Traslados de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la cantidad de registros antes del filtro\n",
    "registros_antes = len(df_traslados_S4)\n",
    "\n",
    "# Convertir Fecha_Proceso a datetime y filtrar por años 2025 y 2026\n",
    "df_traslados_S4['fecha_dt'] = pd.to_datetime(df_traslados_S4['FECHA_PROCESO'], format='%d/%m/%Y')\n",
    "df_traslados_S4['año'] = df_traslados_S4['fecha_dt'].dt.year\n",
    "df_traslados_S4 = df_traslados_S4[df_traslados_S4['año'].isin([2025, 2026])]\n",
    "\n",
    "# Obtener la cantidad de registros después del filtro\n",
    "registros_despues = len(df_traslados_S4)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"========== FILTRADO DE df_traslados_S4 ==========\")\n",
    "print(f\"\\nRegistros antes del filtro: {registros_antes:,}\")\n",
    "print(f\"Registros después del filtro: {registros_despues:,}\")\n",
    "print(f\"Registros eliminados: {(registros_antes - registros_despues):,}\")\n",
    "print(f\"\\n{'='*45}\")\n",
    "\n",
    "print(f\"\\nDistribución por AÑO:\")\n",
    "print(df_traslados_S4['año'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la cantidad de registros antes del filtro\n",
    "registros_antes = len(df_traslados_S4)\n",
    "\n",
    "# Paso 1: Filtrar solo los registros donde RESPUESTA es \"1\"\n",
    "df_traslados_S4 = df_traslados_S4[df_traslados_S4['RESPUESTA'] == '1']\n",
    "\n",
    "registros_despues_respuesta = len(df_traslados_S4)\n",
    "\n",
    "# Paso 2: Eliminar duplicados por TPS_IDN_ID y HST_IDN_NUMERO_IDENTIFICACION\n",
    "# Mantener el primer registro de cada usuario\n",
    "df_traslados_S4 = df_traslados_S4.drop_duplicates(\n",
    "    subset=['TPS_IDN_ID', 'HST_IDN_NUMERO_IDENTIFICACION'], \n",
    "    keep='first'\n",
    ")\n",
    "\n",
    "registros_despues_duplicados = len(df_traslados_S4)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"========== FILTRADO DE df_traslados_S4 ==========\")\n",
    "print(f\"\\nRegistros antes del filtro: {registros_antes:,}\")\n",
    "print(f\"Registros después de filtrar RESPUESTA='1': {registros_despues_respuesta:,}\")\n",
    "print(f\"Registros eliminados por RESPUESTA: {(registros_antes - registros_despues_respuesta):,}\")\n",
    "print(f\"\\nRegistros después de eliminar duplicados: {registros_despues_duplicados:,}\")\n",
    "print(f\"Registros eliminados por duplicados: {(registros_despues_respuesta - registros_despues_duplicados):,}\")\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"REGISTROS FINALES: {registros_despues_duplicados:,}\")\n",
    "print(f\"REGISTROS ELIMINADOS EN TOTAL: {(registros_antes - registros_despues_duplicados):,}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "# Depurar R4 proceso BDUA Traslados de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_traslados_R4\n",
    "# Obtener la cantidad de registros antes del filtro\n",
    "registros_antes = len(df_traslados_R4)\n",
    "\n",
    "# Convertir Fecha_Proceso a datetime y filtrar por años 2025 y 2026\n",
    "df_traslados_R4['fecha_dt'] = pd.to_datetime(df_traslados_R4['FECHA_PROCESO'], format='%d/%m/%Y')\n",
    "df_traslados_R4['año'] = df_traslados_R4['fecha_dt'].dt.year\n",
    "df_traslados_R4 = df_traslados_R4[df_traslados_R4['año'].isin([2025, 2026])]\n",
    "\n",
    "# Obtener la cantidad de registros después del filtro\n",
    "registros_despues = len(df_traslados_R4)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"========== FILTRADO DE df_traslados_R4 ==========\")\n",
    "print(f\"\\nRegistros antes del filtro: {registros_antes:,}\")\n",
    "print(f\"Registros después del filtro: {registros_despues:,}\")\n",
    "print(f\"Registros eliminados: {(registros_antes - registros_despues):,}\")\n",
    "print(f\"\\n{'='*45}\")\n",
    "\n",
    "print(f\"\\nDistribución por AÑO:\")\n",
    "print(df_traslados_R4['año'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la cantidad de registros antes del proceso\n",
    "registros_antes = len(df_traslados_R4)\n",
    "\n",
    "# Paso 1: Modificar RESPUESTA y CAUSAL_RESPUESTA donde GLOSA no es vacío, null o 0\n",
    "df_traslados_R4.loc[\n",
    "    (df_traslados_R4['GLOSA'].notna()) & (df_traslados_R4['GLOSA'] != '0') & (df_traslados_R4['GLOSA'] != ''),\n",
    "    ['RESPUESTA', 'CAUSAL_RESPUESTA']\n",
    "] = '1'\n",
    "\n",
    "# Paso 2: Filtrar solo los registros donde RESPUESTA es \"1\"\n",
    "df_traslados_R4 = df_traslados_R4[df_traslados_R4['RESPUESTA'] == '1']\n",
    "\n",
    "# Obtener la cantidad de registros después del filtro\n",
    "registros_despues = len(df_traslados_R4)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"========== PROCESAMIENTO DE df_traslados_R4 ==========\")\n",
    "print(f\"\\nRegistros antes del proceso: {registros_antes:,}\")\n",
    "print(f\"Registros después del filtro (RESPUESTA='1'): {registros_despues:,}\")\n",
    "print(f\"Registros eliminados: {(registros_antes - registros_despues):,}\")\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"REGISTROS FINALES: {registros_despues:,}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validar duplicados en df_traslados_R4 por ID con ventanas móviles de 2 meses\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"VALIDACIÓN DE DUPLICADOS CON VENTANAS MÓVILES DE 2 MESES\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "registros_antes = len(df_traslados_R4)\n",
    "print(f\"Registros ANTES de eliminar duplicados: {registros_antes:,}\\n\")\n",
    "\n",
    "# Ordenar por ID y fecha\n",
    "df_traslados_R4 = df_traslados_R4.sort_values(['TPS_IDN_ID', 'HST_IDN_NUMERO_IDENTIFICACION', 'fecha_dt']).reset_index(drop=True)\n",
    "\n",
    "# Lista para marcar registros a eliminar\n",
    "indices_a_eliminar = []\n",
    "\n",
    "# Agrupar por ID\n",
    "for (tps_id, hst_id), grupo in df_traslados_R4.groupby(['TPS_IDN_ID', 'HST_IDN_NUMERO_IDENTIFICACION']):\n",
    "    if len(grupo) > 1:\n",
    "        # Ordenar por fecha\n",
    "        grupo_ordenado = grupo.sort_values('fecha_dt')\n",
    "        \n",
    "        # Guardar el primer registro\n",
    "        fecha_anterior = grupo_ordenado.iloc[0]['fecha_dt']\n",
    "        indices_validos = [grupo_ordenado.index[0]]\n",
    "        \n",
    "        # Revisar los demás registros\n",
    "        for idx in grupo_ordenado.index[1:]:\n",
    "            fecha_actual = df_traslados_R4.loc[idx, 'fecha_dt']\n",
    "            \n",
    "            # Calcular diferencia en días\n",
    "            diferencia_dias = (fecha_actual - fecha_anterior).days\n",
    "            \n",
    "            # Si la diferencia es menor a 60 días (2 meses aprox), marcar para eliminar\n",
    "            if diferencia_dias < 60:\n",
    "                indices_a_eliminar.append(idx)\n",
    "            else:\n",
    "                # Si pasan más de 60 días, actualizar fecha de referencia\n",
    "                fecha_anterior = fecha_actual\n",
    "                indices_validos.append(idx)\n",
    "\n",
    "# Eliminar los registros duplicados\n",
    "df_traslados_R4_limpio = df_traslados_R4.drop(indices_a_eliminar).reset_index(drop=True)\n",
    "\n",
    "registros_despues = len(df_traslados_R4_limpio)\n",
    "registros_eliminados = len(indices_a_eliminar)\n",
    "\n",
    "print(f\"Registros DESPUÉS de eliminar duplicados: {registros_despues:,}\")\n",
    "print(f\"Registros ELIMINADOS: {registros_eliminados:,}\\n\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Validación: Contar duplicados restantes\n",
    "duplicados_por_id = df_traslados_R4_limpio.groupby(['TPS_IDN_ID', 'HST_IDN_NUMERO_IDENTIFICACION']).size()\n",
    "duplicados_por_id = duplicados_por_id[duplicados_por_id > 1].sort_values(ascending=False)\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"VALIDACIÓN POST-LIMPIEZA\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "print(f\"Total de IDs que aún aparecen más de 1 vez: {len(duplicados_por_id)}\\n\")\n",
    "\n",
    "if len(duplicados_por_id) > 0:\n",
    "    print(\"Top 10 IDs con más registros:\")\n",
    "    print(duplicados_por_id.head(10))\n",
    "    print(f\"\\n{'='*70}\\n\")\n",
    "    \n",
    "    # Mostrar ejemplo de un ID que quedó con múltiples registros\n",
    "    print(f\"EJEMPLO: ID con múltiples registros (separados por más de 60 días)\\n\")\n",
    "    \n",
    "    id_ejemplo = duplicados_por_id.idxmax()\n",
    "    tps_id, hst_id = id_ejemplo\n",
    "    \n",
    "    registros_ejemplo = df_traslados_R4_limpio[\n",
    "        (df_traslados_R4_limpio['TPS_IDN_ID'] == tps_id) & \n",
    "        (df_traslados_R4_limpio['HST_IDN_NUMERO_IDENTIFICACION'] == hst_id)\n",
    "    ].sort_values('fecha_dt')\n",
    "    \n",
    "    print(f\"ID de ejemplo (TPS_IDN_ID: {tps_id}, HST_IDN_NUMERO_IDENTIFICACION: {hst_id})\")\n",
    "    print(f\"Total de registros para este ID: {len(registros_ejemplo)}\\n\")\n",
    "    print(registros_ejemplo[['TPS_IDN_ID', 'HST_IDN_NUMERO_IDENTIFICACION', 'FECHA_PROCESO', 'año', 'RESPUESTA', 'CAUSAL_RESPUESTA']])\n",
    "    \n",
    "    # Calcular diferencias entre fechas consecutivas\n",
    "    print(f\"\\nDiferencia en días entre registros consecutivos:\")\n",
    "    fechas = registros_ejemplo['fecha_dt'].tolist()\n",
    "    for i in range(1, len(fechas)):\n",
    "        dias = (fechas[i] - fechas[i-1]).days\n",
    "        print(f\"  Entre registro {i} y {i+1}: {dias} días\")\n",
    "else:\n",
    "    print(\"✅ No hay IDs duplicados. Cada ID aparece máximo 1 vez por período de 60 días.\")\n",
    "\n",
    "# Actualizar df_traslados_R4 con los registros limpios\n",
    "df_traslados_R4 = df_traslados_R4_limpio\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"RESUMEN FINAL\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"df_traslados_R4 actualizado con {len(df_traslados_R4):,} registros únicos\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "# Depurar traslados Salida SAT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la cantidad de registros antes del filtro\n",
    "registros_antes = len(df_traslados_SAT)\n",
    "\n",
    "# Filtrar registros donde COL18:\n",
    "# - NO es \"EPS025\" ni \"EPSC25\"\n",
    "# - NO está vacío, nulo o es \"0\"\n",
    "df_traslados_SAT = df_traslados_SAT[\n",
    "    (df_traslados_SAT['COL18'] != 'EPS025') & \n",
    "    (df_traslados_SAT['COL18'] != 'EPSC25') &\n",
    "    (df_traslados_SAT['COL18'].notna()) &  # No es nulo\n",
    "    (df_traslados_SAT['COL18'] != '') &     # No está vacío\n",
    "    (df_traslados_SAT['COL18'] != '0')      # No es \"0\"\n",
    "]\n",
    "\n",
    "# Obtener la cantidad de registros después del filtro\n",
    "registros_despues = len(df_traslados_SAT)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"========== FILTRADO DE df_traslados_SAT ==========\")\n",
    "print(f\"\\nRegistros antes del filtro: {registros_antes:,}\")\n",
    "print(f\"Registros después del filtro: {registros_despues:,}\")\n",
    "print(f\"Registros eliminados: {(registros_antes - registros_despues):,}\")\n",
    "print(f\"\\n{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir COL1 a datetime y filtrar por años 2025 y 2026\n",
    "df_traslados_SAT['COL1_dt'] = pd.to_datetime(df_traslados_SAT['COL1'], format='%d-%m-%Y', errors='coerce')\n",
    "df_traslados_SAT['año'] = df_traslados_SAT['COL1_dt'].dt.year\n",
    "\n",
    "# Obtener registros antes del filtro\n",
    "registros_antes = len(df_traslados_SAT)\n",
    "\n",
    "# Contar valores inválidos (NaT)\n",
    "valores_invalidos = df_traslados_SAT['COL1_dt'].isna().sum()\n",
    "\n",
    "# Filtrar solo años 2025 y 2026 (esto excluirá automáticamente los NaT)\n",
    "df_traslados_SAT = df_traslados_SAT[df_traslados_SAT['año'].isin([2025, 2026])]\n",
    "\n",
    "# Obtener registros después del filtro\n",
    "registros_despues = len(df_traslados_SAT)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"========== FILTRADO DE df_traslados_SAT POR AÑO ==========\")\n",
    "print(f\"\\nRegistros antes del filtro: {registros_antes:,}\")\n",
    "print(f\"Valores con fecha INVÁLIDA: {valores_invalidos:,}\")\n",
    "print(f\"Registros después del filtro: {registros_despues:,}\")\n",
    "print(f\"Registros eliminados: {(registros_antes - registros_despues):,}\")\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"\\nDistribución por AÑO:\")\n",
    "print(df_traslados_SAT['año'].value_counts(dropna=False).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener registros antes del filtro\n",
    "registros_antes = len(df_traslados_SAT)\n",
    "\n",
    "# Filtrar para eliminar registros donde COL3 es \"4\"\n",
    "df_traslados_SAT = df_traslados_SAT[df_traslados_SAT['COL3'] != '4']\n",
    "\n",
    "# Obtener registros después del filtro\n",
    "registros_despues = len(df_traslados_SAT)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"========== FILTRADO DE df_traslados_SAT (COL3 = '4') ==========\")\n",
    "print(f\"\\nRegistros antes del filtro: {registros_antes:,}\")\n",
    "print(f\"Registros después del filtro: {registros_despues:,}\")\n",
    "print(f\"Registros eliminados: {(registros_antes - registros_despues):,}\")\n",
    "print(f\"\\n{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la cantidad de registros antes del filtro\n",
    "registros_antes = len(df_traslados_SAT)\n",
    "\n",
    "# Eliminar registros con las categorías especificadas en COL19\n",
    "categorias_a_eliminar = [\n",
    "    \"Activo Reinscripción en el régimen subsidiado\",\n",
    "    \"Activo afiliación de oficio\",\n",
    "    \"Activo Afiliación Oficio IPS\"\n",
    "]\n",
    "\n",
    "df_traslados_SAT = df_traslados_SAT[~df_traslados_SAT['COL19'].isin(categorias_a_eliminar)]\n",
    "\n",
    "# Obtener la cantidad de registros después del filtro\n",
    "registros_despues = len(df_traslados_SAT)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"========== FILTRADO DE df_traslados_SAT (COL19) ==========\")\n",
    "print(f\"\\nRegistros antes del filtro: {registros_antes:,}\")\n",
    "print(f\"Registros después del filtro: {registros_despues:,}\")\n",
    "print(f\"Registros eliminados: {(registros_antes - registros_despues):,}\")\n",
    "print(f\"\\n{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las categorías y cantidad de registros de la columna COL19 en df_traslados_SAT\n",
    "print(\"=\"*70)\n",
    "print(\"CATEGORÍAS Y CANTIDAD DE REGISTROS EN df_traslados_SAT['COL19']\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTotal de registros: {len(df_traslados_SAT):,}\\n\")\n",
    "print(df_traslados_SAT['COL19'].value_counts())\n",
    "print(f\"\\nTotal de categorías únicas: {df_traslados_SAT['COL19'].nunique()}\")\n",
    "print(f\"\\nRegistros con valores nulos: {df_traslados_SAT['COL19'].isna().sum()}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las categorías y cantidad de registros de la columna COL3 en df_traslados_SAT\n",
    "print(\"=\"*70)\n",
    "print(\"CATEGORÍAS Y CANTIDAD DE REGISTROS EN df_traslados_SAT['COL3']\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTotal de registros: {len(df_traslados_SAT):,}\\n\")\n",
    "print(df_traslados_SAT['COL3'].value_counts())\n",
    "print(f\"\\nTotal de categorías únicas: {df_traslados_SAT['COL3'].nunique()}\")\n",
    "print(f\"\\nRegistros con valores nulos: {df_traslados_SAT['COL3'].isna().sum()}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar categorías de COL3 que NO sean de 1 o 2 dígitos\n",
    "df_traslados_SAT['COL3_length'] = df_traslados_SAT['COL3'].astype(str).str.len()\n",
    "\n",
    "# Obtener categorías con longitud diferente a 1 o 2 dígitos\n",
    "categorias_diferentes = df_traslados_SAT[~df_traslados_SAT['COL3_length'].isin([1, 2])]['COL3'].value_counts()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CATEGORÍAS DE COL3 CON LONGITUD DIFERENTE A 1 O 2 DÍGITOS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTotal de categorías diferentes: {len(categorias_diferentes)}\\n\")\n",
    "print(categorias_diferentes)\n",
    "print(f\"\\nTotal de registros con categorías diferentes: {categorias_diferentes.sum():,}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Limpiar columna temporal\n",
    "df_traslados_SAT = df_traslados_SAT.drop('COL3_length', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "# Guardar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear workbook y agregar las hojas de datos\n",
    "output_path = r\"C:\\Users\\crist\\OneDrive - 891856000_CAPRESOCA E P S\\Escritorio\\Yesid Rincón Z\\informes\\2026\\CTO 102.2026\\CTO102.2026 Informe  #02\\12 Actividad\\Salidas EPS S4-R4-NS-SAT\\Resultados_Especiales.xlsx\"\n",
    "\n",
    "# Convertir fecha_archivo a datetime para agrupar por mes en ambos DataFrames\n",
    "df_resultadosEspeciales['fecha_dt'] = pd.to_datetime(df_resultadosEspeciales['fecha_archivo'], format='%d/%m/%Y')\n",
    "df_resultadosEspeciales['mes_año'] = df_resultadosEspeciales['fecha_dt'].dt.to_period('M').astype(str)\n",
    "\n",
    "df_ns_municipios['fecha_dt'] = pd.to_datetime(df_ns_municipios['fecha_archivo'], format='%d/%m/%Y')\n",
    "df_ns_municipios['mes_año'] = df_ns_municipios['fecha_dt'].dt.to_period('M').astype(str)\n",
    "\n",
    "# Para df_ns_BDUA ya tenemos fecha_dt del filtrado anterior\n",
    "df_ns_BDUA['mes_año'] = df_ns_BDUA['fecha_dt'].dt.to_period('M').astype(str)\n",
    "\n",
    "# Para df_traslados_S4 ya tenemos fecha_dt del filtrado anterior\n",
    "df_traslados_S4['mes_año'] = df_traslados_S4['fecha_dt'].dt.to_period('M').astype(str)\n",
    "\n",
    "# Para df_traslados_R4 ya tenemos fecha_dt del filtrado anterior\n",
    "df_traslados_R4['mes_año'] = df_traslados_R4['fecha_dt'].dt.to_period('M').astype(str)\n",
    "\n",
    "# Para df_traslados_SAT usar COL1_dt que ya se creó en el filtrado anterior\n",
    "df_traslados_SAT['mes_año'] = df_traslados_SAT['COL1_dt'].dt.to_period('M').astype(str)\n",
    "\n",
    "with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "    # ==================== HOJA 1: Resultados Especiales ====================\n",
    "    df_resultadosEspeciales.to_excel(writer, sheet_name='Resultados_Especiales', index=False)\n",
    "    \n",
    "    # ==================== HOJA 2: NS Municipios ====================\n",
    "    df_ns_municipios.to_excel(writer, sheet_name='NS municipios', index=False)\n",
    "    \n",
    "    # ==================== HOJA 3: NS BDUA ====================\n",
    "    df_ns_BDUA.to_excel(writer, sheet_name='NS_BDUA', index=False)\n",
    "    \n",
    "    # ==================== HOJA 4: Traslados Salida S4 ====================\n",
    "    df_traslados_S4.to_excel(writer, sheet_name='Traslados Salida S4', index=False)\n",
    "    \n",
    "    # ==================== HOJA 5: Traslados Salida R4 ====================\n",
    "    df_traslados_R4.to_excel(writer, sheet_name='Traslados Salida R4', index=False)\n",
    "    \n",
    "    # ==================== HOJA 6: Traslados Salida SAT ====================\n",
    "    df_traslados_SAT.to_excel(writer, sheet_name='Traslados Salida SAT', index=False)\n",
    "    \n",
    "    # ==================== HOJA 7: RESUMEN CONSOLIDADO ====================\n",
    "    # Preparar resúmenes\n",
    "    resumen_re = df_resultadosEspeciales.groupby('mes_año').size().sort_index()\n",
    "    df_resumen_re = pd.DataFrame({\n",
    "        'Mes/Año': resumen_re.index,\n",
    "        'Fallecidos MinSalud': resumen_re.values\n",
    "    })\n",
    "    \n",
    "    resumen_ns = df_ns_municipios.groupby(['mes_año', 11]).size().unstack(fill_value=0).sort_index()\n",
    "    df_resumen_ns = pd.DataFrame({\n",
    "        'Mes/Año': resumen_ns.index,\n",
    "        'N09 - Fallecidos Municipios': resumen_ns['N09'] if 'N09' in resumen_ns.columns else 0,\n",
    "        'N13 - Retiros Alcaldías': resumen_ns['N13'] if 'N13' in resumen_ns.columns else 0\n",
    "    })\n",
    "    \n",
    "    # Resumen NS BDUA\n",
    "    resumen_bdua = df_ns_BDUA.groupby(['mes_año', 'NOVEDAD']).size().unstack(fill_value=0).sort_index()\n",
    "    df_resumen_bdua = pd.DataFrame({\n",
    "        'Mes/Año': resumen_bdua.index,\n",
    "        'N09 - BDUA': resumen_bdua['N09'] if 'N09' in resumen_bdua.columns else 0,\n",
    "        'N14 - BDUA': resumen_bdua['N14'] if 'N14' in resumen_bdua.columns else 0\n",
    "    })\n",
    "    \n",
    "    # Resumen Traslados S4\n",
    "    resumen_s4 = df_traslados_S4.groupby('mes_año').size().sort_index()\n",
    "    df_resumen_s4 = pd.DataFrame({\n",
    "        'Mes/Año': resumen_s4.index,\n",
    "        'S4 - Traslados': resumen_s4.values\n",
    "    })\n",
    "    \n",
    "    # Resumen Traslados R4\n",
    "    resumen_r4 = df_traslados_R4.groupby('mes_año').size().sort_index()\n",
    "    df_resumen_r4 = pd.DataFrame({\n",
    "        'Mes/Año': resumen_r4.index,\n",
    "        'R4 - Traslados': resumen_r4.values\n",
    "    })\n",
    "    \n",
    "    # Resumen Traslados SAT\n",
    "    resumen_sat = df_traslados_SAT.groupby('mes_año').size().sort_index()\n",
    "    df_resumen_sat = pd.DataFrame({\n",
    "        'Mes/Año': resumen_sat.index,\n",
    "        'SAT - Traslados': resumen_sat.values\n",
    "    })\n",
    "    \n",
    "    # Combinar todos los resúmenes en uno solo\n",
    "    df_resumen_total = pd.merge(df_resumen_re, df_resumen_ns, on='Mes/Año', how='outer')\n",
    "    df_resumen_total = pd.merge(df_resumen_total, df_resumen_bdua, on='Mes/Año', how='outer')\n",
    "    df_resumen_total = pd.merge(df_resumen_total, df_resumen_s4, on='Mes/Año', how='outer')\n",
    "    df_resumen_total = pd.merge(df_resumen_total, df_resumen_r4, on='Mes/Año', how='outer')\n",
    "    df_resumen_total = pd.merge(df_resumen_total, df_resumen_sat, on='Mes/Año', how='outer').fillna(0)\n",
    "    \n",
    "    # CONVERTIR TODO A ENTEROS\n",
    "    columnas_numericas = ['Fallecidos MinSalud', 'N09 - Fallecidos Municipios', 'N13 - Retiros Alcaldías', \n",
    "                          'N09 - BDUA', 'N14 - BDUA', 'S4 - Traslados', 'R4 - Traslados', 'SAT - Traslados']\n",
    "    for col in columnas_numericas:\n",
    "        df_resumen_total[col] = df_resumen_total[col].astype(int)\n",
    "    \n",
    "    df_resumen_total['Total Salidas'] = (\n",
    "        df_resumen_total['Fallecidos MinSalud'] + \n",
    "        df_resumen_total['N09 - Fallecidos Municipios'] + \n",
    "        df_resumen_total['N13 - Retiros Alcaldías'] +\n",
    "        df_resumen_total['N09 - BDUA'] +\n",
    "        df_resumen_total['N14 - BDUA'] +\n",
    "        df_resumen_total['S4 - Traslados'] +\n",
    "        df_resumen_total['R4 - Traslados'] +\n",
    "        df_resumen_total['SAT - Traslados']\n",
    "    )\n",
    "    df_resumen_total = df_resumen_total.sort_values('Mes/Año')\n",
    "    \n",
    "    # AGREGAR FILA DE TOTALES\n",
    "    fila_totales = pd.DataFrame({\n",
    "        'Mes/Año': ['TOTAL'],\n",
    "        'Fallecidos MinSalud': [df_resumen_total['Fallecidos MinSalud'].sum()],\n",
    "        'N09 - Fallecidos Municipios': [df_resumen_total['N09 - Fallecidos Municipios'].sum()],\n",
    "        'N13 - Retiros Alcaldías': [df_resumen_total['N13 - Retiros Alcaldías'].sum()],\n",
    "        'N09 - BDUA': [df_resumen_total['N09 - BDUA'].sum()],\n",
    "        'N14 - BDUA': [df_resumen_total['N14 - BDUA'].sum()],\n",
    "        'S4 - Traslados': [df_resumen_total['S4 - Traslados'].sum()],\n",
    "        'R4 - Traslados': [df_resumen_total['R4 - Traslados'].sum()],\n",
    "        'SAT - Traslados': [df_resumen_total['SAT - Traslados'].sum()],\n",
    "        'Total Salidas': [df_resumen_total['Total Salidas'].sum()]\n",
    "    })\n",
    "    \n",
    "    df_resumen_total = pd.concat([df_resumen_total, fila_totales], ignore_index=True)\n",
    "    \n",
    "    # Escribir el resumen consolidado\n",
    "    df_resumen_total.to_excel(writer, sheet_name='Resumen', index=False, startrow=0, startcol=0)\n",
    "    \n",
    "    # Obtener la hoja para agregar formatos\n",
    "    workbook = writer.book\n",
    "    ws_resumen = writer.sheets['Resumen']\n",
    "    \n",
    "    # Aplicar estilos al encabezado\n",
    "    header_fill = PatternFill(start_color=\"366092\", end_color=\"366092\", fill_type=\"solid\")\n",
    "    header_font = Font(bold=True, color=\"FFFFFF\")\n",
    "    \n",
    "    for cell in ws_resumen[1]:\n",
    "        cell.fill = header_fill\n",
    "        cell.font = header_font\n",
    "        cell.alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "    \n",
    "    # Aplicar estilos a la fila de TOTALES\n",
    "    fila_total_idx = len(df_resumen_total) + 1  # +1 porque la primera fila es el encabezado\n",
    "    total_fill = PatternFill(start_color=\"FFC000\", end_color=\"FFC000\", fill_type=\"solid\")\n",
    "    total_font = Font(bold=True, color=\"000000\")\n",
    "    \n",
    "    for col in range(1, 11):  # Columnas A hasta J (ahora incluye SAT)\n",
    "        cell = ws_resumen.cell(row=fila_total_idx, column=col)\n",
    "        cell.fill = total_fill\n",
    "        cell.font = total_font\n",
    "        cell.alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "    \n",
    "    # Ajustar ancho de columnas\n",
    "    ws_resumen.column_dimensions['A'].width = 15\n",
    "    ws_resumen.column_dimensions['B'].width = 22\n",
    "    ws_resumen.column_dimensions['C'].width = 25\n",
    "    ws_resumen.column_dimensions['D'].width = 25\n",
    "    ws_resumen.column_dimensions['E'].width = 18\n",
    "    ws_resumen.column_dimensions['F'].width = 18\n",
    "    ws_resumen.column_dimensions['G'].width = 18\n",
    "    ws_resumen.column_dimensions['H'].width = 18\n",
    "    ws_resumen.column_dimensions['I'].width = 18\n",
    "    ws_resumen.column_dimensions['J'].width = 15\n",
    "    \n",
    "    # ==================== GRÁFICO 1: Fallecidos MinSalud ====================\n",
    "    from openpyxl.chart import BarChart, Reference\n",
    "    from openpyxl.chart.label import DataLabelList\n",
    "    \n",
    "    chart1 = BarChart()\n",
    "    chart1.type = \"col\"\n",
    "    chart1.style = 10\n",
    "    chart1.title = \"Fallecidos reportados por el Ministerio de Salud\"\n",
    "    chart1.y_axis.title = 'Cantidad de Afiliados'\n",
    "    chart1.x_axis.title = 'Periodo (Mes/Año)'\n",
    "    \n",
    "    # EXCLUIR LA FILA DE TOTALES de los gráficos\n",
    "    data1 = Reference(ws_resumen, min_col=2, min_row=1, max_row=len(df_resumen_total))\n",
    "    cats1 = Reference(ws_resumen, min_col=1, min_row=2, max_row=len(df_resumen_total))\n",
    "    \n",
    "    chart1.add_data(data1, titles_from_data=True)\n",
    "    chart1.set_categories(cats1)\n",
    "    \n",
    "    chart1.dataLabels = DataLabelList()\n",
    "    chart1.dataLabels.showVal = True\n",
    "    chart1.dataLabels.showLegendKey = False\n",
    "    chart1.dataLabels.showCatName = False\n",
    "    chart1.dataLabels.showSerName = False\n",
    "    \n",
    "    chart1.legend = None\n",
    "    chart1.height = 12\n",
    "    chart1.width = 20\n",
    "    \n",
    "    ws_resumen.add_chart(chart1, \"L2\")\n",
    "    \n",
    "    # ==================== GRÁFICO 2: NS Municipios ====================\n",
    "    chart2 = BarChart()\n",
    "    chart2.type = \"col\"\n",
    "    chart2.style = 11\n",
    "    chart2.title = \"Salidas reportadas por Alcaldías\"\n",
    "    chart2.y_axis.title = 'Cantidad de Afiliados'\n",
    "    chart2.x_axis.title = 'Periodo (Mes/Año)'\n",
    "    \n",
    "    data2 = Reference(ws_resumen, min_col=3, max_col=4, min_row=1, max_row=len(df_resumen_total))\n",
    "    cats2 = Reference(ws_resumen, min_col=1, min_row=2, max_row=len(df_resumen_total))\n",
    "    \n",
    "    chart2.add_data(data2, titles_from_data=True)\n",
    "    chart2.set_categories(cats2)\n",
    "    \n",
    "    chart2.dataLabels = DataLabelList()\n",
    "    chart2.dataLabels.showVal = True\n",
    "    chart2.dataLabels.showLegendKey = False\n",
    "    chart2.dataLabels.showCatName = False\n",
    "    chart2.dataLabels.showSerName = False\n",
    "    \n",
    "    chart2.legend.position = 'r'\n",
    "    chart2.height = 12\n",
    "    chart2.width = 20\n",
    "    \n",
    "    ws_resumen.add_chart(chart2, \"L22\")\n",
    "    \n",
    "    # ==================== GRÁFICO 3: NS BDUA (EPS) ====================\n",
    "    chart3 = BarChart()\n",
    "    chart3.type = \"col\"\n",
    "    chart3.style = 12\n",
    "    chart3.title = \"Novedades reportadas por la EPS (BDUA)\"\n",
    "    chart3.y_axis.title = 'Cantidad de Afiliados'\n",
    "    chart3.x_axis.title = 'Periodo (Mes/Año)'\n",
    "    \n",
    "    data3 = Reference(ws_resumen, min_col=5, max_col=6, min_row=1, max_row=len(df_resumen_total))\n",
    "    cats3 = Reference(ws_resumen, min_col=1, min_row=2, max_row=len(df_resumen_total))\n",
    "    \n",
    "    chart3.add_data(data3, titles_from_data=True)\n",
    "    chart3.set_categories(cats3)\n",
    "    \n",
    "    chart3.dataLabels = DataLabelList()\n",
    "    chart3.dataLabels.showVal = True\n",
    "    chart3.dataLabels.showLegendKey = False\n",
    "    chart3.dataLabels.showCatName = False\n",
    "    chart3.dataLabels.showSerName = False\n",
    "    \n",
    "    chart3.legend.position = 'r'\n",
    "    chart3.height = 12\n",
    "    chart3.width = 20\n",
    "    \n",
    "    ws_resumen.add_chart(chart3, \"L42\")\n",
    "    \n",
    "    # ==================== GRÁFICO 4: Traslados S4, R4 y SAT ====================\n",
    "    chart4 = BarChart()\n",
    "    chart4.type = \"col\"\n",
    "    chart4.style = 13\n",
    "    chart4.title = \"Traslados de Salida - Procesos S4, R4 y SAT\"\n",
    "    chart4.y_axis.title = 'Cantidad de Afiliados'\n",
    "    chart4.x_axis.title = 'Periodo (Mes/Año)'\n",
    "    \n",
    "    data4 = Reference(ws_resumen, min_col=7, max_col=9, min_row=1, max_row=len(df_resumen_total))\n",
    "    cats4 = Reference(ws_resumen, min_col=1, min_row=2, max_row=len(df_resumen_total))\n",
    "    \n",
    "    chart4.add_data(data4, titles_from_data=True)\n",
    "    chart4.set_categories(cats4)\n",
    "    \n",
    "    chart4.dataLabels = DataLabelList()\n",
    "    chart4.dataLabels.showVal = True\n",
    "    chart4.dataLabels.showLegendKey = False\n",
    "    chart4.dataLabels.showCatName = False\n",
    "    chart4.dataLabels.showSerName = False\n",
    "    \n",
    "    chart4.legend.position = 'r'\n",
    "    chart4.height = 12\n",
    "    chart4.width = 20\n",
    "    \n",
    "    ws_resumen.add_chart(chart4, \"L62\")\n",
    "\n",
    "print(f\"Archivo Excel guardado en: {output_path}\")\n",
    "print(f\"\\nResumen Consolidado por Mes/Año:\\n{df_resumen_total}\")\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"TOTAL DE REGISTROS POR FUENTE:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"- Fallecidos MinSalud:          {df_resumen_total['Fallecidos MinSalud'].iloc[-1]}\")\n",
    "print(f\"- N09 Fallecidos Municipios:    {df_resumen_total['N09 - Fallecidos Municipios'].iloc[-1]}\")\n",
    "print(f\"- N13 Retiros Alcaldías:        {df_resumen_total['N13 - Retiros Alcaldías'].iloc[-1]}\")\n",
    "print(f\"- N09 BDUA:                     {df_resumen_total['N09 - BDUA'].iloc[-1]}\")\n",
    "print(f\"- N14 BDUA:                     {df_resumen_total['N14 - BDUA'].iloc[-1]}\")\n",
    "print(f\"- S4 Traslados:                 {df_resumen_total['S4 - Traslados'].iloc[-1]}\")\n",
    "print(f\"- R4 Traslados:                 {df_resumen_total['R4 - Traslados'].iloc[-1]}\")\n",
    "print(f\"- SAT Traslados:                {df_resumen_total['SAT - Traslados'].iloc[-1]}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"TOTAL SALIDAS:                  {df_resumen_total['Total Salidas'].iloc[-1]}\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
