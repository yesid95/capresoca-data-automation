{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a51c825",
   "metadata": {},
   "source": [
    "# Modulos, Clases y funciones Externas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3884943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías estándar de Python\n",
    "import datetime  # Manejo de fechas y horas\n",
    "import pandas as pd  # Manipulación y análisis de datos en DataFrames\n",
    "import numpy as np  # Operaciones numéricas y manejo eficiente de arrays\n",
    "import sys  # Acceso a variables y funciones del sistema\n",
    "import re  # Expresiones regulares para procesamiento de texto\n",
    "import os  # Operaciones del sistema de archivos\n",
    "\n",
    "# Añadir la carpeta raíz del proyecto al sys.path para importar módulos personalizados\n",
    "sys.path.append(os.path.abspath(\"c:/Users/osmarrincon/Documents/capresoca-data-automation\"))\n",
    "#sys.path.append(os.path.abspath(\"D:\\Proyectos Python\\capresoca-data-automation\"))  # Ruta alternativa (comentada)\n",
    "\n",
    "# Importar función y clase personalizada del proyecto\n",
    "from src.file_loader import cargar_maestros_ADRES  # Función para cargar archivos maestros ADRES\n",
    "from src.data_cleaning import BduaReportProcessor      # Clase para limpiar y normalizar población Maestro ADRES\n",
    "from src.data_cleaning import DataCleaner # Clase para limpiar y normalizar DataFrames de Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2703f3c6",
   "metadata": {},
   "source": [
    "# Rutas y varaibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34700c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_Pila_Validada = r\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Escritorio\\Yesid Rincón Z\\Traslados\\Procesos BDUA\\2025\\07_Julio\\15\\Dataframe 15-07-2025.xlsx\"\n",
    "R_Maestro__EPSC25 = r\"C:\\Users\\osmarrincon\\OneDrive - uniminuto.edu\\Capresoca\\AlmostClear\\Procesos BDUA\\Contributivo\\Maestro\\2025-2\\EPSC25MC0014072025.TXT\"\n",
    "R_Maestro__EPS025 = r\"C:\\Users\\osmarrincon\\OneDrive - uniminuto.edu\\Capresoca\\AlmostClear\\Procesos BDUA\\Subsidiados\\Maestro\\MS\\2025-2\\EPS025MS0014072025.TXT\"\n",
    "\n",
    "S_Excel = r\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Escritorio\\Yesid Rincón Z\\Traslados\\Procesos BDUA\\2025\\07_Julio\\15\\Prueba.xlsx\"\n",
    "\n",
    "# Crear el objeto de fecha\n",
    "fecha_Minima = datetime.datetime(2025, 5, 1)\n",
    "fecha_reporte = datetime.datetime(2025, 7, 15)\n",
    "fecha_proxi_reporte = datetime.datetime(2025, 7, 22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b99dab",
   "metadata": {},
   "source": [
    "# Cargue Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "151626aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar y combinar los maestros\n",
    "maestro_ADRES = cargar_maestros_ADRES(R_Maestro__EPS025, R_Maestro__EPSC25)\n",
    "Pila_Validada = pd.read_excel(R_Pila_Validada, sheet_name=\"Sheet1\", header=0, dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec56b49",
   "metadata": {},
   "source": [
    "# Listado censal o Sisben ADRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4eca49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicar la columna \"MARCASISBENIV+MARCASISBENIII_2\" y nombrarla \"MARCASISBENIV+MARCASISBENIII\"\n",
    "maestro_ADRES[\"MARCASISBENIV+MARCASISBENIII_2\"] = \\\n",
    "    maestro_ADRES[\"MARCASISBENIV+MARCASISBENIII\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "373e62b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instanciar el procesador: Se crea un objeto pasando el DataFrame.\n",
    "#    La jerarquía de población ya está definida por defecto dentro de la clase.\n",
    "processor = BduaReportProcessor(df=maestro_ADRES)\n",
    "\n",
    "# 2. Ejecutar la limpieza y asignarla de vuelta.\n",
    "#    El método retorna un DataFrame completamente nuevo con la columna actualizada.\n",
    "maestro_ADRES = processor.prioritize_population_markers(\n",
    "    col_name=\"MARCASISBENIV+MARCASISBENIII\"\n",
    ")\n",
    "\n",
    "# ¡Listo! 'maestro_ADRES' ahora contiene los datos limpios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d2a8ac",
   "metadata": {},
   "source": [
    "# Contrucción S1 movilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a9aaf5",
   "metadata": {},
   "source": [
    "## Pila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44dc99e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros: 862, Columnas: 38\n",
      "Porcentaje de vacíos por columna:\n",
      "ENT_ID                              100.0\n",
      "TPS_IDN_ID                            0.0\n",
      "HST_IDN_NUMERO_IDENTIFICACION         0.0\n",
      "AFL_PRIMER_APELLIDO                 100.0\n",
      "AFL_SEGUNDO_APELLIDO                100.0\n",
      "AFL_PRIMER_NOMBRE                   100.0\n",
      "AFL_SEGUNDO_NOMBRE                  100.0\n",
      "AFL_FECHA_NACIMIENTO                100.0\n",
      "TPS_GNR_ID                          100.0\n",
      "TPS_IDN_ID_2                        100.0\n",
      "HST_IDN_NUMERO_IDENTIFICACION_2     100.0\n",
      "AFL_PRIMER_APELLIDO_2               100.0\n",
      "AFL_SEGUNDO_APELLIDO_2              100.0\n",
      "AFL_PRIMER_NOMBRE_2                 100.0\n",
      "AFL_SEGUNDO_NOMBRE_2                100.0\n",
      "AFL_FECHA_NACIMIENTO_2              100.0\n",
      "TPS_GNR_ID_2                        100.0\n",
      "DPR_ID                              100.0\n",
      "MNC_ID                              100.0\n",
      "ZNS_ID                              100.0\n",
      "FECHA_AFILIACION_MOVILIDAD            0.0\n",
      "TPS_GRP_PBL_ID                      100.0\n",
      "TPS_NVL_SSB_ID                      100.0\n",
      "TIPO_TRASLADO                       100.0\n",
      "CND_AFL_SBS_METODOLOGIA             100.0\n",
      "CND_AFL_SBS_SUBGRUPO_SIV              0.0\n",
      "CON_DISCAPACIDAD                    100.0\n",
      "TPS_IDN_CF_ID                       100.0\n",
      "HST_IDN_NUMERO_CF_IDENTIFICACION    100.0\n",
      "TPS_PRN_ID                          100.0\n",
      "TPS_AFL_ID                          100.0\n",
      "TPS_ETN_ID                          100.0\n",
      "NOM_RESGUARDO_INDIGENA              100.0\n",
      "PAIS_NACIMIENTO                     100.0\n",
      "LUGAR_NACIMIENTO                    100.0\n",
      "NACIONALIDAD                        100.0\n",
      "SEXO_IDENTIFICACION                 100.0\n",
      "TIPO_DISCAPACIDAD                   100.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Definir las columnas del nuevo DataFrame\n",
    "new_columns = [\n",
    "    \"ENT_ID\", \"TPS_IDN_ID\", \"HST_IDN_NUMERO_IDENTIFICACION\", \"AFL_PRIMER_APELLIDO\", \"AFL_SEGUNDO_APELLIDO\",\n",
    "    \"AFL_PRIMER_NOMBRE\", \"AFL_SEGUNDO_NOMBRE\", \"AFL_FECHA_NACIMIENTO\", \"TPS_GNR_ID\", \"TPS_IDN_ID_2\",\n",
    "    \"HST_IDN_NUMERO_IDENTIFICACION_2\", \"AFL_PRIMER_APELLIDO_2\", \"AFL_SEGUNDO_APELLIDO_2\", \"AFL_PRIMER_NOMBRE_2\",\n",
    "    \"AFL_SEGUNDO_NOMBRE_2\", \"AFL_FECHA_NACIMIENTO_2\", \"TPS_GNR_ID_2\", \"DPR_ID\", \"MNC_ID\", \"ZNS_ID\",\n",
    "    \"FECHA_AFILIACION_MOVILIDAD\", \"TPS_GRP_PBL_ID\", \"TPS_NVL_SSB_ID\", \"TIPO_TRASLADO\", \"CND_AFL_SBS_METODOLOGIA\",\n",
    "    \"CND_AFL_SBS_SUBGRUPO_SIV\", \"CON_DISCAPACIDAD\", \"TPS_IDN_CF_ID\", \"HST_IDN_NUMERO_CF_IDENTIFICACION\",\n",
    "    \"TPS_PRN_ID\", \"TPS_AFL_ID\", \"TPS_ETN_ID\", \"NOM_RESGUARDO_INDIGENA\",\n",
    "    \"PAIS_NACIMIENTO\", \"LUGAR_NACIMIENTO\", \"NACIONALIDAD\", \"SEXO_IDENTIFICACION\", \"TIPO_DISCAPACIDAD\"\n",
    "]\n",
    "\n",
    "# Filtrar registros donde 'Movilidad' contiene 'S1'\n",
    "mask = Pila_Validada[\"Movilidad\"].str.contains(\"S1\", na=False)\n",
    "filtered = Pila_Validada.loc[mask]\n",
    "\n",
    "# Crear el nuevo DataFrame S1 con valores vacíos\n",
    "S1 = pd.DataFrame('', index=filtered.index, columns=new_columns)\n",
    "\n",
    "# Asignar los valores requeridos\n",
    "S1.loc[:, \"TPS_IDN_ID\"] = filtered[\"Tipo Documento Cotizante\"]\n",
    "S1.loc[:, \"HST_IDN_NUMERO_IDENTIFICACION\"] = filtered[\"N° Identificación Cotizante\"]\n",
    "S1.loc[:, \"FECHA_AFILIACION_MOVILIDAD\"] = filtered[\"Fecha envio\"]\n",
    "S1.loc[:, \"CND_AFL_SBS_SUBGRUPO_SIV\"] = filtered[\"Población_2\"]\n",
    "\n",
    "# Mostrar cantidad de registros, columnas y porcentaje de vacíos por columna\n",
    "print(f\"Registros: {S1.shape[0]}, Columnas: {S1.shape[1]}\")\n",
    "print(\"Porcentaje de vacíos por columna:\")\n",
    "print(S1.isin(['', None, np.nan]).mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7ef77d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "S1[\"Where\"] = \"Pila\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b78f9eb",
   "metadata": {},
   "source": [
    "## Beneficairios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd0fe5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> S1 columns antes de strip():\n",
      "[\"'ENT_ID'\", \"'TPS_IDN_ID'\", \"'HST_IDN_NUMERO_IDENTIFICACION'\", \"'AFL_PRIMER_APELLIDO'\", \"'AFL_SEGUNDO_APELLIDO'\", \"'AFL_PRIMER_NOMBRE'\", \"'AFL_SEGUNDO_NOMBRE'\", \"'AFL_FECHA_NACIMIENTO'\", \"'TPS_GNR_ID'\", \"'TPS_IDN_ID_2'\", \"'HST_IDN_NUMERO_IDENTIFICACION_2'\", \"'AFL_PRIMER_APELLIDO_2'\", \"'AFL_SEGUNDO_APELLIDO_2'\", \"'AFL_PRIMER_NOMBRE_2'\", \"'AFL_SEGUNDO_NOMBRE_2'\", \"'AFL_FECHA_NACIMIENTO_2'\", \"'TPS_GNR_ID_2'\", \"'DPR_ID'\", \"'MNC_ID'\", \"'ZNS_ID'\", \"'FECHA_AFILIACION_MOVILIDAD'\", \"'TPS_GRP_PBL_ID'\", \"'TPS_NVL_SSB_ID'\", \"'TIPO_TRASLADO'\", \"'CND_AFL_SBS_METODOLOGIA'\", \"'CND_AFL_SBS_SUBGRUPO_SIV'\", \"'CON_DISCAPACIDAD'\", \"'TPS_IDN_CF_ID'\", \"'HST_IDN_NUMERO_CF_IDENTIFICACION'\", \"'TPS_PRN_ID'\", \"'TPS_AFL_ID'\", \"'TPS_ETN_ID'\", \"'NOM_RESGUARDO_INDIGENA'\", \"'PAIS_NACIMIENTO'\", \"'LUGAR_NACIMIENTO'\", \"'NACIONALIDAD'\", \"'SEXO_IDENTIFICACION'\", \"'TIPO_DISCAPACIDAD'\", \"'Where'\"]\n",
      ">> maestro_ADRES columns antes de strip():\n",
      "[\"'AFL_ID'\", \"'ENT_ID'\", \"'TPS_IDN_ID_CF'\", \"'HST_IDN_NUMERO_IDENTIFICACION_CF'\", \"'TPS_IDN_ID'\", \"'HST_IDN_NUMERO_IDENTIFICACION'\", \"'AFL_PRIMER_APELLIDO'\", \"'AFL_SEGUNDO_APELLIDO'\", \"'AFL_PRIMER_NOMBRE'\", \"'AFL_SEGUNDO_NOMBRE'\", \"'AFL_FECHA_NACIMIENTO'\", \"'TPS_GNR_ID'\", \"'AFL_PAIS_NACIMIENTO'\", \"'AFL_MUNICIPIO_NACIMIENTO'\", \"'AFL_NACIONALIDAD'\", \"'AFL_SEXO_IDENTIFICACION'\", \"'AFL_DISCAPACIDAD'\", \"'TPS_AFL_ID'\", \"'TPS_PRN_ID'\", \"'TPS_GRP_PBL_ID'\", \"'TPS_NVL_SSB_ID'\", \"'NUMEROFICHASISBEN'\", \"'TPS_CND_BNF_ID'\", \"'DPR_ID'\", \"'MNC_ID'\", \"'ZNS_ID'\", \"'AFL_FECHA_AFILIACION_SGSSS'\", \"'AFC_FECHA_INICIO'\", \"'NUMERO CONTRATO'\", \"'FECHADE INICIO DEL CONTRATO'\", \"'CNT_AFL_TPS_GRP_PBL_ID'\", \"'CNT_AFL_TPS_PRT_ETN_ID'\", \"'TPS_MDL_SBS_ID'\", \"'TPS_EST_AFL_ID'\", \"'CND_AFL_FECHA_INICIO'\", \"'CND_AFL_FECHA_INICIO'\", \"'GRP_FML_COTIZANTE_ID'\", \"'PORTABILIDAD'\", \"'COD_IPS_P'\", \"'MTDLG_G_P'\", \"'SUB_SISBEN_IV'\", \"'MARCASISBENIV+MARCASISBENIII'\", \"'CRUCE_BDEX_RNEC'\", \"'MARCASISBENIV+MARCASISBENIII_2'\"]\n",
      ">> S1 columns después de strip():\n",
      "[\"'ENT_ID'\", \"'TPS_IDN_ID'\", \"'HST_IDN_NUMERO_IDENTIFICACION'\", \"'AFL_PRIMER_APELLIDO'\", \"'AFL_SEGUNDO_APELLIDO'\", \"'AFL_PRIMER_NOMBRE'\", \"'AFL_SEGUNDO_NOMBRE'\", \"'AFL_FECHA_NACIMIENTO'\", \"'TPS_GNR_ID'\", \"'TPS_IDN_ID_2'\", \"'HST_IDN_NUMERO_IDENTIFICACION_2'\", \"'AFL_PRIMER_APELLIDO_2'\", \"'AFL_SEGUNDO_APELLIDO_2'\", \"'AFL_PRIMER_NOMBRE_2'\", \"'AFL_SEGUNDO_NOMBRE_2'\", \"'AFL_FECHA_NACIMIENTO_2'\", \"'TPS_GNR_ID_2'\", \"'DPR_ID'\", \"'MNC_ID'\", \"'ZNS_ID'\", \"'FECHA_AFILIACION_MOVILIDAD'\", \"'TPS_GRP_PBL_ID'\", \"'TPS_NVL_SSB_ID'\", \"'TIPO_TRASLADO'\", \"'CND_AFL_SBS_METODOLOGIA'\", \"'CND_AFL_SBS_SUBGRUPO_SIV'\", \"'CON_DISCAPACIDAD'\", \"'TPS_IDN_CF_ID'\", \"'HST_IDN_NUMERO_CF_IDENTIFICACION'\", \"'TPS_PRN_ID'\", \"'TPS_AFL_ID'\", \"'TPS_ETN_ID'\", \"'NOM_RESGUARDO_INDIGENA'\", \"'PAIS_NACIMIENTO'\", \"'LUGAR_NACIMIENTO'\", \"'NACIONALIDAD'\", \"'SEXO_IDENTIFICACION'\", \"'TIPO_DISCAPACIDAD'\", \"'Where'\"]\n",
      ">> maestro_ADRES columns después de strip():\n",
      "[\"'AFL_ID'\", \"'ENT_ID'\", \"'TPS_IDN_ID_CF'\", \"'HST_IDN_NUMERO_IDENTIFICACION_CF'\", \"'TPS_IDN_ID'\", \"'HST_IDN_NUMERO_IDENTIFICACION'\", \"'AFL_PRIMER_APELLIDO'\", \"'AFL_SEGUNDO_APELLIDO'\", \"'AFL_PRIMER_NOMBRE'\", \"'AFL_SEGUNDO_NOMBRE'\", \"'AFL_FECHA_NACIMIENTO'\", \"'TPS_GNR_ID'\", \"'AFL_PAIS_NACIMIENTO'\", \"'AFL_MUNICIPIO_NACIMIENTO'\", \"'AFL_NACIONALIDAD'\", \"'AFL_SEXO_IDENTIFICACION'\", \"'AFL_DISCAPACIDAD'\", \"'TPS_AFL_ID'\", \"'TPS_PRN_ID'\", \"'TPS_GRP_PBL_ID'\", \"'TPS_NVL_SSB_ID'\", \"'NUMEROFICHASISBEN'\", \"'TPS_CND_BNF_ID'\", \"'DPR_ID'\", \"'MNC_ID'\", \"'ZNS_ID'\", \"'AFL_FECHA_AFILIACION_SGSSS'\", \"'AFC_FECHA_INICIO'\", \"'NUMERO CONTRATO'\", \"'FECHADE INICIO DEL CONTRATO'\", \"'CNT_AFL_TPS_GRP_PBL_ID'\", \"'CNT_AFL_TPS_PRT_ETN_ID'\", \"'TPS_MDL_SBS_ID'\", \"'TPS_EST_AFL_ID'\", \"'CND_AFL_FECHA_INICIO'\", \"'CND_AFL_FECHA_INICIO'\", \"'GRP_FML_COTIZANTE_ID'\", \"'PORTABILIDAD'\", \"'COD_IPS_P'\", \"'MTDLG_G_P'\", \"'SUB_SISBEN_IV'\", \"'MARCASISBENIV+MARCASISBENIII'\", \"'CRUCE_BDEX_RNEC'\", \"'MARCASISBENIV+MARCASISBENIII_2'\"]\n",
      "Registros: 862, Columnas: 39\n",
      ">> beneficiarios columns:\n",
      "['AFL_ID', 'ENT_ID', 'TPS_IDN_ID_CF', 'HST_IDN_NUMERO_IDENTIFICACION_CF', 'TPS_IDN_ID_master', 'HST_IDN_NUMERO_IDENTIFICACION_master', 'AFL_PRIMER_APELLIDO', 'AFL_SEGUNDO_APELLIDO', 'AFL_PRIMER_NOMBRE', 'AFL_SEGUNDO_NOMBRE', 'AFL_FECHA_NACIMIENTO', 'TPS_GNR_ID', 'AFL_PAIS_NACIMIENTO', 'AFL_MUNICIPIO_NACIMIENTO', 'AFL_NACIONALIDAD', 'AFL_SEXO_IDENTIFICACION', 'AFL_DISCAPACIDAD', 'TPS_AFL_ID', 'TPS_PRN_ID', 'TPS_GRP_PBL_ID', 'TPS_NVL_SSB_ID', 'NUMEROFICHASISBEN', 'TPS_CND_BNF_ID', 'DPR_ID', 'MNC_ID', 'ZNS_ID', 'AFL_FECHA_AFILIACION_SGSSS', 'AFC_FECHA_INICIO', 'NUMERO CONTRATO', 'FECHADE INICIO DEL CONTRATO', 'CNT_AFL_TPS_GRP_PBL_ID', 'CNT_AFL_TPS_PRT_ETN_ID', 'TPS_MDL_SBS_ID', 'TPS_EST_AFL_ID', 'CND_AFL_FECHA_INICIO', 'CND_AFL_FECHA_INICIO', 'GRP_FML_COTIZANTE_ID', 'PORTABILIDAD', 'COD_IPS_P', 'MTDLG_G_P', 'SUB_SISBEN_IV', 'MARCASISBENIV+MARCASISBENIII', 'CRUCE_BDEX_RNEC', 'MARCASISBENIV+MARCASISBENIII_2', 'TPS_IDN_ID_s1', 'HST_IDN_NUMERO_IDENTIFICACION_s1', 'FECHA_AFILIACION_MOVILIDAD']\n",
      "Registros después del concat: 1077\n",
      "Columnas después del concat:  39\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Debug: mostrar nombres de columnas antes de cualquier operación\n",
    "# ----------------------------------------------------\n",
    "print(\">> S1 columns antes de strip():\")\n",
    "print([repr(c) for c in S1.columns.tolist()])\n",
    "print(\">> maestro_ADRES columns antes de strip():\")\n",
    "print([repr(c) for c in maestro_ADRES.columns.tolist()])\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Limpiar espacios invisibles en los nombres de columna\n",
    "# ----------------------------------------------------\n",
    "S1.columns            = S1.columns.str.strip()\n",
    "maestro_ADRES.columns = maestro_ADRES.columns.str.strip()\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Debug: volver a mostrar nombres de columnas después de strip()\n",
    "# ----------------------------------------------------\n",
    "print(\">> S1 columns después de strip():\")\n",
    "print([repr(c) for c in S1.columns.tolist()])\n",
    "print(\">> maestro_ADRES columns después de strip():\")\n",
    "print([repr(c) for c in maestro_ADRES.columns.tolist()])\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 0) Cantidad de registros y columnas en S1\n",
    "# ----------------------------------------------------\n",
    "print(f\"Registros: {S1.shape[0]}, Columnas: {S1.shape[1]}\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 1) Preparar sólo las claves de S1 (cabezas de familia),\n",
    "#    incluyendo FECHA_AFILIACION_MOVILIDAD para luego propagarla\n",
    "# ----------------------------------------------------\n",
    "s1_keys = (\n",
    "    S1[[\"TPS_IDN_ID\", \"HST_IDN_NUMERO_IDENTIFICACION\", \"FECHA_AFILIACION_MOVILIDAD\"]]\n",
    "    .drop_duplicates(subset=[\"TPS_IDN_ID\", \"HST_IDN_NUMERO_IDENTIFICACION\"])\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 2) Emparejar S1 (cabezas) con maestro_ADRES (beneficiarios)\n",
    "#    - Usamos sufijos para distinguir columnas duplicadas\n",
    "# ----------------------------------------------------\n",
    "beneficiarios = (\n",
    "    maestro_ADRES\n",
    "    .merge(\n",
    "        s1_keys,\n",
    "        left_on=[\"TPS_IDN_ID_CF\", \"HST_IDN_NUMERO_IDENTIFICACION_CF\"],\n",
    "        right_on=[\"TPS_IDN_ID\",    \"HST_IDN_NUMERO_IDENTIFICACION\"],\n",
    "        how=\"inner\",\n",
    "        suffixes=(\"_master\", \"_s1\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Debug: ver columnas que resultaron de este merge\n",
    "print(\">> beneficiarios columns:\")\n",
    "print(beneficiarios.columns.tolist())\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 3) Construir los nuevos registros con las columnas solicitadas,\n",
    "#    propagando FECHA_AFILIACION_MOVILIDAD desde la familia cabeza\n",
    "# ----------------------------------------------------\n",
    "nuevos = pd.DataFrame({\n",
    "    # ID del beneficiario (de maestro_ADRES con sufijo _master)\n",
    "    \"TPS_IDN_ID\":                        beneficiarios[\"TPS_IDN_ID_master\"],\n",
    "    \"HST_IDN_NUMERO_IDENTIFICACION\":     beneficiarios[\"HST_IDN_NUMERO_IDENTIFICACION_master\"],\n",
    "    # Subgrupo según MARCASISBENIV+MARCASISBENIII\n",
    "    \"CND_AFL_SBS_SUBGRUPO_SIV\":          beneficiarios[\"MARCASISBENIV+MARCASISBENIII\"],\n",
    "    # IDs de la cabeza de familia\n",
    "    \"TPS_IDN_CF_ID\":                     beneficiarios[\"TPS_IDN_ID_CF\"],\n",
    "    \"HST_IDN_NUMERO_CF_IDENTIFICACION\":  beneficiarios[\"HST_IDN_NUMERO_IDENTIFICACION_CF\"],\n",
    "    # TPS_PRN_ID del beneficiario\n",
    "    \"TPS_PRN_ID\":                        beneficiarios[\"TPS_PRN_ID\"],\n",
    "    # Marcamos estos nuevos registros con la etiqueta fija\n",
    "    \"Where\":                             \"Beneficiarios Pila\",\n",
    "    # Propagamos la misma fecha de movilidad que tenía la cabeza de familia\n",
    "    \"FECHA_AFILIACION_MOVILIDAD\":        beneficiarios[\"FECHA_AFILIACION_MOVILIDAD\"],\n",
    "})\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 4) Añadir los nuevos registros al final de S1\n",
    "# ----------------------------------------------------\n",
    "S1 = pd.concat([S1, nuevos], ignore_index=True)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 5) Mostrar resumen final\n",
    "# ----------------------------------------------------\n",
    "print(f\"Registros después del concat: {S1.shape[0]}\")\n",
    "print(f\"Columnas después del concat:  {S1.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c3e90",
   "metadata": {},
   "source": [
    "### Fechas de Beneficairios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccfe2fc",
   "metadata": {},
   "source": [
    "## Sisben Beneficiarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc0de7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar el mapeo de los valores de maestro_ADRES[\"MARCASISBENIV+MARCASISBENIII\"]\n",
    "# a S1[\"CND_AFL_SBS_SUBGRUPO_SIV\"] solo donde S1[\"Where\"] == \"Beneficiarios Pila\"\n",
    "\n",
    "# Crear un diccionario para búsqueda rápida por ID\n",
    "maestro_map = maestro_ADRES.set_index([\"TPS_IDN_ID\", \"HST_IDN_NUMERO_IDENTIFICACION\"])[\"MARCASISBENIV+MARCASISBENIII\"]\n",
    "\n",
    "# Actualizar S1 usando .apply para mantener el nombre de las columnas\n",
    "def actualizar_subgrupo(row):\n",
    "    if row.get(\"Where\") == \"Beneficiarios Pila\":\n",
    "        key = (row[\"TPS_IDN_ID\"], row[\"HST_IDN_NUMERO_IDENTIFICACION\"])\n",
    "        valor = maestro_map.get(key, row[\"CND_AFL_SBS_SUBGRUPO_SIV\"])\n",
    "        return valor\n",
    "    return row[\"CND_AFL_SBS_SUBGRUPO_SIV\"]\n",
    "\n",
    "S1[\"CND_AFL_SBS_SUBGRUPO_SIV\"] = S1.apply(actualizar_subgrupo, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5f43ed",
   "metadata": {},
   "source": [
    "## Datos del Maestro al S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d61b9693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) Defino cómo se llaman en maestro → cómo quiero que queden en S1\n",
    "column_mapping = {\n",
    "    \"AFL_PAIS_NACIMIENTO\":     \"PAIS_NACIMIENTO\",\n",
    "    \"AFL_MUNICIPIO_NACIMIENTO\":\"LUGAR_NACIMIENTO\",\n",
    "    \"AFL_NACIONALIDAD\":        \"NACIONALIDAD\",\n",
    "    \"AFL_SEXO_IDENTIFICACION\": \"SEXO_IDENTIFICACION\",\n",
    "    \"AFL_DISCAPACIDAD\":        \"TIPO_DISCAPACIDAD\",\n",
    "    \"DPR_ID\":                  \"DPR_ID\",\n",
    "    \"MNC_ID\":                  \"MNC_ID\",\n",
    "    \"ZNS_ID\":                  \"ZNS_ID\",\n",
    "    \"TPS_AFL_ID\":              \"TPS_AFL_ID\",\n",
    "    # (y las que ya tenías antes…)\n",
    "    \"AFL_PRIMER_APELLIDO\":    \"AFL_PRIMER_APELLIDO\",\n",
    "    \"AFL_SEGUNDO_APELLIDO\":   \"AFL_SEGUNDO_APELLIDO\",\n",
    "    \"AFL_PRIMER_NOMBRE\":      \"AFL_PRIMER_NOMBRE\",\n",
    "    \"AFL_SEGUNDO_NOMBRE\":     \"AFL_SEGUNDO_NOMBRE\",\n",
    "    \"AFL_FECHA_NACIMIENTO\":   \"AFL_FECHA_NACIMIENTO\",\n",
    "    \"TPS_GNR_ID\":             \"TPS_GNR_ID\",\n",
    "}\n",
    "\n",
    "join_keys = [\"TPS_IDN_ID\", \"HST_IDN_NUMERO_IDENTIFICACION\"]\n",
    "\n",
    "# 2) Preparo el maestro: me quedo solo con las columnas que necesito y\n",
    "#    las renombro para que coincidan con S1:\n",
    "maestro_subset = (\n",
    "    maestro_ADRES[list(column_mapping.keys()) + join_keys]\n",
    "    .rename(columns=column_mapping)\n",
    ")\n",
    "\n",
    "# 3) Hago el merge contra S1; pandas añadirá un sufijo solo a las columnas\n",
    "#    del maestro (porque ya existen en S1):\n",
    "S1_merged = S1.merge(\n",
    "    maestro_subset,\n",
    "    on=join_keys,\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_maestro\")\n",
    ")\n",
    "\n",
    "# 4) Ahora, para cada columna de destino 'col', relleno S1[col] solo donde\n",
    "#    esté vacío usando la versión '_maestro', y luego elimino esa columna:\n",
    "for col in column_mapping.values():\n",
    "    maestro_col = f\"{col}_maestro\"\n",
    "    if maestro_col in S1_merged:\n",
    "        S1_merged[col] = S1_merged[col].replace(\"\", pd.NA) \\\n",
    "                                       .fillna(S1_merged[maestro_col]) \\\n",
    "                                       .fillna(\"\")  # opcional volver a cadena vacía\n",
    "        S1_merged.drop(columns=maestro_col, inplace=True)\n",
    "\n",
    "# 5) S1_merged es tu S1 final, con el mismo esquema de columnas y\n",
    "#    solo rellenando lo que estaba vacío:\n",
    "S1 = S1_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24a64468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignar los valores de las columnas base a las columnas \"_2\" en S1\n",
    "cols_base = [\n",
    "    \"TPS_IDN_ID\",\n",
    "    \"HST_IDN_NUMERO_IDENTIFICACION\",\n",
    "    \"AFL_PRIMER_APELLIDO\",\n",
    "    \"AFL_SEGUNDO_APELLIDO\",\n",
    "    \"AFL_PRIMER_NOMBRE\",\n",
    "    \"AFL_SEGUNDO_NOMBRE\",\n",
    "    \"AFL_FECHA_NACIMIENTO\",\n",
    "    \"TPS_GNR_ID\"\n",
    "]\n",
    "cols_2 = [\n",
    "    \"TPS_IDN_ID_2\",\n",
    "    \"HST_IDN_NUMERO_IDENTIFICACION_2\",\n",
    "    \"AFL_PRIMER_APELLIDO_2\",\n",
    "    \"AFL_SEGUNDO_APELLIDO_2\",\n",
    "    \"AFL_PRIMER_NOMBRE_2\",\n",
    "    \"AFL_SEGUNDO_NOMBRE_2\",\n",
    "    \"AFL_FECHA_NACIMIENTO_2\",\n",
    "    \"TPS_GNR_ID_2\"\n",
    "]\n",
    "\n",
    "for base, col2 in zip(cols_base, cols_2):\n",
    "    S1[col2] = S1[base]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c593bf5",
   "metadata": {},
   "source": [
    "## Sisben S1 \n",
    "1. Tipo de población \"TPS_GRP_PBL_ID\"\n",
    "2. Nivel de sisben \"TPS_NVL_SSB_ID\"\n",
    "3. Metodologia del sisben \"CND_AFL_SBS_METODOLOGIA\"\n",
    "4. Grupo sisben \"CND_AFL_SBS_SUBGRUPO_SIV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16936195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_nvl_ssb(subgrupo):\n",
    "    if pd.isna(subgrupo):\n",
    "        return \"\"\n",
    "    lc_match = re.match(r\"LC\\((\\d+)\\)\", subgrupo)\n",
    "    if lc_match:\n",
    "        return lc_match.group(1)\n",
    "    siv_match = re.match(r\"SIV\\([A-Z0-9]+\\)\", subgrupo)\n",
    "    if siv_match:\n",
    "        return \"5\"\n",
    "    return \"\"\n",
    "\n",
    "S1[\"TPS_GRP_PBL_ID\"] = S1[\"CND_AFL_SBS_SUBGRUPO_SIV\"].apply(extract_nvl_ssb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c5b3e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignación condicional según las reglas descritas\n",
    "def assign_values(row):\n",
    "    grp_pbl_id = row[\"TPS_GRP_PBL_ID\"]\n",
    "    subgrupo = row[\"CND_AFL_SBS_SUBGRUPO_SIV\"]\n",
    "    if grp_pbl_id != \"5\":\n",
    "        row[\"TPS_NVL_SSB_ID\"] = \"N\"\n",
    "        row[\"CND_AFL_SBS_METODOLOGIA\"] = \"3\"\n",
    "        row[\"CND_AFL_SBS_SUBGRUPO_SIV\"] = \"\"\n",
    "    else:\n",
    "        # Extraer la letra y número de SIV(xxx)\n",
    "        match = re.match(r\"SIV\\(([A-Z])(\\d{2})\\)\", subgrupo)\n",
    "        if match:\n",
    "            letra = match.group(1)\n",
    "            numero = match.group(2)\n",
    "            if letra in [\"A\", \"B\"]:\n",
    "                row[\"TPS_NVL_SSB_ID\"] = \"1\"\n",
    "                row[\"CND_AFL_SBS_METODOLOGIA\"] = \"2\"\n",
    "            elif letra == \"C\":\n",
    "                row[\"TPS_NVL_SSB_ID\"] = \"2\"\n",
    "                row[\"CND_AFL_SBS_METODOLOGIA\"] = \"2\"\n",
    "            row[\"CND_AFL_SBS_SUBGRUPO_SIV\"] = f\"{letra}{numero}\"\n",
    "        else:\n",
    "            # Si no coincide con el patrón, dejar vacío\n",
    "            row[\"TPS_NVL_SSB_ID\"] = \"\"\n",
    "            row[\"CND_AFL_SBS_METODOLOGIA\"] = \"\"\n",
    "            row[\"CND_AFL_SBS_SUBGRUPO_SIV\"] = \"\"\n",
    "    return row\n",
    "\n",
    "S1 = S1.apply(assign_values, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b98db57",
   "metadata": {},
   "source": [
    "# Tipo y Fechas de movilidad\n",
    "1. Se asigna el tipo de movilidad, acorde al corte del proceso a reportar \"TIPO_TRASLADO\"\n",
    "2. se valida y se corigue la fecha de ser mayor a la de la fecha del reporte \"FECHA_AFILIACION_MOVILIDAD\"  y menor a la fecha del sigueinte reporte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb18d276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Procesando la columna de fecha 'FECHA_AFILIACION_MOVILIDAD'...\n",
      "ADVERTENCIA: Se encontraron 429 fechas no válidas que fueron convertidas a NaT.\n",
      "INFO: Conversión finalizada.\n"
     ]
    }
   ],
   "source": [
    "# Asignar valor 3 a todos los registros en TIPO_TRASLADO\n",
    "S1[\"TIPO_TRASLADO\"] = \"3\"\n",
    "\n",
    "\n",
    "# Convertir la columna de fechas a datetime\n",
    "## --- 1. Instanciar la clase ---\n",
    "# Creas un objeto \"limpiador\" con tu DataFrame\n",
    "cleaner = DataCleaner(df=S1)\n",
    "\n",
    "## --- 2. Ejecutar el método ---\n",
    "# Llamas al método específico para la tarea que necesitas.\n",
    "# Este devuelve un DataFrame nuevo y limpio que debes asignar.\n",
    "S1 = cleaner.process_date_column(column_name=\"FECHA_AFILIACION_MOVILIDAD\")\n",
    "\n",
    "# Inicializar la columna de validación\n",
    "S1[\"Validación fecha\"] = \"\"\n",
    "\n",
    "# Procesar cada registro según la lógica de negocio\n",
    "def validar_fecha(row):\n",
    "    fecha = row[\"FECHA_AFILIACION_MOVILIDAD\"]\n",
    "    if pd.isnull(fecha):\n",
    "        return row\n",
    "\n",
    "    # Si la fecha es menor a la mínima, se ajusta a la mínima\n",
    "    if fecha < fecha_Minima:\n",
    "        row[\"FECHA_AFILIACION_MOVILIDAD\"] = fecha_Minima\n",
    "        row[\"TIPO_TRASLADO\"] = \"3\"\n",
    "        row[\"Validación fecha\"] = \"\"\n",
    "    # Si la fecha es mayor a la fecha de reporte\n",
    "    elif fecha > fecha_reporte:\n",
    "        # Si es menor a la fecha del próximo reporte\n",
    "        if fecha < fecha_proxi_reporte:\n",
    "            # Cambiar a un mes exacto antes\n",
    "            nueva_fecha = fecha - pd.DateOffset(months=1)\n",
    "            row[\"FECHA_AFILIACION_MOVILIDAD\"] = nueva_fecha\n",
    "            row[\"TIPO_TRASLADO\"] = \"4\"\n",
    "            row[\"Validación fecha\"] = \"\"\n",
    "        else:\n",
    "            # Si es igual o mayor al próximo reporte, dejar para próximos reportes\n",
    "            row[\"TIPO_TRASLADO\"] = \"\"\n",
    "            row[\"Validación fecha\"] = \"proceso para proximos reportes\"\n",
    "    else:\n",
    "        # Fecha válida, no se modifica\n",
    "        row[\"TIPO_TRASLADO\"] = \"3\"\n",
    "        row[\"Validación fecha\"] = \"\"\n",
    "    return row\n",
    "\n",
    "S1 = S1.apply(validar_fecha, axis=1)\n",
    "\n",
    "# Si quieres que la columna de fecha vuelva a formato string:\n",
    "S1[\"FECHA_AFILIACION_MOVILIDAD\"] = S1[\"FECHA_AFILIACION_MOVILIDAD\"].dt.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a4c7eb",
   "metadata": {},
   "source": [
    "# Guardamos Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16a45d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo Excel guardado en: C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Escritorio\\Yesid Rincón Z\\Traslados\\Procesos BDUA\\2025\\07_Julio\\15\\Prueba.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with pd.ExcelWriter(S_Excel, engine=\"openpyxl\") as writer:\n",
    "    S1.to_excel(writer, sheet_name=\"S1\", index=False)\n",
    "    #maestro_ADRES.to_excel(writer, sheet_name=\"maestro_ADRES\", index=False)\n",
    "\n",
    "print(\"Archivo Excel guardado en:\", S_Excel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35e1b962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AFL_ID', 'ENT_ID', 'TPS_IDN_ID_CF', 'HST_IDN_NUMERO_IDENTIFICACION_CF',\n",
       "       'TPS_IDN_ID', 'HST_IDN_NUMERO_IDENTIFICACION', 'AFL_PRIMER_APELLIDO',\n",
       "       'AFL_SEGUNDO_APELLIDO', 'AFL_PRIMER_NOMBRE', 'AFL_SEGUNDO_NOMBRE',\n",
       "       'AFL_FECHA_NACIMIENTO', 'TPS_GNR_ID', 'AFL_PAIS_NACIMIENTO',\n",
       "       'AFL_MUNICIPIO_NACIMIENTO', 'AFL_NACIONALIDAD',\n",
       "       'AFL_SEXO_IDENTIFICACION', 'AFL_DISCAPACIDAD', 'TPS_AFL_ID',\n",
       "       'TPS_PRN_ID', 'TPS_GRP_PBL_ID', 'TPS_NVL_SSB_ID', 'NUMEROFICHASISBEN',\n",
       "       'TPS_CND_BNF_ID', 'DPR_ID', 'MNC_ID', 'ZNS_ID',\n",
       "       'AFL_FECHA_AFILIACION_SGSSS', 'AFC_FECHA_INICIO', 'NUMERO CONTRATO',\n",
       "       'FECHADE INICIO DEL CONTRATO', 'CNT_AFL_TPS_GRP_PBL_ID',\n",
       "       'CNT_AFL_TPS_PRT_ETN_ID', 'TPS_MDL_SBS_ID', 'TPS_EST_AFL_ID',\n",
       "       'CND_AFL_FECHA_INICIO', 'CND_AFL_FECHA_INICIO', 'GRP_FML_COTIZANTE_ID',\n",
       "       'PORTABILIDAD', 'COD_IPS_P', 'MTDLG_G_P', 'SUB_SISBEN_IV',\n",
       "       'MARCASISBENIV+MARCASISBENIII', 'CRUCE_BDEX_RNEC',\n",
       "       'MARCASISBENIV+MARCASISBENIII_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maestro_ADRES.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
