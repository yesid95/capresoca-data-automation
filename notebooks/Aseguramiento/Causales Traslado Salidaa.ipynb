{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Mudulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar librerÃ­as para manejo de datos\n",
    "import pandas as pd  # manipulaciÃ³n de tablas, lectura/escritura CSV/Excel, pivot, merge\n",
    "import numpy as np  # arrays, operaciones numÃ©ricas y algebra lineal\n",
    "\n",
    "# VisualizaciÃ³n (bonitas e interactivas) para tableros de control\n",
    "import matplotlib.pyplot as plt  # grÃ¡ficos estÃ¡ticos bÃ¡sicos y personalizaciÃ³n fina\n",
    "import seaborn as sns  # estilos y grÃ¡ficos estadÃ­sticos estÃ©ticos sobre matplotlib\n",
    "import plotly.express as px  # grÃ¡ficos interactivos sencillos y rÃ¡pidos para dashboards\n",
    "import plotly.graph_objects as go  # construcciÃ³n de grÃ¡ficos interactivos mÃ¡s avanzados\n",
    "import altair as alt  # visualizaciones declarativas e interactividad (Vega-Lite)\n",
    "from bokeh.plotting import figure, show  # visualizaciones interactivas y widgets para dashboards\n",
    "\n",
    "# Rutas, archivos y utilidades del sistema\n",
    "import os  # operaciones con el sistema de archivos, variables de entorno\n",
    "from pathlib import Path  # manejo de rutas como objetos (recomendado)\n",
    "import glob  # bÃºsqueda de ficheros por patrones\n",
    "\n",
    "# Expresiones regulares y manejo de fechas\n",
    "import re  # bÃºsqueda y limpieza de texto con patrones\n",
    "from datetime import datetime, timedelta  # fechas y tiempos bÃ¡sicos\n",
    "from dateutil import parser as date_parser  # parseo flexible de cadenas a fechas\n",
    "\n",
    "# Lectura/escritura de Excel y archivos planos\n",
    "import csv  # lectura/escritura de CSV con la librerÃ­a estÃ¡ndar\n",
    "import io  # manejo de buffers en memoria\n",
    "try:\n",
    "    from openpyxl import load_workbook  # leer/escribir archivos .xlsx (engine usado por pandas)\n",
    "except Exception:\n",
    "    pass  # openpyxl puede no estar instalado en el entorno\n",
    "\n",
    "# Utilidades para procesamiento\n",
    "from tqdm import tqdm  # barras de progreso (Ãºtil al procesar muchos archivos o filas)\n",
    "\n",
    "# Configuraciones visuales por defecto\n",
    "sns.set_theme()  # tema por defecto para seaborn/matplotlib\n",
    "plt.rcParams[\"figure.dpi\"] = 100  # resoluciÃ³n de figuras en notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Rutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_raiz = r\"C:\\Users\\crist\\OneDrive - 891856000_CAPRESOCA E P S\\Escritorio\\Yesid RincÃ³n Z\\informes\\2026\\CTO 102.2026\\CTO102.2026 Informe  #01\\10 Actividades\"\n",
    "\n",
    "R_s2 = R_raiz + r\"\\S2\"\n",
    "R_s4 = R_raiz + r\"\\S4\"\n",
    "R_r2 = R_raiz + r\"\\R2\"\n",
    "R_r4 = R_raiz + r\"\\R4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Datafarmes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## R4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que la ruta existe\n",
    "if not os.path.exists(R_r4):\n",
    "    print(f\"âŒ ERROR: La carpeta no existe: {R_r4}\")\n",
    "else:\n",
    "    print(f\"âœ“ Carpeta encontrada: {R_r4}\")\n",
    "    \n",
    "    # Obtener todos los archivos .NEG y .VAL de la carpeta R_r4\n",
    "    archivos_r4 = glob.glob(os.path.join(R_r4, \"*.NEG\")) + glob.glob(os.path.join(R_r4, \"*.VAL\"))\n",
    "    \n",
    "    # Verificar si se encontraron archivos\n",
    "    if len(archivos_r4) == 0:\n",
    "        print(f\"âš ï¸ No se encontraron archivos .NEG o .VAL en: {R_r4}\")\n",
    "    else:\n",
    "        print(f\"âœ“ Archivos encontrados: {len(archivos_r4)}\")\n",
    "        \n",
    "        # Lista para almacenar los dataframes\n",
    "        lista_df = []\n",
    "        archivos_vacios = []\n",
    "        \n",
    "        # Cargar cada archivo\n",
    "        for archivo in archivos_r4:\n",
    "            try:\n",
    "                # Verificar si el archivo estÃ¡ vacÃ­o\n",
    "                if os.path.getsize(archivo) == 0:\n",
    "                    archivos_vacios.append(os.path.basename(archivo))\n",
    "                    continue\n",
    "                \n",
    "                # Extraer rÃ©gimen y fecha del nombre del archivo\n",
    "                nombre_archivo = os.path.basename(archivo)\n",
    "                \n",
    "                # Determinar rÃ©gimen\n",
    "                if \"EPSC\" in nombre_archivo:\n",
    "                    regimen = \"Contributivo\"\n",
    "                else:\n",
    "                    regimen = \"Subsidiado\"\n",
    "                \n",
    "                # Extraer fecha (Ãºltimos 8 dÃ­gitos antes de la extensiÃ³n)\n",
    "                # Ejemplo: R4EPSC2523012026.NEG -> 23012026\n",
    "                patron_fecha = re.search(r'(\\d{8})\\.(NEG|VAL)$', nombre_archivo)\n",
    "                if patron_fecha:\n",
    "                    fecha_str = patron_fecha.group(1)\n",
    "                    # Convertir de ddmmyyyy a formato fecha\n",
    "                    dia = fecha_str[:2]\n",
    "                    mes = fecha_str[2:4]\n",
    "                    anio = fecha_str[4:]\n",
    "                    fecha_proceso = f\"{dia}/{mes}/{anio}\"\n",
    "                else:\n",
    "                    fecha_proceso = \"Sin fecha\"\n",
    "                \n",
    "                df_temp = pd.read_csv(\n",
    "                    archivo,\n",
    "                    sep=\",\",\n",
    "                    header=None,\n",
    "                    encoding=\"latin-1\",  # ANSI\n",
    "                    dtype=str\n",
    "                )\n",
    "                \n",
    "                # Agregar columnas de rÃ©gimen y fecha\n",
    "                df_temp['regimen'] = regimen\n",
    "                df_temp['fecha_proceso'] = fecha_proceso\n",
    "                \n",
    "                lista_df.append(df_temp)\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error al leer {os.path.basename(archivo)}: {e}\")\n",
    "        \n",
    "        # Mostrar archivos vacÃ­os omitidos\n",
    "        if archivos_vacios:\n",
    "            print(f\"\\nâš ï¸ Archivos vacÃ­os omitidos: {len(archivos_vacios)}\")\n",
    "            for archivo in archivos_vacios:\n",
    "                print(f\"   - {archivo}\")\n",
    "        \n",
    "        # Concatenar todos los dataframes\n",
    "        if len(lista_df) > 0:\n",
    "            df_r4 = pd.concat(lista_df, ignore_index=True)\n",
    "            \n",
    "            print(f\"\\nğŸ“Š Resumen:\")\n",
    "            print(f\"Archivos cargados exitosamente: {len(lista_df)}\")\n",
    "            print(f\"Total de registros: {len(df_r4)}\")\n",
    "            print(f\"\\n{df_r4.head()}\")\n",
    "        else:\n",
    "            print(\"âŒ No se pudieron cargar dataframes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## S4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que la ruta existe\n",
    "if not os.path.exists(R_s4):\n",
    "    print(f\"âŒ ERROR: La carpeta no existe: {R_s4}\")\n",
    "else:\n",
    "    print(f\"âœ“ Carpeta encontrada: {R_s4}\")\n",
    "    \n",
    "    # Obtener todos los archivos .NEG y .VAL de la carpeta R_s4\n",
    "    archivos_s4 = glob.glob(os.path.join(R_s4, \"*.NEG\")) + glob.glob(os.path.join(R_s4, \"*.VAL\"))\n",
    "    \n",
    "    # Verificar si se encontraron archivos\n",
    "    if len(archivos_s4) == 0:\n",
    "        print(f\"âš ï¸ No se encontraron archivos .NEG o .VAL en: {R_s4}\")\n",
    "    else:\n",
    "        print(f\"âœ“ Archivos encontrados: {len(archivos_s4)}\")\n",
    "        \n",
    "        # Lista para almacenar los dataframes\n",
    "        lista_df = []\n",
    "        archivos_vacios = []\n",
    "        \n",
    "        # Cargar cada archivo\n",
    "        for archivo in archivos_s4:\n",
    "            try:\n",
    "                # Verificar si el archivo estÃ¡ vacÃ­o\n",
    "                if os.path.getsize(archivo) == 0:\n",
    "                    archivos_vacios.append(os.path.basename(archivo))\n",
    "                    continue\n",
    "                \n",
    "                # Extraer rÃ©gimen y fecha del nombre del archivo\n",
    "                nombre_archivo = os.path.basename(archivo)\n",
    "                \n",
    "                # Determinar rÃ©gimen\n",
    "                if \"EPSC\" in nombre_archivo:\n",
    "                    regimen = \"Contributivo\"\n",
    "                else:\n",
    "                    regimen = \"Subsidiado\"\n",
    "                \n",
    "                # Extraer fecha (Ãºltimos 8 dÃ­gitos antes de la extensiÃ³n)\n",
    "                patron_fecha = re.search(r'(\\d{8})\\.(NEG|VAL)$', nombre_archivo)\n",
    "                if patron_fecha:\n",
    "                    fecha_str = patron_fecha.group(1)\n",
    "                    # Convertir de ddmmyyyy a formato fecha\n",
    "                    dia = fecha_str[:2]\n",
    "                    mes = fecha_str[2:4]\n",
    "                    anio = fecha_str[4:]\n",
    "                    fecha_proceso = f\"{dia}/{mes}/{anio}\"\n",
    "                else:\n",
    "                    fecha_proceso = \"Sin fecha\"\n",
    "                \n",
    "                df_temp = pd.read_csv(\n",
    "                    archivo,\n",
    "                    sep=\",\",\n",
    "                    header=None,\n",
    "                    encoding=\"latin-1\",  # ANSI\n",
    "                    dtype=str\n",
    "                )\n",
    "                \n",
    "                # Agregar columnas de rÃ©gimen y fecha\n",
    "                df_temp['regimen'] = regimen\n",
    "                df_temp['fecha_proceso'] = fecha_proceso\n",
    "                \n",
    "                lista_df.append(df_temp)\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error al leer {os.path.basename(archivo)}: {e}\")\n",
    "        \n",
    "        # Mostrar archivos vacÃ­os omitidos\n",
    "        if archivos_vacios:\n",
    "            print(f\"\\nâš ï¸ Archivos vacÃ­os omitidos: {len(archivos_vacios)}\")\n",
    "            for archivo in archivos_vacios:\n",
    "                print(f\"   - {archivo}\")\n",
    "        \n",
    "        # Concatenar todos los dataframes\n",
    "        if len(lista_df) > 0:\n",
    "            df_s4 = pd.concat(lista_df, ignore_index=True)\n",
    "            \n",
    "            print(f\"\\nğŸ“Š Resumen:\")\n",
    "            print(f\"Archivos cargados exitosamente: {len(lista_df)}\")\n",
    "            print(f\"Total de registros: {len(df_s4)}\")\n",
    "            print(f\"\\n{df_s4.head()}\")\n",
    "        else:\n",
    "            print(\"âŒ No se pudieron cargar dataframes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que la ruta existe\n",
    "if not os.path.exists(R_s2):\n",
    "    print(f\"âŒ ERROR: La carpeta no existe: {R_s2}\")\n",
    "else:\n",
    "    print(f\"âœ“ Carpeta encontrada: {R_s2}\")\n",
    "    \n",
    "    # Obtener todos los archivos .TXT de la carpeta R_s2\n",
    "    archivos_s2 = glob.glob(os.path.join(R_s2, \"*.TXT\"))\n",
    "    \n",
    "    # Verificar si se encontraron archivos\n",
    "    if len(archivos_s2) == 0:\n",
    "        print(f\"âš ï¸ No se encontraron archivos .TXT en: {R_s2}\")\n",
    "    else:\n",
    "        print(f\"âœ“ Archivos encontrados: {len(archivos_s2)}\")\n",
    "        \n",
    "        # Lista para almacenar los dataframes\n",
    "        lista_df = []\n",
    "        archivos_vacios = []\n",
    "        \n",
    "        # Cargar cada archivo\n",
    "        for archivo in archivos_s2:\n",
    "            try:\n",
    "                # Verificar si el archivo estÃ¡ vacÃ­o\n",
    "                if os.path.getsize(archivo) == 0:\n",
    "                    archivos_vacios.append(os.path.basename(archivo))\n",
    "                    continue\n",
    "                \n",
    "                # Extraer rÃ©gimen y fecha del nombre del archivo\n",
    "                nombre_archivo = os.path.basename(archivo)\n",
    "                \n",
    "                # Determinar rÃ©gimen\n",
    "                if \"EPSC\" in nombre_archivo:\n",
    "                    regimen = \"Contributivo\"\n",
    "                else:\n",
    "                    regimen = \"Subsidiado\"\n",
    "                \n",
    "                # Extraer fecha (Ãºltimos 8 dÃ­gitos antes de la extensiÃ³n)\n",
    "                patron_fecha = re.search(r'(\\d{8})\\.TXT$', nombre_archivo)\n",
    "                if patron_fecha:\n",
    "                    fecha_str = patron_fecha.group(1)\n",
    "                    # Convertir de ddmmyyyy a formato fecha\n",
    "                    dia = fecha_str[:2]\n",
    "                    mes = fecha_str[2:4]\n",
    "                    anio = fecha_str[4:]\n",
    "                    fecha_proceso = f\"{dia}/{mes}/{anio}\"\n",
    "                else:\n",
    "                    fecha_proceso = \"Sin fecha\"\n",
    "                \n",
    "                df_temp = pd.read_csv(\n",
    "                    archivo,\n",
    "                    sep=\",\",\n",
    "                    header=None,\n",
    "                    encoding=\"latin-1\",  # ANSI\n",
    "                    dtype=str\n",
    "                )\n",
    "                \n",
    "                # Agregar columnas de rÃ©gimen y fecha\n",
    "                df_temp['regimen'] = regimen\n",
    "                df_temp['fecha_proceso'] = fecha_proceso\n",
    "                \n",
    "                lista_df.append(df_temp)\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error al leer {os.path.basename(archivo)}: {e}\")\n",
    "        \n",
    "        # Mostrar archivos vacÃ­os omitidos\n",
    "        if archivos_vacios:\n",
    "            print(f\"\\nâš ï¸ Archivos vacÃ­os omitidos: {len(archivos_vacios)}\")\n",
    "            for archivo in archivos_vacios:\n",
    "                print(f\"   - {archivo}\")\n",
    "        \n",
    "        # Concatenar todos los dataframes\n",
    "        if len(lista_df) > 0:\n",
    "            df_s2 = pd.concat(lista_df, ignore_index=True)\n",
    "            \n",
    "            print(f\"\\nğŸ“Š Resumen:\")\n",
    "            print(f\"Archivos cargados exitosamente: {len(lista_df)}\")\n",
    "            print(f\"Total de registros: {len(df_s2)}\")\n",
    "            print(f\"\\n{df_s2.head()}\")\n",
    "        else:\n",
    "            print(\"âŒ No se pudieron cargar dataframes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que la ruta existe\n",
    "if not os.path.exists(R_r2):\n",
    "    print(f\"âŒ ERROR: La carpeta no existe: {R_r2}\")\n",
    "else:\n",
    "    print(f\"âœ“ Carpeta encontrada: {R_r2}\")\n",
    "    \n",
    "    # Obtener todos los archivos .TXT de la carpeta R_r2\n",
    "    archivos_r2 = glob.glob(os.path.join(R_r2, \"*.TXT\"))\n",
    "    \n",
    "    # Verificar si se encontraron archivos\n",
    "    if len(archivos_r2) == 0:\n",
    "        print(f\"âš ï¸ No se encontraron archivos .TXT en: {R_r2}\")\n",
    "    else:\n",
    "        print(f\"âœ“ Archivos encontrados: {len(archivos_r2)}\")\n",
    "        \n",
    "        # Lista para almacenar los dataframes\n",
    "        lista_df = []\n",
    "        archivos_vacios = []\n",
    "        \n",
    "        # Cargar cada archivo\n",
    "        for archivo in archivos_r2:\n",
    "            try:\n",
    "                # Verificar si el archivo estÃ¡ vacÃ­o\n",
    "                if os.path.getsize(archivo) == 0:\n",
    "                    archivos_vacios.append(os.path.basename(archivo))\n",
    "                    continue\n",
    "                \n",
    "                # Extraer rÃ©gimen y fecha del nombre del archivo\n",
    "                nombre_archivo = os.path.basename(archivo)\n",
    "                \n",
    "                # Determinar rÃ©gimen\n",
    "                if \"EPSC\" in nombre_archivo:\n",
    "                    regimen = \"Contributivo\"\n",
    "                else:\n",
    "                    regimen = \"Subsidiado\"\n",
    "                \n",
    "                # Extraer fecha (Ãºltimos 8 dÃ­gitos antes de la extensiÃ³n)\n",
    "                patron_fecha = re.search(r'(\\d{8})\\.TXT$', nombre_archivo)\n",
    "                if patron_fecha:\n",
    "                    fecha_str = patron_fecha.group(1)\n",
    "                    # Convertir de ddmmyyyy a formato fecha\n",
    "                    dia = fecha_str[:2]\n",
    "                    mes = fecha_str[2:4]\n",
    "                    anio = fecha_str[4:]\n",
    "                    fecha_proceso = f\"{dia}/{mes}/{anio}\"\n",
    "                else:\n",
    "                    fecha_proceso = \"Sin fecha\"\n",
    "                \n",
    "                df_temp = pd.read_csv(\n",
    "                    archivo,\n",
    "                    sep=\",\",\n",
    "                    header=None,\n",
    "                    encoding=\"latin-1\",  # ANSI\n",
    "                    dtype=str\n",
    "                )\n",
    "                \n",
    "                # Agregar columnas de rÃ©gimen y fecha\n",
    "                df_temp['regimen'] = regimen\n",
    "                df_temp['fecha_proceso'] = fecha_proceso\n",
    "                \n",
    "                lista_df.append(df_temp)\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error al leer {os.path.basename(archivo)}: {e}\")\n",
    "        \n",
    "        # Mostrar archivos vacÃ­os omitidos\n",
    "        if archivos_vacios:\n",
    "            print(f\"\\nâš ï¸ Archivos vacÃ­os omitidos: {len(archivos_vacios)}\")\n",
    "            for archivo in archivos_vacios:\n",
    "                print(f\"   - {archivo}\")\n",
    "        \n",
    "        # Concatenar todos los dataframes\n",
    "        if len(lista_df) > 0:\n",
    "            df_r2 = pd.concat(lista_df, ignore_index=True)\n",
    "            \n",
    "            print(f\"\\nğŸ“Š Resumen:\")\n",
    "            print(f\"Archivos cargados exitosamente: {len(lista_df)}\")\n",
    "            print(f\"Total de registros: {len(df_r2)}\")\n",
    "            print(f\"\\n{df_r2.head()}\")\n",
    "        else:\n",
    "            print(\"âŒ No se pudieron cargar dataframes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "# Validar integridad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"VALIDACIÃ“N DE INTEGRIDAD DE REGISTROS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ValidaciÃ³n S2 vs S4\n",
    "print(\"\\nğŸ“‹ SOLICITUDES (S2 vs S4)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if 'df_s2' in locals() and 'df_s4' in locals():\n",
    "    total_s2 = len(df_s2)\n",
    "    total_s4 = len(df_s4)\n",
    "    diferencia_s = total_s2 - total_s4\n",
    "    \n",
    "    print(f\"Total registros S2 (Solicitudes recibidas): {total_s2:,}\")\n",
    "    print(f\"Total registros S4 (Respuestas enviadas):   {total_s4:,}\")\n",
    "    print(f\"Diferencia:                                  {diferencia_s:,}\")\n",
    "    \n",
    "    if diferencia_s == 0:\n",
    "        print(\"âœ… CORRECTO: Todas las solicitudes tienen respuesta\")\n",
    "    elif diferencia_s > 0:\n",
    "        print(f\"âš ï¸ ALERTA: Hay {diferencia_s} solicitudes sin respuesta\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ ALERTA: Hay {abs(diferencia_s)} respuestas de mÃ¡s\")\n",
    "else:\n",
    "    print(\"âŒ ERROR: No se pudieron cargar los dataframes S2 o S4\")\n",
    "\n",
    "# ValidaciÃ³n R2 vs R4\n",
    "print(\"\\nğŸ“‹ RESPUESTAS (R2 vs R4)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if 'df_r2' in locals() and 'df_r4' in locals():\n",
    "    total_r2 = len(df_r2)\n",
    "    total_r4 = len(df_r4)\n",
    "    diferencia_r = total_r2 - total_r4\n",
    "    \n",
    "    print(f\"Total registros R2 (Solicitudes enviadas):  {total_r2:,}\")\n",
    "    print(f\"Total registros R4 (Respuestas recibidas):  {total_r4:,}\")\n",
    "    print(f\"Diferencia:                                  {diferencia_r:,}\")\n",
    "    \n",
    "    if diferencia_r == 0:\n",
    "        print(\"âœ… CORRECTO: Todas las solicitudes tienen respuesta\")\n",
    "    elif diferencia_r > 0:\n",
    "        print(f\"âš ï¸ ALERTA: Hay {diferencia_r} solicitudes sin respuesta\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ ALERTA: Hay {abs(diferencia_r)} respuestas de mÃ¡s\")\n",
    "else:\n",
    "    print(\"âŒ ERROR: No se pudieron cargar los dataframes R2 o R4\")\n",
    "\n",
    "# Resumen general\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RESUMEN GENERAL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if all(df in locals() for df in ['df_s2', 'df_s4', 'df_r2', 'df_r4']):\n",
    "    print(f\"\\nTotal solicitudes RECIBIDAS (S):  {total_s2:,}\")\n",
    "    print(f\"Total respuestas ENVIADAS (S):     {total_s4:,}\")\n",
    "    print(f\"Total solicitudes ENVIADAS (R):    {total_r2:,}\")\n",
    "    print(f\"Total respuestas RECIBIDAS (R):    {total_r4:,}\")\n",
    "    \n",
    "    integridad_s = \"âœ…\" if diferencia_s == 0 else \"âš ï¸\"\n",
    "    integridad_r = \"âœ…\" if diferencia_r == 0 else \"âš ï¸\"\n",
    "    \n",
    "    print(f\"\\n{integridad_s} Integridad Solicitudes (S): {'COMPLETA' if diferencia_s == 0 else 'INCOMPLETA'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# Unificar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## S2 - S4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"UNIFICACIÃ“N S2 - S4 (SOLICITUDES RECIBIDAS Y RESPUESTAS ENVIADAS)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if 'df_s2' in locals() and 'df_s4' in locals():\n",
    "    # Asignar nombres a las columnas de S2\n",
    "    df_s2_trabajo = df_s2.copy()\n",
    "    df_s2_trabajo.columns = [f'col_{i}' for i in range(len(df_s2.columns) - 2)] + ['regimen', 'fecha_proceso']\n",
    "    df_s2_trabajo = df_s2_trabajo.rename(columns={'col_0': 'id_afiliado'})\n",
    "    \n",
    "    # Asignar nombres a las columnas de S4\n",
    "    df_s4_trabajo = df_s4.copy()\n",
    "    df_s4_trabajo.columns = [f'col_{i}' for i in range(len(df_s4.columns) - 2)] + ['regimen', 'fecha_proceso']\n",
    "    df_s4_trabajo = df_s4_trabajo.rename(columns={\n",
    "        'col_0': 'id_afiliado',\n",
    "        'col_4': 'respuesta',\n",
    "        'col_5': 'causal'\n",
    "    })\n",
    "    \n",
    "    # Convertir fecha_proceso a formato datetime para comparaciones\n",
    "    df_s2_trabajo['fecha_proceso_dt'] = pd.to_datetime(df_s2_trabajo['fecha_proceso'], format='%d/%m/%Y')\n",
    "    df_s4_trabajo['fecha_proceso_dt'] = pd.to_datetime(df_s4_trabajo['fecha_proceso'], format='%d/%m/%Y')\n",
    "    \n",
    "    print(\"\\nğŸ“‹ Estructura de datos:\")\n",
    "    print(f\"S2 - Columnas: {list(df_s2_trabajo.columns)}\")\n",
    "    print(f\"S4 - Columnas: {list(df_s4_trabajo.columns)}\")\n",
    "    \n",
    "    # Crear lista para almacenar los matches\n",
    "    resultados = []\n",
    "    \n",
    "    print(\"\\nğŸ”„ Procesando unificaciÃ³n...\")\n",
    "    \n",
    "    # Por cada registro en S2, buscar su respuesta en S4\n",
    "    for idx, row_s2 in tqdm(df_s2_trabajo.iterrows(), total=len(df_s2_trabajo)):\n",
    "        id_afiliado = row_s2['id_afiliado']\n",
    "        fecha_s2 = row_s2['fecha_proceso_dt']\n",
    "        regimen_s2 = row_s2['regimen']\n",
    "        \n",
    "        # Buscar respuestas en S4 para este afiliado\n",
    "        # Filtrar por: mismo id, mismo rÃ©gimen, y fecha entre 1-4 dÃ­as despuÃ©s\n",
    "        respuestas_candidatas = df_s4_trabajo[\n",
    "            (df_s4_trabajo['id_afiliado'] == id_afiliado) &\n",
    "            (df_s4_trabajo['regimen'] == regimen_s2) &\n",
    "            (df_s4_trabajo['fecha_proceso_dt'] >= fecha_s2) &\n",
    "            (df_s4_trabajo['fecha_proceso_dt'] <= fecha_s2 + pd.Timedelta(days=4))\n",
    "        ]\n",
    "        \n",
    "        # Si hay respuestas, tomar la mÃ¡s reciente\n",
    "        if len(respuestas_candidatas) > 0:\n",
    "            respuesta_final = respuestas_candidatas.sort_values('fecha_proceso_dt', ascending=False).iloc[0]\n",
    "            \n",
    "            # Crear registro unificado\n",
    "            registro = row_s2.copy()\n",
    "            registro['respuesta'] = respuesta_final['respuesta']\n",
    "            registro['causal'] = respuesta_final['causal']\n",
    "            registro['fecha_respuesta'] = respuesta_final['fecha_proceso']\n",
    "            registro['dias_respuesta'] = (respuesta_final['fecha_proceso_dt'] - fecha_s2).days\n",
    "        else:\n",
    "            # No se encontrÃ³ respuesta\n",
    "            registro = row_s2.copy()\n",
    "            registro['respuesta'] = 'Sin respuesta'\n",
    "            registro['causal'] = 'Sin respuesta'\n",
    "            registro['fecha_respuesta'] = 'Sin respuesta'\n",
    "            registro['dias_respuesta'] = None\n",
    "        \n",
    "        resultados.append(registro)\n",
    "    \n",
    "    # Crear dataframe unificado\n",
    "    df_s2_s4_unificado = pd.DataFrame(resultados)\n",
    "    \n",
    "    # Eliminar columna temporal\n",
    "    df_s2_s4_unificado = df_s2_s4_unificado.drop('fecha_proceso_dt', axis=1)\n",
    "    \n",
    "    print(\"\\nâœ… UnificaciÃ³n completada\")\n",
    "    print(f\"\\nğŸ“Š Resumen:\")\n",
    "    print(f\"Total registros S2: {len(df_s2_trabajo):,}\")\n",
    "    print(f\"Registros con respuesta: {len(df_s2_s4_unificado[df_s2_s4_unificado['respuesta'] != 'Sin respuesta']):,}\")\n",
    "    print(f\"Registros sin respuesta: {len(df_s2_s4_unificado[df_s2_s4_unificado['respuesta'] == 'Sin respuesta']):,}\")\n",
    "    \n",
    "    # EstadÃ­sticas de respuestas\n",
    "    print(\"\\nğŸ“ˆ DistribuciÃ³n de respuestas:\")\n",
    "    if 'respuesta' in df_s2_s4_unificado.columns:\n",
    "        distribucion = df_s2_s4_unificado[df_s2_s4_unificado['respuesta'] != 'Sin respuesta']['respuesta'].value_counts()\n",
    "        for valor, cantidad in distribucion.items():\n",
    "            estado = \"Aprobadas\" if valor == '1' else \"Negadas\"\n",
    "            print(f\"  {estado} ({valor}): {cantidad:,}\")\n",
    "    \n",
    "    # EstadÃ­sticas de dÃ­as de respuesta\n",
    "    print(\"\\nâ±ï¸ Tiempo de respuesta:\")\n",
    "    dias_validos = df_s2_s4_unificado[df_s2_s4_unificado['dias_respuesta'].notna()]['dias_respuesta']\n",
    "    if len(dias_validos) > 0:\n",
    "        print(f\"  Promedio: {dias_validos.mean():.1f} dÃ­as\")\n",
    "        print(f\"  MÃ­nimo: {dias_validos.min():.0f} dÃ­as\")\n",
    "        print(f\"  MÃ¡ximo: {dias_validos.max():.0f} dÃ­as\")\n",
    "    \n",
    "    print(f\"\\n{df_s2_s4_unificado.head(10)}\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ ERROR: No se pudieron cargar los dataframes S2 o S4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Quitar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"DEPURACIÃ“N DE DUPLICADOS - PRIORIZACIÃ“N DE APROBACIONES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if 'df_s2_s4_unificado' in locals():\n",
    "    print(\"\\nğŸ“‹ AnÃ¡lisis de duplicados antes de depurar:\")\n",
    "    print(f\"Total de registros: {len(df_s2_s4_unificado):,}\")\n",
    "    \n",
    "    # Identificar duplicados por id_afiliado y rÃ©gimen\n",
    "    duplicados = df_s2_s4_unificado.groupby(['id_afiliado', 'regimen']).size()\n",
    "    afiliados_duplicados = duplicados[duplicados > 1]\n",
    "    \n",
    "    print(f\"Afiliados Ãºnicos: {len(duplicados):,}\")\n",
    "    print(f\"Afiliados con mÃºltiples solicitudes: {len(afiliados_duplicados):,}\")\n",
    "    \n",
    "    if len(afiliados_duplicados) > 0:\n",
    "        print(f\"\\nğŸ“Š DistribuciÃ³n de solicitudes por afiliado:\")\n",
    "        dist_solicitudes = afiliados_duplicados.value_counts().sort_index()\n",
    "        for num_solicitudes, cantidad in dist_solicitudes.items():\n",
    "            print(f\"  {num_solicitudes} solicitudes: {cantidad:,} afiliados\")\n",
    "    \n",
    "    # Crear copia para trabajar\n",
    "    df_depurado = df_s2_s4_unificado.copy()\n",
    "    \n",
    "    # Convertir respuesta a numÃ©rico para ordenamiento (1=aprobado, 0=negado, -1=sin respuesta)\n",
    "    df_depurado['respuesta_num'] = df_depurado['respuesta'].apply(\n",
    "        lambda x: 1 if x == '1' else (0 if x == '0' else -1)\n",
    "    )\n",
    "    \n",
    "    # Convertir fecha_respuesta a datetime para ordenamiento\n",
    "    df_depurado['fecha_respuesta_dt'] = pd.to_datetime(\n",
    "        df_depurado['fecha_respuesta'], \n",
    "        format='%d/%m/%Y', \n",
    "        errors='coerce'\n",
    "    )\n",
    "    \n",
    "    print(\"\\nğŸ”„ Aplicando lÃ³gica de depuraciÃ³n:\")\n",
    "    print(\"  1. Priorizar aprobaciones (respuesta = 1)\")\n",
    "    print(\"  2. Si no hay aprobaciones, tomar la negaciÃ³n mÃ¡s reciente\")\n",
    "    print(\"  3. Si no hay respuestas, tomar la solicitud mÃ¡s reciente\")\n",
    "    \n",
    "    # Ordenar por: id_afiliado, rÃ©gimen, respuesta (descendente), fecha (descendente)\n",
    "    df_depurado_sorted = df_depurado.sort_values(\n",
    "        by=['id_afiliado', 'regimen', 'respuesta_num', 'fecha_respuesta_dt'],\n",
    "        ascending=[True, True, False, False]\n",
    "    )\n",
    "    \n",
    "    # Mantener solo el primer registro de cada grupo (el mÃ¡s prioritario)\n",
    "    df_s2_s4_depurado = df_depurado_sorted.groupby(['id_afiliado', 'regimen']).first().reset_index()\n",
    "    \n",
    "    # Eliminar columnas auxiliares\n",
    "    df_s2_s4_depurado = df_s2_s4_depurado.drop(['respuesta_num', 'fecha_respuesta_dt'], axis=1)\n",
    "    \n",
    "    print(\"\\nâœ… DepuraciÃ³n completada\")\n",
    "    print(f\"\\nğŸ“Š Resumen despuÃ©s de depurar:\")\n",
    "    print(f\"Total de registros depurados: {len(df_s2_s4_depurado):,}\")\n",
    "    print(f\"Registros eliminados (duplicados): {len(df_s2_s4_unificado) - len(df_s2_s4_depurado):,}\")\n",
    "    \n",
    "    # EstadÃ­sticas de respuestas despuÃ©s de depurar\n",
    "    print(\"\\nğŸ“ˆ DistribuciÃ³n de respuestas (datos depurados):\")\n",
    "    if 'respuesta' in df_s2_s4_depurado.columns:\n",
    "        distribucion = df_s2_s4_depurado['respuesta'].value_counts()\n",
    "        total_con_respuesta = len(df_s2_s4_depurado[df_s2_s4_depurado['respuesta'] != 'Sin respuesta'])\n",
    "        \n",
    "        for valor, cantidad in distribucion.items():\n",
    "            if valor == '1':\n",
    "                estado = \"Aprobadas\"\n",
    "                porcentaje = (cantidad / total_con_respuesta * 100) if total_con_respuesta > 0 else 0\n",
    "                print(f\"  {estado} ({valor}): {cantidad:,} ({porcentaje:.1f}%)\")\n",
    "            elif valor == '0':\n",
    "                estado = \"Negadas\"\n",
    "                porcentaje = (cantidad / total_con_respuesta * 100) if total_con_respuesta > 0 else 0\n",
    "                print(f\"  {estado} ({valor}): {cantidad:,} ({porcentaje:.1f}%)\")\n",
    "            else:\n",
    "                print(f\"  Sin respuesta: {cantidad:,}\")\n",
    "    \n",
    "    # AnÃ¡lisis por rÃ©gimen\n",
    "    print(\"\\nğŸ“Š DistribuciÃ³n por rÃ©gimen:\")\n",
    "    dist_regimen = df_s2_s4_depurado.groupby(['regimen', 'respuesta']).size().unstack(fill_value=0)\n",
    "    print(dist_regimen)\n",
    "    \n",
    "    # AnÃ¡lisis de causales de negaciÃ³n (solo para registros negados)\n",
    "    negados = df_s2_s4_depurado[df_s2_s4_depurado['respuesta'] == '0']\n",
    "    if len(negados) > 0:\n",
    "        print(\"\\nğŸ“‹ Top 10 causales de negaciÃ³n:\")\n",
    "        causales = negados['causal'].value_counts().head(10)\n",
    "        for causal, cantidad in causales.items():\n",
    "            porcentaje = (cantidad / len(negados) * 100)\n",
    "            print(f\"  Causal {causal}: {cantidad:,} ({porcentaje:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n{df_s2_s4_depurado.head(10)}\")\n",
    "    \n",
    "    # Guardar estadÃ­sticas de casos depurados\n",
    "    print(\"\\nğŸ“ Ejemplos de casos depurados:\")\n",
    "    ejemplos_depurados = df_s2_s4_unificado[\n",
    "        df_s2_s4_unificado.duplicated(subset=['id_afiliado', 'regimen'], keep=False)\n",
    "    ].sort_values(['id_afiliado', 'fecha_proceso'])\n",
    "    \n",
    "    if len(ejemplos_depurados) > 0:\n",
    "        print(f\"\\nPrimeros 5 afiliados con mÃºltiples solicitudes:\")\n",
    "        for id_afiliado in ejemplos_depurados['id_afiliado'].unique()[:5]:\n",
    "            casos = ejemplos_depurados[ejemplos_depurados['id_afiliado'] == id_afiliado]\n",
    "            print(f\"\\n  ID: {id_afiliado}\")\n",
    "            for idx, row in casos.iterrows():\n",
    "                print(f\"    Fecha: {row['fecha_proceso']} | Respuesta: {row['respuesta']} | Causal: {row['causal']}\")\n",
    "            # Mostrar el registro que se mantuvo\n",
    "            mantenido = df_s2_s4_depurado[df_s2_s4_depurado['id_afiliado'] == id_afiliado]\n",
    "            if len(mantenido) > 0:\n",
    "                print(f\"    âœ… REGISTRO FINAL: Respuesta={mantenido.iloc[0]['respuesta']}, Fecha={mantenido.iloc[0]['fecha_respuesta']}\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ ERROR: No se encuentra el dataframe unificado df_s2_s4_unificado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"CATEGORIZACIÃ“N DE APROBACIONES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if 'df_s2_s4_depurado' in locals():\n",
    "    # Crear copia para trabajar\n",
    "    df_categorizado = df_s2_s4_depurado.copy()\n",
    "    \n",
    "    # Inicializar columna descripcion vacÃ­a\n",
    "    df_categorizado['descripcion'] = ''\n",
    "    \n",
    "    # Identificar registros aprobados\n",
    "    aprobados = df_categorizado['respuesta'] == '1'\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Total de registros aprobados: {aprobados.sum():,}\")\n",
    "    \n",
    "    # CategorÃ­a 1: DispersiÃ³n geogrÃ¡fica (departamento diferente a 85)\n",
    "    dispersion = aprobados & (df_categorizado['col_8'] != '85')\n",
    "    df_categorizado.loc[dispersion, 'descripcion'] = 'DispersiÃ³n geogrÃ¡fica'\n",
    "    \n",
    "    # CategorÃ­a 2: Solicitud formal (todos los demÃ¡s aprobados en departamento 85)\n",
    "    solicitud_formal = aprobados & (df_categorizado['col_8'] == '85')\n",
    "    df_categorizado.loc[solicitud_formal, 'descripcion'] = 'Solicitud formal'\n",
    "    \n",
    "    print(\"\\nâœ… CategorizaciÃ³n completada\")\n",
    "    print(f\"\\nğŸ“‹ DistribuciÃ³n de categorÃ­as:\")\n",
    "    print(f\"  DispersiÃ³n geogrÃ¡fica: {dispersion.sum():,}\")\n",
    "    print(f\"  Solicitud formal: {solicitud_formal.sum():,}\")\n",
    "    \n",
    "    # Validar que todos los aprobados tienen categorÃ­a\n",
    "    aprobados_sin_categoria = aprobados & (df_categorizado['descripcion'] == '')\n",
    "    if aprobados_sin_categoria.sum() > 0:\n",
    "        print(f\"\\nâš ï¸ ALERTA: {aprobados_sin_categoria.sum()} aprobados sin categorÃ­a\")\n",
    "    \n",
    "    # Mostrar distribuciÃ³n por rÃ©gimen\n",
    "    print(\"\\nğŸ“Š DistribuciÃ³n por rÃ©gimen y categorÃ­a:\")\n",
    "    dist_regimen_cat = df_categorizado[aprobados].groupby(['regimen', 'descripcion']).size().unstack(fill_value=0)\n",
    "    print(dist_regimen_cat)\n",
    "    \n",
    "    # Mostrar ejemplos\n",
    "    print(f\"\\nğŸ“ Ejemplos de categorizaciÃ³n:\")\n",
    "    print(\"\\nDispersiÃ³n geogrÃ¡fica:\")\n",
    "    print(df_categorizado[dispersion][['id_afiliado', 'col_8', 'regimen', 'respuesta', 'descripcion']].head(3))\n",
    "    \n",
    "    print(\"\\nSolicitud formal:\")\n",
    "    print(df_categorizado[solicitud_formal][['id_afiliado', 'col_8', 'regimen', 'respuesta', 'descripcion']].head(3))\n",
    "    \n",
    "    # Guardar resultado en nuevo dataframe\n",
    "    df_s2_s4_final = df_categorizado.copy()\n",
    "    \n",
    "    print(f\"\\nâœ… Dataframe final creado: df_s2_s4_final\")\n",
    "    print(f\"Total de registros: {len(df_s2_s4_final):,}\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ ERROR: No se encuentra el dataframe depurado df_s2_s4_depurado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## R2 -R4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"UNIFICACIÃ“N R2 - R4 (SOLICITUDES ENVIADAS Y RESPUESTAS RECIBIDAS)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if 'df_r2' in locals() and 'df_r4' in locals():\n",
    "    # Asignar nombres a las columnas de R2\n",
    "    df_r2_trabajo = df_r2.copy()\n",
    "    df_r2_trabajo.columns = [f'col_{i}' for i in range(len(df_r2.columns) - 2)] + ['regimen', 'fecha_proceso']\n",
    "    df_r2_trabajo = df_r2_trabajo.rename(columns={'col_0': 'id_afiliado'})\n",
    "    \n",
    "    # Asignar nombres a las columnas de R4\n",
    "    df_r4_trabajo = df_r4.copy()\n",
    "    df_r4_trabajo.columns = [f'col_{i}' for i in range(len(df_r4.columns) - 2)] + ['regimen', 'fecha_proceso']\n",
    "    df_r4_trabajo = df_r4_trabajo.rename(columns={\n",
    "        'col_0': 'id_afiliado',\n",
    "        'col_5': 'respuesta',\n",
    "        'col_6': 'causal'\n",
    "    })\n",
    "    \n",
    "    # Convertir fecha_proceso a formato datetime para comparaciones\n",
    "    df_r2_trabajo['fecha_proceso_dt'] = pd.to_datetime(df_r2_trabajo['fecha_proceso'], format='%d/%m/%Y')\n",
    "    df_r4_trabajo['fecha_proceso_dt'] = pd.to_datetime(df_r4_trabajo['fecha_proceso'], format='%d/%m/%Y')\n",
    "    \n",
    "    print(\"\\nğŸ“‹ Estructura de datos:\")\n",
    "    print(f\"R2 - Columnas: {list(df_r2_trabajo.columns)}\")\n",
    "    print(f\"R4 - Columnas: {list(df_r4_trabajo.columns)}\")\n",
    "    \n",
    "    # Crear lista para almacenar los matches\n",
    "    resultados = []\n",
    "    \n",
    "    print(\"\\nğŸ”„ Procesando unificaciÃ³n...\")\n",
    "    \n",
    "    # Por cada registro en R2, buscar su respuesta en R4\n",
    "    for idx, row_r2 in tqdm(df_r2_trabajo.iterrows(), total=len(df_r2_trabajo)):\n",
    "        id_afiliado = row_r2['id_afiliado']\n",
    "        fecha_r2 = row_r2['fecha_proceso_dt']\n",
    "        regimen_r2 = row_r2['regimen']\n",
    "        \n",
    "        # Buscar respuestas en R4 para este afiliado\n",
    "        # Filtrar por: mismo id, mismo rÃ©gimen, y fecha entre 1-4 dÃ­as despuÃ©s\n",
    "        respuestas_candidatas = df_r4_trabajo[\n",
    "            (df_r4_trabajo['id_afiliado'] == id_afiliado) &\n",
    "            (df_r4_trabajo['regimen'] == regimen_r2) &\n",
    "            (df_r4_trabajo['fecha_proceso_dt'] >= fecha_r2) &\n",
    "            (df_r4_trabajo['fecha_proceso_dt'] <= fecha_r2 + pd.Timedelta(days=4))\n",
    "        ]\n",
    "        \n",
    "        # Si hay respuestas, tomar la mÃ¡s reciente\n",
    "        if len(respuestas_candidatas) > 0:\n",
    "            respuesta_final = respuestas_candidatas.sort_values('fecha_proceso_dt', ascending=False).iloc[0]\n",
    "            \n",
    "            # Crear registro unificado\n",
    "            registro = row_r2.copy()\n",
    "            registro['respuesta'] = respuesta_final['respuesta']\n",
    "            registro['causal'] = respuesta_final['causal']\n",
    "            registro['fecha_respuesta'] = respuesta_final['fecha_proceso']\n",
    "            registro['dias_respuesta'] = (respuesta_final['fecha_proceso_dt'] - fecha_r2).days\n",
    "        else:\n",
    "            # No se encontrÃ³ respuesta\n",
    "            registro = row_r2.copy()\n",
    "            registro['respuesta'] = 'Sin respuesta'\n",
    "            registro['causal'] = 'Sin respuesta'\n",
    "            registro['fecha_respuesta'] = 'Sin respuesta'\n",
    "            registro['dias_respuesta'] = None\n",
    "        \n",
    "        resultados.append(registro)\n",
    "    \n",
    "    # Crear dataframe unificado\n",
    "    df_r2_r4_unificado = pd.DataFrame(resultados)\n",
    "    \n",
    "    # Eliminar columna temporal\n",
    "    df_r2_r4_unificado = df_r2_r4_unificado.drop('fecha_proceso_dt', axis=1)\n",
    "    \n",
    "    print(\"\\nâœ… UnificaciÃ³n completada\")\n",
    "    print(f\"\\nğŸ“Š Resumen:\")\n",
    "    print(f\"Total registros R2: {len(df_r2_trabajo):,}\")\n",
    "    print(f\"Registros con respuesta: {len(df_r2_r4_unificado[df_r2_r4_unificado['respuesta'] != 'Sin respuesta']):,}\")\n",
    "    print(f\"Registros sin respuesta: {len(df_r2_r4_unificado[df_r2_r4_unificado['respuesta'] == 'Sin respuesta']):,}\")\n",
    "    \n",
    "    # EstadÃ­sticas de respuestas\n",
    "    print(\"\\nğŸ“ˆ DistribuciÃ³n de respuestas:\")\n",
    "    if 'respuesta' in df_r2_r4_unificado.columns:\n",
    "        distribucion = df_r2_r4_unificado[df_r2_r4_unificado['respuesta'] != 'Sin respuesta']['respuesta'].value_counts()\n",
    "        for valor, cantidad in distribucion.items():\n",
    "            estado = \"Aprobadas\" if valor == '1' else \"Negadas\"\n",
    "            print(f\"  {estado} ({valor}): {cantidad:,}\")\n",
    "    \n",
    "    # EstadÃ­sticas de dÃ­as de respuesta\n",
    "    print(\"\\nâ±ï¸ Tiempo de respuesta:\")\n",
    "    dias_validos = df_r2_r4_unificado[df_r2_r4_unificado['dias_respuesta'].notna()]['dias_respuesta']\n",
    "    if len(dias_validos) > 0:\n",
    "        print(f\"  Promedio: {dias_validos.mean():.1f} dÃ­as\")\n",
    "        print(f\"  MÃ­nimo: {dias_validos.min():.0f} dÃ­as\")\n",
    "        print(f\"  MÃ¡ximo: {dias_validos.max():.0f} dÃ­as\")\n",
    "    \n",
    "    print(f\"\\n{df_r2_r4_unificado.head(10)}\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ ERROR: No se pudieron cargar los dataframes R2 o R4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### Quitar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"DEPURACIÃ“N DE DUPLICADOS R2-R4 - PRIORIZACIÃ“N DE APROBACIONES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if 'df_r2_r4_unificado' in locals():\n",
    "    print(\"\\nğŸ“‹ AnÃ¡lisis de duplicados antes de depurar:\")\n",
    "    print(f\"Total de registros: {len(df_r2_r4_unificado):,}\")\n",
    "    \n",
    "    # Identificar duplicados por id_afiliado y rÃ©gimen\n",
    "    duplicados = df_r2_r4_unificado.groupby(['id_afiliado', 'regimen']).size()\n",
    "    afiliados_duplicados = duplicados[duplicados > 1]\n",
    "    \n",
    "    print(f\"Afiliados Ãºnicos: {len(duplicados):,}\")\n",
    "    print(f\"Afiliados con mÃºltiples solicitudes: {len(afiliados_duplicados):,}\")\n",
    "    \n",
    "    if len(afiliados_duplicados) > 0:\n",
    "        print(f\"\\nğŸ“Š DistribuciÃ³n de solicitudes por afiliado:\")\n",
    "        dist_solicitudes = afiliados_duplicados.value_counts().sort_index()\n",
    "        for num_solicitudes, cantidad in dist_solicitudes.items():\n",
    "            print(f\"  {num_solicitudes} solicitudes: {cantidad:,} afiliados\")\n",
    "    \n",
    "    # Crear copia para trabajar\n",
    "    df_depurado = df_r2_r4_unificado.copy()\n",
    "    \n",
    "    # Convertir respuesta a numÃ©rico para ordenamiento (1=aprobado, 0=negado, -1=sin respuesta)\n",
    "    df_depurado['respuesta_num'] = df_depurado['respuesta'].apply(\n",
    "        lambda x: 1 if x == '1' else (0 if x == '0' else -1)\n",
    "    )\n",
    "    \n",
    "    # Convertir fecha_respuesta a datetime para ordenamiento\n",
    "    df_depurado['fecha_respuesta_dt'] = pd.to_datetime(\n",
    "        df_depurado['fecha_respuesta'], \n",
    "        format='%d/%m/%Y', \n",
    "        errors='coerce'\n",
    "    )\n",
    "    \n",
    "    print(\"\\nğŸ”„ Aplicando lÃ³gica de depuraciÃ³n:\")\n",
    "    print(\"  1. Priorizar aprobaciones (respuesta = 1)\")\n",
    "    print(\"  2. Si no hay aprobaciones, tomar la negaciÃ³n mÃ¡s reciente\")\n",
    "    print(\"  3. Si no hay respuestas, tomar la solicitud mÃ¡s reciente\")\n",
    "    \n",
    "    # Ordenar por: id_afiliado, rÃ©gimen, respuesta (descendente), fecha (descendente)\n",
    "    df_depurado_sorted = df_depurado.sort_values(\n",
    "        by=['id_afiliado', 'regimen', 'respuesta_num', 'fecha_respuesta_dt'],\n",
    "        ascending=[True, True, False, False]\n",
    "    )\n",
    "    \n",
    "    # Mantener solo el primer registro de cada grupo (el mÃ¡s prioritario)\n",
    "    df_r2_r4_depurado = df_depurado_sorted.groupby(['id_afiliado', 'regimen']).first().reset_index()\n",
    "    \n",
    "    # Eliminar columnas auxiliares\n",
    "    df_r2_r4_depurado = df_r2_r4_depurado.drop(['respuesta_num', 'fecha_respuesta_dt'], axis=1)\n",
    "    \n",
    "    print(\"\\nâœ… DepuraciÃ³n completada\")\n",
    "    print(f\"\\nğŸ“Š Resumen despuÃ©s de depurar:\")\n",
    "    print(f\"Total de registros depurados: {len(df_r2_r4_depurado):,}\")\n",
    "    print(f\"Registros eliminados (duplicados): {len(df_r2_r4_unificado) - len(df_r2_r4_depurado):,}\")\n",
    "    \n",
    "    # EstadÃ­sticas de respuestas despuÃ©s de depurar\n",
    "    print(\"\\nğŸ“ˆ DistribuciÃ³n de respuestas (datos depurados):\")\n",
    "    if 'respuesta' in df_r2_r4_depurado.columns:\n",
    "        distribucion = df_r2_r4_depurado['respuesta'].value_counts()\n",
    "        total_con_respuesta = len(df_r2_r4_depurado[df_r2_r4_depurado['respuesta'] != 'Sin respuesta'])\n",
    "        \n",
    "        for valor, cantidad in distribucion.items():\n",
    "            if valor == '1':\n",
    "                estado = \"Aprobadas\"\n",
    "                porcentaje = (cantidad / total_con_respuesta * 100) if total_con_respuesta > 0 else 0\n",
    "                print(f\"  {estado} ({valor}): {cantidad:,} ({porcentaje:.1f}%)\")\n",
    "            elif valor == '0':\n",
    "                estado = \"Negadas\"\n",
    "                porcentaje = (cantidad / total_con_respuesta * 100) if total_con_respuesta > 0 else 0\n",
    "                print(f\"  {estado} ({valor}): {cantidad:,} ({porcentaje:.1f}%)\")\n",
    "            else:\n",
    "                print(f\"  Sin respuesta: {cantidad:,}\")\n",
    "    \n",
    "    # AnÃ¡lisis por rÃ©gimen\n",
    "    print(\"\\nğŸ“Š DistribuciÃ³n por rÃ©gimen:\")\n",
    "    dist_regimen = df_r2_r4_depurado.groupby(['regimen', 'respuesta']).size().unstack(fill_value=0)\n",
    "    print(dist_regimen)\n",
    "    \n",
    "    # AnÃ¡lisis de causales de negaciÃ³n (solo para registros negados)\n",
    "    negados = df_r2_r4_depurado[df_r2_r4_depurado['respuesta'] == '0']\n",
    "    if len(negados) > 0:\n",
    "        print(\"\\nğŸ“‹ Top 10 causales de negaciÃ³n:\")\n",
    "        causales = negados['causal'].value_counts().head(10)\n",
    "        for causal, cantidad in causales.items():\n",
    "            porcentaje = (cantidad / len(negados) * 100)\n",
    "            print(f\"  Causal {causal}: {cantidad:,} ({porcentaje:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n{df_r2_r4_depurado.head(10)}\")\n",
    "    \n",
    "    # Guardar estadÃ­sticas de casos depurados\n",
    "    print(\"\\nğŸ“ Ejemplos de casos depurados:\")\n",
    "    ejemplos_depurados = df_r2_r4_unificado[\n",
    "        df_r2_r4_unificado.duplicated(subset=['id_afiliado', 'regimen'], keep=False)\n",
    "    ].sort_values(['id_afiliado', 'fecha_proceso'])\n",
    "    \n",
    "    if len(ejemplos_depurados) > 0:\n",
    "        print(f\"\\nPrimeros 5 afiliados con mÃºltiples solicitudes:\")\n",
    "        for id_afiliado in ejemplos_depurados['id_afiliado'].unique()[:5]:\n",
    "            casos = ejemplos_depurados[ejemplos_depurados['id_afiliado'] == id_afiliado]\n",
    "            print(f\"\\n  ID: {id_afiliado}\")\n",
    "            for idx, row in casos.iterrows():\n",
    "                print(f\"    Fecha: {row['fecha_proceso']} | Respuesta: {row['respuesta']} | Causal: {row['causal']}\")\n",
    "            # Mostrar el registro que se mantuvo\n",
    "            mantenido = df_r2_r4_depurado[df_r2_r4_depurado['id_afiliado'] == id_afiliado]\n",
    "            if len(mantenido) > 0:\n",
    "                print(f\"    âœ… REGISTRO FINAL: Respuesta={mantenido.iloc[0]['respuesta']}, Fecha={mantenido.iloc[0]['fecha_respuesta']}\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ ERROR: No se encuentra el dataframe unificado df_r2_r4_unificado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### Categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"CATEGORIZACIÃ“N DE APROBACIONES R2-R4\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if 'df_r2_r4_depurado' in locals():\n",
    "    # Crear copia para trabajar\n",
    "    df_categorizado = df_r2_r4_depurado.copy()\n",
    "    \n",
    "    # Inicializar columna descripcion vacÃ­a\n",
    "    df_categorizado['descripcion'] = ''\n",
    "    \n",
    "    # Identificar registros aprobados\n",
    "    aprobados = df_categorizado['respuesta'] == '1'\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Total de registros aprobados: {aprobados.sum():,}\")\n",
    "    \n",
    "    # CategorÃ­a 1: DispersiÃ³n geogrÃ¡fica (departamento diferente a 85)\n",
    "    dispersion = aprobados & (df_categorizado['col_7'] != '85')\n",
    "    df_categorizado.loc[dispersion, 'descripcion'] = 'DispersiÃ³n geogrÃ¡fica'\n",
    "    \n",
    "    # CategorÃ­a 2: Solicitud formal (todos los demÃ¡s aprobados en departamento 85)\n",
    "    solicitud_formal = aprobados & (df_categorizado['col_7'] == '85')\n",
    "    df_categorizado.loc[solicitud_formal, 'descripcion'] = 'Solicitud formal'\n",
    "    \n",
    "    print(\"\\nâœ… CategorizaciÃ³n completada\")\n",
    "    print(f\"\\nğŸ“‹ DistribuciÃ³n de categorÃ­as:\")\n",
    "    print(f\"  DispersiÃ³n geogrÃ¡fica: {dispersion.sum():,}\")\n",
    "    print(f\"  Solicitud formal: {solicitud_formal.sum():,}\")\n",
    "    \n",
    "    # Validar que todos los aprobados tienen categorÃ­a\n",
    "    aprobados_sin_categoria = aprobados & (df_categorizado['descripcion'] == '')\n",
    "    if aprobados_sin_categoria.sum() > 0:\n",
    "        print(f\"\\nâš ï¸ ALERTA: {aprobados_sin_categoria.sum()} aprobados sin categorÃ­a\")\n",
    "    \n",
    "    # Mostrar distribuciÃ³n por rÃ©gimen\n",
    "    print(\"\\nğŸ“Š DistribuciÃ³n por rÃ©gimen y categorÃ­a:\")\n",
    "    dist_regimen_cat = df_categorizado[aprobados].groupby(['regimen', 'descripcion']).size().unstack(fill_value=0)\n",
    "    print(dist_regimen_cat)\n",
    "    \n",
    "    # Mostrar ejemplos\n",
    "    print(f\"\\nğŸ“ Ejemplos de categorizaciÃ³n:\")\n",
    "    print(\"\\nDispersiÃ³n geogrÃ¡fica:\")\n",
    "    print(df_categorizado[dispersion][['id_afiliado', 'col_7', 'regimen', 'respuesta', 'descripcion']].head(3))\n",
    "    \n",
    "    print(\"\\nSolicitud formal:\")\n",
    "    print(df_categorizado[solicitud_formal][['id_afiliado', 'col_7', 'regimen', 'respuesta', 'descripcion']].head(3))\n",
    "    \n",
    "    # Guardar resultado en nuevo dataframe\n",
    "    df_r2_r4_final = df_categorizado.copy()\n",
    "    \n",
    "    print(f\"\\nâœ… Dataframe final creado: df_r2_r4_final\")\n",
    "    print(f\"Total de registros: {len(df_r2_r4_final):,}\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ ERROR: No se encuentra el dataframe depurado df_r2_r4_depurado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "# DashBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## Unificar procesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"PREPARACIÃ“N DE DATOS - ANÃLISIS CORRECTO DE FLUJOS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Preparar S2-S4 (Hacia EPS SUBSIDIADAS)\n",
    "if 'df_s2_s4_final' in locals():\n",
    "    df_salidas_subs = df_s2_s4_final.copy()\n",
    "    df_salidas_subs['eps_destino_tipo'] = 'EPS Subsidiada'\n",
    "    df_salidas_subs['regimen_origen'] = df_salidas_subs['regimen']  # De quÃ© rÃ©gimen de Capresoca salen\n",
    "    df_salidas_subs['eps_destino_cod'] = df_salidas_subs['col_1']\n",
    "    df_salidas_subs['departamento_destino'] = df_salidas_subs['col_8']\n",
    "    df_salidas_subs['municipio_destino'] = df_salidas_subs['col_9']\n",
    "    df_salidas_subs['fecha_efectiva'] = df_salidas_subs['col_11']\n",
    "    \n",
    "    # Clasificar tipo de migraciÃ³n\n",
    "    def clasificar_migracion_s4(row):\n",
    "        if row['regimen_origen'] == 'Subsidiado':\n",
    "            return 'Cambio lateral (Subsâ†’Subs)'\n",
    "        else:\n",
    "            return 'MigraciÃ³n descendente (Contâ†’Subs)'\n",
    "    \n",
    "    df_salidas_subs['tipo_migracion'] = df_salidas_subs.apply(clasificar_migracion_s4, axis=1)\n",
    "    \n",
    "    print(f\"âœ… SALIDAS hacia EPS SUBSIDIADAS (S4):\")\n",
    "    print(f\"   Total: {len(df_salidas_subs):,}\")\n",
    "    print(f\"\\n   Desde Subsidiado: {len(df_salidas_subs[df_salidas_subs['regimen_origen'] == 'Subsidiado']):,}\")\n",
    "    print(f\"   Desde Contributivo: {len(df_salidas_subs[df_salidas_subs['regimen_origen'] == 'Contributivo']):,}\")\n",
    "\n",
    "# Preparar R2-R4 (Hacia EPS CONTRIBUTIVAS)\n",
    "if 'df_r2_r4_final' in locals():\n",
    "    df_salidas_cont = df_r2_r4_final.copy()\n",
    "    df_salidas_cont['eps_destino_tipo'] = 'EPS Contributiva'\n",
    "    df_salidas_cont['regimen_origen'] = df_salidas_cont['regimen']  # De quÃ© rÃ©gimen de Capresoca salen\n",
    "    df_salidas_cont['eps_destino_cod'] = df_salidas_cont['col_1']\n",
    "    df_salidas_cont['departamento_destino'] = df_salidas_cont['col_13']\n",
    "    df_salidas_cont['municipio_destino'] = df_salidas_cont['col_14']\n",
    "    df_salidas_cont['fecha_efectiva'] = df_salidas_cont['col_9']\n",
    "    \n",
    "    # Clasificar tipo de migraciÃ³n\n",
    "    def clasificar_migracion_r4(row):\n",
    "        if row['regimen_origen'] == 'Contributivo':\n",
    "            return 'Cambio lateral (Contâ†’Cont)'\n",
    "        else:\n",
    "            return 'MigraciÃ³n ascendente (Subsâ†’Cont)'\n",
    "    \n",
    "    df_salidas_cont['tipo_migracion'] = df_salidas_cont.apply(clasificar_migracion_r4, axis=1)\n",
    "    \n",
    "    print(f\"\\nâœ… SALIDAS hacia EPS CONTRIBUTIVAS (R4):\")\n",
    "    print(f\"   Total: {len(df_salidas_cont):,}\")\n",
    "    print(f\"\\n   Desde Subsidiado: {len(df_salidas_cont[df_salidas_cont['regimen_origen'] == 'Subsidiado']):,}\")\n",
    "    print(f\"   Desde Contributivo: {len(df_salidas_cont[df_salidas_cont['regimen_origen'] == 'Contributivo']):,}\")\n",
    "\n",
    "# AnÃ¡lisis de impacto financiero\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANÃLISIS DE IMPACTO FINANCIERO POR FECHA EFECTIVA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for df_name, df in [('S4', df_salidas_subs), ('R4', df_salidas_cont)]:\n",
    "    if df is not None:\n",
    "        df['fecha_efectiva_dt'] = pd.to_datetime(df['fecha_efectiva'], format='%d/%m/%Y', errors='coerce')\n",
    "        df['fecha_proceso_dt'] = pd.to_datetime(df['fecha_proceso'], format='%d/%m/%Y')\n",
    "        \n",
    "        # Calcular retroactividad\n",
    "        df['retroactivo'] = df['fecha_efectiva_dt'] < df['fecha_proceso_dt']\n",
    "        df['mismo_mes'] = (df['fecha_efectiva_dt'].dt.to_period('M') == \n",
    "                           df['fecha_proceso_dt'].dt.to_period('M'))\n",
    "        \n",
    "        # Clasificar impacto\n",
    "        def clasificar_impacto(row):\n",
    "            if row['respuesta'] != '1':\n",
    "                return 'No aplica'\n",
    "            elif row['retroactivo'] or row['mismo_mes']:\n",
    "                return 'Impacto inmediato'\n",
    "            else:\n",
    "                return 'Impacto diferido'\n",
    "        \n",
    "        df['impacto_financiero'] = df.apply(clasificar_impacto, axis=1)\n",
    "        \n",
    "        print(f\"\\n{df_name} - Impacto financiero:\")\n",
    "        aprobados = df[df['respuesta'] == '1']\n",
    "        if len(aprobados) > 0:\n",
    "            impacto = aprobados['impacto_financiero'].value_counts()\n",
    "            for categoria, cantidad in impacto.items():\n",
    "                print(f\"   {categoria}: {cantidad:,}\")\n",
    "\n",
    "# Unificar todas las salidas\n",
    "if 'df_salidas_subs' in locals() and 'df_salidas_cont' in locals():\n",
    "    df_salidas_total = pd.concat([df_salidas_subs, df_salidas_cont], ignore_index=True)\n",
    "    \n",
    "    print(f\"\\n\" + \"=\" * 80)\n",
    "    print(f\"RESUMEN TOTAL DE SALIDAS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nTotal salidas: {len(df_salidas_total):,}\")\n",
    "    \n",
    "    aprobados_total = df_salidas_total[df_salidas_total['respuesta'] == '1']\n",
    "    print(f\"Aprobadas: {len(aprobados_total):,}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š DistribuciÃ³n por tipo de migraciÃ³n (aprobados):\")\n",
    "    dist_migracion = aprobados_total['tipo_migracion'].value_counts()\n",
    "    for tipo, cantidad in dist_migracion.items():\n",
    "        porcentaje = (cantidad / len(aprobados_total) * 100)\n",
    "        print(f\"   {tipo}: {cantidad:,} ({porcentaje:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š DistribuciÃ³n por rÃ©gimen origen y destino (aprobados):\")\n",
    "    tabla_cruzada = pd.crosstab(\n",
    "        aprobados_total['regimen_origen'], \n",
    "        aprobados_total['eps_destino_tipo'],\n",
    "        margins=True\n",
    "    )\n",
    "    print(tabla_cruzada)\n",
    "    \n",
    "    print(f\"\\nâœ… Dataset unificado creado: df_salidas_total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"PREPARACIÃ“N FINAL DE DATOS PARA DASHBOARD\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Preparar S2-S4 (Salidas hacia EPS SUBSIDIADAS)\n",
    "if 'df_s2_s4_final' in locals():\n",
    "    df_salidas_subs = df_s2_s4_final.copy()\n",
    "    df_salidas_subs['eps_destino_tipo'] = 'EPS Subsidiada'\n",
    "    df_salidas_subs['regimen_origen'] = df_salidas_subs['regimen']\n",
    "    df_salidas_subs['eps_destino_cod'] = df_salidas_subs['col_1']\n",
    "    df_salidas_subs['departamento_destino'] = df_salidas_subs['col_8']\n",
    "    df_salidas_subs['municipio_destino'] = df_salidas_subs['col_9']\n",
    "    df_salidas_subs['fecha_efectiva'] = df_salidas_subs['col_11']\n",
    "    \n",
    "    # Clasificar tipo de migraciÃ³n\n",
    "    def clasificar_migracion_s4(row):\n",
    "        if row['regimen_origen'] == 'Subsidiado':\n",
    "            return 'Cambio lateral (Subsâ†’Subs)'\n",
    "        else:\n",
    "            return 'MigraciÃ³n descendente (Contâ†’Subs)'\n",
    "    \n",
    "    df_salidas_subs['tipo_migracion'] = df_salidas_subs.apply(clasificar_migracion_s4, axis=1)\n",
    "    \n",
    "    print(f\"âœ… SALIDAS hacia EPS SUBSIDIADAS (S4): {len(df_salidas_subs):,}\")\n",
    "\n",
    "# Preparar R2-R4 (Salidas hacia EPS CONTRIBUTIVAS)\n",
    "if 'df_r2_r4_final' in locals():\n",
    "    df_salidas_cont = df_r2_r4_final.copy()\n",
    "    df_salidas_cont['eps_destino_tipo'] = 'EPS Contributiva'\n",
    "    df_salidas_cont['regimen_origen'] = df_salidas_cont['regimen']\n",
    "    df_salidas_cont['eps_destino_cod'] = df_salidas_cont['col_1']\n",
    "    df_salidas_cont['departamento_destino'] = df_salidas_cont['col_13']\n",
    "    df_salidas_cont['municipio_destino'] = df_salidas_cont['col_14']\n",
    "    df_salidas_cont['fecha_efectiva'] = df_salidas_cont['col_9']\n",
    "    \n",
    "    # Clasificar tipo de migraciÃ³n\n",
    "    def clasificar_migracion_r4(row):\n",
    "        if row['regimen_origen'] == 'Contributivo':\n",
    "            return 'Cambio lateral (Contâ†’Cont)'\n",
    "        else:\n",
    "            return 'MigraciÃ³n ascendente (Subsâ†’Cont)'\n",
    "    \n",
    "    df_salidas_cont['tipo_migracion'] = df_salidas_cont.apply(clasificar_migracion_r4, axis=1)\n",
    "    \n",
    "    print(f\"âœ… SALIDAS hacia EPS CONTRIBUTIVAS (R4): {len(df_salidas_cont):,}\")\n",
    "\n",
    "# AnÃ¡lisis de impacto financiero por fecha efectiva\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANÃLISIS DE IMPACTO FINANCIERO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for df_name, df_temp in [('Subsidiadas', df_salidas_subs), ('Contributivas', df_salidas_cont)]:\n",
    "    if df_temp is not None:\n",
    "        df_temp['fecha_efectiva_dt'] = pd.to_datetime(df_temp['fecha_efectiva'], format='%d/%m/%Y', errors='coerce')\n",
    "        df_temp['fecha_proceso_dt'] = pd.to_datetime(df_temp['fecha_proceso'], format='%d/%m/%Y')\n",
    "        \n",
    "        df_temp['retroactivo'] = df_temp['fecha_efectiva_dt'] < df_temp['fecha_proceso_dt']\n",
    "        df_temp['mismo_mes'] = (df_temp['fecha_efectiva_dt'].dt.to_period('M') == \n",
    "                                df_temp['fecha_proceso_dt'].dt.to_period('M'))\n",
    "        \n",
    "        def clasificar_impacto(row):\n",
    "            if row['respuesta'] != '1':\n",
    "                return 'No aplica'\n",
    "            elif row['retroactivo'] or row['mismo_mes']:\n",
    "                return 'Impacto inmediato (RestituciÃ³n UPC)'\n",
    "            else:\n",
    "                return 'Impacto diferido (Mantiene UPC)'\n",
    "        \n",
    "        df_temp['impacto_financiero'] = df_temp.apply(clasificar_impacto, axis=1)\n",
    "        \n",
    "        aprobados = df_temp[df_temp['respuesta'] == '1']\n",
    "        if len(aprobados) > 0:\n",
    "            print(f\"\\nEPS {df_name}:\")\n",
    "            impacto = aprobados['impacto_financiero'].value_counts()\n",
    "            for categoria, cantidad in impacto.items():\n",
    "                print(f\"  {categoria}: {cantidad:,}\")\n",
    "\n",
    "# Unificar todas las salidas\n",
    "if 'df_salidas_subs' in locals() and 'df_salidas_cont' in locals():\n",
    "    df_salidas_total = pd.concat([df_salidas_subs, df_salidas_cont], ignore_index=True)\n",
    "    \n",
    "    print(f\"\\nâœ… Dataset unificado creado: df_salidas_total\")\n",
    "    print(f\"Total de salidas: {len(df_salidas_total):,}\")\n",
    "    print(f\"Aprobadas: {len(df_salidas_total[df_salidas_total['respuesta'] == '1']):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## SECCIÃ“N 1: KPIs PRINCIPALES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECCIÃ“N 1: KPIs PRINCIPALES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DASHBOARD DE SALIDAS - CAPRESOCA EPS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if 'df_salidas_total' in locals():\n",
    "    # Filtrar solo aprobados\n",
    "    df_aprobados = df_salidas_total[df_salidas_total['respuesta'] == '1'].copy()\n",
    "    \n",
    "    from plotly.subplots import make_subplots\n",
    "    import plotly.graph_objects as go\n",
    "    \n",
    "    # MÃ©tricas principales\n",
    "    total_salidas = len(df_aprobados)\n",
    "    salidas_subs = len(df_aprobados[df_aprobados['regimen_origen'] == 'Subsidiado'])\n",
    "    salidas_cont = len(df_aprobados[df_aprobados['regimen_origen'] == 'Contributivo'])\n",
    "    \n",
    "    dispersion = len(df_aprobados[df_aprobados['descripcion'] == 'DispersiÃ³n geogrÃ¡fica'])\n",
    "    solicitud_formal = len(df_aprobados[df_aprobados['descripcion'] == 'Solicitud formal'])\n",
    "    \n",
    "    impacto_inmediato = len(df_aprobados[df_aprobados['impacto_financiero'] == 'Impacto inmediato (RestituciÃ³n UPC)'])\n",
    "    impacto_diferido = total_salidas - impacto_inmediato\n",
    "    \n",
    "    # Calcular porcentajes\n",
    "    pct_subs = (salidas_subs / total_salidas * 100) if total_salidas > 0 else 0\n",
    "    pct_cont = (salidas_cont / total_salidas * 100) if total_salidas > 0 else 0\n",
    "    pct_dispersion = (dispersion / total_salidas * 100) if total_salidas > 0 else 0\n",
    "    pct_formal = (solicitud_formal / total_salidas * 100) if total_salidas > 0 else 0\n",
    "    pct_inmediato = (impacto_inmediato / total_salidas * 100) if total_salidas > 0 else 0\n",
    "    pct_diferido = (impacto_diferido / total_salidas * 100) if total_salidas > 0 else 0\n",
    "    \n",
    "    # Calcular salidas a EPS contributivas\n",
    "    hacia_contrib = len(df_aprobados[df_aprobados['eps_destino_tipo'] == 'EPS Contributiva'])\n",
    "    pct_hacia_contrib = (hacia_contrib / total_salidas * 100) if total_salidas > 0 else 0\n",
    "    \n",
    "    # Crear subplots para KPIs\n",
    "    fig_kpis = make_subplots(\n",
    "        rows=2, cols=4,\n",
    "        specs=[[{'type': 'indicator'}, {'type': 'indicator'}, {'type': 'indicator'}, {'type': 'indicator'}],\n",
    "               [{'type': 'indicator'}, {'type': 'indicator'}, {'type': 'indicator'}, {'type': 'indicator'}]],\n",
    "        vertical_spacing=0.3\n",
    "    )\n",
    "    \n",
    "    # Fila 1\n",
    "    fig_kpis.add_trace(go.Indicator(\n",
    "        mode = \"number\",\n",
    "        value = total_salidas,\n",
    "        title = {\"text\": \"<b>Total Salidas<br>Aprobadas</b>\", \"font\": {\"size\": 16}},\n",
    "        number = {\"font\": {\"size\": 60, \"color\": \"#2c3e50\"}},\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    fig_kpis.add_trace(go.Indicator(\n",
    "        mode = \"number\",\n",
    "        value = salidas_subs,\n",
    "        title = {\"text\": f\"<b>Desde Subsidiado</b><br><span style='font-size:14px'>{pct_subs:.1f}% del total</span>\", \"font\": {\"size\": 14}},\n",
    "        number = {\"font\": {\"size\": 50, \"color\": \"#e74c3c\"}},\n",
    "    ), row=1, col=2)\n",
    "    \n",
    "    fig_kpis.add_trace(go.Indicator(\n",
    "        mode = \"number\",\n",
    "        value = salidas_cont,\n",
    "        title = {\"text\": f\"<b>Desde Contributivo</b><br><span style='font-size:14px'>{pct_cont:.1f}% del total</span>\", \"font\": {\"size\": 14}},\n",
    "        number = {\"font\": {\"size\": 50, \"color\": \"#3498db\"}},\n",
    "    ), row=1, col=3)\n",
    "    \n",
    "    fig_kpis.add_trace(go.Indicator(\n",
    "        mode = \"number\",\n",
    "        value = impacto_inmediato,\n",
    "        title = {\"text\": f\"<b>Impacto Inmediato</b><br><span style='font-size:14px'>âš ï¸ {pct_inmediato:.1f}% (RestituciÃ³n UPC)</span>\", \"font\": {\"size\": 14}},\n",
    "        number = {\"font\": {\"size\": 50, \"color\": \"#e67e22\"}},\n",
    "    ), row=1, col=4)\n",
    "    \n",
    "    # Fila 2\n",
    "    fig_kpis.add_trace(go.Indicator(\n",
    "        mode = \"number\",\n",
    "        value = dispersion,\n",
    "        title = {\"text\": f\"<b>DispersiÃ³n GeogrÃ¡fica</b><br><span style='font-size:14px'>{pct_dispersion:.1f}% del total</span>\", \"font\": {\"size\": 14}},\n",
    "        number = {\"font\": {\"size\": 50, \"color\": \"#9b59b6\"}},\n",
    "    ), row=2, col=1)\n",
    "    \n",
    "    fig_kpis.add_trace(go.Indicator(\n",
    "        mode = \"number\",\n",
    "        value = solicitud_formal,\n",
    "        title = {\"text\": f\"<b>Solicitud Formal</b><br><span style='font-size:14px'>{pct_formal:.1f}% del total</span>\", \"font\": {\"size\": 14}},\n",
    "        number = {\"font\": {\"size\": 50, \"color\": \"#16a085\"}},\n",
    "    ), row=2, col=2)\n",
    "    \n",
    "    fig_kpis.add_trace(go.Indicator(\n",
    "        mode = \"number\",\n",
    "        value = impacto_diferido,\n",
    "        title = {\"text\": f\"<b>Impacto Diferido</b><br><span style='font-size:14px'>âœ… {pct_diferido:.1f}% (Mantiene UPC)</span>\", \"font\": {\"size\": 14}},\n",
    "        number = {\"font\": {\"size\": 50, \"color\": \"#27ae60\"}},\n",
    "    ), row=2, col=3)\n",
    "    \n",
    "    fig_kpis.add_trace(go.Indicator(\n",
    "        mode = \"number\",\n",
    "        value = hacia_contrib,\n",
    "        title = {\"text\": f\"<b>MigraciÃ³n Ascendente</b><br><span style='font-size:14px'>{pct_hacia_contrib:.1f}% hacia contributivo</span>\", \"font\": {\"size\": 14}},\n",
    "        number = {\"font\": {\"size\": 50, \"color\": \"#f39c12\"}},\n",
    "    ), row=2, col=4)\n",
    "    \n",
    "    fig_kpis.update_layout(\n",
    "        height=500,\n",
    "        title_text=\"ğŸ“Š KPIs Principales - Traslados de Salida Enero 2026\",\n",
    "        title_font_size=22,\n",
    "        title_x=0.5,\n",
    "        title_xanchor='center',\n",
    "        margin=dict(t=100, b=20)\n",
    "    )\n",
    "    \n",
    "    fig_kpis.show()\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ ERROR: No se encuentra el dataframe unificado df_salidas_total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "## SECCIÃ“N 2: MATRIZ DE MIGRACIÃ“N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECCIÃ“N 2: MATRIZ DE MIGRACIÃ“N\n",
    "# ============================================================================\n",
    "\n",
    "if 'df_aprobados' in locals():\n",
    "    import plotly.graph_objects as go\n",
    "    \n",
    "    tabla_migracion = pd.crosstab(\n",
    "        df_aprobados['regimen_origen'], \n",
    "        df_aprobados['eps_destino_tipo'],\n",
    "        margins=True,\n",
    "        margins_name='Total'\n",
    "    )\n",
    "    \n",
    "    fig_matriz = go.Figure(data=[go.Table(\n",
    "        header=dict(\n",
    "            values=['<b>RÃ©gimen Origen</b>'] + ['<b>' + col + '</b>' for col in tabla_migracion.columns],\n",
    "            fill_color='#1f77b4',\n",
    "            align='center',\n",
    "            font=dict(color='white', size=14)\n",
    "        ),\n",
    "        cells=dict(\n",
    "            values=[tabla_migracion.index] + [tabla_migracion[col] for col in tabla_migracion.columns],\n",
    "            fill_color=[['#f0f0f0', 'white'] * len(tabla_migracion)],\n",
    "            align='center',\n",
    "            font=dict(size=13),\n",
    "            height=30\n",
    "        )\n",
    "    )])\n",
    "    \n",
    "    fig_matriz.update_layout(\n",
    "        title_text=\"ğŸ”„ Matriz de MigraciÃ³n: Origen â†’ Destino\",\n",
    "        title_font_size=18,\n",
    "        height=300\n",
    "    )\n",
    "    \n",
    "    fig_matriz.show()\n",
    "else:\n",
    "    print(\"âŒ ERROR: Ejecuta primero la secciÃ³n de KPIs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "## SECCIÃ“N 3: ANÃLISIS POR TIPO DE MIGRACIÃ“N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECCIÃ“N 3: ANÃLISIS POR TIPO DE MIGRACIÃ“N\n",
    "# ============================================================================\n",
    "\n",
    "if 'df_aprobados' in locals():\n",
    "    import plotly.graph_objects as go\n",
    "    \n",
    "    tipo_migracion = df_aprobados['tipo_migracion'].value_counts()\n",
    "    \n",
    "    fig_tipo = go.Figure(data=[\n",
    "        go.Bar(\n",
    "            x=tipo_migracion.index,\n",
    "            y=tipo_migracion.values,\n",
    "            text=tipo_migracion.values,\n",
    "            textposition='auto',\n",
    "            marker_color=['#2ecc71', '#e74c3c', '#3498db', '#f39c12']\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    fig_tipo.update_layout(\n",
    "        title_text=\"ğŸ”€ DistribuciÃ³n por Tipo de MigraciÃ³n\",\n",
    "        title_font_size=18,\n",
    "        xaxis_title=\"Tipo de MigraciÃ³n\",\n",
    "        yaxis_title=\"Cantidad de Afiliados\",\n",
    "        height=400,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig_tipo.show()\n",
    "else:\n",
    "    print(\"âŒ ERROR: Ejecuta primero la secciÃ³n de KPIs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "## SECCIÃ“N 4: DISTRIBUCIÃ“N GEOGRÃFICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECCIÃ“N 4: DISTRIBUCIÃ“N GEOGRÃFICA\n",
    "# ============================================================================\n",
    "\n",
    "if 'df_aprobados' in locals():\n",
    "    import plotly.graph_objects as go\n",
    "    \n",
    "    # Top 10 Departamentos destino\n",
    "    top_deptos = df_aprobados['departamento_destino'].value_counts().head(10)\n",
    "    \n",
    "    # Calcular porcentajes\n",
    "    total_aprobados_graf = len(df_aprobados)\n",
    "    porcentajes = (top_deptos / total_aprobados_graf * 100).round(1)\n",
    "    \n",
    "    # Crear texto enriquecido para las barras\n",
    "    text_labels = [\n",
    "        f\"<b>{cant}</b> afiliados<br>({pct}% del total)\" \n",
    "        for cant, pct in zip(top_deptos.values, porcentajes.values)\n",
    "    ]\n",
    "    \n",
    "    # Asignar colores degradados segÃºn cantidad\n",
    "    colores = ['#1a5490' if i == 0 else '#3498db' if i < 3 else '#5dade2' \n",
    "               for i in range(len(top_deptos))]\n",
    "    \n",
    "    fig_deptos = go.Figure(data=[\n",
    "        go.Bar(\n",
    "            y=top_deptos.index,\n",
    "            x=top_deptos.values,\n",
    "            orientation='h',\n",
    "            text=text_labels,\n",
    "            textposition='auto',\n",
    "            marker_color=colores,\n",
    "            marker_line_color='#2c3e50',\n",
    "            marker_line_width=1,\n",
    "            hovertemplate='<b>Departamento %{y}</b><br>' +\n",
    "                          'Afiliados: %{x}<br>' +\n",
    "                          'Porcentaje: %{customdata}%<br>' +\n",
    "                          '<extra></extra>',\n",
    "            customdata=porcentajes.values\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    fig_deptos.update_layout(\n",
    "        title_text=f\"<b>Top 10 Departamentos Destino</b><br>\" +\n",
    "                   f\"<sub>Total de salidas aprobadas: {total_aprobados_graf:,} afiliados</sub>\",\n",
    "        title_font_size=20,\n",
    "        title_x=0.5,\n",
    "        title_xanchor='center',\n",
    "        xaxis_title=\"<b>Cantidad de Afiliados</b>\",\n",
    "        yaxis_title=\"<b>CÃ³digo Departamento</b>\",\n",
    "        height=600,  # Aumentado de 550 a 600\n",
    "        plot_bgcolor='white',\n",
    "        paper_bgcolor='white',\n",
    "        margin=dict(l=80, r=50, t=100, b=120),  # Aumentado margen inferior de 80 a 120\n",
    "        xaxis=dict(\n",
    "            gridcolor='#ecf0f1',\n",
    "            showgrid=True,\n",
    "            zeroline=False\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            autorange='reversed',\n",
    "            gridcolor='#ecf0f1'\n",
    "        ),\n",
    "        font=dict(family=\"Arial, sans-serif\", size=12)\n",
    "    )\n",
    "    \n",
    "    # Agregar anotaciÃ³n con resumen\n",
    "    concentracion_top3 = top_deptos.head(3).sum()\n",
    "    pct_concentracion = (concentracion_top3 / total_aprobados_graf * 100)\n",
    "    \n",
    "    fig_deptos.add_annotation(\n",
    "        text=f\"Los 3 principales departamentos concentran el <b>{pct_concentracion:.1f}%</b> de las salidas\",\n",
    "        xref=\"paper\", yref=\"paper\",\n",
    "        x=0.5, y=-0.15,  # Cambiado de -0.12 a -0.15\n",
    "        showarrow=False,\n",
    "        font=dict(size=13, color='#2c3e50'),\n",
    "        xanchor='center'\n",
    "    )\n",
    "    \n",
    "    fig_deptos.show()\n",
    "    \n",
    "    # Resumen en texto\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ANÃLISIS GEOGRÃFICO - TOP 10 DEPARTAMENTOS DESTINO\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nTotal de afiliados que causaron salida: {total_aprobados_graf:,}\")\n",
    "    print(f\"\\nDistribuciÃ³n por departamento:\\n\")\n",
    "    \n",
    "    for idx, (depto, cantidad) in enumerate(top_deptos.items(), 1):\n",
    "        porcentaje = (cantidad / total_aprobados_graf * 100)\n",
    "        barra = \"â–ˆ\" * int(porcentaje / 2)\n",
    "        print(f\"{idx:2d}. Depto {depto}: {cantidad:3d} afiliados ({porcentaje:5.1f}%) {barra}\")\n",
    "    \n",
    "    # Calcular concentraciÃ³n\n",
    "    otros_deptos = total_aprobados_graf - top_deptos.sum()\n",
    "    pct_otros = (otros_deptos / total_aprobados_graf * 100)\n",
    "    \n",
    "    print(f\"\\nOtros departamentos: {otros_deptos:,} afiliados ({pct_otros:.1f}%)\")\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    \n",
    "else:\n",
    "    print(\"ERROR: Ejecuta primero la secciÃ³n de KPIs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "## SECCIÃ“N 5: TOP EPS DESTINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECCIÃ“N 5: TOP EPS DESTINO\n",
    "# ============================================================================\n",
    "\n",
    "if 'df_aprobados' in locals():\n",
    "    import plotly.graph_objects as go\n",
    "    \n",
    "    top_eps = df_aprobados['eps_destino_cod'].value_counts().head(15)\n",
    "    \n",
    "    fig_eps = go.Figure(data=[\n",
    "        go.Bar(\n",
    "            x=top_eps.index,\n",
    "            y=top_eps.values,\n",
    "            text=top_eps.values,\n",
    "            textposition='auto',\n",
    "            marker_color='#e74c3c'\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    fig_eps.update_layout(\n",
    "        title_text=\"ğŸ¥ Top 15 EPS Destino (que nos quitan mÃ¡s afiliados)\",\n",
    "        title_font_size=18,\n",
    "        xaxis_title=\"CÃ³digo EPS\",\n",
    "        yaxis_title=\"Cantidad de Afiliados\",\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig_eps.show()\n",
    "else:\n",
    "    print(\"âŒ ERROR: Ejecuta primero la secciÃ³n de KPIs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "## SECCIÃ“N 6: DISTRIBUCIÃ“N POR CATEGORÃA Y RÃ‰GIMEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECCIÃ“N 6: DISTRIBUCIÃ“N POR CATEGORÃA Y RÃ‰GIMEN\n",
    "# ============================================================================\n",
    "\n",
    "if 'df_aprobados' in locals():\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    \n",
    "    # AnÃ¡lisis de categorÃ­as\n",
    "    categorias_dist = df_aprobados['descripcion'].value_counts()\n",
    "    \n",
    "    # AnÃ¡lisis cruzado: categorÃ­a x rÃ©gimen\n",
    "    tabla_cat_regimen = pd.crosstab(\n",
    "        df_aprobados['descripcion'], \n",
    "        df_aprobados['regimen_origen'],\n",
    "        margins=True,\n",
    "        margins_name='Total'\n",
    "    )\n",
    "    \n",
    "    # Crear subplots\n",
    "    fig_categorias = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        specs=[[{'type': 'pie'}, {'type': 'bar'}]],\n",
    "        subplot_titles=(\n",
    "            '<b>DistribuciÃ³n General</b>',\n",
    "            '<b>Desglose por RÃ©gimen</b>'\n",
    "        ),\n",
    "        horizontal_spacing=0.2\n",
    "    )\n",
    "    \n",
    "    # 1. GRÃFICO DE DONA\n",
    "    colores_categoria = {\n",
    "        'DispersiÃ³n geogrÃ¡fica': '#9b59b6',\n",
    "        'Solicitud formal': '#16a085'\n",
    "    }\n",
    "    \n",
    "    colors = [colores_categoria.get(cat, '#95a5a6') for cat in categorias_dist.index]\n",
    "    \n",
    "    labels_limpias = [\n",
    "        'DispersiÃ³n<br>geogrÃ¡fica' if cat == 'DispersiÃ³n geogrÃ¡fica' else 'Solicitud<br>formal'\n",
    "        for cat in categorias_dist.index\n",
    "    ]\n",
    "    \n",
    "    fig_categorias.add_trace(go.Pie(\n",
    "        labels=labels_limpias,\n",
    "        values=categorias_dist.values,\n",
    "        hole=0.55,\n",
    "        marker=dict(\n",
    "            colors=colors, \n",
    "            line=dict(color='white', width=3)\n",
    "        ),\n",
    "        textinfo='percent',\n",
    "        textposition='inside',\n",
    "        textfont=dict(size=16, color='white', family='Arial Black'),\n",
    "        hovertemplate='<b>%{label}</b><br>' +\n",
    "                      'Cantidad: %{value:,} afiliados<br>' +\n",
    "                      'Porcentaje: %{percent}<br>' +\n",
    "                      '<extra></extra>',\n",
    "        showlegend=True\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    # 2. BARRAS AGRUPADAS\n",
    "    if 'Total' in tabla_cat_regimen.columns:\n",
    "        tabla_sin_total = tabla_cat_regimen.drop('Total', axis=1)\n",
    "        tabla_sin_total = tabla_sin_total.drop('Total', axis=0)\n",
    "    else:\n",
    "        tabla_sin_total = tabla_cat_regimen\n",
    "    \n",
    "    for idx, regimen in enumerate(tabla_sin_total.columns):\n",
    "        color_base = '#e74c3c' if regimen == 'Subsidiado' else '#3498db'\n",
    "        \n",
    "        fig_categorias.add_trace(go.Bar(\n",
    "            name=f'<b>{regimen}</b>',\n",
    "            x=tabla_sin_total.index,\n",
    "            y=tabla_sin_total[regimen],\n",
    "            text=[f'<b>{int(val)}</b>' for val in tabla_sin_total[regimen].values],\n",
    "            textposition='outside',\n",
    "            textfont=dict(size=14, color=color_base),\n",
    "            marker_color=color_base,\n",
    "            marker_line_color='white',\n",
    "            marker_line_width=2,\n",
    "            hovertemplate='<b>%{x}</b><br>' +\n",
    "                          f'{regimen}: %{{y:,}} afiliados<br>' +\n",
    "                          '<extra></extra>',\n",
    "            opacity=0.9\n",
    "        ), row=1, col=2)\n",
    "    \n",
    "    # Texto central en la dona - CORREGIDO CON MEJOR ESPACIADO\n",
    "    total_categorizado = categorias_dist.sum()\n",
    "    fig_categorias.add_annotation(\n",
    "        text=f'<span style=\"font-size:14px\">Total</span><br><br>' +\n",
    "             f'<span style=\"font-size:36px; font-weight:bold\">{total_categorizado}</span><br>' +\n",
    "             f'<span style=\"font-size:12px\">afiliados</span>',\n",
    "        x=0.185, \n",
    "        y=0.5,\n",
    "        xref='paper', \n",
    "        yref='paper',\n",
    "        font=dict(color='#2c3e50'),\n",
    "        showarrow=False,\n",
    "        align='center'\n",
    "    )\n",
    "    \n",
    "    # Layout\n",
    "    fig_categorias.update_layout(\n",
    "        title=dict(\n",
    "            text=\"<b>ğŸ“Š AnÃ¡lisis de Salidas por CategorÃ­a y RÃ©gimen</b>\",\n",
    "            font=dict(size=20),\n",
    "            x=0.5,\n",
    "            xanchor='center'\n",
    "        ),\n",
    "        height=550,\n",
    "        plot_bgcolor='white',\n",
    "        paper_bgcolor='white',\n",
    "        margin=dict(t=100, b=100, l=60, r=60),\n",
    "        barmode='group',\n",
    "        bargap=0.3,\n",
    "        showlegend=True,\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=-0.20,\n",
    "            xanchor=\"center\",\n",
    "            x=0.75,\n",
    "            font=dict(size=13),\n",
    "            bgcolor='rgba(255,255,255,0.8)',\n",
    "            bordercolor='#bdc3c7',\n",
    "            borderwidth=1\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Configurar ejes de barras\n",
    "    fig_categorias.update_xaxes(\n",
    "        title_text=\"\",\n",
    "        tickfont=dict(size=11),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig_categorias.update_yaxes(\n",
    "        title_text=\"<b>Cantidad de Afiliados</b>\",\n",
    "        title_font=dict(size=13),\n",
    "        gridcolor='#ecf0f1',\n",
    "        gridwidth=1,\n",
    "        range=[0, max(tabla_sin_total.max()) * 1.15],\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig_categorias.show()\n",
    "    \n",
    "    # (El resto del cÃ³digo de resumen textual se mantiene igual...)\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ ERROR: Ejecuta primero la secciÃ³n de KPIs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "## SECCIÃ“N 7: IMPACTO FINANCIERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECCIÃ“N 7: IMPACTO FINANCIERO\n",
    "# ============================================================================\n",
    "\n",
    "if 'df_aprobados' in locals():\n",
    "    import plotly.graph_objects as go\n",
    "    \n",
    "    # AnÃ¡lisis de impacto financiero\n",
    "    impacto_dist = df_aprobados['impacto_financiero'].value_counts()\n",
    "    \n",
    "    # Calcular totales y porcentajes\n",
    "    total_aprobados_impacto = len(df_aprobados)\n",
    "    impacto_inmediato_cant = impacto_dist.get('Impacto inmediato (RestituciÃ³n UPC)', 0)\n",
    "    impacto_diferido_cant = impacto_dist.get('Impacto diferido (Mantiene UPC)', 0)\n",
    "    \n",
    "    pct_inmediato = (impacto_inmediato_cant / total_aprobados_impacto * 100) if total_aprobados_impacto > 0 else 0\n",
    "    pct_diferido = (impacto_diferido_cant / total_aprobados_impacto * 100) if total_aprobados_impacto > 0 else 0\n",
    "    \n",
    "    # ExplicaciÃ³n contextual\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ“Œ CONTEXTO: Â¿QUÃ‰ SIGNIFICA EL IMPACTO FINANCIERO?\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nCuando un afiliado se traslada a otra EPS, la fecha efectiva del traslado\")\n",
    "    print(\"determina el impacto financiero para CAPRESOCA:\\n\")\n",
    "    \n",
    "    print(\"ğŸ”´ IMPACTO INMEDIATO (RestituciÃ³n de UPC):\")\n",
    "    print(\"   â†’ Ocurre cuando la fecha efectiva es RETROACTIVA o en el MISMO MES\")\n",
    "    print(\"   â†’ CAPRESOCA debe devolver la UPC recibida por ese afiliado\")\n",
    "    print(\"   â†’ Representa una pÃ©rdida financiera inmediata\")\n",
    "    print(\"   â†’ Afecta el flujo de caja del periodo actual\\n\")\n",
    "    \n",
    "    print(\"ğŸŸ¢ IMPACTO DIFERIDO (Mantiene UPC):\")\n",
    "    print(\"   â†’ Ocurre cuando la fecha efectiva es en un MES FUTURO\")\n",
    "    print(\"   â†’ CAPRESOCA conserva la UPC del mes actual\")\n",
    "    print(\"   â†’ La salida se ejecuta en el siguiente periodo\")\n",
    "    print(\"   â†’ Permite planificar y ajustar presupuesto\\n\")\n",
    "    \n",
    "    print(\"ğŸ’¡ IMPORTANCIA PARA LA TOMA DE DECISIONES:\")\n",
    "    print(f\"   â€¢ Un {pct_inmediato:.1f}% de impacto inmediato puede afectar liquidez\")\n",
    "    print(\"   â€¢ Requiere provisiones financieras para restituciones\")\n",
    "    print(\"   â€¢ Indica la eficiencia en los tiempos de procesamiento\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "    \n",
    "    # Colores con semÃ¡foro claro\n",
    "    colors_impacto = ['#e74c3c' if 'inmediato' in str(x).lower() else '#27ae60' for x in impacto_dist.index]\n",
    "    \n",
    "    # Crear etiquetas personalizadas\n",
    "    labels_personalizadas = []\n",
    "    for label in impacto_dist.index:\n",
    "        if 'inmediato' in str(label).lower():\n",
    "            labels_personalizadas.append('âš ï¸ Impacto Inmediato<br>(RestituciÃ³n UPC)')\n",
    "        else:\n",
    "            labels_personalizadas.append('âœ… Impacto Diferido<br>(Mantiene UPC)')\n",
    "    \n",
    "    # Crear grÃ¡fico de dona mejorado\n",
    "    fig_impacto = go.Figure(data=[\n",
    "        go.Pie(\n",
    "            labels=labels_personalizadas,\n",
    "            values=impacto_dist.values,\n",
    "            hole=0.5,\n",
    "            marker=dict(\n",
    "                colors=colors_impacto,\n",
    "                line=dict(color='white', width=3)\n",
    "            ),\n",
    "            textinfo='percent+value',\n",
    "            textfont=dict(size=14, color='white', family='Arial Black'),\n",
    "            textposition='inside',\n",
    "            hovertemplate='<b>%{label}</b><br>' +\n",
    "                          'Cantidad: %{value:,} afiliados<br>' +\n",
    "                          'Porcentaje: %{percent}<br>' +\n",
    "                          '<extra></extra>',\n",
    "            pull=[0.05 if 'inmediato' in str(label).lower() else 0 for label in impacto_dist.index]  # Resaltar impacto inmediato\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    # Layout mejorado\n",
    "    fig_impacto.update_layout(\n",
    "        title=dict(\n",
    "            text=f\"<b>ğŸ’° Impacto Financiero por Fecha Efectiva</b><br>\" +\n",
    "                 f\"<sub>Total de traslados aprobados: {total_aprobados_impacto:,} afiliados</sub>\",\n",
    "            font=dict(size=20),\n",
    "            x=0.5,\n",
    "            xanchor='center'\n",
    "        ),\n",
    "        height=600,\n",
    "        plot_bgcolor='white',\n",
    "        paper_bgcolor='white',\n",
    "        margin=dict(t=120, b=100, l=50, r=50),\n",
    "        showlegend=True,\n",
    "        legend=dict(\n",
    "            orientation=\"v\",\n",
    "            yanchor=\"middle\",\n",
    "            y=0.5,\n",
    "            xanchor=\"left\",\n",
    "            x=1.05,\n",
    "            font=dict(size=13)\n",
    "        ),\n",
    "        annotations=[\n",
    "            # Texto central en la dona\n",
    "            dict(\n",
    "                text=f'<b>Impacto<br>UPC</b><br><br>{total_aprobados_impacto:,}<br>afiliados',\n",
    "                x=0.5, y=0.5,\n",
    "                font=dict(size=16, color='#2c3e50', family='Arial'),\n",
    "                showarrow=False\n",
    "            ),\n",
    "            # Advertencia si impacto inmediato es alto\n",
    "            dict(\n",
    "                text=f\"<b>âš ï¸ ATENCIÃ“N:</b> {pct_inmediato:.1f}% requiere restituciÃ³n de UPC\" if pct_inmediato > 20 else \n",
    "                     f\"<b>âœ… FAVORABLE:</b> Solo {pct_inmediato:.1f}% requiere restituciÃ³n de UPC\",\n",
    "                xref=\"paper\", yref=\"paper\",\n",
    "                x=0.5, y=-0.15,\n",
    "                showarrow=False,\n",
    "                font=dict(size=14, color='#e74c3c' if pct_inmediato > 20 else '#27ae60'),\n",
    "                xanchor='center'\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    fig_impacto.show()\n",
    "    \n",
    "    # Resumen cuantitativo\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ“Š RESUMEN DE IMPACTO FINANCIERO\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nğŸ”´ Impacto Inmediato (RestituciÃ³n UPC):\")\n",
    "    print(f\"   â€¢ Cantidad: {impacto_inmediato_cant:,} afiliados\")\n",
    "    print(f\"   â€¢ Porcentaje: {pct_inmediato:.1f}%\")\n",
    "    print(f\"   â€¢ InterpretaciÃ³n: {'âš ï¸ ALTO - Requiere atenciÃ³n' if pct_inmediato > 30 else 'âœ… MODERADO - Dentro de lo esperado' if pct_inmediato > 15 else 'âœ… BAJO - SituaciÃ³n favorable'}\")\n",
    "    \n",
    "    print(f\"\\nğŸŸ¢ Impacto Diferido (Mantiene UPC):\")\n",
    "    print(f\"   â€¢ Cantidad: {impacto_diferido_cant:,} afiliados\")\n",
    "    print(f\"   â€¢ Porcentaje: {pct_diferido:.1f}%\")\n",
    "    print(f\"   â€¢ InterpretaciÃ³n: {'âœ… EXCELENTE - Mayor tiempo para planificar' if pct_diferido > 70 else 'âš ï¸ Revisar tiempos de procesamiento'}\")\n",
    "    \n",
    "    print(\"\\nğŸ’¡ RECOMENDACIONES:\")\n",
    "    if pct_inmediato > 30:\n",
    "        print(\"   1. Revisar tiempos de procesamiento de solicitudes\")\n",
    "        print(\"   2. Implementar alertas tempranas de traslados\")\n",
    "        print(\"   3. Provisionar recursos para restituciones de UPC\")\n",
    "        print(\"   4. Analizar causas de fechas efectivas retroactivas\")\n",
    "    elif pct_inmediato > 15:\n",
    "        print(\"   1. Monitorear tendencia mensual de impacto inmediato\")\n",
    "        print(\"   2. Optimizar tiempos de respuesta a solicitudes\")\n",
    "        print(\"   3. Mantener provisiones para restituciones\")\n",
    "    else:\n",
    "        print(\"   1. Mantener los procesos actuales\")\n",
    "        print(\"   2. Documentar buenas prÃ¡cticas\")\n",
    "        print(\"   3. Seguimiento mensual preventivo\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ ERROR: Ejecuta primero la secciÃ³n de KPIs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "## SECCIÃ“N 8: ANÃLISIS DE TASA DE APROBACIÃ“N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECCIÃ“N 8: ANÃLISIS DE TASA DE APROBACIÃ“N\n",
    "# ============================================================================\n",
    "\n",
    "if 'df_salidas_total' in locals():\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    \n",
    "    # Calcular mÃ©tricas de aprobaciÃ³n\n",
    "    total_solicitudes = len(df_salidas_total)\n",
    "    total_aprobadas = len(df_salidas_total[df_salidas_total['respuesta'] == '1'])\n",
    "    total_negadas = len(df_salidas_total[df_salidas_total['respuesta'] == '0'])\n",
    "    sin_respuesta = len(df_salidas_total[df_salidas_total['respuesta'] == 'Sin respuesta'])\n",
    "    \n",
    "    tasa_aprobacion = (total_aprobadas / total_solicitudes * 100) if total_solicitudes > 0 else 0\n",
    "    tasa_negacion = (total_negadas / total_solicitudes * 100) if total_solicitudes > 0 else 0\n",
    "    \n",
    "    # Calcular aprobaciÃ³n por rÃ©gimen\n",
    "    aprobacion_regimen = df_salidas_total.groupby(['regimen_origen', 'respuesta']).size().unstack(fill_value=0)\n",
    "    total_por_regimen = aprobacion_regimen.sum(axis=1)\n",
    "    \n",
    "    # Crear figura con 2 grÃ¡ficos\n",
    "    fig_aprobacion = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        specs=[[{'type': 'indicator'}, {'type': 'bar'}]],\n",
    "        subplot_titles=('', 'Tasa de AprobaciÃ³n por RÃ©gimen'),\n",
    "        horizontal_spacing=0.2,\n",
    "        column_widths=[0.4, 0.6]\n",
    "    )\n",
    "    \n",
    "    # 1. GAUGE - Tasa de aprobaciÃ³n general (SIN delta)\n",
    "    fig_aprobacion.add_trace(go.Indicator(\n",
    "        mode = \"gauge+number\",\n",
    "        value = tasa_aprobacion,\n",
    "        title = {'text': f\"<b>Tasa de AprobaciÃ³n General</b><br><span style='font-size:14px'>{total_aprobadas:,} de {total_solicitudes:,} solicitudes</span>\", \n",
    "                 'font': {'size': 16}},\n",
    "        number = {'suffix': '%', 'font': {'size': 50, 'color': '#2c3e50'}},\n",
    "        gauge = {\n",
    "            'axis': {'range': [None, 100], 'ticksuffix': '%', 'tickfont': {'size': 12}},\n",
    "            'bar': {'color': \"#2ecc71\", 'thickness': 0.8},\n",
    "            'bgcolor': \"white\",\n",
    "            'borderwidth': 2,\n",
    "            'bordercolor': \"#bdc3c7\",\n",
    "            'steps': [\n",
    "                {'range': [0, 30], 'color': \"#ffebee\"},\n",
    "                {'range': [30, 60], 'color': \"#fff3e0\"},\n",
    "                {'range': [60, 100], 'color': \"#e8f5e9\"}\n",
    "            ],\n",
    "            'threshold': {\n",
    "                'line': {'color': \"#2c3e50\", 'width': 4},\n",
    "                'thickness': 0.75,\n",
    "                'value': tasa_aprobacion\n",
    "            }\n",
    "        }\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    # 2. BARRAS - ComparaciÃ³n por rÃ©gimen\n",
    "    if '1' in aprobacion_regimen.columns:\n",
    "        pct_aprobacion_regimen = (aprobacion_regimen['1'] / total_por_regimen * 100)\n",
    "        \n",
    "        colores = ['#e74c3c' if r == 'Subsidiado' else '#3498db' for r in pct_aprobacion_regimen.index]\n",
    "        \n",
    "        fig_aprobacion.add_trace(go.Bar(\n",
    "            x=pct_aprobacion_regimen.index,\n",
    "            y=pct_aprobacion_regimen.values,\n",
    "            text=[f\"<b>{pct:.1f}%</b><br>{int(aprobacion_regimen.loc[r, '1']):,}/{int(total_por_regimen[r]):,}\" \n",
    "                  for r, pct in pct_aprobacion_regimen.items()],\n",
    "            textposition='auto',\n",
    "            marker_color=colores,\n",
    "            showlegend=False,\n",
    "            textfont={'size': 14, 'color': 'white'}\n",
    "        ), row=1, col=2)\n",
    "    \n",
    "    # Layout general\n",
    "    fig_aprobacion.update_layout(\n",
    "        height=400,\n",
    "        title_text=f\"ğŸ“Š AnÃ¡lisis de Tasa de AprobaciÃ³n - Enero 2026\",\n",
    "        title_font_size=22,\n",
    "        title_x=0.5,\n",
    "        title_xanchor='center',\n",
    "        margin=dict(t=80, b=60, l=50, r=50),\n",
    "        plot_bgcolor='white',\n",
    "        paper_bgcolor='white'\n",
    "    )\n",
    "    \n",
    "    # Configurar eje Y para barras\n",
    "    fig_aprobacion.update_yaxes(\n",
    "        title_text=\"% AprobaciÃ³n\",\n",
    "        range=[0, 100],\n",
    "        gridcolor='#ecf0f1',\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig_aprobacion.update_xaxes(\n",
    "        title_text=\"RÃ©gimen de Origen\",\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig_aprobacion.show()\n",
    "    \n",
    "    # Resumen en texto\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ“Š RESUMEN DE APROBACIÃ“N - ENERO 2026\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"\\nğŸ”¢ VOLUMEN:\")\n",
    "    print(f\"   â€¢ Total de solicitudes recibidas: {total_solicitudes:,}\")\n",
    "    print(f\"   â€¢ Solicitudes aprobadas: {total_aprobadas:,}\")\n",
    "    print(f\"   â€¢ Solicitudes negadas: {total_negadas:,}\")\n",
    "    \n",
    "    print(f\"\\nâœ… TASA DE APROBACIÃ“N GENERAL: {tasa_aprobacion:.1f}%\")\n",
    "    \n",
    "    if tasa_aprobacion >= 70:\n",
    "        status = \"ğŸŸ¢ ALTA\"\n",
    "        mensaje = \"Excelente desempeÃ±o en gestiÃ³n de solicitudes\"\n",
    "    elif tasa_aprobacion >= 50:\n",
    "        status = \"ğŸŸ¡ MEDIA\"\n",
    "        mensaje = \"Revisar principales causales de negaciÃ³n\"\n",
    "    else:\n",
    "        status = \"ğŸ”´ BAJA\"\n",
    "        mensaje = \"Requiere anÃ¡lisis detallado y plan de acciÃ³n\"\n",
    "    \n",
    "    print(f\"   {status} - {mensaje}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ POR RÃ‰GIMEN:\")\n",
    "    for regimen in aprobacion_regimen.index:\n",
    "        total_reg = total_por_regimen[regimen]\n",
    "        aprobadas_reg = aprobacion_regimen.loc[regimen, '1'] if '1' in aprobacion_regimen.columns else 0\n",
    "        pct_reg = (aprobadas_reg / total_reg * 100) if total_reg > 0 else 0\n",
    "        print(f\"   â€¢ {regimen}: {pct_reg:.1f}% ({int(aprobadas_reg):,} de {int(total_reg):,})\")\n",
    "    \n",
    "    if total_negadas > 0:\n",
    "        print(f\"\\nâŒ TOP 3 CAUSALES DE NEGACIÃ“N:\")\n",
    "        negados = df_salidas_total[df_salidas_total['respuesta'] == '0']\n",
    "        top_causales = negados['causal'].value_counts().head(3)\n",
    "        for idx, (causal, cantidad) in enumerate(top_causales.items(), 1):\n",
    "            pct_causal = (cantidad / total_negadas * 100)\n",
    "            print(f\"   {idx}. Causal {causal}: {cantidad:,} ({pct_causal:.1f}%)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ ERROR: No se encuentra el dataframe df_salidas_total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "## SECCIÃ“N 9: ANÃLISIS DE MIGRACIÃ“N INTERNA EN CASANARE (DEPARTAMENTO 85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECCIÃ“N 9: ANÃLISIS DE MIGRACIÃ“N INTERNA EN CASANARE (DEPARTAMENTO 85)\n",
    "# ============================================================================\n",
    "\n",
    "if 'df_aprobados' in locals():\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    \n",
    "    # Filtrar traslados dentro de Casanare (departamento 85)\n",
    "    migracion_interna = df_aprobados[df_aprobados['departamento_destino'] == '85'].copy()\n",
    "    \n",
    "    total_migracion_interna = len(migracion_interna)\n",
    "    pct_migracion_interna = (total_migracion_interna / len(df_aprobados) * 100) if len(df_aprobados) > 0 else 0\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ“Œ CONTEXTO: Â¿POR QUÃ‰ ES CRÃTICA LA MIGRACIÃ“N INTERNA?\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nLa migraciÃ³n interna (dentro del departamento 85 - Casanare) es el indicador\")\n",
    "    print(\"MÃS PREOCUPANTE para CAPRESOCA porque revela problemas estructurales:\\n\")\n",
    "    \n",
    "    print(\"ğŸ”´ IMPLICACIONES:\")\n",
    "    print(\"   â†’ El afiliado SE VA a otra EPS en el MISMO municipio donde CAPRESOCA opera\")\n",
    "    print(\"   â†’ Indica INSATISFACCIÃ“N con los servicios de CAPRESOCA\")\n",
    "    print(\"   â†’ La competencia estÃ¡ ganando afiliados en NUESTRO territorio\")\n",
    "    print(\"   â†’ Posibles causas: mala atenciÃ³n mÃ©dica, IPS deficientes, procesos lentos\\n\")\n",
    "    \n",
    "    print(\"ğŸ’¡ IMPORTANCIA ESTRATÃ‰GICA:\")\n",
    "    print(\"   â€¢ Refleja DIRECTAMENTE la calidad del servicio percibida\")\n",
    "    print(\"   â€¢ Permite identificar municipios con MAYOR insatisfacciÃ³n\")\n",
    "    print(\"   â€¢ Requiere ACCIÃ“N INMEDIATA para mejorar servicios\")\n",
    "    print(\"   â€¢ Es el tipo de pÃ©rdida MÃS EVITABLE\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "    \n",
    "    if total_migracion_interna > 0:\n",
    "        # AnÃ¡lisis por rÃ©gimen\n",
    "        dist_regimen = migracion_interna['regimen_origen'].value_counts()\n",
    "        \n",
    "        # Top 10 municipios con mÃ¡s migraciÃ³n interna\n",
    "        top_municipios = migracion_interna['municipio_destino'].value_counts().head(10)\n",
    "        \n",
    "        # Calcular porcentajes\n",
    "        porcentajes_mun = (top_municipios / total_migracion_interna * 100).round(1)\n",
    "        \n",
    "        # Top EPS que reciben estos afiliados\n",
    "        top_eps_casanare = migracion_interna['eps_destino_cod'].value_counts().head(5)\n",
    "        \n",
    "        # Crear figura con 2 subgrÃ¡ficos\n",
    "        fig_migracion = make_subplots(\n",
    "            rows=1, cols=2,\n",
    "            subplot_titles=(\n",
    "                '<b>Top 10 Municipios de Casanare con Mayor Fuga</b>',\n",
    "                '<b>EPS que Captan Nuestros Afiliados en Casanare</b>'\n",
    "            ),\n",
    "            horizontal_spacing=0.15,\n",
    "            specs=[[{'type': 'bar'}, {'type': 'bar'}]]\n",
    "        )\n",
    "        \n",
    "        # 1. BARRAS HORIZONTALES - Top municipios\n",
    "        colores_municipios = ['#c0392b' if i < 3 else '#e74c3c' if i < 5 else '#ec7063' \n",
    "                              for i in range(len(top_municipios))]\n",
    "        \n",
    "        fig_migracion.add_trace(go.Bar(\n",
    "            y=top_municipios.index,\n",
    "            x=top_municipios.values,\n",
    "            orientation='h',\n",
    "            text=[f\"<b>{cant}</b><br>({pct}%)\" for cant, pct in zip(top_municipios.values, porcentajes_mun.values)],\n",
    "            textposition='auto',\n",
    "            marker_color=colores_municipios,\n",
    "            marker_line_color='#641e16',\n",
    "            marker_line_width=1.5,\n",
    "            hovertemplate='<b>Municipio %{y}</b><br>' +\n",
    "                          'Afiliados perdidos: %{x}<br>' +\n",
    "                          '<extra></extra>',\n",
    "            showlegend=False\n",
    "        ), row=1, col=1)\n",
    "        \n",
    "        # 2. BARRAS VERTICALES - Top EPS competidoras\n",
    "        colores_eps = ['#16a085' if i == 0 else '#1abc9c' if i < 3 else '#48c9b0' \n",
    "                       for i in range(len(top_eps_casanare))]\n",
    "        \n",
    "        fig_migracion.add_trace(go.Bar(\n",
    "            x=top_eps_casanare.index,\n",
    "            y=top_eps_casanare.values,\n",
    "            text=top_eps_casanare.values,\n",
    "            textposition='auto',\n",
    "            marker_color=colores_eps,\n",
    "            marker_line_color='#117a65',\n",
    "            marker_line_width=1.5,\n",
    "            hovertemplate='<b>EPS %{x}</b><br>' +\n",
    "                          'Afiliados captados: %{y}<br>' +\n",
    "                          '<extra></extra>',\n",
    "            showlegend=False,\n",
    "            textfont={'size': 14, 'color': 'white'}\n",
    "        ), row=1, col=2)\n",
    "        \n",
    "        # Layout general\n",
    "        fig_migracion.update_layout(\n",
    "            title=dict(\n",
    "                text=f\"<b>ğŸš¨ ANÃLISIS CRÃTICO: MigraciÃ³n Interna en Casanare</b><br>\" +\n",
    "                     f\"<sub>{total_migracion_interna:,} afiliados ({pct_migracion_interna:.1f}% del total) se fueron a otra EPS en el mismo departamento</sub>\",\n",
    "                font=dict(size=20),\n",
    "                x=0.5,\n",
    "                xanchor='center'\n",
    "            ),\n",
    "            height=500,\n",
    "            plot_bgcolor='white',\n",
    "            paper_bgcolor='white',\n",
    "            margin=dict(t=120, b=80, l=50, r=50),\n",
    "            showlegend=False\n",
    "        )\n",
    "        \n",
    "        # Configurar ejes\n",
    "        fig_migracion.update_xaxes(\n",
    "            title_text=\"<b>Afiliados Perdidos</b>\",\n",
    "            gridcolor='#ecf0f1',\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        fig_migracion.update_yaxes(\n",
    "            title_text=\"<b>CÃ³digo Municipio</b>\",\n",
    "            autorange='reversed',\n",
    "            gridcolor='#ecf0f1',\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        fig_migracion.update_xaxes(\n",
    "            title_text=\"<b>CÃ³digo EPS Receptora</b>\",\n",
    "            row=1, col=2\n",
    "        )\n",
    "        \n",
    "        fig_migracion.update_yaxes(\n",
    "            title_text=\"<b>Afiliados Captados</b>\",\n",
    "            gridcolor='#ecf0f1',\n",
    "            row=1, col=2\n",
    "        )\n",
    "        \n",
    "        fig_migracion.show()\n",
    "        \n",
    "        # Resumen detallado en texto\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"ğŸ“Š RESUMEN DE MIGRACIÃ“N INTERNA - CASANARE (DEPTO 85)\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        print(f\"\\nğŸ”¢ MAGNITUD DEL PROBLEMA:\")\n",
    "        print(f\"   â€¢ Total de afiliados perdidos en Casanare: {total_migracion_interna:,}\")\n",
    "        print(f\"   â€¢ Representa el {pct_migracion_interna:.1f}% de todas las salidas\")\n",
    "        \n",
    "        print(f\"\\nğŸ“‹ DISTRIBUCIÃ“N POR RÃ‰GIMEN:\")\n",
    "        for regimen, cantidad in dist_regimen.items():\n",
    "            pct_reg = (cantidad / total_migracion_interna * 100)\n",
    "            print(f\"   â€¢ {regimen}: {cantidad:,} afiliados ({pct_reg:.1f}%)\")\n",
    "        \n",
    "        print(f\"\\nğŸ˜ï¸ TOP 5 MUNICIPIOS MÃS CRÃTICOS:\")\n",
    "        for idx, (municipio, cantidad) in enumerate(top_municipios.head(5).items(), 1):\n",
    "            pct = (cantidad / total_migracion_interna * 100)\n",
    "            nivel = \"ğŸ”´ CRÃTICO\" if idx <= 2 else \"ğŸŸ  ALTO\" if idx <= 3 else \"ğŸŸ¡ MODERADO\"\n",
    "            print(f\"   {idx}. Municipio {municipio}: {cantidad:,} afiliados ({pct:.1f}%) - {nivel}\")\n",
    "        \n",
    "        print(f\"\\nğŸ¥ TOP 3 EPS COMPETIDORAS EN CASANARE:\")\n",
    "        for idx, (eps, cantidad) in enumerate(top_eps_casanare.head(3).items(), 1):\n",
    "            pct = (cantidad / total_migracion_interna * 100)\n",
    "            print(f\"   {idx}. EPS {eps}: {cantidad:,} afiliados captados ({pct:.1f}%)\")\n",
    "        \n",
    "        # ComparaciÃ³n con dispersiÃ³n geogrÃ¡fica\n",
    "        dispersion_geografica = len(df_aprobados[df_aprobados['departamento_destino'] != '85'])\n",
    "        \n",
    "        print(f\"\\nğŸ“Š COMPARACIÃ“N:\")\n",
    "        print(f\"   â€¢ MigraciÃ³n INTERNA (mismo depto): {total_migracion_interna:,} ({pct_migracion_interna:.1f}%)\")\n",
    "        print(f\"   â€¢ DispersiÃ³n GEOGRÃFICA (otro depto): {dispersion_geografica:,} \" +\n",
    "              f\"({(dispersion_geografica/len(df_aprobados)*100):.1f}%)\")\n",
    "        \n",
    "        print(f\"\\nğŸ’¡ INTERPRETACIÃ“N:\")\n",
    "        if pct_migracion_interna > 50:\n",
    "            print(\"   ğŸ”´ CRÃTICO: MÃ¡s del 50% de las salidas son EVITABLES\")\n",
    "            print(\"   â†’ Indica GRAVES problemas de calidad del servicio\")\n",
    "            print(\"   â†’ Requiere INTERVENCIÃ“N INMEDIATA de la alta direcciÃ³n\")\n",
    "        elif pct_migracion_interna > 30:\n",
    "            print(\"   ğŸŸ  ALTO: Un porcentaje significativo de salidas es por insatisfacciÃ³n\")\n",
    "            print(\"   â†’ Revisar calidad de atenciÃ³n en municipios crÃ­ticos\")\n",
    "            print(\"   â†’ Implementar plan de mejora urgente\")\n",
    "        else:\n",
    "            print(\"   ğŸŸ¢ CONTROLADO: La mayorÃ­a de salidas son por dispersiÃ³n geogrÃ¡fica\")\n",
    "            print(\"   â†’ Mantener estÃ¡ndares de calidad\")\n",
    "            print(\"   â†’ Seguimiento preventivo en municipios identificados\")\n",
    "        \n",
    "        print(f\"\\nğŸ¯ RECOMENDACIONES PRIORITARIAS:\")\n",
    "        print(\"   1. AUDITAR servicios en los 3 municipios mÃ¡s crÃ­ticos\")\n",
    "        print(\"   2. ENTREVISTAR afiliados que se trasladaron (encuestas de salida)\")\n",
    "        print(\"   3. EVALUAR desempeÃ±o de IPS contratadas en esos municipios\")\n",
    "        print(\"   4. COMPARAR tiempos de respuesta vs. competencia\")\n",
    "        print(\"   5. IMPLEMENTAR plan de retenciÃ³n focalizado\")\n",
    "        print(\"   6. MEJORAR canales de comunicaciÃ³n y quejas\")\n",
    "        \n",
    "        # AnÃ¡lisis de tipo de migraciÃ³n interna\n",
    "        if 'tipo_migracion' in migracion_interna.columns:\n",
    "            print(f\"\\nğŸ”€ TIPO DE MIGRACIÃ“N INTERNA:\")\n",
    "            tipo_mig_int = migracion_interna['tipo_migracion'].value_counts()\n",
    "            for tipo, cant in tipo_mig_int.items():\n",
    "                pct_tipo = (cant / total_migracion_interna * 100)\n",
    "                print(f\"   â€¢ {tipo}: {cant:,} ({pct_tipo:.1f}%)\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        \n",
    "    else:\n",
    "        print(\"\\nâœ… EXCELENTE: No hay migraciÃ³n interna detectada en Casanare\")\n",
    "        print(\"Todas las salidas son hacia otros departamentos (dispersiÃ³n geogrÃ¡fica)\")\n",
    "        \n",
    "else:\n",
    "    print(\"âŒ ERROR: Ejecuta primero la secciÃ³n de KPIs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "## SECCIÃ“N 10: RESUMEN EJECUTIVO COMPLETO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECCIÃ“N 10: RESUMEN EJECUTIVO COMPLETO\n",
    "# ============================================================================\n",
    "\n",
    "if 'df_salidas_total' in locals() and 'df_aprobados' in locals():\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"RESUMEN EJECUTIVO - TRASLADOS DE SALIDA ENERO 2026\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 1. RESUMEN GENERAL\n",
    "    print(\"\\nğŸ“Š 1. RESUMEN GENERAL DE SOLICITUDES\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Total de solicitudes procesadas: {total_solicitudes:,}\")\n",
    "    print(f\"Solicitudes aprobadas: {total_aprobadas:,}\")\n",
    "    print(f\"Solicitudes negadas: {total_negadas:,}\")\n",
    "    if sin_respuesta > 0:\n",
    "        print(f\"Solicitudes sin respuesta: {sin_respuesta:,}\")\n",
    "    print(f\"\\nâœ… TASA DE APROBACIÃ“N GENERAL: {tasa_aprobacion:.1f}%\")\n",
    "    \n",
    "    # 2. ANÃLISIS POR RÃ‰GIMEN\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"ğŸ“‹ 2. ANÃLISIS POR RÃ‰GIMEN DE ORIGEN\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Desde Subsidiado: {salidas_subs:,} ({pct_subs:.1f}%)\")\n",
    "    print(f\"Desde Contributivo: {salidas_cont:,} ({pct_cont:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n   Tasa de aprobaciÃ³n por rÃ©gimen:\")\n",
    "    for regimen in aprobacion_regimen.index:\n",
    "        total_reg = total_por_regimen[regimen]\n",
    "        aprobadas_reg = aprobacion_regimen.loc[regimen, '1'] if '1' in aprobacion_regimen.columns else 0\n",
    "        pct_reg = (aprobadas_reg / total_reg * 100) if total_reg > 0 else 0\n",
    "        print(f\"   {regimen}: {pct_reg:.1f}%\")\n",
    "    \n",
    "    # 3. DESTINO DE LAS SALIDAS\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"ğŸ¥ 3. DESTINO DE LAS SALIDAS APROBADAS\")\n",
    "    print(\"-\" * 80)\n",
    "    destino_dist = df_aprobados['eps_destino_tipo'].value_counts()\n",
    "    for tipo, cant in destino_dist.items():\n",
    "        print(f\"{tipo}: {cant:,} ({cant/total_salidas*100:.1f}%)\")\n",
    "    \n",
    "    # 4. CATEGORIZACIÃ“N\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"ğŸ“ 4. CATEGORIZACIÃ“N DE SALIDAS\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"DispersiÃ³n geogrÃ¡fica: {dispersion:,} ({pct_dispersion:.1f}%)\")\n",
    "    print(f\"Solicitud formal: {solicitud_formal:,} ({pct_formal:.1f}%)\")\n",
    "    \n",
    "    # 5. TIPO DE MIGRACIÃ“N\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"ğŸ”€ 5. TIPO DE MIGRACIÃ“N\")\n",
    "    print(\"-\" * 80)\n",
    "    tipo_dist = df_aprobados['tipo_migracion'].value_counts()\n",
    "    for tipo, cant in tipo_dist.items():\n",
    "        print(f\"{tipo}: {cant:,} ({cant/total_salidas*100:.1f}%)\")\n",
    "    \n",
    "    # 6. IMPACTO FINANCIERO\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"ğŸ’° 6. IMPACTO FINANCIERO\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"âš ï¸ Impacto Inmediato (RestituciÃ³n UPC): {impacto_inmediato:,} ({pct_inmediato:.1f}%)\")\n",
    "    print(f\"âœ… Impacto Diferido (Mantiene UPC): {impacto_diferido:,} ({pct_diferido:.1f}%)\")\n",
    "    \n",
    "    # 7. MIGRACIÃ“N INTERNA EN CASANARE (NUEVO - MÃS CRÃTICO)\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"ğŸš¨ 7. MIGRACIÃ“N INTERNA EN CASANARE (DEPARTAMENTO 85)\")\n",
    "    print(\"-\" * 80)\n",
    "    migracion_interna_total = len(df_aprobados[df_aprobados['departamento_destino'] == '85'])\n",
    "    pct_interna = (migracion_interna_total / total_salidas * 100) if total_salidas > 0 else 0\n",
    "    \n",
    "    print(f\"Afiliados que se fueron a otra EPS en Casanare: {migracion_interna_total:,} ({pct_interna:.1f}%)\")\n",
    "    \n",
    "    if migracion_interna_total > 0:\n",
    "        casanare_data = df_aprobados[df_aprobados['departamento_destino'] == '85']\n",
    "        top_3_mun_casanare = casanare_data['municipio_destino'].value_counts().head(3)\n",
    "        \n",
    "        print(f\"\\nTop 3 municipios crÃ­ticos:\")\n",
    "        for idx, (mun, cant) in enumerate(top_3_mun_casanare.items(), 1):\n",
    "            print(f\"   {idx}. Municipio {mun}: {cant:,} afiliados\")\n",
    "        \n",
    "        if pct_interna > 30:\n",
    "            print(f\"\\n   ğŸ”´ ALERTA CRÃTICA: {pct_interna:.1f}% de pÃ©rdidas son EVITABLES\")\n",
    "            print(\"   â†’ Indica problemas graves de calidad en el servicio\")\n",
    "    \n",
    "    # 8. TOP EPS DESTINO\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"ğŸ” 8. TOP 5 EPS QUE MÃS AFILIADOS RECIBEN\")\n",
    "    print(\"-\" * 80)\n",
    "    top_5_eps = df_aprobados['eps_destino_cod'].value_counts().head(5)\n",
    "    for idx, (eps, cantidad) in enumerate(top_5_eps.items(), 1):\n",
    "        print(f\"{idx}. EPS {eps}: {cantidad:,} afiliados ({cantidad/total_aprobadas*100:.1f}%)\")\n",
    "    \n",
    "    # 9. TOP DEPARTAMENTOS DESTINO\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"ğŸ“ 9. TOP 5 DEPARTAMENTOS DESTINO\")\n",
    "    print(\"-\" * 80)\n",
    "    top_5_deptos = df_aprobados['departamento_destino'].value_counts().head(5)\n",
    "    for idx, (depto, cantidad) in enumerate(top_5_deptos.items(), 1):\n",
    "        print(f\"{idx}. Departamento {depto}: {cantidad:,} afiliados ({cantidad/total_aprobadas*100:.1f}%)\")\n",
    "    \n",
    "    # 10. CAUSALES DE NEGACIÃ“N\n",
    "    if total_negadas > 0:\n",
    "        print(\"\\n\" + \"-\" * 80)\n",
    "        print(\"âŒ 10. PRINCIPALES CAUSALES DE NEGACIÃ“N\")\n",
    "        print(\"-\" * 80)\n",
    "        negados = df_salidas_total[df_salidas_total['respuesta'] == '0']\n",
    "        top_5_causales = negados['causal'].value_counts().head(5)\n",
    "        for idx, (causal, cantidad) in enumerate(top_5_causales.items(), 1):\n",
    "            print(f\"{idx}. Causal {causal}: {cantidad:,} ({cantidad/total_negadas*100:.1f}%)\")\n",
    "    \n",
    "    # 11. CONCLUSIONES Y RECOMENDACIONES\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ’¡ 11. CONCLUSIONES Y RECOMENDACIONES\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"\\nâœ“ La tasa de aprobaciÃ³n general es de {tasa_aprobacion:.1f}%\")\n",
    "    \n",
    "    if tasa_aprobacion >= 70:\n",
    "        print(\"  â†’ Tasa de aprobaciÃ³n ALTA - buen indicador de gestiÃ³n\")\n",
    "    elif tasa_aprobacion >= 50:\n",
    "        print(\"  â†’ Tasa de aprobaciÃ³n MEDIA - revisar causales de negaciÃ³n\")\n",
    "    else:\n",
    "        print(\"  â†’ Tasa de aprobaciÃ³n BAJA - requiere anÃ¡lisis detallado\")\n",
    "    \n",
    "    print(f\"\\nâœ“ El {pct_inmediato:.1f}% de las salidas tienen impacto financiero inmediato\")\n",
    "    if pct_inmediato > 50:\n",
    "        print(\"  âš ï¸ ALERTA: MÃ¡s del 50% requiere restituciÃ³n de UPC\")\n",
    "        print(\"  â†’ Revisar tiempos de procesamiento y fechas efectivas\")\n",
    "    \n",
    "    # NUEVA CONCLUSIÃ“N CRÃTICA SOBRE MIGRACIÃ“N INTERNA\n",
    "    print(f\"\\nâœ“ El {pct_interna:.1f}% son por migraciÃ³n INTERNA en Casanare\")\n",
    "    if pct_interna > 30:\n",
    "        print(\"  ğŸ”´ CRÃTICO: PÃ©rdida de afiliados en territorio propio\")\n",
    "        print(\"  â†’ PRIORIDAD MÃXIMA: Auditar calidad de servicio en municipios crÃ­ticos\")\n",
    "        print(\"  â†’ Implementar encuestas de satisfacciÃ³n y plan de retenciÃ³n\")\n",
    "    elif pct_interna > 15:\n",
    "        print(\"  ğŸŸ  ATENCIÃ“N: Nivel significativo de insatisfacciÃ³n local\")\n",
    "        print(\"  â†’ Revisar desempeÃ±o de IPS en municipios identificados\")\n",
    "    else:\n",
    "        print(\"  ğŸŸ¢ CONTROLADO: MayorÃ­a de salidas por dispersiÃ³n geogrÃ¡fica\")\n",
    "    \n",
    "    print(f\"\\nâœ“ El {pct_dispersion:.1f}% son por dispersiÃ³n geogrÃ¡fica (otros departamentos)\")\n",
    "    if pct_dispersion > 50:\n",
    "        print(\"  â†’ SituaciÃ³n NORMAL - pÃ©rdidas esperadas por movilidad\")\n",
    "    \n",
    "    regimen_mayor = salidas_subs if salidas_subs > salidas_cont else salidas_cont\n",
    "    regimen_nombre = \"Subsidiado\" if salidas_subs > salidas_cont else \"Contributivo\"\n",
    "    pct_mayor = (regimen_mayor / total_aprobadas * 100)\n",
    "    \n",
    "    print(f\"\\nâœ“ El {pct_mayor:.1f}% de las salidas provienen del rÃ©gimen {regimen_nombre}\")\n",
    "    print(f\"  â†’ Focalizar estrategias de retenciÃ³n en este rÃ©gimen\")\n",
    "    \n",
    "    # RECOMENDACIÃ“N FINAL PRIORIZADA\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ¯ ACCIONES PRIORITARIAS RECOMENDADAS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if pct_interna > 30:\n",
    "        print(\"\\n1. ğŸ”´ URGENTE - MIGRACIÃ“N INTERNA:\")\n",
    "        print(\"   â€¢ Auditar servicios en municipios crÃ­ticos de Casanare\")\n",
    "        print(\"   â€¢ Encuestas de satisfacciÃ³n a afiliados\")\n",
    "        print(\"   â€¢ Plan de mejora inmediato en calidad de atenciÃ³n\")\n",
    "    \n",
    "    if pct_inmediato > 30:\n",
    "        print(\"\\n2. ğŸŸ  IMPORTANTE - IMPACTO FINANCIERO:\")\n",
    "        print(\"   â€¢ Optimizar tiempos de respuesta a solicitudes\")\n",
    "        print(\"   â€¢ Provisionar recursos para restituciones UPC\")\n",
    "    \n",
    "    print(\"\\n3. ğŸŸ¡ SEGUIMIENTO - MONITOREO CONTINUO:\")\n",
    "    print(\"   â€¢ AnÃ¡lisis mensual de tendencias\")\n",
    "    print(\"   â€¢ Benchmark con competencia local\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"Fecha del informe: Enero 2026\")\n",
    "    print(f\"Total de afiliados que salieron: {total_aprobadas:,}\")\n",
    "    print(f\"Afiliados perdidos en Casanare (evitables): {migracion_interna_total:,}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ ERROR: Ejecuta primero las secciones anteriores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "# Duardar dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXPORTAR RESULTADOS A EXCEL\n",
    "# ============================================================================\n",
    "\n",
    "if 'df_salidas_total' in locals():\n",
    "    import pandas as pd\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Generar nombre de archivo con fecha\n",
    "    fecha_actual = datetime.now().strftime(\"%Y%m%d\")\n",
    "    nombre_archivo = f\"Traslados_Salida_{fecha_actual}.xlsx\"\n",
    "    ruta_salida = os.path.join(R_raiz, nombre_archivo)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ“Š EXPORTANDO RESULTADOS A EXCEL\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        # Crear writer de Excel con mÃºltiples hojas\n",
    "        with pd.ExcelWriter(ruta_salida, engine='openpyxl') as writer:\n",
    "            \n",
    "            # 1. HOJA PRINCIPAL - Todos los datos\n",
    "            df_salidas_total.to_excel(\n",
    "                writer, \n",
    "                sheet_name='Datos Completos',\n",
    "                index=False\n",
    "            )\n",
    "            \n",
    "            # 2. HOJA - Solo aprobados\n",
    "            df_aprobados.to_excel(\n",
    "                writer,\n",
    "                sheet_name='Aprobados',\n",
    "                index=False\n",
    "            )\n",
    "            \n",
    "            # 3. HOJA - Resumen ejecutivo\n",
    "            resumen_data = {\n",
    "                'Indicador': [\n",
    "                    'Total Solicitudes',\n",
    "                    'Total Aprobadas',\n",
    "                    'Total Negadas',\n",
    "                    'Tasa de AprobaciÃ³n (%)',\n",
    "                    'Desde Subsidiado',\n",
    "                    'Desde Contributivo',\n",
    "                    'DispersiÃ³n GeogrÃ¡fica',\n",
    "                    'Solicitud Formal',\n",
    "                    'Impacto Inmediato',\n",
    "                    'Impacto Diferido',\n",
    "                    'MigraciÃ³n Interna (Casanare)'\n",
    "                ],\n",
    "                'Valor': [\n",
    "                    total_solicitudes,\n",
    "                    total_aprobadas,\n",
    "                    total_negadas,\n",
    "                    round(tasa_aprobacion, 1),\n",
    "                    salidas_subs,\n",
    "                    salidas_cont,\n",
    "                    dispersion,\n",
    "                    solicitud_formal,\n",
    "                    impacto_inmediato,\n",
    "                    impacto_diferido,\n",
    "                    len(df_aprobados[df_aprobados['departamento_destino'] == '85'])\n",
    "                ]\n",
    "            }\n",
    "            \n",
    "            df_resumen = pd.DataFrame(resumen_data)\n",
    "            df_resumen.to_excel(\n",
    "                writer,\n",
    "                sheet_name='Resumen',\n",
    "                index=False\n",
    "            )\n",
    "            \n",
    "            # 4. HOJA - Top Municipios CrÃ­ticos\n",
    "            if len(df_aprobados[df_aprobados['departamento_destino'] == '85']) > 0:\n",
    "                migracion_interna = df_aprobados[df_aprobados['departamento_destino'] == '85']\n",
    "                top_municipios = migracion_interna['municipio_destino'].value_counts().head(10).reset_index()\n",
    "                top_municipios.columns = ['Municipio', 'Cantidad']\n",
    "                top_municipios.to_excel(\n",
    "                    writer,\n",
    "                    sheet_name='Municipios CrÃ­ticos',\n",
    "                    index=False\n",
    "                )\n",
    "            \n",
    "            # 5. HOJA - Top EPS Destino\n",
    "            top_eps = df_aprobados['eps_destino_cod'].value_counts().head(15).reset_index()\n",
    "            top_eps.columns = ['EPS', 'Cantidad']\n",
    "            top_eps.to_excel(\n",
    "                writer,\n",
    "                sheet_name='Top EPS Destino',\n",
    "                index=False\n",
    "            )\n",
    "            \n",
    "            # 6. HOJA - Causales de NegaciÃ³n\n",
    "            if total_negadas > 0:\n",
    "                negados = df_salidas_total[df_salidas_total['respuesta'] == '0']\n",
    "                causales = negados['causal'].value_counts().reset_index()\n",
    "                causales.columns = ['Causal', 'Cantidad']\n",
    "                causales.to_excel(\n",
    "                    writer,\n",
    "                    sheet_name='Causales NegaciÃ³n',\n",
    "                    index=False\n",
    "                )\n",
    "        \n",
    "        print(f\"\\nâœ… Archivo guardado exitosamente:\")\n",
    "        print(f\"   ğŸ“‚ UbicaciÃ³n: {ruta_salida}\")\n",
    "        print(f\"   ğŸ“„ Nombre: {nombre_archivo}\")\n",
    "        print(f\"\\nğŸ“‹ Hojas creadas:\")\n",
    "        print(f\"   1. Datos Completos ({len(df_salidas_total):,} registros)\")\n",
    "        print(f\"   2. Aprobados ({len(df_aprobados):,} registros)\")\n",
    "        print(f\"   3. Resumen (11 indicadores)\")\n",
    "        print(f\"   4. Municipios CrÃ­ticos (Top 10)\")\n",
    "        print(f\"   5. Top EPS Destino (Top 15)\")\n",
    "        print(f\"   6. Causales NegaciÃ³n ({total_negadas:,} registros)\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ERROR al guardar archivo: {e}\")\n",
    "        print(f\"\\nVerifica que:\")\n",
    "        print(f\"  â€¢ La ruta existe: {R_raiz}\")\n",
    "        print(f\"  â€¢ Tienes permisos de escritura\")\n",
    "        print(f\"  â€¢ El archivo no estÃ¡ abierto en Excel\")\n",
    "        \n",
    "else:\n",
    "    print(\"âŒ ERROR: No se encuentra el dataframe df_salidas_total\")\n",
    "    print(\"Ejecuta primero las secciones anteriores del anÃ¡lisis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
