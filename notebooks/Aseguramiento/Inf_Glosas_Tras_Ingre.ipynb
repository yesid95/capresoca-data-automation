{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Mudulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd  # Manipulaci칩n y an치lisis de datos estructurados\n",
    "from docx import Document  # Creaci칩n y edici칩n de documentos Word\n",
    "from docx.shared import Inches  # Definici칩n de medidas en pulgadas para documentos\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH  # Alineaci칩n de p치rrafos en documentos\n",
    "from docx.enum.table import WD_TABLE_ALIGNMENT  # Alineaci칩n de tablas en documentos\n",
    "import seaborn as sns  # Visualizaci칩n estad칤stica avanzada y gr치ficos est칠ticos\n",
    "import numpy as np  # Operaciones matem치ticas y arrays multidimensionales\n",
    "from docx.oxml.ns import qn  # Manejo de espacios de nombres XML en documentos\n",
    "from docx.oxml import OxmlElement\n",
    "from datetime import datetime  # Manejo de fechas y tiempo\n",
    "import io  # Operaciones de entrada/salida de datos en memoria\n",
    "from plotly.subplots import make_subplots\n",
    "import calendar # Funciones relacionadas con calendarios\n",
    "from docx.shared import Inches, RGBColor # Medidas y colores RGB para documentos\n",
    "\n",
    "import matplotlib.pyplot as plt  # Creaci칩n de gr치ficos y visualizaciones\n",
    "import plotly.express as px  # Gr치ficos interactivos modernos y elegantes\n",
    "import plotly.graph_objects as go  # Gr치ficos personalizados de alta calidad\n",
    "from matplotlib import style  # Estilos predefinidos para matplotlib\n",
    "import warnings  # Control de advertencias del sistema\n",
    "warnings.filterwarnings('ignore')  # Suprimir advertencias para output limpio\n",
    "import os # Interacci칩n con el sistema operativo\n",
    "import glob  # Manejo de rutas y archivos del sistema operativo\n",
    "\n",
    "\n",
    "# 1. Definici칩n de la paleta institucional (Rojo y Verde)\n",
    "# Es una lista de c칩digos hexadecimales.\n",
    "PALETA_EPS = ['#C23034', '#289452']\n",
    "\n",
    "# Si necesitas m치s de dos colores, puedes generar tonos intermedios o a침adir\n",
    "# un color secundario si la EPS lo tuviera. Por simplicidad, usamos los 2 principales:\n",
    "# PALETA_EPS = ['#C23034', '#289452', '#D35457', '#42A862'] \n",
    "\n",
    "# 2. Aplicar el estilo de Seaborn para un aspecto limpio (usa el Negro/Blanco)\n",
    "sns.set_style(\"whitegrid\")  # Fondo blanco con rejilla gris\n",
    "\n",
    "# 3. Sobreescribir la paleta por defecto con la paleta institucional\n",
    "sns.set_palette(PALETA_EPS) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Rutas y varaibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Home\n",
    "\n",
    "# Definir la fecha de trabajo\n",
    "#fecha_trabajo = \"01/10/2025\"  # Formato dd/mm/yyyy\n",
    "\n",
    "#Rutas\n",
    "#R_Documento = r\"C:\\Users\\crist\\OneDrive - 891856000_CAPRESOCA E P S\\Escritorio\\Yesid Rinc칩n Z\\informes\\2025\\CTO135.2025 Informe  #11\\ACTIVIDAD 14\\Informe Glosas\\FO-GD-07 INFORME.docx\"\n",
    "#R_Ms = r\"C:\\Users\\crist\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\Procesos BDUA\\Subsidiados\\Procesos BDUA EPS\\MS\\MS Negado\\All_MS_NEG.TXT\"\n",
    "#R_MS_val = r\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\Procesos BDUA\\Subsidiados\\Procesos BDUA EPS\\MS\\MS Validados\\All_MS_VAL.TXT\"\n",
    "#R_s3 = r\"C:\\Users\\crist\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\Procesos BDUA\\Subsidiados\\Procesos BDUA EPS\\S3\\All-S3.txt\"\n",
    "#R_Glosa_eh = r\"C:\\Users\\crist\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\Constantes\\glosas_error_humano.txt\"\n",
    "#R_glosas = r\"C:\\Users\\crist\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\Constantes\\Glosas ADRES 2025.xlsx\"\n",
    "#R_Expedientes_SIE = r\"C:\\Users\\crist\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\SIE\\Aseguramiento\\Expedientes\\A침os\"\n",
    "#R_Municipios = r\"C:\\Users\\crist\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\Constantes\\Departamentos.txt\"\n",
    "#R_Salida = r\"C:\\Users\\crist\\OneDrive - 891856000_CAPRESOCA E P S\\Escritorio\\Yesid Rinc칩n Z\\informes\\2025\\CTO135.2025 Informe  #11\\ACTIVIDAD 14\\Informe Glosas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Office\n",
    "## Home\n",
    "\n",
    "# Definir la fecha de trabajo\n",
    "fecha_trabajo = \"01/11/2025\"  # Formato dd/mm/yyyy\n",
    "\n",
    "#Rutas\n",
    "R_Documento = r\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Escritorio\\Yesid Rinc칩n Z\\informes\\2025\\CTO135.2025 Informe  #12\\ACTIVIDAD 14\\Informe Glosas\\FO-GD-07 INFORME.docx\"\n",
    "R_Ms = r\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\Procesos BDUA\\Subsidiados\\Procesos BDUA EPS\\MS\\MS Negado\\All_MS_NEG.TXT\"\n",
    "R_MS_val = r\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\Procesos BDUA\\Subsidiados\\Procesos BDUA EPS\\MS\\MS Validados\\All_MS_VAL.TXT\"\n",
    "R_s3 = r\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\Procesos BDUA\\Subsidiados\\Procesos BDUA EPS\\S3\\All-S3.txt\"\n",
    "R_Glosa_eh = r\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\Constantes\\glosas_error_humano.txt\"\n",
    "R_glosas = r\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\Constantes\\Glosas ADRES 2025.xlsx\"\n",
    "R_Expedientes_SIE = r\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\SIE\\Aseguramiento\\Expedientes\\A침os\"\n",
    "R_Municipios = r\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\Constantes\\Departamentos.txt\"\n",
    "R_Salida = r\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Escritorio\\Yesid Rinc칩n Z\\informes\\2025\\CTO135.2025 Informe  #12\\ACTIVIDAD 14\\Informe Glosas\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Cargue Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ms = pd.read_csv(R_Ms, sep=',', encoding='ansi', dtype=str)\n",
    "df_ms_val = pd.read_csv(R_MS_val, sep=',', encoding='ansi', dtype=str)\n",
    "df_s3 = pd.read_csv(R_s3, sep=',', encoding='ansi', dtype=str)\n",
    "df_glosa_eh = pd.read_csv(R_Glosa_eh, sep=';', encoding='ansi', dtype=str)\n",
    "df_Municipios = pd.read_csv(R_Municipios, sep=';', encoding='UTF-8', dtype=str)\n",
    "df_glosas = pd.read_excel(R_glosas, sheet_name='Glosas de Negocio_BDUA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para almacenar todos los dataframes\n",
    "dataframes_list = []\n",
    "\n",
    "# Obtener todos los archivos .txt de la ruta\n",
    "archivos_txt = glob.glob(os.path.join(R_Expedientes_SIE, \"*.txt\"))\n",
    "\n",
    "# Leer cada archivo y agregarlo a la lista\n",
    "for archivo in archivos_txt:\n",
    "    try:\n",
    "        df_temp = pd.read_csv(archivo, sep='|', encoding='ansi', dtype=str)\n",
    "        dataframes_list.append(df_temp)\n",
    "        print(f\"Archivo cargado: {os.path.basename(archivo)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar {archivo}: {e}\")\n",
    "\n",
    "# Concatenar todos los dataframes en uno solo\n",
    "if dataframes_list:\n",
    "    df_expedientes = pd.concat(dataframes_list, ignore_index=True)\n",
    "    print(f\"\\nDataframe consolidado creado con {len(df_expedientes)} filas\")\n",
    "    print(f\"Columnas: {list(df_expedientes.columns)}\")\n",
    "else:\n",
    "    print(\"No se encontraron archivos o no se pudieron cargar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Limpieza general de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Expedientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar las categor칤as 칰nicas de la columna 'Proceso' en df_expedientes\n",
    "print(\"Categor칤as 칰nicas en df_expedientes['Proceso']:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "categorias_proceso = df_expedientes['Proceso'].value_counts().sort_values(ascending=False)\n",
    "print(categorias_proceso)\n",
    "\n",
    "print(f\"\\nTotal de categor칤as 칰nicas: {len(categorias_proceso)}\")\n",
    "print(f\"Total de registros: {len(df_expedientes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar df_expedientes para mantener solo las categor칤as espec칤ficas de procesos\n",
    "categorias_permitidas = [\n",
    "    \"Afiliaci칩n R칠gimen Subsidiado Cabeza de Familia\", \n",
    "    \"Afiliaci칩n R칠gimen Subsidiado Beneficiario\", \n",
    "    \"Afiliaci칩n R칠gimen Subsidiado Nacimiento\", \n",
    "    \"Ingreso Afiliado Contributivo Nacimiento\"\n",
    "]\n",
    "\n",
    "df_expedientes = df_expedientes[df_expedientes['Proceso'].isin(categorias_permitidas)]\n",
    "\n",
    "print(f\"Registros despu칠s del filtro por categor칤as de proceso: {len(df_expedientes)}\")\n",
    "print(f\"Categor칤as 칰nicas restantes: {df_expedientes['Proceso'].unique()}\")\n",
    "print(f\"\\nConteo por categor칤a:\")\n",
    "print(df_expedientes['Proceso'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna 'Fecha Grabado' a datetime\n",
    "df_expedientes['Fecha_Grabado_dt'] = pd.to_datetime(df_expedientes['Fecha Grabado'], format='%Y/%m/%d %H:%M', errors='coerce')\n",
    "\n",
    "# Ordenar por fecha de grabado (m치s reciente primero)\n",
    "df_expedientes = df_expedientes.sort_values('Fecha_Grabado_dt', ascending=False)\n",
    "\n",
    "# Eliminar duplicados manteniendo el primer registro (m치s reciente) para cada combinaci칩n de Tipo Documento y N칰mero Identificaci칩n\n",
    "df_expedientes = df_expedientes.drop_duplicates(subset=['Tipo Documento', 'N칰mero Identificaci칩n'], keep='first')\n",
    "\n",
    "print(f\"Registros despu칠s de eliminar duplicados: {len(df_expedientes)}\")\n",
    "print(f\"Registros con fecha de grabado v치lida: {df_expedientes['Fecha_Grabado_dt'].notna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Listado de Glosas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiar el dataframe df_glosas eliminando registros vac칤os y seleccionando solo las columnas necesarias\n",
    "\n",
    "# Paso 1: Mostrar el estado inicial del dataframe\n",
    "print(\"Estado inicial de df_glosas:\")\n",
    "print(f\"Total de filas: {len(df_glosas)}\")\n",
    "print(f\"Valores nulos en columna 'Glosa ': {df_glosas['Glosa '].isna().sum()}\")\n",
    "print(f\"Columnas actuales: {list(df_glosas.columns)}\")\n",
    "\n",
    "# Paso 2: Eliminar filas donde la columna 'Glosa ' est칠 vac칤a (NaN)\n",
    "df_glosas = df_glosas.dropna(subset=['Glosa '])\n",
    "\n",
    "print(f\"\\nDespu칠s de eliminar registros con 'Glosa ' vac칤a:\")\n",
    "print(f\"Total de filas: {len(df_glosas)}\")\n",
    "\n",
    "# Paso 3: Seleccionar solo las columnas 'Glosa ' y 'Descripci칩n'\n",
    "df_glosas = df_glosas[['Glosa ', 'Descripci칩n']]\n",
    "\n",
    "# Paso 4: Renombrar la columna 'Glosa ' a 'Glosa' para corregir el error tipogr치fico\n",
    "df_glosas = df_glosas.rename(columns={'Glosa ': 'Glosa'})\n",
    "\n",
    "# Eliminar espacios en blanco al inicio y al final de la columna 'Glosa'\n",
    "df_glosas['Glosa'] = df_glosas['Glosa'].str.strip()\n",
    "\n",
    "print(f\"\\nDespu칠s de seleccionar columnas y corregir nombres:\")\n",
    "print(f\"Columnas finales: {list(df_glosas.columns)}\")\n",
    "print(f\"Forma del dataframe: {df_glosas.shape}\")\n",
    "\n",
    "# Paso 5: Mostrar una muestra del dataframe limpio\n",
    "print(f\"\\nPrimeras 5 filas del dataframe limpio:\")\n",
    "print(df_glosas.head())\n",
    "\n",
    "# Paso 6: Verificar que no hay valores nulos en las columnas finales\n",
    "print(f\"\\nVerificaci칩n de valores nulos:\")\n",
    "print(f\"Valores nulos en 'Glosa': {df_glosas['Glosa'].isna().sum()}\")\n",
    "print(f\"Valores nulos en 'Descripci칩n': {df_glosas['Descripci칩n'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_glosas.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## MS depurar periodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la fecha de trabajo a datetime para extraer mes y a침o\n",
    "fecha_trabajo_dt = pd.to_datetime(fecha_trabajo, format='%d/%m/%Y')\n",
    "mes_trabajo = fecha_trabajo_dt.month\n",
    "a침o_trabajo = fecha_trabajo_dt.year\n",
    "\n",
    "# Convertir la columna Fecha_Proceso a datetime\n",
    "df_ms['Fecha_Proceso_dt'] = pd.to_datetime(df_ms['Fecha_Proceso'], format='%d/%m/%Y')\n",
    "\n",
    "# Filtrar el dataframe por mes y a침o\n",
    "df_ms = df_ms[(df_ms['Fecha_Proceso_dt'].dt.month == mes_trabajo) & \n",
    "                       (df_ms['Fecha_Proceso_dt'].dt.year == a침o_trabajo)]\n",
    "\n",
    "print(f\"Registros originales: {len(df_ms)}\")\n",
    "print(f\"Registros filtrados para {mes_trabajo}/{a침o_trabajo}: {len(df_ms)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### MS unicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar duplicados en df_ms bas치ndose en Tipo y N칰mero de Identificaci칩n\n",
    "print(f\"Registros originales en df_ms: {len(df_ms)}\")\n",
    "\n",
    "# Mantener el primer registro para cada combinaci칩n 칰nica de TPS_IDN_ID y HST_IDN_NUMERO_IDENTIFICACION\n",
    "df_ms = df_ms.drop_duplicates(subset=['TPS_IDN_ID', 'HST_IDN_NUMERO_IDENTIFICACION'], keep='first')\n",
    "\n",
    "print(f\"Registros despu칠s de eliminar duplicados: {len(df_ms)}\")\n",
    "print(f\"Registros eliminados: {len(df_ms) - len(df_ms)}\")\n",
    "\n",
    "# Verificar que no hay duplicados\n",
    "duplicados_verificacion = df_ms.duplicated(subset=['TPS_IDN_ID', 'HST_IDN_NUMERO_IDENTIFICACION']).sum()\n",
    "print(f\"Verificaci칩n - Duplicados restantes: {duplicados_verificacion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 1. PREPARACI칍N Y FILTRADO DE VALIDADOS (APROBADOS)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Convertir la fecha de trabajo a datetime para extraer mes y a침o (si no se ha hecho)\n",
    "fecha_trabajo_dt = pd.to_datetime(fecha_trabajo, format='%d/%m/%Y')\n",
    "mes_trabajo = fecha_trabajo_dt.month\n",
    "a침o_trabajo = fecha_trabajo_dt.year\n",
    "\n",
    "# Convertir la columna Fecha_Proceso a datetime en df_ms_val\n",
    "df_ms_val['Fecha_Proceso_dt'] = pd.to_datetime(df_ms_val['Fecha_Proceso'], format='%d/%m/%Y')\n",
    "\n",
    "# Filtrar el dataframe de validados por mes y a침o\n",
    "df_ms_val = df_ms_val[(df_ms_val['Fecha_Proceso_dt'].dt.month == mes_trabajo) & \n",
    "                      (df_ms_val['Fecha_Proceso_dt'].dt.year == a침o_trabajo)]\n",
    "\n",
    "print(f\"Registros Validados (Aprobados) en el periodo: {len(df_ms_val)}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. L칍GICA DE EXCLUSI칍N (LIMPIEZA DE APROBADOS)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Crear llaves 칰nicas (Tipo + N칰mero) para identificar inequ칤vocamente a cada afiliado\n",
    "# Hacemos esto en ambos dataframes para poder compararlos\n",
    "df_ms['Llave_Unica'] = df_ms['TPS_IDN_ID'].astype(str) + '_' + df_ms['HST_IDN_NUMERO_IDENTIFICACION'].astype(str)\n",
    "df_ms_val['Llave_Unica'] = df_ms_val['TPS_IDN_ID'].astype(str) + '_' + df_ms_val['HST_IDN_NUMERO_IDENTIFICACION'].astype(str)\n",
    "\n",
    "# Identificar los IDs que tuvieron al menos una glosa (Errores)\n",
    "ids_con_glosa = set(df_ms['Llave_Unica'])\n",
    "\n",
    "# Filtrar los validados: Excluir los que aparecen en la lista de glosados\n",
    "# Esto nos deja solo los \"Aprobados Limpios\" (que pasaron a la primera sin errores)\n",
    "df_validados_limpios = df_ms_val[~df_ms_val['Llave_Unica'].isin(ids_con_glosa)].copy()\n",
    "\n",
    "print(f\"Validados 'Limpios' (sin glosas previas): {len(df_validados_limpios)}\")\n",
    "print(f\"Registros que fueron validados pero tuvieron glosa (Recuperados): {len(df_ms_val) - len(df_validados_limpios)}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3. ASIGNACI칍N DE USUARIOS Y C츼LCULO DE EFECTIVIDAD\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Necesitamos saber qui칠n ingres칩 los registros exitosos.\n",
    "# Usamos df_expedientes como maestro de usuarios.\n",
    "df_expedientes['Llave_Unica'] = df_expedientes['Tipo Documento'].astype(str) + '_' + df_expedientes['N칰mero Identificaci칩n'].astype(str)\n",
    "\n",
    "# Creamos un diccionario para mapear ID -> Usuario\n",
    "mapa_usuarios = df_expedientes.set_index('Llave_Unica')['Usuario Grabado'].to_dict()\n",
    "\n",
    "# Asignamos el usuario al dataframe de validados limpios\n",
    "df_validados_limpios['Usuario Grabado'] = df_validados_limpios['Llave_Unica'].map(mapa_usuarios)\n",
    "\n",
    "# Nota: df_ms (Glosados) ya deber칤a tener 'Usuario Grabado' por el merge anterior. \n",
    "# Si no, descomenta la siguiente l칤nea:\n",
    "df_ms['Usuario Grabado'] = df_ms['Llave_Unica'].map(mapa_usuarios)\n",
    "\n",
    "# Calcular m칠tricas por usuario\n",
    "# 1. 칄xitos: Cantidad de registros en validados_limpios por usuario\n",
    "exitos_por_usuario = df_validados_limpios['Usuario Grabado'].value_counts()\n",
    "\n",
    "# 2. Errores: Cantidad de registros 칰nicos en df_ms por usuario\n",
    "# Aseguramos contar registros 칰nicos glosados (si un registro tuvo 2 glosas, cuenta como 1 registro con error)\n",
    "errores_por_usuario = df_ms.drop_duplicates(subset=['Llave_Unica'])['Usuario Grabado'].value_counts()\n",
    "\n",
    "# Consolidar en un DataFrame de Efectividad\n",
    "df_efectividad = pd.DataFrame({\n",
    "    'Exitosos_Limpios': exitos_por_usuario,\n",
    "    'Con_Error': errores_por_usuario\n",
    "}).fillna(0)\n",
    "\n",
    "# Calcular totales y porcentaje\n",
    "df_efectividad['Total_Gestionados'] = df_efectividad['Exitosos_Limpios'] + df_efectividad['Con_Error']\n",
    "df_efectividad['Porcentaje_Efectividad'] = (df_efectividad['Exitosos_Limpios'] / df_efectividad['Total_Gestionados']) * 100\n",
    "\n",
    "# Filtrar usuarios con muy pocos registros si es necesario (ej. > 5 registros) para no ensuciar el gr치fico\n",
    "df_efectividad = df_efectividad[df_efectividad['Total_Gestionados'] > 0]\n",
    "\n",
    "# Ordenar por efectividad (de menor a mayor para el gr치fico)\n",
    "df_efectividad = df_efectividad.sort_values('Porcentaje_Efectividad', ascending=True)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4. VISUALIZACI칍N\n",
    "# -----------------------------------------------------------------------------\n",
    "plt.figure(figsize=(15, max(8, len(df_efectividad) * 0.6)))\n",
    "\n",
    "# Crear gr치fico de barras\n",
    "bars = plt.barh(range(len(df_efectividad)), df_efectividad['Porcentaje_Efectividad'], \n",
    "                color=PALETA_EPS[1], alpha=0.8, edgecolor='white', linewidth=1)\n",
    "\n",
    "# Etiquetas Eje Y\n",
    "plt.yticks(range(len(df_efectividad)), df_efectividad.index, fontsize=11)\n",
    "\n",
    "# T칤tulos\n",
    "plt.title(f'Efectividad de Ingreso (Calidad \"A la Primera\")\\n{calendar.month_name[mes_trabajo]} {a침o_trabajo}', \n",
    "          fontsize=16, fontweight='bold', color=PALETA_EPS[1], pad=20)\n",
    "plt.xlabel('Porcentaje de Efectividad (%)', fontsize=12)\n",
    "plt.ylabel('Usuario Grabado', fontsize=12)\n",
    "\n",
    "# Agregar etiquetas de datos en las barras\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    usuario = df_efectividad.index[i]\n",
    "    total = int(df_efectividad.loc[usuario, 'Total_Gestionados'])\n",
    "    errores = int(df_efectividad.loc[usuario, 'Con_Error'])\n",
    "    \n",
    "    # Texto: % Efectividad (X errores de Y total)\n",
    "    label_text = f'{width:.1f}%  ({errores} errores / {total} total)'\n",
    "    \n",
    "    plt.text(max(0, width) + 1, bar.get_y() + bar.get_height()/2, \n",
    "             label_text, ha='left', va='center', fontsize=10, fontweight='bold', color='#444')\n",
    "\n",
    "# L칤neas de referencia\n",
    "plt.axvline(x=100, color='gray', linestyle='--', alpha=0.3)\n",
    "plt.axvline(x=95, color='orange', linestyle=':', alpha=0.5, label='Meta 95%')\n",
    "\n",
    "# Estilo\n",
    "plt.grid(True, axis='x', alpha=0.3)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['left'].set_visible(False)\n",
    "plt.xlim(0, 115) # Espacio para texto\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Guardar\n",
    "carpeta_anexos = os.path.join(R_Salida, \"anexos\")\n",
    "os.makedirs(carpeta_anexos, exist_ok=True)\n",
    "nombre_archivo = f\"Grafico_Efectividad_Calidad_{mes_trabajo}_{a침o_trabajo}.png\"\n",
    "ruta_guardado = os.path.join(carpeta_anexos, nombre_archivo)\n",
    "plt.savefig(ruta_guardado, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "\n",
    "# Resumen en consola\n",
    "print(f\"\\n游늵 RESUMEN DE CALIDAD DE DATOS\")\n",
    "print(\"=\" * 60)\n",
    "print(df_efectividad[['Total_Gestionados', 'Exitosos_Limpios', 'Con_Error', 'Porcentaje_Efectividad']].sort_values('Porcentaje_Efectividad', ascending=False))\n",
    "print# -----------------------------------------------------------------------------\n",
    "# 1. PREPARACI칍N Y FILTRADO DE VALIDADOS (APROBADOS)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Convertir la fecha de trabajo a datetime para extraer mes y a침o (si no se ha hecho)\n",
    "fecha_trabajo_dt = pd.to_datetime(fecha_trabajo, format='%d/%m/%Y')\n",
    "mes_trabajo = fecha_trabajo_dt.month\n",
    "a침o_trabajo = fecha_trabajo_dt.year\n",
    "\n",
    "# Convertir la columna Fecha_Proceso a datetime en df_ms_val\n",
    "df_ms_val['Fecha_Proceso_dt'] = pd.to_datetime(df_ms_val['Fecha_Proceso'], format='%d/%m/%Y')\n",
    "\n",
    "# Filtrar el dataframe de validados por mes y a침o\n",
    "df_ms_val = df_ms_val[(df_ms_val['Fecha_Proceso_dt'].dt.month == mes_trabajo) & \n",
    "                      (df_ms_val['Fecha_Proceso_dt'].dt.year == a침o_trabajo)]\n",
    "\n",
    "print(f\"Registros Validados (Aprobados) en el periodo: {len(df_ms_val)}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. L칍GICA DE EXCLUSI칍N (LIMPIEZA DE APROBADOS)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Crear llaves 칰nicas (Tipo + N칰mero) para identificar inequ칤vocamente a cada afiliado\n",
    "# Hacemos esto en ambos dataframes para poder compararlos\n",
    "df_ms['Llave_Unica'] = df_ms['TPS_IDN_ID'].astype(str) + '_' + df_ms['HST_IDN_NUMERO_IDENTIFICACION'].astype(str)\n",
    "df_ms_val['Llave_Unica'] = df_ms_val['TPS_IDN_ID'].astype(str) + '_' + df_ms_val['HST_IDN_NUMERO_IDENTIFICACION'].astype(str)\n",
    "\n",
    "# Identificar los IDs que tuvieron al menos una glosa (Errores)\n",
    "ids_con_glosa = set(df_ms['Llave_Unica'])\n",
    "\n",
    "# Filtrar los validados: Excluir los que aparecen en la lista de glosados\n",
    "# Esto nos deja solo los \"Aprobados Limpios\" (que pasaron a la primera sin errores)\n",
    "df_validados_limpios = df_ms_val[~df_ms_val['Llave_Unica'].isin(ids_con_glosa)].copy()\n",
    "\n",
    "print(f\"Validados 'Limpios' (sin glosas previas): {len(df_validados_limpios)}\")\n",
    "print(f\"Registros que fueron validados pero tuvieron glosa (Recuperados): {len(df_ms_val) - len(df_validados_limpios)}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3. ASIGNACI칍N DE USUARIOS Y C츼LCULO DE EFECTIVIDAD\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Necesitamos saber qui칠n ingres칩 los registros exitosos.\n",
    "# Usamos df_expedientes como maestro de usuarios.\n",
    "df_expedientes['Llave_Unica'] = df_expedientes['Tipo Documento'].astype(str) + '_' + df_expedientes['N칰mero Identificaci칩n'].astype(str)\n",
    "\n",
    "# Creamos un diccionario para mapear ID -> Usuario\n",
    "mapa_usuarios = df_expedientes.set_index('Llave_Unica')['Usuario Grabado'].to_dict()\n",
    "\n",
    "# Asignamos el usuario al dataframe de validados limpios\n",
    "df_validados_limpios['Usuario Grabado'] = df_validados_limpios['Llave_Unica'].map(mapa_usuarios)\n",
    "\n",
    "# Nota: df_ms (Glosados) ya deber칤a tener 'Usuario Grabado' por el merge anterior. \n",
    "# Si no, descomenta la siguiente l칤nea:\n",
    "# df_ms['Usuario Grabado'] = df_ms['Llave_Unica'].map(mapa_usuarios)\n",
    "\n",
    "# Calcular m칠tricas por usuario\n",
    "# 1. 칄xitos: Cantidad de registros en validados_limpios por usuario\n",
    "exitos_por_usuario = df_validados_limpios['Usuario Grabado'].value_counts()\n",
    "\n",
    "# 2. Errores: Cantidad de registros 칰nicos en df_ms por usuario\n",
    "# Aseguramos contar registros 칰nicos glosados (si un registro tuvo 2 glosas, cuenta como 1 registro con error)\n",
    "errores_por_usuario = df_ms.drop_duplicates(subset=['Llave_Unica'])['Usuario Grabado'].value_counts()\n",
    "\n",
    "# Consolidar en un DataFrame de Efectividad\n",
    "df_efectividad = pd.DataFrame({\n",
    "    'Exitosos_Limpios': exitos_por_usuario,\n",
    "    'Con_Error': errores_por_usuario\n",
    "}).fillna(0)\n",
    "\n",
    "# Calcular totales y porcentaje\n",
    "df_efectividad['Total_Gestionados'] = df_efectividad['Exitosos_Limpios'] + df_efectividad['Con_Error']\n",
    "df_efectividad['Porcentaje_Efectividad'] = (df_efectividad['Exitosos_Limpios'] / df_efectividad['Total_Gestionados']) * 100\n",
    "\n",
    "# Filtrar usuarios con muy pocos registros si es necesario (ej. > 5 registros) para no ensuciar el gr치fico\n",
    "df_efectividad = df_efectividad[df_efectividad['Total_Gestionados'] > 0]\n",
    "\n",
    "# Ordenar por efectividad (de menor a mayor para el gr치fico)\n",
    "df_efectividad = df_efectividad.sort_values('Porcentaje_Efectividad', ascending=True)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4. VISUALIZACI칍N\n",
    "# -----------------------------------------------------------------------------\n",
    "plt.figure(figsize=(15, max(8, len(df_efectividad) * 0.6)))\n",
    "\n",
    "# Crear gr치fico de barras\n",
    "bars = plt.barh(range(len(df_efectividad)), df_efectividad['Porcentaje_Efectividad'], \n",
    "                color=PALETA_EPS[1], alpha=0.8, edgecolor='white', linewidth=1)\n",
    "\n",
    "# Etiquetas Eje Y\n",
    "plt.yticks(range(len(df_efectividad)), df_efectividad.index, fontsize=11)\n",
    "\n",
    "# T칤tulos\n",
    "plt.title(f'Efectividad de Ingreso (Calidad \"A la Primera\")\\n{calendar.month_name[mes_trabajo]} {a침o_trabajo}', \n",
    "          fontsize=16, fontweight='bold', color=PALETA_EPS[1], pad=20)\n",
    "plt.xlabel('Porcentaje de Efectividad (%)', fontsize=12)\n",
    "plt.ylabel('Usuario Grabado', fontsize=12)\n",
    "\n",
    "# Agregar etiquetas de datos en las barras\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    usuario = df_efectividad.index[i]\n",
    "    total = int(df_efectividad.loc[usuario, 'Total_Gestionados'])\n",
    "    errores = int(df_efectividad.loc[usuario, 'Con_Error'])\n",
    "    \n",
    "    # Texto: % Efectividad (X errores de Y total)\n",
    "    label_text = f'{width:.1f}%  ({errores} errores / {total} total)'\n",
    "    \n",
    "    plt.text(max(0, width) + 1, bar.get_y() + bar.get_height()/2, \n",
    "             label_text, ha='left', va='center', fontsize=10, fontweight='bold', color='#444')\n",
    "\n",
    "# L칤neas de referencia\n",
    "plt.axvline(x=100, color='gray', linestyle='--', alpha=0.3)\n",
    "plt.axvline(x=95, color='orange', linestyle=':', alpha=0.5, label='Meta 95%')\n",
    "\n",
    "# Estilo\n",
    "plt.grid(True, axis='x', alpha=0.3)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['left'].set_visible(False)\n",
    "plt.xlim(0, 115) # Espacio para texto\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Guardar\n",
    "carpeta_anexos = os.path.join(R_Salida, \"anexos\")\n",
    "os.makedirs(carpeta_anexos, exist_ok=True)\n",
    "nombre_archivo = f\"Grafico_Efectividad_Calidad_{mes_trabajo}_{a침o_trabajo}.png\"\n",
    "ruta_guardado = os.path.join(carpeta_anexos, nombre_archivo)\n",
    "plt.savefig(ruta_guardado, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "\n",
    "# Resumen en consola\n",
    "print(f\"\\n游늵 RESUMEN DE CALIDAD DE DATOS\")\n",
    "print(\"=\" * 60)\n",
    "print(df_efectividad[['Total_Gestionados', 'Exitosos_Limpios', 'Con_Error', 'Porcentaje_Efectividad']].sort_values('Porcentaje_Efectividad', ascending=False))\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Crear funci칩n para extraer el n칰mero de glosas\n",
    "def contar_glosas(glosa_text):\n",
    "    if pd.isna(glosa_text):\n",
    "        return 0\n",
    "    return glosa_text.count('GN')\n",
    "\n",
    "# Crear funci칩n para extraer la glosa principal (primera glosa)\n",
    "def extraer_glosa_principal(glosa_text):\n",
    "    if pd.isna(glosa_text):\n",
    "        return None\n",
    "    # Buscar el primer patr칩n GN seguido de 4 d칤gitos\n",
    "    match = re.search(r'GN\\d{4}', glosa_text)\n",
    "    return match.group() if match else None\n",
    "\n",
    "# Aplicar las funciones al dataframe df_ms\n",
    "df_ms['No_Glosas_Calculado'] = df_ms['GLOSA'].apply(contar_glosas)\n",
    "df_ms['Glosa_Principal'] = df_ms['GLOSA'].apply(extraer_glosa_principal).str.strip()\n",
    "\n",
    "# Mostrar algunas filas para verificar\n",
    "print(\"Verificaci칩n de las nuevas columnas:\")\n",
    "print(df_ms[['GLOSA', 'No_Glosas', 'No_Glosas_Calculado', 'Glosa_Principal']].head(10))\n",
    "\n",
    "# Comparar el conteo calculado con el existente\n",
    "print(f\"\\n쮺oinciden los conteos? {(df_ms['No_Glosas'].astype(int) == df_ms['No_Glosas_Calculado']).all()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer merge para agregar el nombre del municipio\n",
    "df_ms = df_ms.merge(\n",
    "    df_Municipios[['CODIGO', 'Nombre Municipio']], \n",
    "    left_on='MNC_ID', \n",
    "    right_on='CODIGO', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Eliminar la columna CODIGO duplicada si no la necesitas\n",
    "df_ms = df_ms.drop('CODIGO', axis=1)\n",
    "\n",
    "print(f\"Columnas despu칠s del merge: {list(df_ms.columns)}\")\n",
    "print(f\"Nuevas columnas agregadas: Nombre Municipio\")\n",
    "print(f\"Registros con municipio encontrado: {df_ms['Nombre Municipio'].notna().sum()}\")\n",
    "print(f\"Registros sin municipio: {df_ms['Nombre Municipio'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer merge para agregar el nombre del municipio\n",
    "df_ms_val = df_ms_val.merge(\n",
    "    df_Municipios[['CODIGO', 'Nombre Municipio']], \n",
    "    left_on='MNC_ID', \n",
    "    right_on='CODIGO', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Eliminar la columna CODIGO duplicada si no la necesitas\n",
    "df_ms_val = df_ms_val.drop('CODIGO', axis=1)\n",
    "\n",
    "print(f\"Columnas despu칠s del merge: {list(df_ms_val.columns)}\")\n",
    "print(f\"Nuevas columnas agregadas: Nombre Municipio\")\n",
    "print(f\"Registros con municipio encontrado: {df_ms_val['Nombre Municipio'].notna().sum()}\")\n",
    "print(f\"Registros sin municipio: {df_ms_val['Nombre Municipio'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_ms.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer merge entre df_ms_val y df_expedientes para traer la columna 'Usuario Grabado'\n",
    "df_ms_val = df_ms_val.merge(\n",
    "    df_expedientes[['Tipo Documento', 'N칰mero Identificaci칩n', 'Usuario Grabado']], \n",
    "    left_on=['TPS_IDN_ID', 'HST_IDN_NUMERO_IDENTIFICACION'], \n",
    "    right_on=['Tipo Documento', 'N칰mero Identificaci칩n'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Eliminar las columnas duplicadas del merge\n",
    "df_ms_val = df_ms_val.drop(['Tipo Documento', 'N칰mero Identificaci칩n'], axis=1)\n",
    "\n",
    "print(f\"Columnas despu칠s del merge: {list(df_ms_val.columns)}\")\n",
    "print(f\"Nueva columna agregada: Usuario Grabado\")\n",
    "print(f\"Registros con Usuario Grabado encontrado: {df_ms_val['Usuario Grabado'].notna().sum()}\")\n",
    "print(f\"Registros sin Usuario Grabado: {df_ms_val['Usuario Grabado'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer merge para agregar la descripci칩n de las glosas\n",
    "df_ms = df_ms.merge(\n",
    "    df_glosa_eh[['Codigo', 'Descripcion']], \n",
    "    left_on='Glosa_Principal', \n",
    "    right_on='Codigo', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Renombrar la columna Descripcion a Descripcion_Glosa\n",
    "df_ms = df_ms.rename(columns={'Descripcion': 'Descripcion_Glosa'})\n",
    "\n",
    "# Eliminar la columna Codigo duplicada del merge\n",
    "df_ms = df_ms.drop('Codigo', axis=1)\n",
    "\n",
    "print(f\"Columnas despu칠s del merge: {list(df_ms.columns)}\")\n",
    "print(f\"Nueva columna agregada: Descripcion_Glosa\")\n",
    "print(f\"Registros con descripci칩n encontrada: {df_ms['Descripcion_Glosa'].notna().sum()}\")\n",
    "print(f\"Registros sin descripci칩n: {df_ms['Descripcion_Glosa'].isna().sum()}\")\n",
    "\n",
    "# Verificar algunas filas para confirmar el resultado\n",
    "print(\"\\nVerificaci칩n de las primeras 5 filas:\")\n",
    "print(df_ms[['Glosa_Principal', 'Descripcion_Glosa']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## S3 depurar periodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la fecha de trabajo a datetime para extraer mes y a침o\n",
    "fecha_trabajo_dt = pd.to_datetime(fecha_trabajo, format='%d/%m/%Y')\n",
    "mes_trabajo = fecha_trabajo_dt.month\n",
    "a침o_trabajo = fecha_trabajo_dt.year\n",
    "\n",
    "# Convertir la columna Fecha_Proceso a datetime\n",
    "df_s3['Fecha_Proceso_dt'] = pd.to_datetime(df_s3['Fecha_Proceso'], format='%d/%m/%Y')\n",
    "\n",
    "# Filtrar el dataframe por mes y a침o\n",
    "df_s3 = df_s3[(df_s3['Fecha_Proceso_dt'].dt.month == mes_trabajo) & \n",
    "                       (df_s3['Fecha_Proceso_dt'].dt.year == a침o_trabajo)]\n",
    "\n",
    "print(f\"Registros originales: {len(df_s3)}\")\n",
    "print(f\"Registros filtrados para {mes_trabajo}/{a침o_trabajo}: {len(df_s3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### S3 Unicos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar duplicados en df_s3 bas치ndose en Tipo y N칰mero de Identificaci칩n\n",
    "print(f\"Registros originales en df_s3: {len(df_s3)}\")\n",
    "\n",
    "# Mantener el primer registro para cada combinaci칩n 칰nica de TPS_IDN_ID y HST_IDN_NUMERO_IDENTIFICACION\n",
    "df_s3 = df_s3.drop_duplicates(subset=['TPS_IDN_ID', 'HST_IDN_NUMERO_IDENTIFICACION'], keep='first')\n",
    "\n",
    "print(f\"Registros despu칠s de eliminar duplicados: {len(df_s3)}\")\n",
    "\n",
    "# Verificar que no hay duplicados\n",
    "duplicados_verificacion = df_s3.duplicated(subset=['TPS_IDN_ID', 'HST_IDN_NUMERO_IDENTIFICACION']).sum()\n",
    "print(f\"Verificaci칩n - Duplicados restantes: {duplicados_verificacion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar df_s3 para mantener solo registros con TIPO_TRASLADO igual a 0, 1 o 2\n",
    "df_s3 = df_s3[df_s3['TIPO_TRASLADO'].isin(['0', '1', '2'])]\n",
    "\n",
    "print(f\"Registros despu칠s del filtro por TIPO_TRASLADO (0, 1, 2): {len(df_s3)}\")\n",
    "print(f\"Valores 칰nicos en TIPO_TRASLADO: {df_s3['TIPO_TRASLADO'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar las funciones para extraer glosas al dataframe df_s3\n",
    "df_s3['No_Glosas_Calculado'] = df_s3['GLOSA'].apply(contar_glosas)\n",
    "df_s3['Glosa_Principal'] = df_s3['GLOSA'].apply(extraer_glosa_principal).str.strip()\n",
    "\n",
    "# Hacer merge para agregar el nombre del municipio\n",
    "df_s3 = df_s3.merge(\n",
    "    df_Municipios[['CODIGO', 'Nombre Municipio']], \n",
    "    left_on='MNC_ID', \n",
    "    right_on='CODIGO', \n",
    "    how='left'\n",
    ").drop('CODIGO', axis=1)\n",
    "\n",
    "# Hacer merge para traer la columna 'Usuario Grabado'\n",
    "df_s3 = df_s3.merge(\n",
    "    df_expedientes[['Tipo Documento', 'N칰mero Identificaci칩n', 'Usuario Grabado']], \n",
    "    left_on=['TPS_IDN_ID', 'HST_IDN_NUMERO_IDENTIFICACION'], \n",
    "    right_on=['Tipo Documento', 'N칰mero Identificaci칩n'], \n",
    "    how='left'\n",
    ").drop(['Tipo Documento', 'N칰mero Identificaci칩n'], axis=1)\n",
    "\n",
    "# Hacer merge para agregar la descripci칩n de las glosas\n",
    "df_s3 = df_s3.merge(\n",
    "    df_glosa_eh[['Codigo', 'Descripcion']], \n",
    "    left_on='Glosa_Principal', \n",
    "    right_on='Codigo', \n",
    "    how='left'\n",
    ").rename(columns={'Descripcion': 'Descripcion_Glosa'}).drop('Codigo', axis=1)\n",
    "\n",
    "print(\"--- Procesamiento de df_s3 completado ---\")\n",
    "print(f\"Columnas finales: {list(df_s3.columns)}\")\n",
    "print(f\"Registros con municipio: {df_s3['Nombre Municipio'].notna().sum()}\")\n",
    "print(f\"Registros con Usuario Grabado: {df_s3['Usuario Grabado'].notna().sum()}\")\n",
    "print(f\"Registros con descripci칩n de glosa: {df_s3['Descripcion_Glosa'].notna().sum()}\")\n",
    "print(\"\\nVerificaci칩n de las primeras 5 filas:\")\n",
    "print(df_s3[['Glosa_Principal', 'Nombre Municipio', 'Usuario Grabado', 'Descripcion_Glosa']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "# Informe MS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "## dashboard MS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definici칩n de la paleta institucional (Rojo y Verde)\n",
    "PALETA_EPS = ['#C23034', '#289452', '#D35457', '#42A862']\n",
    "\n",
    "\n",
    "def crear_dashboard_ms_mejorado(df_ms, mes_trabajo, a침o_trabajo, PALETA_EPS, R_Salida):\n",
    "    \n",
    "    # --- NO SE NECESITA C칍DIGO DE MAPEO ---\n",
    "    # La columna 'Nombre Municipio' ya est치 en df_ms\n",
    "    # -------------------------------------\n",
    "\n",
    "    # Obtener nombre del mes en espa침ol\n",
    "    meses_esp = {\n",
    "        1: 'Enero', 2: 'Febrero', 3: 'Marzo', 4: 'Abril',\n",
    "        5: 'Mayo', 6: 'Junio', 7: 'Julio', 8: 'Agosto',\n",
    "        9: 'Septiembre', 10: 'Octubre', 11: 'Noviembre', 12: 'Diciembre'\n",
    "    }\n",
    "    mes_nombre = meses_esp[mes_trabajo]\n",
    "    \n",
    "    # Crear carpeta anexos si no existe\n",
    "    carpeta_anexos = os.path.join(R_Salida, \"anexos\")\n",
    "    os.makedirs(carpeta_anexos, exist_ok=True)\n",
    "    \n",
    "    # --- Configuraci칩n General de Matplotlib ---\n",
    "    plt.style.use('seaborn-v0_8-whitegrid') # Estilo base m치s moderno\n",
    "    \n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'sans-serif',\n",
    "        'font.sans-serif': ['Arial', 'Helvetica', 'Lato'],\n",
    "        'text.color': '#444444',\n",
    "        'axes.labelcolor': '#444444',\n",
    "        'xtick.color': '#444444',\n",
    "        'ytick.color': '#444444',\n",
    "        'axes.edgecolor': 'white',\n",
    "        'axes.facecolor': 'white',\n",
    "        'figure.facecolor': 'white',\n",
    "        'grid.color': '#EAEAEA',\n",
    "        'grid.linewidth': 0.8,\n",
    "        'axes.titlesize': 16,\n",
    "        'axes.titleweight': 'bold',\n",
    "        'figure.titlesize': 26,\n",
    "        'figure.titleweight': 'bold',\n",
    "        'lines.linewidth': 2.5,\n",
    "        'lines.markerfacecolor': PALETA_EPS[0],\n",
    "        'lines.markeredgecolor': 'white',\n",
    "        'lines.markeredgewidth': 1.5,\n",
    "    })\n",
    "\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 14))\n",
    "    \n",
    "    fig.suptitle(f'Dashboard de Glosas MS - {mes_nombre} {a침o_trabajo}\\nSistema de Monitoreo CAPRESOCA EPS', \n",
    "                 fontsize=24, fontweight='bold', color=PALETA_EPS[0], y=1.0) \n",
    "\n",
    "    # --- 1. Gr치fica de registros por fecha con 치rea sombreada ---\n",
    "    registros_por_fecha = df_ms.groupby('Fecha_Proceso_dt').size()\n",
    "    \n",
    "    ax1.plot(registros_por_fecha.index, registros_por_fecha.values, \n",
    "             color=PALETA_EPS[0], linewidth=2.5, marker='o', markersize=8, markeredgecolor='white')\n",
    "    ax1.fill_between(registros_por_fecha.index, registros_por_fecha.values, \n",
    "                     alpha=0.15, color=PALETA_EPS[0])\n",
    "    \n",
    "    ax1.set_title('Registros por Fecha de Proceso', fontsize=16, fontweight='bold', pad=20, color=PALETA_EPS[0])\n",
    "    ax1.grid(True, which='major', axis='y', linestyle='--', linewidth=0.7)\n",
    "    ax1.grid(False, which='major', axis='x')\n",
    "    ax1.tick_params(axis='x', rotation=45, labelsize=10)\n",
    "    ax1.tick_params(axis='y', labelsize=10)\n",
    "    ax1.set_ylabel('N칰mero de Registros', fontsize=12)\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    ax1.spines['right'].set_visible(False)\n",
    "    ax1.spines['left'].set_visible(False)\n",
    "    ax1.spines['bottom'].set_color('#DDDDDD')\n",
    "\n",
    "    for i, val in enumerate(registros_por_fecha.values):\n",
    "        ax1.annotate(f'{val}', (registros_por_fecha.index[i], val), \n",
    "                     textcoords=\"offset points\", xytext=(0,12), ha='center',\n",
    "                     fontsize=10, fontweight='bold', color=PALETA_EPS[2])\n",
    "    \n",
    "    ax1.xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%d-%b')) \n",
    "\n",
    "    # --- 2. Top Glosas Principales ---\n",
    "    top_glosas = df_ms['Glosa_Principal'].value_counts().nlargest(10).sort_values(ascending=True)\n",
    "    \n",
    "    n_colors = len(top_glosas)\n",
    "    colors = [plt.cm.get_cmap('Reds')(x) for x in np.linspace(0.45, 0.85, n_colors)]\n",
    "    \n",
    "    bars = ax2.barh(range(len(top_glosas)), top_glosas.values, color=colors, \n",
    "                    edgecolor='white', linewidth=0.5, height=0.8)\n",
    "    ax2.set_yticks(range(len(top_glosas)))\n",
    "    ax2.set_yticklabels(top_glosas.index, fontsize=11)\n",
    "    ax2.set_title('Top 10 Glosas Principales', fontsize=16, fontweight='bold', pad=20, color=PALETA_EPS[0])\n",
    "    ax2.grid(False)\n",
    "    ax2.tick_params(axis='x', labelsize=10)\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    ax2.spines['right'].set_visible(False)\n",
    "    ax2.spines['left'].set_visible(False)\n",
    "    ax2.spines['bottom'].set_color('#DDDDDD')\n",
    "    ax2.set_xlim(0, max(top_glosas.values) * 1.20)\n",
    "\n",
    "    for i, bar in enumerate(bars):\n",
    "        width = bar.get_width()\n",
    "        ax2.text(width + (max(top_glosas.values) * 0.02), bar.get_y() + bar.get_height()/2, \n",
    "                 f'{int(width)}', ha='left', va='center', fontsize=10, fontweight='bold', color='#555555')\n",
    "    \n",
    "    # --- 3. Top municipios ---\n",
    "    top_municipios = df_ms['Nombre Municipio'].value_counts().head(10)\n",
    "    \n",
    "    bars3 = ax3.bar(top_municipios.index, top_municipios.values, \n",
    "                    color=PALETA_EPS[0], alpha=0.85, edgecolor='white', linewidth=1)\n",
    "    \n",
    "    ax3.set_xticklabels(top_municipios.index, rotation=45, ha='right', fontsize=11)\n",
    "    \n",
    "    ax3.set_title('Top 10 Municipios con m치s Glosas', fontsize=16, fontweight='bold', pad=20, color=PALETA_EPS[0])\n",
    "    ax3.grid(True, which='major', axis='y', linestyle='--', linewidth=0.7)\n",
    "    ax3.grid(False, which='major', axis='x')\n",
    "    ax3.tick_params(axis='y', labelsize=10)\n",
    "    ax3.set_ylim(0, max(top_municipios.values) * 1.20)\n",
    "    ax3.spines['top'].set_visible(False)\n",
    "    ax3.spines['right'].set_visible(False)\n",
    "    ax3.spines['left'].set_visible(False)\n",
    "    ax3.spines['bottom'].set_color('#DDDDDD')\n",
    "\n",
    "    for bar in bars3:\n",
    "        height = bar.get_height()\n",
    "        ax3.annotate(f'{int(height)}',\n",
    "                     xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                     xytext=(0, 3),  # 3 points vertical offset\n",
    "                     textcoords=\"offset points\",\n",
    "                     ha='center', va='bottom', fontsize=10, fontweight='bold', color=PALETA_EPS[2])\n",
    "    \n",
    "    # --- 4. Tabla resumen con m칠tricas ---\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    total_registros = len(df_ms)\n",
    "    fechas_unicas = df_ms['Fecha_Proceso_dt'].nunique()\n",
    "    glosas_unicas = df_ms['Glosa_Principal'].nunique()\n",
    "    municipios_unicos = df_ms['Nombre Municipio'].nunique() \n",
    "    fecha_min = df_ms['Fecha_Proceso_dt'].min().strftime('%d/%m/%Y')\n",
    "    fecha_max = df_ms['Fecha_Proceso_dt'].max().strftime('%d/%m/%Y')\n",
    "    promedio_diario = total_registros / fechas_unicas if fechas_unicas > 0 else 0\n",
    "    municipio_principal_nombre = top_municipios.index[0]\n",
    "    \n",
    "    tabla_data = [\n",
    "        ['Total Registros', f'{total_registros:,}'],\n",
    "        ['Fechas de Proceso', f'{fechas_unicas}'],\n",
    "        ['Glosas 칔nicas', f'{glosas_unicas}'],\n",
    "        ['Municipios (칰nicos)', f'{municipios_unicos}'],\n",
    "        ['Glosa Principal', f'{top_glosas.index[-1]}'],\n",
    "        ['Municipio Principal', f'{municipio_principal_nombre}']\n",
    "    ]\n",
    "    \n",
    "    table = ax4.table(cellText=tabla_data,\n",
    "                      colLabels=['M칠trica', 'Valor'],\n",
    "                      cellLoc='left',\n",
    "                      loc='center',\n",
    "                      colWidths=[0.55, 0.35])\n",
    "    \n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1, 2.5)\n",
    "    \n",
    "    for (row, col), cell in table.get_celld().items():\n",
    "        cell.set_edgecolor('none')\n",
    "        if row == 0:\n",
    "            cell.set_text_props(weight='bold', color='white')\n",
    "            cell.set_facecolor(PALETA_EPS[0])\n",
    "            cell.set_height(0.15)\n",
    "        else:\n",
    "            cell.set_facecolor('#F9F9F9' if row % 2 == 0 else 'white')\n",
    "            cell.set_height(0.12)\n",
    "            if col == 0:\n",
    "                cell.get_text().set_weight('bold')\n",
    "                cell.get_text().set_color('#555555')\n",
    "            else:\n",
    "                cell.get_text().set_color('#222222')\n",
    "\n",
    "    ax4.set_title('Resumen General del Per칤odo', fontsize=16, fontweight='bold', pad=20, color=PALETA_EPS[0])\n",
    "    \n",
    "    # --- Ajustar layout y guardar ---\n",
    "    plt.tight_layout(pad=3.0)\n",
    "    plt.subplots_adjust(top=0.88, hspace=0.45, wspace=0.3)\n",
    "    \n",
    "    \n",
    "    nombre_archivo_png = f\"Dashboard_Glosas_MS_{mes_nombre}_{a침o_trabajo}.png\"\n",
    "    ruta_png = os.path.join(carpeta_anexos, nombre_archivo_png)\n",
    "    \n",
    "    plt.savefig(ruta_png, dpi=300, bbox_inches='tight', facecolor='white', format='png')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    print(f\"游 Dashboard guardado como PNG en: {ruta_png}\")\n",
    "    print(f\"游늵 RESUMEN DASHBOARD GLOSAS {mes_nombre.upper()} {a침o_trabajo}\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"游늰 Per칤odo analizado: {fecha_min} - {fecha_max}\")\n",
    "    print(f\"游늶 Total registros procesados: {total_registros:,}\")\n",
    "    print(f\"游낀 Glosa m치s frecuente: {top_glosas.index[-1]} ({top_glosas.iloc[-1]:,} casos - {(top_glosas.iloc[-1]/total_registros*100):.1f}%)\")\n",
    "    print(f\"游끶勇 Municipio con m치s casos: {municipio_principal_nombre} ({top_municipios.iloc[0]:,} registros - {(top_municipios.iloc[0]/total_registros*100):.1f}%)\")\n",
    "    print(f\"游늳 Promedio registros por d칤a: {promedio_diario:.1f}\")\n",
    "    print(f\"游늵 Concentraci칩n top 5 glosas: {(top_glosas.tail(5).sum()/total_registros*100):.1f}%\")\n",
    "    print(f\"游꿢 Archivo guardado: {nombre_archivo_png}\")\n",
    "    \n",
    "    return fig, ruta_png\n",
    "\n",
    "\n",
    "# Ejecutar la funci칩n\n",
    "fig_dashboard, ruta_archivo_png_1 = crear_dashboard_ms_mejorado(\n",
    "    df_ms, \n",
    "    mes_trabajo, \n",
    "    a침o_trabajo, \n",
    "    PALETA_EPS, \n",
    "    R_Salida\n",
    ")\n",
    "\n",
    "print(f\"\\n춰El dashboard est치 listo! La ruta para insertar en Word es:\\n{ruta_archivo_png_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "## RESUMEN POR USUARIO MS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear visualizaci칩n de registros por Usuario Grabado\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Contar registros por usuario y ordenar de mayor a menor\n",
    "usuarios_count = df_ms['Usuario Grabado'].value_counts()\n",
    "\n",
    "# Crear gr치fico de barras horizontal\n",
    "bars = plt.barh(range(len(usuarios_count)), usuarios_count.values, \n",
    "                color=PALETA_EPS[0], alpha=0.8, edgecolor='white', linewidth=1)\n",
    "\n",
    "# Configurar etiquetas del eje Y\n",
    "plt.yticks(range(len(usuarios_count)), usuarios_count.index, fontsize=11)\n",
    "\n",
    "# Configurar t칤tulos y etiquetas\n",
    "plt.title('Registros de Glosas MS por Usuario Grabado\\nOctubre 2025', \n",
    "          fontsize=16, fontweight='bold', color=PALETA_EPS[0], pad=20)\n",
    "plt.xlabel('N칰mero de Registros', fontsize=12)\n",
    "plt.ylabel('Usuario Grabado', fontsize=12)\n",
    "\n",
    "# Agregar valores en las barras\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    plt.text(width + (max(usuarios_count.values) * 0.01), bar.get_y() + bar.get_height()/2, \n",
    "             f'{int(width)}', ha='left', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Configurar grid y estilo\n",
    "plt.grid(True, axis='x', alpha=0.3)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['left'].set_visible(False)\n",
    "\n",
    "# Ajustar l칤mites del eje X\n",
    "plt.xlim(0, max(usuarios_count.values) * 1.15)\n",
    "\n",
    "# Ajustar layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Guardar la imagen en la carpeta anexos\n",
    "carpeta_anexos = os.path.join(R_Salida, \"anexos\")\n",
    "os.makedirs(carpeta_anexos, exist_ok=True)\n",
    "\n",
    "#Guardar imagen\n",
    "nombre_archivo_usuarios = f\"Grafico_Usuarios_MS_{mes_trabajo}_{a침o_trabajo}.png\"\n",
    "ruta_archivo_png_2 = os.path.join(carpeta_anexos, nombre_archivo_usuarios)\n",
    "plt.savefig(ruta_archivo_png_2, dpi=300, bbox_inches='tight', \n",
    "           facecolor='white', format='png')\n",
    "\n",
    "\n",
    "# Mostrar estad칤sticas resumidas\n",
    "total_registros = len(df_ms)\n",
    "total_usuarios = len(usuarios_count)\n",
    "promedio_por_usuario = total_registros / total_usuarios\n",
    "\n",
    "print(f\"游늵 RESUMEN POR USUARIO GRABADO\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"游논 Total de usuarios: {total_usuarios}\")\n",
    "print(f\"游늶 Total de registros: {total_registros}\")\n",
    "print(f\"游늳 Promedio por usuario: {promedio_por_usuario:.1f}\")\n",
    "print(f\"游볞 Usuario con m치s registros: {usuarios_count.index[0]} ({usuarios_count.iloc[0]} registros)\")\n",
    "print(f\"游늵 Top 3 usuarios concentran: {(usuarios_count.head(3).sum()/total_registros*100):.1f}% del total\")\n",
    "print(f\"游 Imagen guardada en: {ruta_archivo_png_2}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "### Efectivida por usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# C츼LCULO DE EFECTIVIDAD POR PROMOTOR\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# 1. Crear llaves 칰nicas para identificar registros (Tipo + Numero)\n",
    "# Esto nos asegura que estamos contando personas 칰nicas y no intentos repetidos\n",
    "df_ms['Llave'] = df_ms['TPS_IDN_ID'].astype(str) + df_ms['HST_IDN_NUMERO_IDENTIFICACION'].astype(str)\n",
    "df_ms_val['Llave'] = df_ms_val['TPS_IDN_ID'].astype(str) + df_ms_val['HST_IDN_NUMERO_IDENTIFICACION'].astype(str)\n",
    "\n",
    "# 2. Obtener el universo total de registros 칰nicos gestionados por usuario\n",
    "# Concatenamos las llaves y usuarios de ambos dataframes (Glosados + Validados)\n",
    "cols_clave = ['Usuario Grabado', 'Llave']\n",
    "df_total_gestion = pd.concat([df_ms[cols_clave], df_ms_val[cols_clave]], ignore_index=True)\n",
    "\n",
    "# Eliminamos duplicados para tener 1 registro 칰nico por afiliado gestionado\n",
    "df_total_gestion = df_total_gestion.drop_duplicates(subset=['Llave'])\n",
    "\n",
    "# 3. Calcular m칠tricas\n",
    "# A. Total de registros 칰nicos que toc칩 cada usuario (El universo de su trabajo)\n",
    "total_por_usuario = df_total_gestion['Usuario Grabado'].value_counts()\n",
    "\n",
    "# B. Total de registros que tuvieron error (Tu variable original usuarios_count)\n",
    "# Como df_ms ya lo hab칤as limpiado de duplicados antes, esto cuenta cu치ntos registros le quedaron mal\n",
    "usuarios_count = df_ms['Usuario Grabado'].value_counts()\n",
    "\n",
    "# C. Crear DataFrame consolidado cruzando ambas informaciones\n",
    "df_efectividad = pd.DataFrame({\n",
    "    'Total_Gestionados': total_por_usuario,\n",
    "    'Con_Error': usuarios_count  # <--- Aqu칤 est치 tu variable usuarios_count\n",
    "}).fillna(0) # Rellenar con 0 si alguien no tuvo errores (춰Felicidades a ese usuario!)\n",
    "\n",
    "# D. Calcular porcentaje de efectividad\n",
    "# F칩rmula: (Total - Errores) / Total * 100\n",
    "df_efectividad['Efectividad_Pct'] = ((df_efectividad['Total_Gestionados'] - df_efectividad['Con_Error']) / df_efectividad['Total_Gestionados']) * 100\n",
    "\n",
    "# Ordenar de menor a mayor efectividad para el gr치fico\n",
    "df_efectividad = df_efectividad.sort_values('Efectividad_Pct', ascending=True)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# VISUALIZACI칍N\n",
    "# -----------------------------------------------------------------------------\n",
    "plt.figure(figsize=(15, max(8, len(df_efectividad) * 0.6)))\n",
    "\n",
    "# Crear gr치fico de barras horizontal\n",
    "# Usamos PALETA_EPS[1] (Verde) porque estamos graficando Efectividad (algo positivo)\n",
    "bars = plt.barh(range(len(df_efectividad)), df_efectividad['Efectividad_Pct'], \n",
    "                color=PALETA_EPS[1], alpha=0.8, edgecolor='white', linewidth=1)\n",
    "\n",
    "# Configurar etiquetas del eje Y\n",
    "plt.yticks(range(len(df_efectividad)), df_efectividad.index, fontsize=11)\n",
    "\n",
    "# Configurar t칤tulos y etiquetas\n",
    "plt.title(f'Efectividad de Ingreso de Datos por Promotor\\n(Registros sin Glosa / Total Gestionados) - {mes_trabajo}/{a침o_trabajo}', \n",
    "          fontsize=16, fontweight='bold', color=PALETA_EPS[1], pad=20)\n",
    "plt.xlabel('Porcentaje de Efectividad (%)', fontsize=12)\n",
    "plt.ylabel('Promotor / Usuario', fontsize=12)\n",
    "\n",
    "# Agregar valores en las barras\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    usuario = df_efectividad.index[i]\n",
    "    \n",
    "    # Recuperamos los datos del dataframe para la etiqueta\n",
    "    total = int(df_efectividad.loc[usuario, 'Total_Gestionados'])\n",
    "    errores = int(df_efectividad.loc[usuario, 'Con_Error']) # Esto es el valor de usuarios_count para este usuario\n",
    "    aciertos = total - errores\n",
    "    \n",
    "    # Texto: Porcentaje + detalle (Aciertos/Total)\n",
    "    texto_etiqueta = f'{width:.1f}% ({aciertos}/{total})'\n",
    "    \n",
    "    plt.text(width + 1, bar.get_y() + bar.get_height()/2, \n",
    "             texto_etiqueta, ha='left', va='center', fontsize=10, fontweight='bold', color='#444')\n",
    "\n",
    "# L칤nea de meta (opcional, ej: 95%)\n",
    "plt.axvline(x=95, color='orange', linestyle='--', alpha=0.5, label='Meta 95%')\n",
    "\n",
    "# Configurar grid y estilo\n",
    "plt.grid(True, axis='x', alpha=0.3)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['left'].set_visible(False)\n",
    "\n",
    "# Ajustar l칤mites del eje X (hasta 115 para dar espacio al texto)\n",
    "plt.xlim(0, 115)\n",
    "\n",
    "# Ajustar layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Guardar la imagen en la carpeta anexos\n",
    "carpeta_anexos = os.path.join(R_Salida, \"anexos\")\n",
    "os.makedirs(carpeta_anexos, exist_ok=True)\n",
    "\n",
    "# Guardar imagen\n",
    "nombre_archivo_efectividad = f\"Grafico_Efectividad_Promotores_{mes_trabajo}_{a침o_trabajo}.png\"\n",
    "ruta_archivo_png_efectividad = os.path.join(carpeta_anexos, nombre_archivo_efectividad)\n",
    "plt.savefig(ruta_archivo_png_efectividad, dpi=300, bbox_inches='tight', \n",
    "           facecolor='white', format='png')\n",
    "\n",
    "# Mostrar estad칤sticas resumidas\n",
    "promedio_efectividad = df_efectividad['Efectividad_Pct'].mean()\n",
    "mejor_usuario = df_efectividad.index[-1]\n",
    "mejor_valor = df_efectividad['Efectividad_Pct'].iloc[-1]\n",
    "\n",
    "print(f\"游늵 RESUMEN DE EFECTIVIDAD POR PROMOTOR\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"游논 Total de promotores evaluados: {len(df_efectividad)}\")\n",
    "print(f\"游늳 Efectividad Promedio del equipo: {promedio_efectividad:.1f}%\")\n",
    "print(f\"游볞 Promotor m치s efectivo: {mejor_usuario} ({mejor_valor:.1f}%)\")\n",
    "print(\"-\" * 60)\n",
    "# Mostrar tabla ordenada de mejor a peor para la consola\n",
    "# Aqu칤 ver치s la columna 'Con_Error' que equivale a tu antiguo usuarios_count\n",
    "print(df_efectividad[['Total_Gestionados', 'Con_Error', 'Efectividad_Pct']].sort_values('Efectividad_Pct', ascending=False))\n",
    "print(f\"游 Imagen guardada en: {ruta_archivo_png_efectividad}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "# Informe S3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "## dashboard S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_dashboard_s3_mejorado(df_s3, mes_trabajo, a침o_trabajo, PALETA_EPS, R_Salida):\n",
    "    \n",
    "    # Obtener nombre del mes en espa침ol\n",
    "    meses_esp = {\n",
    "        1: 'Enero', 2: 'Febrero', 3: 'Marzo', 4: 'Abril',\n",
    "        5: 'Mayo', 6: 'Junio', 7: 'Julio', 8: 'Agosto',\n",
    "        9: 'Septiembre', 10: 'Octubre', 11: 'Noviembre', 12: 'Diciembre'\n",
    "    }\n",
    "    mes_nombre = meses_esp[mes_trabajo]\n",
    "    \n",
    "    # Crear carpeta anexos si no existe\n",
    "    carpeta_anexos = os.path.join(R_Salida, \"anexos\")\n",
    "    os.makedirs(carpeta_anexos, exist_ok=True)\n",
    "    \n",
    "    # Configuraci칩n General de Matplotlib\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'sans-serif', 'font.sans-serif': ['Arial', 'Helvetica', 'Lato'],\n",
    "        'text.color': '#444444', 'axes.labelcolor': '#444444',\n",
    "        'xtick.color': '#444444', 'ytick.color': '#444444',\n",
    "        'axes.edgecolor': 'white', 'axes.facecolor': 'white', 'figure.facecolor': 'white',\n",
    "        'grid.color': '#EAEAEA', 'grid.linewidth': 0.8,\n",
    "        'axes.titlesize': 16, 'axes.titleweight': 'bold',\n",
    "        'figure.titlesize': 26, 'figure.titleweight': 'bold',\n",
    "        'lines.linewidth': 2.5, 'lines.markerfacecolor': PALETA_EPS[1], 'lines.markeredgecolor': 'white',\n",
    "        'lines.markeredgewidth': 1.5,\n",
    "    })\n",
    "\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 14))\n",
    "    \n",
    "    fig.suptitle(f'Dashboard de Glosas S3 (Traslados) - {mes_nombre} {a침o_trabajo}\\nSistema de Monitoreo CAPRESOCA EPS', \n",
    "                 fontsize=24, fontweight='bold', color=PALETA_EPS[1], y=1.0) \n",
    "\n",
    "    # --- 1. Gr치fica de registros por fecha con etiquetas ---\n",
    "    registros_por_fecha = df_s3.groupby('Fecha_Proceso_dt').size()\n",
    "    \n",
    "    ax1.plot(registros_por_fecha.index, registros_por_fecha.values, \n",
    "             color=PALETA_EPS[1], linewidth=2.5, marker='o', markersize=8, markeredgecolor='white')\n",
    "    ax1.fill_between(registros_por_fecha.index, registros_por_fecha.values, \n",
    "                     alpha=0.15, color=PALETA_EPS[1])\n",
    "    \n",
    "    ax1.set_title('Registros por Fecha de Proceso', fontsize=16, fontweight='bold', pad=20, color=PALETA_EPS[1])\n",
    "    ax1.grid(True, which='major', axis='y', linestyle='--', linewidth=0.7)\n",
    "    ax1.grid(False, which='major', axis='x')\n",
    "    ax1.tick_params(axis='x', rotation=45, labelsize=10)\n",
    "    ax1.tick_params(axis='y', labelsize=10)\n",
    "    ax1.set_ylabel('N칰mero de Registros', fontsize=12)\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    ax1.spines['right'].set_visible(False)\n",
    "    ax1.spines['left'].set_visible(False)\n",
    "    ax1.spines['bottom'].set_color('#DDDDDD')\n",
    "\n",
    "    for i, val in enumerate(registros_por_fecha.values):\n",
    "        ax1.annotate(f'{val}', (registros_por_fecha.index[i], val), \n",
    "                     textcoords=\"offset points\", xytext=(0,12), ha='center',\n",
    "                     fontsize=10, fontweight='bold', color=PALETA_EPS[1])\n",
    "    \n",
    "    ax1.xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%d-%b'))\n",
    "\n",
    "    # --- 2. Top Glosas Principales con etiquetas ---\n",
    "    top_glosas = df_s3['Glosa_Principal'].value_counts().nlargest(10).sort_values(ascending=True)\n",
    "    \n",
    "    n_colors = len(top_glosas)\n",
    "    colors = [plt.cm.get_cmap('Greens')(x) for x in np.linspace(0.45, 0.85, n_colors)]\n",
    "    \n",
    "    bars = ax2.barh(range(len(top_glosas)), top_glosas.values, color=colors, \n",
    "                    edgecolor='white', linewidth=0.5, height=0.8)\n",
    "    ax2.set_yticks(range(len(top_glosas)))\n",
    "    ax2.set_yticklabels(top_glosas.index, fontsize=11)\n",
    "    ax2.set_title('Top 10 Glosas Principales (S3)', fontsize=16, fontweight='bold', pad=20, color=PALETA_EPS[1])\n",
    "    ax2.grid(False)\n",
    "    ax2.tick_params(axis='x', labelsize=10)\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    ax2.spines['right'].set_visible(False)\n",
    "    ax2.spines['left'].set_visible(False)\n",
    "    ax2.spines['bottom'].set_color('#DDDDDD')\n",
    "    ax2.set_xlim(0, max(top_glosas.values) * 1.20)\n",
    "\n",
    "    for i, bar in enumerate(bars):\n",
    "        width = bar.get_width()\n",
    "        ax2.text(width + (max(top_glosas.values) * 0.02), bar.get_y() + bar.get_height()/2, \n",
    "                 f'{int(width)}', ha='left', va='center', fontsize=10, fontweight='bold', color='#555555')\n",
    "\n",
    "    # --- 3. Top municipios con etiquetas ---\n",
    "    top_municipios = df_s3['Nombre Municipio'].value_counts().head(10)\n",
    "    \n",
    "    bars3 = ax3.bar(top_municipios.index, top_municipios.values, \n",
    "                    color=PALETA_EPS[1], alpha=0.85, edgecolor='white', linewidth=1)\n",
    "    \n",
    "    ax3.set_xticklabels(top_municipios.index, rotation=45, ha='right', fontsize=11)\n",
    "    \n",
    "    ax3.set_title('Top 10 Municipios con m치s Glosas (S3)', fontsize=16, fontweight='bold', pad=20, color=PALETA_EPS[1])\n",
    "    ax3.grid(True, which='major', axis='y', linestyle='--', linewidth=0.7)\n",
    "    ax3.grid(False, which='major', axis='x')\n",
    "    ax3.tick_params(axis='y', labelsize=10)\n",
    "    ax3.set_ylim(0, max(top_municipios.values) * 1.20)\n",
    "    ax3.spines['top'].set_visible(False)\n",
    "    ax3.spines['right'].set_visible(False)\n",
    "    ax3.spines['left'].set_visible(False)\n",
    "    ax3.spines['bottom'].set_color('#DDDDDD')\n",
    "\n",
    "    for bar in bars3:\n",
    "        height = bar.get_height()\n",
    "        ax3.annotate(f'{int(height)}',\n",
    "                     xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                     xytext=(0, 3),\n",
    "                     textcoords=\"offset points\",\n",
    "                     ha='center', va='bottom', fontsize=10, fontweight='bold', color=PALETA_EPS[1])\n",
    "\n",
    "    # --- 4. Tabla resumen mejorada ---\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    total_registros = len(df_s3)\n",
    "    fechas_unicas = df_s3['Fecha_Proceso_dt'].nunique()\n",
    "    glosas_unicas = df_s3['Glosa_Principal'].nunique()\n",
    "    municipios_unicos = df_s3['Nombre Municipio'].nunique()\n",
    "    fecha_min = df_s3['Fecha_Proceso_dt'].min().strftime('%d/%m/%Y')\n",
    "    fecha_max = df_s3['Fecha_Proceso_dt'].max().strftime('%d/%m/%Y')\n",
    "    promedio_diario = total_registros / fechas_unicas if fechas_unicas > 0 else 0\n",
    "    municipio_principal_nombre = top_municipios.index[0]\n",
    "    \n",
    "    tabla_data = [\n",
    "        ['Total Registros', f'{total_registros:,}'],\n",
    "        ['Fechas de Proceso', f'{fechas_unicas}'],\n",
    "        ['Glosas 칔nicas', f'{glosas_unicas}'],\n",
    "        ['Municipios (칰nicos)', f'{municipios_unicos}'],\n",
    "        ['Glosa Principal', f'{top_glosas.index[-1]}'],\n",
    "        ['Municipio Principal', f'{municipio_principal_nombre}']\n",
    "    ]\n",
    "    \n",
    "    table = ax4.table(cellText=tabla_data,\n",
    "                      colLabels=['M칠trica', 'Valor'],\n",
    "                      cellLoc='left',\n",
    "                      loc='center',\n",
    "                      colWidths=[0.55, 0.35])\n",
    "    \n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1, 2.5)\n",
    "    \n",
    "    for (row, col), cell in table.get_celld().items():\n",
    "        cell.set_edgecolor('none')\n",
    "        if row == 0:\n",
    "            cell.set_text_props(weight='bold', color='white')\n",
    "            cell.set_facecolor(PALETA_EPS[1])\n",
    "            cell.set_height(0.15)\n",
    "        else:\n",
    "            cell.set_facecolor('#F9F9F9' if row % 2 == 0 else 'white')\n",
    "            cell.set_height(0.12)\n",
    "            if col == 0:\n",
    "                cell.get_text().set_weight('bold')\n",
    "                cell.get_text().set_color('#555555')\n",
    "            else:\n",
    "                cell.get_text().set_color('#222222')\n",
    "\n",
    "    ax4.set_title('Resumen General del Per칤odo (S3)', fontsize=16, fontweight='bold', pad=20, color=PALETA_EPS[1])\n",
    "    \n",
    "    # --- Ajustar layout y guardar ---\n",
    "    plt.tight_layout(pad=3.0)\n",
    "    plt.subplots_adjust(top=0.88, hspace=0.45, wspace=0.3)\n",
    "    \n",
    "    ruta_archivo_png_3 = f\"Dashboard_Glosas_S3_{mes_nombre}_{a침o_trabajo}.png\"\n",
    "    ruta_archivo_png_3 = os.path.join(carpeta_anexos, ruta_archivo_png_3)\n",
    "    plt.savefig(ruta_archivo_png_3, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "\n",
    "    # --- Resumen final impreso ---\n",
    "    print(f\"游 Dashboard S3 guardado como PNG en: {ruta_archivo_png_3}\")\n",
    "    print(f\"游늵 RESUMEN DASHBOARD GLOSAS S3 {mes_nombre.upper()} {a침o_trabajo}\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"游늰 Per칤odo analizado: {fecha_min} - {fecha_max}\")\n",
    "    print(f\"游늶 Total registros procesados: {total_registros:,}\")\n",
    "    print(f\"游낀 Glosa m치s frecuente: {top_glosas.index[-1]} ({top_glosas.iloc[-1]:,} casos - {(top_glosas.iloc[-1]/total_registros*100):.1f}%)\")\n",
    "    print(f\"游끶勇 Municipio con m치s casos: {municipio_principal_nombre} ({top_municipios.iloc[0]:,} registros - {(top_municipios.iloc[0]/total_registros*100):.1f}%)\")\n",
    "    print(f\"游늳 Promedio registros por d칤a: {promedio_diario:.1f}\")\n",
    "    print(f\"游늵 Concentraci칩n top 5 glosas: {(top_glosas.tail(5).sum()/total_registros*100):.1f}%\")\n",
    "    print(f\"游꿢 Archivo guardado: {ruta_archivo_png_3}\")\n",
    "    \n",
    "    return fig, ruta_archivo_png_3\n",
    "\n",
    "# Ejecutar la funci칩n para el dashboard S3\n",
    "fig_dashboard_s3, ruta_archivo_png_3 = crear_dashboard_s3_mejorado(\n",
    "    df_s3, \n",
    "    mes_trabajo, \n",
    "    a침o_trabajo, \n",
    "    PALETA_EPS, \n",
    "    R_Salida\n",
    ")\n",
    "print(f\"\\n춰El dashboard de S3 est치 listo! La ruta es:\\n{ruta_archivo_png_3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "## RESUMEN POR USUARIO S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "meses_esp = {\n",
    "        1: 'Enero', 2: 'Febrero', 3: 'Marzo', 4: 'Abril',\n",
    "        5: 'Mayo', 6: 'Junio', 7: 'Julio', 8: 'Agosto',\n",
    "        9: 'Septiembre', 10: 'Octubre', 11: 'Noviembre', 12: 'Diciembre'\n",
    "    }\n",
    "mes_nombre = meses_esp[mes_trabajo]\n",
    "\n",
    "# Crear visualizaci칩n de registros por Usuario Grabado para S3\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Contar registros por usuario y ordenar de mayor a menor, manejando posibles NaN\n",
    "usuarios_count_s3 = df_s3['Usuario Grabado'].dropna().value_counts()\n",
    "\n",
    "# Verificar si hay datos para graficar\n",
    "if not usuarios_count_s3.empty:\n",
    "    # Crear gr치fico de barras horizontal\n",
    "    bars_s3 = plt.barh(range(len(usuarios_count_s3)), usuarios_count_s3.values, \n",
    "                    color=PALETA_EPS[1], alpha=0.8, edgecolor='white', linewidth=1)\n",
    "\n",
    "    # Configurar etiquetas del eje Y\n",
    "    plt.yticks(range(len(usuarios_count_s3)), usuarios_count_s3.index, fontsize=11)\n",
    "\n",
    "    # Configurar t칤tulos y etiquetas\n",
    "    plt.title(f'Registros de Glosas S3 por Usuario Grabado\\n{mes_nombre} {a침o_trabajo}', \n",
    "              fontsize=16, fontweight='bold', color=PALETA_EPS[1], pad=20)\n",
    "    plt.xlabel('N칰mero de Registros', fontsize=12)\n",
    "    plt.ylabel('Usuario Grabado', fontsize=12)\n",
    "\n",
    "    # Agregar valores en las barras\n",
    "    for i, bar in enumerate(bars_s3):\n",
    "        width = bar.get_width()\n",
    "        plt.text(width + (max(usuarios_count_s3.values) * 0.01), bar.get_y() + bar.get_height()/2, \n",
    "                 f'{int(width)}', ha='left', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "    # Configurar grid y estilo\n",
    "    plt.grid(True, axis='x', alpha=0.3)\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.gca().spines['left'].set_visible(False)\n",
    "\n",
    "    # Ajustar l칤mites del eje X\n",
    "    plt.xlim(0, max(usuarios_count_s3.values) * 1.15)\n",
    "\n",
    "    # Ajustar layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Guardar la imagen en la carpeta anexos\n",
    "    carpeta_anexos = os.path.join(R_Salida, \"anexos\")\n",
    "    os.makedirs(carpeta_anexos, exist_ok=True)\n",
    "\n",
    "    # Guardar imagen\n",
    "    nombre_archivo_usuarios_s3 = f\"Grafico_Usuarios_S3_{mes_nombre}_{a침o_trabajo}.png\"\n",
    "    ruta_archivo_png_4 = os.path.join(carpeta_anexos, nombre_archivo_usuarios_s3)\n",
    "    plt.savefig(ruta_archivo_png_4, dpi=300, bbox_inches='tight', \n",
    "               facecolor='white', format='png')\n",
    "\n",
    "    # Mostrar estad칤sticas resumidas\n",
    "    total_registros_s3 = len(df_s3)\n",
    "    total_usuarios_s3 = len(usuarios_count_s3)\n",
    "    promedio_por_usuario_s3 = total_registros_s3 / total_usuarios_s3 if total_usuarios_s3 > 0 else 0\n",
    "\n",
    "    print(f\"游늵 RESUMEN POR USUARIO GRABADO (S3)\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"游논 Total de usuarios: {total_usuarios_s3}\")\n",
    "    print(f\"游늶 Total de registros con usuario: {usuarios_count_s3.sum()}\")\n",
    "    print(f\"游늳 Promedio por usuario: {promedio_por_usuario_s3:.1f}\")\n",
    "    print(f\"游볞 Usuario con m치s registros: {usuarios_count_s3.index[0]} ({usuarios_count_s3.iloc[0]} registros)\")\n",
    "    if total_registros_s3 > 0:\n",
    "        print(f\"游늵 Top 3 usuarios concentran: {(usuarios_count_s3.head(3).sum()/total_registros_s3*100):.1f}% del total\")\n",
    "    print(f\"游 Imagen guardada en: {ruta_archivo_png_4}\")\n",
    "\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No se encontraron datos de 'Usuario Grabado' para graficar en el per칤odo seleccionado para S3.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "# Contruccion Docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actualizar_documento_word(R_Documento, fecha_trabajo, mes_nombre, a침o_trabajo, imagenes_dict, df_ms, df_s3, R_Salida, tablas_dict):\n",
    "    \"\"\"\n",
    "    Actualiza un documento de Word reemplazando etiquetas con valores din치micos e im치genes.\n",
    "    \n",
    "    Par치metros:\n",
    "    - R_Documento: Ruta al documento Word plantilla\n",
    "    - fecha_trabajo: Fecha en formato dd/mm/yyyy\n",
    "    - mes_nombre: Nombre del mes (ej: \"Octubre\")\n",
    "    - a침o_trabajo: A침o como entero\n",
    "    - imagenes_dict: Diccionario con {placeholder: ruta_imagen}.\n",
    "    - df_ms: DataFrame con los datos de MS\n",
    "    - R_Salida: Carpeta donde guardar el documento actualizado\n",
    "    - tablas_dict: Diccionario con {placeholder: DataFrame} para tablas\n",
    "    \"\"\"\n",
    "    \n",
    "    # Cargar el documento Word\n",
    "    doc = Document(R_Documento)\n",
    "\n",
    "    # --- Generar la fecha de elaboraci칩n del informe (fecha actual) ---\n",
    "    fecha_actual = datetime.now()\n",
    "    meses_esp = {\n",
    "        1: 'Enero', 2: 'Febrero', 3: 'Marzo', 4: 'Abril',\n",
    "        5: 'Mayo', 6: 'Junio', 7: 'Julio', 8: 'Agosto',\n",
    "        9: 'Septiembre', 10: 'Octubre', 11: 'Noviembre', 12: 'Diciembre'\n",
    "    }\n",
    "    # Formato: \"{{dia}} de {{mes}} de {{a침o}}\"\n",
    "    fecha_elaboracion = f\"{fecha_actual.day} de {meses_esp[fecha_actual.month]} de {fecha_actual.year}\"\n",
    "\n",
    "    \n",
    "    # --- Definir los valores para reemplazar las etiquetas ---\n",
    "    \n",
    "    # Obtener estad칤sticas del dataframe para los p치rrafos MS\n",
    "    total_registros = len(df_ms)\n",
    "    glosas_unicas = df_ms['Glosa_Principal'].nunique()\n",
    "    municipios_unicos = df_ms['Nombre Municipio'].nunique()\n",
    "    \n",
    "    # Obtener estad칤sticas del dataframe para los p치rrafos S3\n",
    "    total_registros_s3 = len(df_s3)\n",
    "    glosas_unicas_s3 = df_s3['Glosa_Principal'].nunique()\n",
    "    municipios_unicos_s3 = df_s3['Nombre Municipio'].nunique()\n",
    "    \n",
    "    # Glosa m치s frecuente MS\n",
    "    top_glosa = df_ms['Glosa_Principal'].value_counts().index[0]\n",
    "    top_glosa_count = df_ms['Glosa_Principal'].value_counts().iloc[0]\n",
    "    # Buscar la descripci칩n de la glosa principal MS---\n",
    "    descripcion_top_glosa = df_glosas[df_glosas['Glosa'] == top_glosa]['Descripci칩n'].iloc[0]\n",
    "    \n",
    "    # Glosa m치s frecuente S3\n",
    "    top_glosa_s3 = df_s3['Glosa_Principal'].value_counts().index[0]\n",
    "    top_glosa_count_s3 = df_s3['Glosa_Principal'].value_counts().iloc[0]\n",
    "    # Buscar la descripci칩n de la glosa principal S3 ---\n",
    "    descripcion_top_glosa_s3 = df_glosas[df_glosas['Glosa'] == top_glosa_s3]['Descripci칩n'].iloc[0]\n",
    "    \n",
    "    # Municipio con m치s registros MS\n",
    "    top_municipio = df_ms['Nombre Municipio'].value_counts().index[0]\n",
    "    top_municipio_count = df_ms['Nombre Municipio'].value_counts().iloc[0]\n",
    "    \n",
    "    # Municipio con m치s registros S3\n",
    "    top_municipio_s3 = df_s3['Nombre Municipio'].value_counts().index[0]\n",
    "    top_municipio_count_s3 = df_s3['Nombre Municipio'].value_counts().iloc[0]\n",
    "    \n",
    "    # Usuario con m치s registros MS\n",
    "    top_usuario = df_ms['Usuario Grabado'].value_counts().index[0]\n",
    "    top_usuario_count = df_ms['Usuario Grabado'].value_counts().iloc[0]\n",
    "    \n",
    "    # Usuario con m치s registros S3\n",
    "    top_usuario_s3 = df_s3['Usuario Grabado'].value_counts().index[0]\n",
    "    top_usuario_count_s3 = df_s3['Usuario Grabado'].value_counts().iloc[0]\n",
    "    \n",
    "    # Diccionario con todas las etiquetas a reemplazar\n",
    "    etiquetas_reemplazo = {\n",
    "        '{{mes}}': mes_nombre,\n",
    "        '{{ano}}': str(a침o_trabajo),\n",
    "        '{{fecha}}': fecha_elaboracion,\n",
    "        \n",
    "        # P치rrafo 1: Resumen general MS\n",
    "        '{{1_Parrafo}}': f\"\"\"Durante el mes de {mes_nombre} de {a침o_trabajo}, se procesaron un total de {total_registros:,} registros de glosas MS (Maestro de Ingresos r칠gimen Subsidiado) en el sistema BDUA. Este an치lisis comprende {glosas_unicas} tipos diferentes de glosas distribuidas en {municipios_unicos} municipios del 치rea de cobertura de CAPRESOCA EPS. \n",
    "\n",
    "        La glosa m치s frecuente corresponde al c칩digo {top_glosa} ({descripcion_top_glosa}) con {top_glosa_count:,} casos ({(top_glosa_count/total_registros*100):.1f}% del total), lo que indica la necesidad de implementar acciones correctivas espec칤ficas para reducir su incidencia en futuros procesos.\"\"\",\n",
    "        \n",
    "        # P치rrafo 2: An치lisis territorial Ms\n",
    "        '{{2_Parrafo}}': f\"\"\"El an치lisis territorial revela que el municipio de {top_municipio} concentra la mayor cantidad de registros con glosas, representando {top_municipio_count:,} casos ({(top_municipio_count/total_registros*100):.1f}% del total). Esta concentraci칩n sugiere la importancia de fortalecer los procesos de validaci칩n y calidad de datos en las zonas con mayor volumen de afiliaciones.\n",
    "\n",
    "        La distribuci칩n geogr치fica de las glosas permite identificar patrones territoriales que requieren atenci칩n prioritaria para mejorar la calidad de los procesos de afiliaci칩n y reducir las tasas de rechazo por parte del ADRES.\"\"\",\n",
    "        \n",
    "        # P치rrafo 3: An치lisis por usuario MS\n",
    "        '{{3_Parrafo}}': f\"\"\"Respecto al an치lisis por usuario grabado, se identifica que el usuario SIE {top_usuario} es responsable del mayor n칰mero de registros con glosas, acumulando {top_usuario_count:,} casos ({(top_usuario_count/total_registros*100):.1f}% del total). \n",
    "\n",
    "        Esta informaci칩n es fundamental para establecer planes de capacitaci칩n espec칤ficos y fortalecer los controles de calidad en los procesos de digitaci칩n y validaci칩n de datos. La concentraci칩n de errores en usuarios espec칤ficos sugiere oportunidades de mejora en los procedimientos de capacitaci칩n y supervisi칩n del personal.\"\"\",\n",
    "        \n",
    "        # P치rrafo 4: Resumen general S3\n",
    "        '{{4_Parrafo}}': f\"\"\"Durante el mes de {mes_nombre} de {a침o_trabajo}, se procesaron un total de {total_registros_s3:,} registros de glosas S3 (Archivo de Traslados Regimen Subsidiado) en el sistema BDUA. Este an치lisis comprende {glosas_unicas_s3} tipos diferentes de glosas distribuidas en {municipios_unicos_s3} municipios del 치rea de cobertura de CAPRESOCA EPS. \n",
    "        \n",
    "        La glosa m치s frecuente corresponde al c칩digo {top_glosa_s3} ({descripcion_top_glosa_s3}) con {top_glosa_count_s3:,} casos ({(top_glosa_count_s3/total_registros_s3*100):.1f}% del total), lo que indica la necesidad de implementar acciones correctivas espec칤ficas para reducir su incidencia en futuros procesos.\"\"\",\n",
    "        \n",
    "        # P치rrafo 5: An치lisis territorial S3\n",
    "        '{{5_Parrafo}}': f\"\"\"El an치lisis territorial revela que el municipio de {top_municipio_s3} concentra la mayor cantidad de registros con glosas, representando {top_municipio_count_s3:,} casos ({(top_municipio_count_s3/total_registros_s3*100):.1f}% del total). Esta concentraci칩n sugiere la importancia de fortalecer los procesos de validaci칩n y calidad de datos en las zonas con mayor volumen de afiliaciones.\n",
    "\n",
    "        La distribuci칩n geogr치fica de las glosas permite identificar patrones territoriales que requieren atenci칩n prioritaria para mejorar la calidad de los procesos de afiliaci칩n y reducir las tasas de rechazo por parte del ADRES.\"\"\",\n",
    "        \n",
    "        # P치rrafo 6: An치lisis por usuario S3\n",
    "        '{{6_Parrafo}}': f\"\"\"Respecto al an치lisis por usuario grabado, se identifica que el usuario SIE {top_usuario_s3} es responsable del mayor n칰mero de registros con glosas, acumulando {top_usuario_count_s3:,} casos ({(top_usuario_count_s3/total_registros_s3*100):.1f}% del total). \n",
    "\n",
    "        Esta informaci칩n es fundamental para establecer planes de capacitaci칩n espec칤ficos y fortalecer los controles de calidad en los procesos de digitaci칩n y validaci칩n de datos. La concentraci칩n de errores en usuarios espec칤ficos sugiere oportunidades de mejora en los procedimientos de capacitaci칩n y supervisi칩n del personal.\"\"\",\n",
    "        \n",
    "        # P치rrafo 7: Conclusiones\n",
    "        '{{7_Parrafo}}': f\"\"\"El an치lisis de glosas correspondiente a {mes_nombre} de {a침o_trabajo} presenta los siguientes hallazgos clave:\n",
    "        \n",
    "        *   **Proceso de Ingresos (MS):** Se identific칩 un total de {total_registros:,} registros glosados. La glosa principal fue **{top_glosa}** (\"{descripcion_top_glosa}\"), el municipio con mayor incidencia fue **{top_municipio}** y el usuario con m치s registros asociados fue **{top_usuario}**.\n",
    "        *   **Proceso de Traslados (S3):** Se procesaron {total_registros_s3:,} registros con glosas. La causa m치s recurrente fue la glosa **{top_glosa_s3}** (\"{descripcion_top_glosa_s3}\"), con una concentraci칩n territorial en **{top_municipio_s3}** y una mayor cantidad de registros gestionados por el usuario **{top_usuario_s3}**.\n",
    "\n",
    "        Estos resultados cuantitativos establecen una l칤nea base para identificar los focos de error y las 치reas operativas que requieren mayor atenci칩n para la mejora continua de los procesos de aseguramiento.\"\"\",\n",
    "        \n",
    "        # P치rrafo 8: Recomendaciones y Plan de Acci칩n\n",
    "        '{{8_Parrafo}}': f\"\"\"A partir de los hallazgos, es crucial entender que no todas las glosas derivan directamente de errores de digitaci칩n. Algunas, como la **GN0169**, pueden originarse por inconsistencias en las tablas de referencia de ADRES. Por tanto, se recomienda un enfoque dual:\n",
    "\n",
    "        1.  **An치lisis Cualitativo y Generalizaci칩n:** Los l칤deres de proceso deben analizar las glosas m치s frecuentes, como **{top_glosa}** y **{top_glosa_s3}**, para diferenciar entre errores operativos y problemas externos. Se sugiere dialogar con los colaboradores de mayor incidencia ({top_usuario}, {top_usuario_s3}) para comprender las barreras que enfrentan (ej. formularios confusos, falta de herramientas de validaci칩n).\n",
    "\n",
    "        2.  **Fortalecimiento de Procesos:**\n",
    "            *   **Para Errores de Digitaci칩n:** Implementar estrategias de validaci칩n previas al cargue y reforzar las capacitaciones en los puntos de error detectados.\n",
    "            *   **Para Glosas por Datos de Referencia:** Optimizar el cargue de soportes documentales al sistema SIE. Esto agilizar치 la gesti칩n de PQR y auditor칤as necesarias para corregir la informaci칩n en la fuente (ADRES).\n",
    "            *   **c.\tPara Errores de validaci칩n en la construcci칩n del reporte BDUA:** identificar estrategias que puedan fortalecer el reporte en la fase de construcci칩n, as칤 como dar a conocer las barreras actuales a nivel de herramientas, metodolog칤as de trabajo y de apoyo profesional.\n",
    "        3.  **Estrategia Territorial:** Brindar acompa침amiento focalizado a las oficinas de **{top_municipio}** para los procesos de MS y **{top_municipio_s3}** para los procesos de S3, buscando estandarizar procedimientos y asegurar la calidad del dato desde el origen.\n",
    "\n",
    "        **Nota T칠cnica:** Los colores utilizados en los gr치ficos (rojo para MS, verde para S3) corresponden a la paleta institucional de CAPRESOCA EPS y no implican una valoraci칩n negativa o positiva de los procesos, sino una distinci칩n visual para facilitar la interpretaci칩n del informe.\"\"\"\n",
    "    }\n",
    "    \n",
    "    # --- FUNCI칍N DE AN츼LISIS DE TEXTO ---\n",
    "    def agregar_parrafo_formateado(p, texto_con_formato):\n",
    "        \"\"\"\n",
    "        Analiza una cadena de texto con Markdown simple (**negrita**, * vi침eta)\n",
    "        y la agrega a un p치rrafo de Word con el formato correcto.\n",
    "        \"\"\"\n",
    "        import re\n",
    "        # Limpia el p치rrafo antes de agregar contenido nuevo\n",
    "        p.text = \"\"\n",
    "        \n",
    "        # Divide el texto en l칤neas para procesar cada una\n",
    "        for linea in texto_con_formato.strip().split('\\n'):\n",
    "            linea = linea.strip()\n",
    "            if not linea:\n",
    "                continue\n",
    "\n",
    "            # Crea un nuevo p치rrafo para cada l칤nea para manejar vi침etas correctamente\n",
    "            current_p = p.insert_paragraph_before()\n",
    "\n",
    "            # Detectar si es un elemento de lista (vi침eta)\n",
    "            if linea.startswith('* '):\n",
    "                current_p.style = 'List Paragraph'\n",
    "                linea = linea[2:] # Quitar el '* ' del principio\n",
    "            \n",
    "            # Dividir la l칤nea por el delimitador de negrita (**)\n",
    "            fragmentos = re.split(r'(\\*\\*.*?\\*\\*)', linea)\n",
    "            \n",
    "            for frag in fragmentos:\n",
    "                if frag.startswith('**') and frag.endswith('**'):\n",
    "                    current_p.add_run(frag[2:-2]).bold = True\n",
    "                elif frag:\n",
    "                    current_p.add_run(frag)\n",
    "        # Eliminamos el p치rrafo original que usamos como ancla\n",
    "        p_element = p._element\n",
    "        p_element.getparent().remove(p_element)\n",
    "\n",
    "\n",
    "    # --- Funci칩n auxiliar para reemplazar texto en p치rrafos (MODIFICADA) ---\n",
    "    def reemplazar_texto_en_parrafos(doc, etiquetas_dict):\n",
    "        \"\"\"\n",
    "        Reemplaza las etiquetas de texto en todos los p치rrafos, aplicando formato\n",
    "        especial a los placeholders que lo requieran.\n",
    "        \"\"\"\n",
    "        # Lista de placeholders que necesitan formato especial\n",
    "        placeholders_con_formato = ['{{7_Parrafo}}', '{{8_Parrafo}}']\n",
    "\n",
    "        for p in doc.paragraphs:\n",
    "            # Hacemos una copia para poder modificar el texto mientras iteramos\n",
    "            inline_text = p.text\n",
    "            for etiqueta, valor in etiquetas_dict.items():\n",
    "                if etiqueta in inline_text:\n",
    "                    # Si es un p치rrafo que requiere formato especial\n",
    "                    if etiqueta in placeholders_con_formato:\n",
    "                        # Llamamos a la funci칩n que construye el p치rrafo con formato\n",
    "                        agregar_parrafo_formateado(p, valor)\n",
    "                        print(f\"九 P치rrafo con formato din치mico insertado en '{etiqueta}'.\")\n",
    "                        # Rompemos el bucle interno porque este p치rrafo ya fue procesado completamente\n",
    "                        break \n",
    "                    # Si es un reemplazo de texto simple\n",
    "                    else:\n",
    "                        # Hacemos el reemplazo simple. Continuamos por si hay m치s etiquetas en la misma l칤nea.\n",
    "                        p.text = p.text.replace(etiqueta, str(valor))\n",
    "                        inline_text = p.text # Actualizamos el texto para la siguiente iteraci칩n\n",
    "\n",
    "    \n",
    "    # --- Funci칩n auxiliar para reemplazar im치genes ---\n",
    "    def reemplazar_imagenes_en_documento(doc, imagenes_a_reemplazar):\n",
    "        \"\"\"Reemplaza placeholders de im치genes usando un diccionario.\"\"\"\n",
    "        for p in doc.paragraphs:\n",
    "            for placeholder, ruta_imagen in imagenes_a_reemplazar.items():\n",
    "                if placeholder in p.text:\n",
    "                    p.text = p.text.replace(placeholder, '')\n",
    "                    run = p.add_run()\n",
    "                    run.add_picture(ruta_imagen, width=Inches(6.5))\n",
    "                    p.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "                    print(f\"九 Imagen insertada en el placeholder '{placeholder}'.\")\n",
    "                    break # Evita buscar m치s placeholders en el mismo p치rrafo\n",
    "\n",
    "\n",
    "    # --- NUEVA FUNCI칍N AUXILIAR PARA REEMPLAZAR TABLA ---\n",
    "    def reemplazar_placeholder_con_tabla(doc, tablas_a_reemplazar):\n",
    "        \"\"\"Busca placeholders de tablas y los reemplaza usando un diccionario.\"\"\"\n",
    "        # Usamos los colores como strings hexadecimales sin el '#'\n",
    "        color_cabecera_fondo = '289452'\n",
    "        color_cabecera_letra = RGBColor.from_string('FFFFFF')\n",
    "        color_fila_fondo = 'E2F0D9'\n",
    "\n",
    "        # Itera sobre el diccionario de tablas\n",
    "        for placeholder, datos_df in tablas_a_reemplazar.items():\n",
    "            if not isinstance(datos_df, pd.DataFrame) or datos_df.empty:\n",
    "                print(f\"丘멆잺 Datos para la tabla '{placeholder}' no son un DataFrame v치lido o est치n vac칤os.\")\n",
    "                continue\n",
    "\n",
    "            # Busca el p치rrafo con el placeholder para esta tabla espec칤fica\n",
    "            for p in doc.paragraphs:\n",
    "                if placeholder in p.text:\n",
    "                    p.text = p.text.replace(placeholder, '')\n",
    "                    \n",
    "                    num_cols = len(datos_df.columns)\n",
    "                    tabla = doc.add_table(rows=1, cols=num_cols)\n",
    "                    tabla.style = 'Table Grid'\n",
    "                    tabla.alignment = WD_TABLE_ALIGNMENT.CENTER\n",
    "                    tabla.autofit = True\n",
    "\n",
    "                    # Estilo de la cabecera\n",
    "                    hdr_cells = tabla.rows[0].cells\n",
    "                    for i, col_name in enumerate(datos_df.columns):\n",
    "                        cell = hdr_cells[i]\n",
    "                        cell.text = str(col_name)\n",
    "                        \n",
    "                        # --- CORRECCI칍N DEFINITIVA ---\n",
    "                        # Obtener propiedades de la celda\n",
    "                        tcPr = cell._tc.get_or_add_tcPr()\n",
    "                        # Crear el elemento de sombreado (shading)\n",
    "                        shading_elm = OxmlElement('w:shd')\n",
    "                        # Establecer el atributo de color de relleno\n",
    "                        shading_elm.set(qn('w:fill'), color_cabecera_fondo)\n",
    "                        # A침adir el elemento de sombreado a las propiedades de la celda\n",
    "                        tcPr.append(shading_elm)\n",
    "\n",
    "                        para = cell.paragraphs[0]\n",
    "                        para.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "                        run = para.runs[0]\n",
    "                        run.font.bold = True\n",
    "                        run.font.color.rgb = color_cabecera_letra\n",
    "\n",
    "                    # Llenar la tabla con los datos\n",
    "                    for index, row in datos_df.iterrows():\n",
    "                        row_cells = tabla.add_row().cells\n",
    "                        for i, value in enumerate(row):\n",
    "                            cell = row_cells[i]\n",
    "                            cell.text = str(value)\n",
    "\n",
    "                            # --- CORRECCI칍N DEFINITIVA ---\n",
    "                            tcPr = cell._tc.get_or_add_tcPr()\n",
    "                            shading_elm = OxmlElement('w:shd')\n",
    "                            shading_elm.set(qn('w:fill'), color_fila_fondo)\n",
    "                            tcPr.append(shading_elm)\n",
    "\n",
    "                            if i > 0:\n",
    "                                cell.paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "                    \n",
    "                    p._p.addprevious(tabla._tbl)\n",
    "                    print(f\"九 Tabla din치mica insertada en '{placeholder}'.\")\n",
    "                    break # Sale del bucle de p치rrafos y va a la siguiente tabla del diccionario\n",
    "    \n",
    "    # --- Aplicar los reemplazos ---\n",
    "    \n",
    "    # 1. Reemplazar texto en p치rrafos\n",
    "    reemplazar_texto_en_parrafos(doc, etiquetas_reemplazo)\n",
    "    \n",
    "    # 2. Reemplazar im치genes\n",
    "    reemplazar_imagenes_en_documento(doc, imagenes_dict)\n",
    "    \n",
    "    # 3. NUEVO: Reemplazar placeholder con la tabla de usuarios\n",
    "    reemplazar_placeholder_con_tabla(doc, tablas_dict)\n",
    "    \n",
    "    # 4. Reemplazar en tablas si las hay\n",
    "    for table in doc.tables:\n",
    "        for row in table.rows:\n",
    "            for cell in row.cells:\n",
    "                for etiqueta, valor in etiquetas_reemplazo.items():\n",
    "                    if etiqueta in cell.text and not etiqueta.startswith('{{imagen'):\n",
    "                        cell.text = cell.text.replace(etiqueta, valor)\n",
    "    \n",
    "    # 5. Reemplazar texto simple y p치rrafos complejos\n",
    "    for p in doc.paragraphs:\n",
    "        for placeholder, valor in etiquetas_reemplazo.items():\n",
    "            if placeholder in p.text:\n",
    "                # Si es un p치rrafo complejo, usa la funci칩n de formato\n",
    "                if placeholder in ['{{7_Parrafo}}', '{{8_Parrafo}}']:\n",
    "                    p.text = \"\" # Borra el placeholder\n",
    "                    agregar_parrafo_formateado(p, valor)\n",
    "                    print(f\"九 P치rrafo con formato din치mico insertado en '{placeholder}'.\")\n",
    "                # Si no, es un reemplazo simple\n",
    "                else:\n",
    "                    p.text = p.text.replace(placeholder, valor)\n",
    "    \n",
    "    # --- Guardar el documento actualizado ---\n",
    "    nombre_documento_actualizado = f\"INFORME_GLOSAS_MS_S3_{mes_nombre}_{a침o_trabajo}.docx\"\n",
    "    ruta_documento_actualizado = os.path.join(R_Salida, nombre_documento_actualizado)\n",
    "    \n",
    "    # Guardar el documento\n",
    "    doc.save(ruta_documento_actualizado)\n",
    "    \n",
    "    # Mostrar resumen de la operaci칩n\n",
    "    print(f\"九 DOCUMENTO WORD ACTUALIZADO EXITOSAMENTE\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"游늬 Documento original: {R_Documento}\")\n",
    "    print(f\"游 Documento actualizado: {ruta_documento_actualizado}\")\n",
    "    print(f\"游늰 Per칤odo: {mes_nombre} {a침o_trabajo}\")\n",
    "    print(f\"游뒆勇  Imagen 1 (Dashboard): {os.path.basename(ruta_archivo_png_1)}\")\n",
    "    print(f\"游뒆勇  Imagen 2 (Usuarios): {os.path.basename(ruta_archivo_png_efectividad)}\")\n",
    "    print(f\"游늵 Total registros procesados: {total_registros:,}\")\n",
    "    print(f\"游늶 Etiquetas reemplazadas: {len([k for k in etiquetas_reemplazo.keys() if not k.startswith('{{imagen')])}\")\n",
    "    print(f\"游꿢 Im치genes insertadas: 2\")\n",
    "    \n",
    "    return ruta_documento_actualizado, etiquetas_reemplazo\n",
    "\n",
    "# --- EJECUTAR LA FUNCI칍N ---\n",
    "# Obtener el nombre del mes para usar en la funci칩n\n",
    "meses_esp = {\n",
    "    1: 'Enero', 2: 'Febrero', 3: 'Marzo', 4: 'Abril',\n",
    "    5: 'Mayo', 6: 'Junio', 7: 'Julio', 8: 'Agosto',\n",
    "    9: 'Septiembre', 10: 'Octubre', 11: 'Noviembre', 12: 'Diciembre'\n",
    "}\n",
    "\n",
    "# 1. Diccionario de im치genes\n",
    "imagenes_a_insertar = {\n",
    "    '{{imagen_1}}': ruta_archivo_png_1,\n",
    "    '{{imagen_2}}': ruta_archivo_png_efectividad,\n",
    "    '{{imagen_3}}': ruta_archivo_png_3,\n",
    "    '{{imagen_4}}': ruta_archivo_png_4\n",
    "}\n",
    "\n",
    "# 2. Diccionario de tablas\n",
    "# 1. Resetear el 칤ndice (si no lo has hecho ya)\n",
    "df_efectividad = df_efectividad.reset_index()\n",
    "\n",
    "# 2. Aplicar el formato a la columna de efectividad (asumiendo que se llama 'Efectividad_Pct')\n",
    "# La 'f' es de float, el '.2' es el n칰mero de decimales\n",
    "df_efectividad['Efectividad_Pct'] = df_efectividad['Efectividad_Pct'].apply(lambda x: f\"{x:.2f}%\")\n",
    "\n",
    "# (Opcional) Renombrar las columnas para que queden listas para el informe\n",
    "df_efectividad = df_efectividad.rename(columns={\n",
    "    'index': 'Usuario',             # O 'Usuario Grabado' dependiendo de tu versi칩n de pandas\n",
    "    'Total_Gestionados': 'Total',\n",
    "    'Con_Error': 'Errores',\n",
    "    'Efectividad_Pct': 'Efectividad'\n",
    "})\n",
    "\n",
    "\n",
    "usuarios_s3_df = usuarios_count_s3.reset_index()\n",
    "df_efectividad.columns = ['Usuario', 'Total', 'Errores', 'Efectividad' ]\n",
    "usuarios_s3_df.columns = ['Usuario Grabado', 'Errores']\n",
    "tablas_a_insertar = {\n",
    "    '{{tabla_1}}': df_efectividad,\n",
    "    '{{tabla_2}}': usuarios_s3_df\n",
    "    # Si tuvieras otra tabla:\n",
    "    # '{{tabla_2}}': otro_dataframe \n",
    "}\n",
    "\n",
    "# Convertir fecha de trabajo para obtener mes\n",
    "fecha_trabajo_dt = pd.to_datetime(fecha_trabajo, format='%d/%m/%Y')\n",
    "mes_nombre = meses_esp[fecha_trabajo_dt.month]\n",
    "\n",
    "# Ejecutar la actualizaci칩n del documento\n",
    "documento_actualizado, etiquetas_usadas = actualizar_documento_word(\n",
    "    R_Documento=R_Documento,\n",
    "    fecha_trabajo=fecha_trabajo,\n",
    "    mes_nombre=mes_nombre,\n",
    "    a침o_trabajo=a침o_trabajo,\n",
    "    imagenes_dict=imagenes_a_insertar, # <-- Pasar diccionario de im치genes\n",
    "    df_ms=df_ms,\n",
    "    df_s3=df_s3,\n",
    "    R_Salida=R_Salida,\n",
    "    tablas_dict=tablas_a_insertar # <-- Pasar diccionario de tablas\n",
    ")\n",
    "\n",
    "print(f\"\\n游꿀 춰El documento ha sido actualizado y est치 listo para usar!\")\n",
    "print(f\"游닇 Puedes encontrarlo en: {documento_actualizado}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "# Guardar dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Guardar DataFrames en Excel ---\n",
    "\n",
    "# 1. Definir el nombre del archivo de salida\n",
    "# Se usar치 el mes y a침o que ya tienes definidos\n",
    "nombre_archivo_excel = f\"Detalle_Glosas_MS_S3_{mes_nombre}_{a침o_trabajo}.xlsx\"\n",
    "ruta_excel = os.path.join(R_Salida, \"anexos\", nombre_archivo_excel)\n",
    "\n",
    "# 2. Crear un ExcelWriter para guardar en m칰ltiples hojas\n",
    "try:\n",
    "    with pd.ExcelWriter(ruta_excel, engine='xlsxwriter') as writer:\n",
    "        # Guardar df_ms en la hoja 'Glosas MS'\n",
    "        df_ms.to_excel(writer, sheet_name='Glosas MS', index=False)\n",
    "        \n",
    "        # Guardar df_s3 en la hoja 'Glosas S3'\n",
    "        df_s3.to_excel(writer, sheet_name='Glosas S3', index=False)\n",
    "        \n",
    "        # Guardar resumen de usuarios MS\n",
    "        df_efectividad.to_excel(writer, sheet_name='Resumen Usuarios MS', index=False)\n",
    "\n",
    "        # Guardar resumen de usuarios S3\n",
    "        usuarios_s3_df.to_excel(writer, sheet_name='Resumen Usuarios S3', index=False)\n",
    "\n",
    "    print(f\"\\n九 DataFrames guardados exitosamente en el archivo Excel:\")\n",
    "    print(f\"游늯 {ruta_excel}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n仇 Ocurri칩 un error al guardar el archivo Excel: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
