{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\osmarrincon\\AppData\\Local\\Temp\\ipykernel_28512\\2254998357.py:37: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(archivo, delimiter=',', encoding='ANSI', header=None, names=columnas)  # Cambia 'delimiter' y 'encoding' si es necesario\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Columnas faltantes en el DataFrame: ['Columna1', 'Columna2', 'Columna3', 'Columna4', 'Columna5', 'Columna6', 'Columna7', 'Columna8', 'Columna9', 'Columna10', 'Columna11', 'Columna12', 'Columna13', 'Columna14', 'Columna15', 'Columna16', 'Columna17', 'Columna18', 'Columna19', 'Columna20', 'Columna21', 'Columna22', 'Columna23', 'Columna24', 'Columna25', 'Columna26', 'Columna27', 'Columna28', 'Columna29', 'Columna30', 'Columna31', 'Columna32', 'Columna33', 'Columna34', 'Columna35', 'Columna36', 'Columna37', 'Columna38']\n",
      "⚠️ Columnas faltantes en el DataFrame: ['Columna1', 'Columna2', 'Columna3', 'Columna4', 'Columna5', 'Columna6', 'Columna7', 'Columna8', 'Columna9', 'Columna10', 'Columna11', 'Columna12', 'Columna13', 'Columna14', 'Columna15', 'Columna16', 'Columna17', 'Columna18', 'Columna19', 'Columna20', 'Columna21', 'Columna22', 'Columna23', 'Columna24', 'Columna25', 'Columna26', 'Columna27', 'Columna28', 'Columna29', 'Columna30', 'Columna31', 'Columna32', 'Columna33', 'Columna34', 'Columna35', 'Columna36', 'Columna37', 'Columna38']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "Este libro de jupyter realiza el proceso de cruce de validacion del S1 de traslado validando a los usuarios a solicitar a otras EPS\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# ___________________ Nombres de archivos\n",
    "ns_s1_val = \"S1EPS02506052025.VAL\"\n",
    "ns_s1_SIE = \"SIE_S1EPS02513052025.txt\"\n",
    "ns_s1_auto = \"AUTOMATICOS-S1EPS02506052025.VAL\"\n",
    "ns_s5 = \"S5EPS02506052025.TXT\"\n",
    "ns_ms_adres = \"MS ADRES\"\n",
    "ns_expediente = \"Expedientes\"\n",
    "ns_ms_sie = \"Reporte_Validación Archivos Maestro_2025_05_13.csv\"\n",
    "ns_s1_yesid = \"S3_13052025.xlsx\"\n",
    "Nm_Hoja = \"LORENA\"\n",
    "fecha_actual = datetime.now()\n",
    "# ___________________ Rutas Capresoca\n",
    "ruta_salida =     f\"C:/Users/osmarrincon/OneDrive - 891856000_CAPRESOCA E P S/Proyecto INOVA/Colab_Notebooks/Envios Automaticos/S1_traslados/Archivos_base/\"\n",
    "ruta_s1_yesid =   f\"{ruta_salida}{ns_s1_yesid}\"\n",
    "ruta_s1_val =     f\"{ruta_salida}{ns_s1_val}\"\n",
    "ruta_s1_auto =    f\"{ruta_salida}{ns_s1_auto}\"\n",
    "ruta_s1_SIE =    f\"{ruta_salida}{ns_s1_SIE}\"\n",
    "ruta_s5 =         f\"{ruta_salida}{ns_s5}\"\n",
    "ruta_expediente = f\"{ruta_salida}{ns_expediente}\"\n",
    "ruta_ms_adres =   f\"{ruta_salida}{ns_ms_adres}\"\n",
    "ruta_ms_sie =     f\"{ruta_salida}{ns_ms_sie}\"\n",
    "# Usar glob para obtener una lista de todos los archivos .txt en la carpeta\n",
    "archivos_txt = glob.glob(os.path.join(ruta_ms_adres, '*.txt'))\n",
    "# Lista para almacenar cada DataFrame\n",
    "lista_dataframes_Ms_Adres = []\n",
    "for archivo in archivos_txt:\n",
    "    columnas = [f'col-MsAdres-{i+1}' for i in range(0, 43)]  # Aquí ajustas el rango según el número de columnas\n",
    "    df = pd.read_csv(archivo, delimiter=',', encoding='ANSI', header=None, names=columnas)  # Cambia 'delimiter' y 'encoding' si es necesario\n",
    "    lista_dataframes_Ms_Adres.append(df)\n",
    "\n",
    "# _________________ Rutas PC_Yesid\n",
    "# ruta_s1_yesid = \"C:/Users/osmarrincon/OneDrive _ 891856000_CAPRESOCA E P S/Proyecto INOVA/Colab_Notebooks/Envios Automaticos/S1_traslados/Archivos_base/S1_YESID.xlsx\"\n",
    "# ruta_s1_val = \"\"\n",
    "# ruta_s1_auto = \"\"\n",
    "# ruta_s5 = \"\"\n",
    "\n",
    "# _________________ Asegnar Dataframes\n",
    "# Combinar todos los DataFrames en uno solo\n",
    "df_MS_Adres = pd.concat(lista_dataframes_Ms_Adres, ignore_index=True)\n",
    "\n",
    "\n",
    "df_s1_yesid = pd.read_excel(ruta_s1_yesid, sheet_name= Nm_Hoja)\n",
    "# Cargar el archivo s1.val en un DataFrame sin encabezado y asignar nombres de columnas personalizados\n",
    "columnas = [f'col-s1-val{i+1}' for i in range(0, 40)]  # Aquí ajustas el rango según el número de columnas\n",
    "df_s1_val = pd.read_csv(ruta_s1_val, encoding=\"ANSI\", sep=\",\", header=None, names=columnas)\n",
    "# Cargar el archivo s1.auto en un DataFrame sin encabezado y asignar nombres de columnas personalizados\n",
    "columnas = [f'col-s1-auto{i+1}' for i in range(0, 40)]  # Aquí ajustas el rango según el número de columnas\n",
    "df_s1_auto = pd.read_csv(ruta_s1_auto, encoding=\"ANSI\", sep=\",\", header=None, names=columnas)\n",
    "# Cargar el archivo s5 en un DataFrame sin encabezado y asignar nombres de columnas personalizados\n",
    "columnas = [f'col-s5-{i+1}' for i in range(0, 10)]  # Aquí ajustas el rango según el número de columnas\n",
    "df_s5 = pd.read_csv(ruta_s5, encoding=\"ANSI\", sep=\",\", header=None, names=columnas)\n",
    "# 1. Definir nombres de columnas esperados\n",
    "total_columnas = 38\n",
    "columnas = [f'Columna{i+1}' for i in range(total_columnas)]\n",
    "\n",
    "# 2. Cargar el archivo con las columnas que existan\n",
    "df_s1_SIE = pd.read_csv(ruta_s1_SIE, encoding=\"ANSI\", sep=\",\", header=None)\n",
    "\n",
    "# 3. Rellenar columnas faltantes si hay menos de 38\n",
    "if df_s1_SIE.shape[1] < total_columnas:\n",
    "    columnas_faltantes = total_columnas - df_s1_SIE.shape[1]\n",
    "    for i in range(columnas_faltantes):\n",
    "        df_s1_SIE[f'Columna{df_s1_SIE.shape[1] + 1}'] = \"\"  # o puedes usar None, np.nan, 0 según lo que necesites\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# _________________ Diccionario tipo de variables\n",
    "varibles_col_df_s1_yesid = {\n",
    "    \"Columna1\": \"String\", \"Columna2\": \"String\", \"Columna3\": \"String\", \"Columna4\": \"String\",\n",
    "    \"Columna5\": \"String\", \"Columna6\": \"String\", \"Columna7\": \"String\", \"Columna8\": \"Fecha\",\n",
    "    \"Columna9\": \"String\", \"Columna10\": \"String\", \"Columna11\": \"String\", \"Columna12\": \"String\",\n",
    "    \"Columna13\": \"String\", \"Columna14\": \"String\", \"Columna15\": \"String\", \"Columna16\": \"Fecha\",\n",
    "    \"Columna17\": \"String\", \"Columna18\": \"Int\", \"Columna19\": \"Int\", \"Columna20\": \"String\",\n",
    "    \"Columna21\": \"Fecha\", \"Columna22\": \"Int\", \"Columna23\": \"String\",\"Columna24\": \"String\",\n",
    "    \"Columna25\": \"String\", \"Columna26\": \"String\", \"Columna27\": \"String\", \"Columna28\": \"String\",\n",
    "    \"Columna29\": \"String\", \"Columna30\": \"String\", \"Columna31\": \"String\", \"Columna32\": \"String\",\n",
    "    \"Columna33\": \"String\", \"Columna34\": \"String\", \"Columna35\": \"String\", \"Columna36\": \"String\",\n",
    "    \"Columna37\": \"String\", \"Columna38\": \"String\"\n",
    "}\n",
    "varibles_col_df_s1_val = {\n",
    "    \"col-s1-val1\": \"String\", \"col-s1-val2\": \"String\", \"col-s1-val3\": \"String\", \"col-s1-val4\": \"String\",\n",
    "    \"col-s1-val5\": \"String\", \"col-s1-val6\": \"String\", \"col-s1-val7\": \"String\", \"col-s1-val8\": \"Fecha\",\n",
    "    \"col-s1-val9\": \"String\", \"col-s1-val10\": \"String\", \"col-s1-val11\": \"String\", \"col-s1-val12\": \"String\",\n",
    "    \"col-s1-val13\": \"String\", \"col-s1-val14\": \"String\", \"col-s1-val15\": \"String\", \"col-s1-val16\": \"Fecha\",\n",
    "    \"col-s1-val17\": \"String\", \"col-s1-val18\": \"Int\", \"col-s1-val19\": \"Int\", \"col-s1-val20\": \"String\",\n",
    "    \"col-s1-val21\": \"Fecha\", \"col-s1-val22\": \"Int\", \"col-s1-val23\": \"String\",\"col-s1-val24\": \"String\",\n",
    "    \"col-s1-val25\": \"String\", \"col-s1-val26\": \"String\", \"col-s1-val27\": \"String\", \"col-s1-val28\": \"String\",\n",
    "    \"col-s1-val29\": \"String\", \"col-s1-val30\": \"String\", \"col-s1-val31\": \"String\", \"col-s1-val32\": \"String\",\n",
    "    \"col-s1-val33\": \"String\", \"col-s1-val34\": \"String\", \"col-s1-val35\": \"String\", \"col-s1-val36\": \"String\",\n",
    "    \"col-s1-val37\": \"String\", \"col-s1-val38\": \"String\", \"col-s1-val39\": \"String\", \"col-s1-val40\": \"String\"\n",
    "}\n",
    "varibles_col_df_s1_auto = {\n",
    "    \"col-s1-auto1\": \"String\", \"col-s1-auto2\": \"String\", \"col-s1-auto3\": \"String\", \"col-s1-auto4\": \"String\",\n",
    "    \"col-s1-auto5\": \"String\", \"col-s1-auto6\": \"String\", \"col-s1-auto7\": \"String\", \"col-s1-auto8\": \"Fecha\",\n",
    "    \"col-s1-auto9\": \"String\", \"col-s1-auto10\": \"String\", \"col-s1-auto11\": \"String\", \"col-s1-auto12\": \"String\",\n",
    "    \"col-s1-auto13\": \"String\", \"col-s1-auto14\": \"String\", \"col-s1-auto15\": \"String\", \"col-s1-auto16\": \"Fecha\",\n",
    "    \"col-s1-auto17\": \"String\", \"col-s1-auto18\": \"Int\", \"col-s1-auto19\": \"Int\", \"col-s1-auto20\": \"String\",\n",
    "    \"col-s1-auto21\": \"Fecha\", \"col-s1-auto22\": \"Int\", \"col-s1-auto23\": \"String\",\"col-s1-auto24\": \"String\",\n",
    "    \"col-s1-auto25\": \"String\", \"col-s1-auto26\": \"String\", \"col-s1-auto27\": \"String\", \"col-s1-auto28\": \"String\",\n",
    "    \"col-s1-auto29\": \"String\", \"col-s1-auto30\": \"String\", \"col-s1-auto31\": \"String\", \"col-s1-auto32\": \"String\",\n",
    "    \"col-s1-auto33\": \"String\", \"col-s1-auto34\": \"String\", \"col-s1-auto35\": \"String\", \"col-s1-auto36\": \"String\",\n",
    "    \"col-s1-auto37\": \"String\", \"col-s1-auto38\": \"String\", \"col-s1-auto39\": \"String\", \"col-s1-auto40\": \"String\"\n",
    "}\n",
    "varibles_col_df_s5 = {\n",
    "    \"col-s5-1\": \"String\", \"col-s5-2\": \"String\", \"col-s5-3\": \"String\", \"col-s5-4\": \"String\",\n",
    "    \"col-s5-5\": \"String\", \"col-s5-6\": \"String\", \"col-s5-7\": \"String\", \"col-s5-8\": \"Int\",\n",
    "    \"col-s5-9\": \"Int\", \"col-s5-10\": \"String\"\n",
    "}\n",
    "varibles_col_df_MsAdres = {\n",
    "    \"col-MsAdres-1\": \"String\", \"col-MsAdres-2\": \"String\", \"col-MsAdres-3\": \"String\", \"col-MsAdres-4\": \"Int\",\n",
    "    \"col-MsAdres-5\": \"String\", \"col-MsAdres-6\": \"String\", \"col-MsAdres-7\": \"String\", \"col-MsAdres-8\": \"String\",\n",
    "    \"col-MsAdres-9\": \"String\", \"col-MsAdres-10\": \"String\", \"col-MsAdres-11\": \"Fecha\", \"col-MsAdres-12\": \"String\",\n",
    "    \"col-MsAdres-13\": \"String\", \"col-MsAdres-14\": \"String\", \"col-MsAdres-15\": \"String\", \"col-MsAdres-16\": \"Fecha\",\n",
    "    \"col-MsAdres-17\": \"String\", \"col-MsAdres-18\": \"String\", \"col-MsAdres-19\": \"Int\", \"col-MsAdres-20\": \"Int\",\n",
    "    \"col-MsAdres-21\": \"String\", \"col-MsAdres-22\": \"String\", \"col-MsAdres-23\": \"String\",\"col-MsAdres-24\": \"String\",\n",
    "    \"col-MsAdres-25\": \"String\", \"col-MsAdres-26\": \"String\", \"col-MsAdres-27\": \"String\", \"col-MsAdres-28\": \"String\",\n",
    "    \"col-MsAdres-29\": \"String\", \"col-MsAdres-30\": \"Fecha\", \"col-MsAdres-31\": \"Fecha\", \"col-MsAdres-32\": \"Fecha\",\n",
    "    \"col-MsAdres-33\": \"String\", \"col-MsAdres-34\": \"String\", \"col-MsAdres-35\": \"String\", \"col-MsAdres-36\": \"String\",\n",
    "    \"col-MsAdres-37\": \"String\",  \"col-MsAdres-38\": \"String\", \"col-MsAdres-39\": \"String\", \"col-MsAdres-40\": \"String\",\n",
    "    \"col-MsAdres-41\": \"String\", \"col-MsAdres-42\": \"String\", \"col-MsAdres-43\": \"String\"\n",
    "}\n",
    "#_________________ Asigna el tipo de variebles a las columnas de los dataframes\n",
    "\n",
    "def aplicar_tipos_datos(df, diccionario_tipos):\n",
    "    \"\"\"\n",
    "    Aplica los tipos de datos especificados en un diccionario a las columnas de un DataFrame.\n",
    "    \n",
    "    Parámetros:\n",
    "    df (pd.DataFrame): El DataFrame al que se le aplicarán los tipos de datos.\n",
    "    diccionario_tipos (dict): Un diccionario donde las claves son los nombres de las columnas\n",
    "                              y los valores son los tipos de datos que se deben aplicar.\n",
    "                              \n",
    "    Retorna:\n",
    "    pd.DataFrame: El DataFrame con los tipos de datos aplicados.\n",
    "    \"\"\"\n",
    "    columnas_faltantes = []\n",
    "\n",
    "    for col, tipo in diccionario_tipos.items():\n",
    "        if col not in df.columns:\n",
    "            columnas_faltantes.append(col)\n",
    "            continue\n",
    "\n",
    "        if tipo == \"String\":\n",
    "            df[col] = df[col].apply(\n",
    "                lambda x: str(int(float(x))) if pd.notnull(x) and str(x).replace('.', '', 1).isdigit()\n",
    "                else '' if pd.isnull(x)\n",
    "                else str(x).strip()\n",
    "            )\n",
    "\n",
    "        elif tipo == \"Fecha\":\n",
    "            # Convierte a datetime con formato seguro y luego a string tipo dd/mm/yyyy\n",
    "            df[col] = pd.to_datetime(df[col], format=\"%d/%m/%Y\", errors='coerce')\n",
    "            df[col] = df[col].dt.strftime(\"%d/%m/%Y\").fillna('')\n",
    "\n",
    "        elif tipo == \"Int\":\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "        else:\n",
    "            print(f\"⚠️ Tipo de dato no reconocido para la columna {col}: {tipo}\")\n",
    "\n",
    "    if columnas_faltantes:\n",
    "        print(f\"⚠️ Columnas faltantes en el DataFrame: {columnas_faltantes}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Uso de la función aplicar_tipos_datos\n",
    "df_s1_yesid = aplicar_tipos_datos(df_s1_yesid, varibles_col_df_s1_yesid)\n",
    "df_s1_val = aplicar_tipos_datos(df_s1_val, varibles_col_df_s1_val)\n",
    "df_s1_auto = aplicar_tipos_datos(df_s1_auto, varibles_col_df_s1_auto)\n",
    "df_s5 = aplicar_tipos_datos(df_s5, varibles_col_df_s5)\n",
    "df_s1_SIE = aplicar_tipos_datos(df_s1_SIE, varibles_col_df_s1_yesid)\n",
    "df_MS_Adres= aplicar_tipos_datos(df_MS_Adres, varibles_col_df_MsAdres)\n",
    "\n",
    "# Eliminar columnas que tienen todas sus filas vacías\n",
    "df_MS_Adres = df_MS_Adres.dropna(axis=1, how='all')\n",
    "# Obtener las columnas que realmente existen en el DataFrame\n",
    "columnas_a_eliminar = [\"col-MsAdres-1\",\n",
    "                       \"col-MsAdres-20\", \"col-MsAdres-21\", \"col-MsAdres-22\", \"col-MsAdres-27\",\n",
    "                       \"col-MsAdres-28\", \"col-MsAdres-29\", \"col-MsAdres-30\", \"col-MsAdres-31\",\n",
    "                       \"col-MsAdres-32\", \"col-MsAdres-37\", \"col-MsAdres-38\",\n",
    "                       \"col-MsAdres-39\", \"col-MsAdres-40\", \"col-MsAdres-41\"]\n",
    "\n",
    "columnas_existentes = [col for col in columnas_a_eliminar if col in df_MS_Adres.columns]\n",
    "# Eliminar solo las columnas que existen\n",
    "df_MS_Adres = df_MS_Adres.drop(columns=columnas_existentes)\n",
    "\n",
    "#print(df_MS_Adres.columns.tolist) # encabezados de las columnas\n",
    "#print(df_MS_Adres.iloc[0]) # Numero de fila o registro a imprimir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 Index(['col-s1-val1', 'col-s1-val2', 'col-s1-val3', 'col-s1-val4',\n",
      "       'col-s1-val5', 'col-s1-val6', 'col-s1-val7', 'col-s1-val8',\n",
      "       'col-s1-val9', 'col-s1-val10', 'col-s1-val11', 'col-s1-val12',\n",
      "       'col-s1-val13', 'col-s1-val14', 'col-s1-val15', 'col-s1-val16',\n",
      "       'col-s1-val17', 'col-s1-val18', 'col-s1-val19', 'col-s1-val20',\n",
      "       'col-s1-val21', 'col-s1-val22', 'col-s1-val23', 'col-s1-val24',\n",
      "       'col-s1-val25', 'col-s1-val26', 'col-s1-val27', 'col-s1-val28',\n",
      "       'col-s1-val29', 'col-s1-val30', 'col-s1-val31', 'col-s1-val32',\n",
      "       'col-s1-val33', 'col-s1-val34', 'col-s1-val35', 'col-s1-val36',\n",
      "       'col-s1-val37', 'col-s1-val38', 'col-s1-val39', 'col-s1-val40'],\n",
      "      dtype='object')\n",
      "38 Index(['Column1', 'Column2', 'Column3', 'Column4', 'Column5', 'Column6',\n",
      "       'Column7', 'Column8', 'Column9', 'Column10', 'Column11', 'Column12',\n",
      "       'Column13', 'Column14', 'Column15', 'Column16', 'Column17', 'Column18',\n",
      "       'Column19', 'Column20', 'Column21', 'Column22', 'Column23', 'Column24',\n",
      "       'Column25', 'Column26', 'Column27', 'Column28', 'Column29', 'Column30',\n",
      "       'Column31', 'Column32', 'Column33', 'Column34', 'Column35', 'Column36',\n",
      "       'Column37', 'Column38'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(len(df_s1_val.columns), df_s1_val.columns)\n",
    "print(len(df_s1_yesid.columns), df_s1_yesid.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear las columna id de los dataframes\n",
    "df_s1_yesid['id-s1-yesid'] = df_s1_yesid.iloc[:, 1].astype(str) + \"_\" + df_s1_yesid.iloc[:, 2].astype(str)\n",
    "df_s1_val['id-s1_val'] = df_s1_val.iloc[:, 1].astype(str) + \"_\" + df_s1_val.iloc[:, 2].astype(str)\n",
    "df_s1_auto['id-s1_auto'] = df_s1_auto.iloc[:, 1].astype(str) + \"_\" + df_s1_auto.iloc[:, 2].astype(str)\n",
    "df_s5['id-s5'] = df_s5.iloc[:, 2].astype(str) + \"_\" + df_s5.iloc[:, 3].astype(str)\n",
    "df_s1_SIE['id-s1_SIE'] = df_s1_SIE.iloc[:, 1].astype(str) + \"_\" + df_s1_SIE.iloc[:, 2].astype(str)\n",
    "df_MS_Adres['id-MS_Adres'] = df_MS_Adres.iloc[:, 3].astype(str) + \"_\" + df_MS_Adres.iloc[:, 4].astype(str)\n",
    "\n",
    "\n",
    "# Tarea 1: Eliminar registros de df_s1_val que están en df_s1_yesid\n",
    "df_s1_val = df_s1_val[~df_s1_val['id-s1_val'].isin(df_s1_yesid['id-s1-yesid'])]\n",
    "\n",
    "# Tarea 2: Eliminar registros de df_s1_val que están en df_s1_auto\n",
    "df_s1_val = df_s1_val[~df_s1_val['id-s1_val'].isin(df_s1_auto['id-s1_auto'])]\n",
    "\n",
    "# Tarea 3: Eliminar registros de df_s1_val que están en df_s5\n",
    "    #Filtrado de df_s5:\n",
    "filtrados_s5 = df_s5[df_s5.iloc[:, 7] == 1]\n",
    "    #Eliminación de registros de df_s1_val:\n",
    "df_s1_val = df_s1_val[~df_s1_val['id-s1_val'].isin(filtrados_s5['id-s5'])]\n",
    "\n",
    "\n",
    "# Tarea 4: Crear el nuevo DataFrame no_enviar\n",
    "no_enviar = df_s1_auto.iloc[:, [1, 2, 33]].copy()\n",
    "    # Agregar columna con el nombre del DataFrame\n",
    "no_enviar['DataFrame'] = 'df_s1_auto'\n",
    "    # Agregar columna adicional con la descripción \"Aprovados en S1-auto semana anterior\"\n",
    "no_enviar['Comentario'] = 'Aprovados en S1-auto semana anterior'\n",
    "    #  Añadir los registros filtrados de df_s5 a no_enviar\n",
    "filtrados_s5 = filtrados_s5.drop(filtrados_s5.columns[[0, 1, 4, 5, 6, 7, 8, 9]], axis=1)\n",
    "filtrados_s5['DataFrame'] = 'df_s5'\n",
    "filtrados_s5['Comentario'] = 'Aprovados en el S5 la semana anterior'\n",
    "filtrados_s5.columns = no_enviar.columns\n",
    "no_enviar = pd.concat([no_enviar, filtrados_s5], ignore_index=True)\n",
    "\n",
    "# Tarea 5: Eliminar las columnas 31 y 32 de df_s1_val\n",
    "df_s1_val = df_s1_val.drop(df_s1_val.columns[[31, 32]], axis=1)\n",
    "    # Añadir los registros restantes de df_s1_val a df_s1_yesid\n",
    "df_s1_val.columns = df_s1_yesid.columns  # Asegúrate de que df_s1_val tiene las mismas columnas que df_s1_yesid\n",
    "df_s1_yesid = pd.concat([df_s1_yesid, df_s1_val], ignore_index=True)\n",
    "\n",
    "# Tarea 6: validar duplicados de s1_sie y pasarlos a s1_yesid\n",
    "    # Eliminar registros duplicados basados en la columna 'id-s1_SIE'\n",
    "df_s1_SIE = df_s1_SIE.drop_duplicates(subset=['id-s1_SIE'])\n",
    "    # Eliminar registros de df_s1_SIE que están en df_s1_yesid\n",
    "df_s1_SIE = df_s1_SIE[~df_s1_SIE['id-s1_SIE'].isin(df_s1_yesid['id-s1-yesid'])]\n",
    "    # Añadir los registros restantes de df_s1_sie a df_s1_yesid\n",
    "df_s1_SIE.columns = df_s1_yesid.columns \n",
    "df_s1_yesid = pd.concat([df_s1_yesid, df_s1_SIE], ignore_index=True)\n",
    "\n",
    "# Filtra el dataframe maestro adres para identificar usuarios para bajar a subsidiado por estar en estado retirado\n",
    "df_MS_Adres = df_MS_Adres.loc[df_MS_Adres[\"col-MsAdres-34\"] == \"RE\"]\n",
    "df_MS_Adres = df_MS_Adres.loc[df_MS_Adres[\"col-MsAdres-43\"] == \"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar \"SIII(...)\" con una cadena vacía, dejando solo la parte anterior si existe\n",
    "df_MS_Adres[\"col-MsAdres-42\"] = df_MS_Adres[\"col-MsAdres-42\"].str.replace(r'-?SIII\\([^)]+\\)', '', regex=True)\n",
    "# Reemplazar \"SIV(Dxx)\" con una cadena vacía, dejando solo la parte anterior si existe\n",
    "df_MS_Adres[\"col-MsAdres-42\"] = df_MS_Adres[\"col-MsAdres-42\"].str.replace(r'-?SIV\\(D\\d{2}\\)', '', regex=True)\n",
    "\n",
    "# Lista de números a eliminar\n",
    "numeros_a_eliminar = {'0', '11', '14', '16', '22', '25', '29', '34', '35'}\n",
    "\n",
    "def limpiar_listado_censal(cadena):\n",
    "    # Buscar el patrón LC(...) en la cadena\n",
    "    patron = r\"LC\\(([^)]+)\\)\"\n",
    "    coincidencia = re.search(patron, cadena)\n",
    "    \n",
    "    if coincidencia:\n",
    "        # Extraer los números dentro de LC(...)\n",
    "        numeros = coincidencia.group(1).split('|')\n",
    "        \n",
    "        # Filtrar y eliminar los números no deseados\n",
    "        numeros_filtrados = [num for num in numeros if num not in numeros_a_eliminar]\n",
    "        \n",
    "        if numeros_filtrados:\n",
    "            # Reconstruir la cadena LC con los números restantes\n",
    "            nueva_cadena = f\"LC({'|'.join(numeros_filtrados)})\"\n",
    "            return nueva_cadena\n",
    "        else:\n",
    "            return \"\"  # Si todos los números fueron eliminados, devolver cadena vacía\n",
    "    return cadena  # Si no coincide con el patrón LC(...), devolver la cadena original\n",
    "\n",
    "def priorizar_listado_censal(cadena):\n",
    "    # Buscar el patrón LC(...) en la cadena\n",
    "    patron = r\"LC\\(([^)]+)\\)\"\n",
    "    coincidencia = re.search(patron, cadena)\n",
    "    \n",
    "    if coincidencia:\n",
    "        # Extraer los números dentro de LC(...)\n",
    "        numeros = coincidencia.group(1).split('|')\n",
    "        \n",
    "        # Priorizar 9, luego 17\n",
    "        if '9' in numeros:\n",
    "            return \"LC(9)\"\n",
    "        elif '17' in numeros:\n",
    "            return \"LC(17)\"\n",
    "        else:\n",
    "            # Si ni 9 ni 17 están presentes, tomar el primer número\n",
    "            return f\"LC({numeros[0]})\"\n",
    "    return cadena  # Si no coincide con el patrón LC(...), devolver la cadena original\n",
    "\n",
    "\n",
    "# Aplicar la función a la columna del DataFrame\n",
    "df_MS_Adres[\"col-MsAdres-42\"] = df_MS_Adres[\"col-MsAdres-42\"].apply(limpiar_listado_censal)\n",
    "df_MS_Adres = df_MS_Adres[df_MS_Adres[\"col-MsAdres-42\"].str.strip() != \"\"]\n",
    "df_MS_Adres[\"col-MsAdres-42\"] = df_MS_Adres[\"col-MsAdres-42\"].apply(priorizar_listado_censal)\n",
    "\n",
    "df_S1_MS_Adres = df_MS_Adres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las columnas de fecha a formato datetime\n",
    "df_S1_MS_Adres[\"col-MsAdres-35\"] = pd.to_datetime(df_S1_MS_Adres[\"col-MsAdres-35\"], format=\"%d/%m/%Y\")\n",
    "df_S1_MS_Adres[\"col-MsAdres-36\"] = pd.to_datetime(df_S1_MS_Adres[\"col-MsAdres-36\"], format=\"%d/%m/%Y\")\n",
    "\n",
    "# Crear la nueva columna Fecha_maxima con la fecha más reciente entre las dos columnas\n",
    "df_S1_MS_Adres[\"Fecha_maxima\"] = df_S1_MS_Adres[[\"col-MsAdres-35\", \"col-MsAdres-36\"]].max(axis=1)\n",
    "# Convertir la fecha al formato \"dd/mm/yyyy\"\n",
    "df_S1_MS_Adres[\"col-MsAdres-35\"] = df_S1_MS_Adres[\"col-MsAdres-35\"].dt.strftime(\"%d/%m/%Y\").fillna('')\n",
    "df_S1_MS_Adres[\"col-MsAdres-36\"] = df_S1_MS_Adres[\"col-MsAdres-36\"].dt.strftime(\"%d/%m/%Y\").fillna('')\n",
    "df_S1_MS_Adres[\"Fecha_maxima\"] = df_S1_MS_Adres[\"Fecha_maxima\"].dt.strftime(\"%d/%m/%Y\").fillna('')\n",
    "\n",
    "# Obtener las columnas que realmente existen en el DataFrame\n",
    "columnas_a_eliminar = [\n",
    "    \"col-MsAdres-39\", \"col-MsAdres-43\", \"col-MsAdres-35\", \"col-MsAdres-36\"\n",
    "]\n",
    "columnas_existentes = [col for col in columnas_a_eliminar if col in df_S1_MS_Adres.columns]\n",
    "# Eliminar solo las columnas que existen\n",
    "df_S1_MS_Adres = df_S1_MS_Adres.drop(columns=columnas_existentes)\n",
    "\n",
    "# Paso 1: Duplicar las columnas necesarias\n",
    "df_S1_MS_Adres[\"col-MsAdres-5_dup\"] = df_S1_MS_Adres[\"col-MsAdres-5\"]\n",
    "df_S1_MS_Adres[\"col-MsAdres-6_dup\"] = df_S1_MS_Adres[\"col-MsAdres-6\"]\n",
    "df_S1_MS_Adres[\"col-MsAdres-7_dup\"] = df_S1_MS_Adres[\"col-MsAdres-7\"]\n",
    "df_S1_MS_Adres[\"col-MsAdres-8_dup\"] = df_S1_MS_Adres[\"col-MsAdres-8\"]\n",
    "df_S1_MS_Adres[\"col-MsAdres-9_dup\"] = df_S1_MS_Adres[\"col-MsAdres-9\"]\n",
    "df_S1_MS_Adres[\"col-MsAdres-10_dup\"] = df_S1_MS_Adres[\"col-MsAdres-10\"]\n",
    "df_S1_MS_Adres[\"col-MsAdres-11_dup\"] = df_S1_MS_Adres[\"col-MsAdres-11\"]\n",
    "df_S1_MS_Adres[\"col-MsAdres-12_dup\"] = df_S1_MS_Adres[\"col-MsAdres-12\"]\n",
    "\n",
    "# Paso 2: Crear las columnas nuevas y vacías\n",
    "df_S1_MS_Adres[\"Sisben_Adres\"] = \"\"\n",
    "df_S1_MS_Adres[\"SubGrupo_Sisben\"] = \"\"\n",
    "df_S1_MS_Adres[\"Tipo_traslado\"] = 3\n",
    "df_S1_MS_Adres[\"SubCategoria\"] = \"\"\n",
    "df_S1_MS_Adres[\"Discapacidad\"] = df_S1_MS_Adres[\"col-MsAdres-17\"]\n",
    "df_S1_MS_Adres[\"Etnia\"] = \"06\"\n",
    "df_S1_MS_Adres[\"Com. Indigena\"] = \"\"\n",
    "df_S1_MS_Adres[\"País de Nacimiento\"] = df_S1_MS_Adres[\"col-MsAdres-13\"]\n",
    "df_S1_MS_Adres[\"Lugar de Nacimiento\"] = df_S1_MS_Adres[\"col-MsAdres-14\"]\n",
    "df_S1_MS_Adres[\"Nacionalidad\"] = df_S1_MS_Adres[\"col-MsAdres-15\"]\n",
    "df_S1_MS_Adres[\"Sexo de Identificación\"] = df_S1_MS_Adres[\"col-MsAdres-16\"]\n",
    "df_S1_MS_Adres[\"Tipo de condición de discapacidad\"] = df_S1_MS_Adres[\"col-MsAdres-17\"]\n",
    "\n",
    "\n",
    "# Paso 3: Reorganizar las columnas en el orden especificado\n",
    "nuevo_orden = [\n",
    "    \"col-MsAdres-2\", \"col-MsAdres-5\", \"col-MsAdres-6\", \"col-MsAdres-7\", \"col-MsAdres-8\", \"col-MsAdres-9\",\n",
    "    \"col-MsAdres-10\", \"col-MsAdres-11\", \"col-MsAdres-12\", \"col-MsAdres-5_dup\", \"col-MsAdres-6_dup\",\n",
    "    \"col-MsAdres-7_dup\", \"col-MsAdres-8_dup\", \"col-MsAdres-9_dup\", \"col-MsAdres-10_dup\", \"col-MsAdres-11_dup\",\n",
    "    \"col-MsAdres-12_dup\", \"col-MsAdres-24\", \"col-MsAdres-25\", \"col-MsAdres-26\", \"Fecha_maxima\",\n",
    "    \"Sisben_Adres\", \"SubGrupo_Sisben\", \"Tipo_traslado\", \"SubCategoria\", \"col-MsAdres-42\",\n",
    "    \"Discapacidad\", \"col-MsAdres-3\", \"col-MsAdres-4\", \"col-MsAdres-19\", \"col-MsAdres-18\", \"Etnia\", \"Com. Indigena\",\n",
    "    \"País de Nacimiento\", \"Lugar de Nacimiento\", \"Nacionalidad\", \"Sexo de Identificación\", \"Tipo de condición de discapacidad\",\n",
    "    \"id-MS_Adres\"\n",
    "]\n",
    "\n",
    "# Reorganizar el DataFrame\n",
    "df_S1_MS_Adres = df_S1_MS_Adres[nuevo_orden]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataframes = {\n",
    "    'df_s1_yesid': df_s1_yesid,\n",
    "    'df_s1_val': df_s1_val,\n",
    "    'df_s1_auto': df_s1_auto,\n",
    "    'df_s5': df_s5,\n",
    "    'filtrados_s5': filtrados_s5,\n",
    "    'no_enviar': no_enviar,\n",
    "    'df_s1_SIE': df_s1_SIE,\n",
    "    'df_MS_Adres': df_MS_Adres,\n",
    "    'df_S1_MS_Adres': df_S1_MS_Adres\n",
    "}\n",
    "\n",
    "# Especificar la ruta y el nombre del archivo Excel\n",
    "ruta_archivo = f'{ruta_salida}/output.xlsx'\n",
    "\n",
    "# Usar pandas ExcelWriter para guardar en diferentes hojas\n",
    "with pd.ExcelWriter(ruta_archivo, engine='xlsxwriter') as writer:\n",
    "    for nombre, df in dataframes.items():\n",
    "        df.to_excel(writer, sheet_name=nombre, index=False)\n",
    "\n",
    "# Esto guardará todos los DataFrames en el archivo 'output.xlsx', cada uno en una hoja diferente"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
