{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Modulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librería para manipulación y análisis de datos mediante DataFrames\n",
    "import pandas as pd\n",
    "import re\n",
    "# Librería para manipulación de rutas de archivos y directorios\n",
    "from pathlib import Path\n",
    "# Librería para trabajar con fechas y horas\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Rutas y cargue de datafarmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_ms_sie = r\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\SIE\\Aseguramiento\\ms_sie\\Reporte_Validación Archivos Maestro_2025_12_01.csv\"\n",
    "R_Municipios_SIE = r\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\SIE\\codificación de variables categóricas\\Reporte_MUNICIPIOS_2025_05_14.csv\"\n",
    "df_ms_sie = pd.read_csv(r_ms_sie, sep=';', dtype=str, encoding='latin-1')\n",
    "df_Municipios_SIE = pd.read_csv(R_Municipios_SIE, sep=';', dtype=str, encoding='ANSI')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Limpiesa de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombramos la columna \"municipio\" de df_Municipios_SIE a \"ID_COD_municipio\"\n",
    "df_munis = df_Municipios_SIE.rename(columns={\"municipio\": \"ID_COD_municipio\"})[[\"descripcion\", \"ID_COD_municipio\"]]\n",
    "\n",
    "# Hacemos merge entre df_ms_sie y df_munis usando df_ms_sie[\"municipio\"] y df_munis[\"descripcion\"]\n",
    "df_ms_sie = df_ms_sie.merge(df_munis, left_on=\"municipio\", right_on=\"descripcion\", how=\"left\")\n",
    "\n",
    "# Eliminamos la columna \"descripcion\" que ya no es necesaria\n",
    "df_ms_sie.drop(\"descripcion\", axis=1, inplace=True)\n",
    "\n",
    "# Reordenamos las columnas para que \"ID_COD_municipio\" quede justo a la derecha de \"municipio\"\n",
    "cols = list(df_ms_sie.columns)\n",
    "idx = cols.index(\"municipio\")\n",
    "cols.remove(\"ID_COD_municipio\")\n",
    "cols.insert(idx + 1, \"ID_COD_municipio\")\n",
    "Df_SIE = df_ms_sie[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ms_sie = df_ms_sie[['tipo_documento', 'numero_identificacion', 'fecha_nacimiento', 'genero', 'municipio', 'estado', 'regimen', 'direccion', 'celular', 'telefono_1', 'telefono_2', 'correo_electronico', 'ID_COD_municipio']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Activos SIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANTES del filtro - Guardar la cantidad inicial\n",
    "registros_iniciales = len(df_ms_sie)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ESTADO ANTES DEL FILTRO\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTotal de registros: {registros_iniciales}\")\n",
    "print(f\"Número de columnas: {len(df_ms_sie.columns)}\")\n",
    "print(f\"\\nDistribución por estado:\")\n",
    "print(df_ms_sie['estado'].value_counts())\n",
    "print(f\"\\nPorcentaje por estado:\")\n",
    "print(df_ms_sie['estado'].value_counts(normalize=True).round(4) * 100)\n",
    "\n",
    "# APLICAR el filtro\n",
    "df_ms_sie = df_ms_sie[df_ms_sie['estado'] == 'Activo']\n",
    "\n",
    "# DESPUÉS del filtro - Calcular registros finales\n",
    "registros_finales = len(df_ms_sie)\n",
    "registros_eliminados = registros_iniciales - registros_finales\n",
    "porcentaje_eliminado = (registros_eliminados / registros_iniciales * 100) if registros_iniciales > 0 else 0\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ESTADO DESPUÉS DEL FILTRO\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTotal de registros: {registros_finales}\")\n",
    "print(f\"Número de columnas: {len(df_ms_sie.columns)}\")\n",
    "print(f\"\\nDistribución por estado:\")\n",
    "print(df_ms_sie['estado'].value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RESUMEN DE CAMBIOS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Registros iniciales:    {registros_iniciales:,}\")\n",
    "print(f\"Registros finales:      {registros_finales:,}\")\n",
    "print(f\"Registros eliminados:   {registros_eliminados:,}\")\n",
    "print(f\"Porcentaje eliminado:   {porcentaje_eliminado:.2f}%\")\n",
    "print(f\"Porcentaje conservado:  {100 - porcentaje_eliminado:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Municipios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validar y reclasificar municipios según código DANE\n",
    "# Solo los municipios de Casanare (código inicia con 85) mantienen su nombre\n",
    "# Los demás se agrupan en \"Otro Departamento\"\n",
    "\n",
    "df_ms_sie['municipio'] = df_ms_sie.apply(\n",
    "    lambda row: row['municipio'] if str(row['ID_COD_municipio']).startswith('85') else 'Otro Departamento',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Verificar los resultados\n",
    "print(\"=== RESUMEN DE RECLASIFICACIÓN DE MUNICIPIOS ===\")\n",
    "print(\"\\nConteo de registros por categoría:\")\n",
    "print(df_ms_sie['municipio'].value_counts())\n",
    "\n",
    "# Mostrar algunos ejemplos de municipios reclasificados\n",
    "print(\"\\n=== EJEMPLOS DE REGISTROS RECLASIFICADOS ===\")\n",
    "otros_dept = df_ms_sie[df_ms_sie['municipio'] == 'Otro Departamento'][['numero_identificacion', 'municipio', 'ID_COD_municipio']].head(10)\n",
    "print(otros_dept.to_string(index=False))\n",
    "\n",
    "print(f\"\\nTotal de registros en 'Otro Departamento': {(df_ms_sie['municipio'] == 'Otro Departamento').sum()}\")\n",
    "print(f\"Total de registros en municipios de Casanare: {(df_ms_sie['municipio'] != 'Otro Departamento').sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Telefono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiar las columnas de teléfonos dejando solo números\n",
    "df_ms_sie['celular'] = df_ms_sie['celular'].str.replace(r'\\D', '', regex=True)\n",
    "df_ms_sie['telefono_1'] = df_ms_sie['telefono_1'].str.replace(r'\\D', '', regex=True)\n",
    "df_ms_sie['telefono_2'] = df_ms_sie['telefono_2'].str.replace(r'\\D', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Definición de Herramientas ---\n",
    "\n",
    "def obtener_estadisticas(df, columnas, etapa):\n",
    "    \"\"\"\n",
    "    Genera un resumen de cuántos registros tienen datos y cuántos son nulos/vacíos.\n",
    "    Aplica el principio DRY (Don't Repeat Yourself).\n",
    "    \"\"\"\n",
    "    metricas = []\n",
    "    for col in columnas:\n",
    "        if col in df.columns:\n",
    "            # Contamos nulos reales (NaN) y cadenas vacías como \"Vacíos\"\n",
    "            total = len(df)\n",
    "            nulos_reales = df[col].isna().sum()\n",
    "            vacios_str = (df[col] == '').sum()\n",
    "            total_vacios = nulos_reales + vacios_str\n",
    "            con_datos = total - total_vacios\n",
    "            \n",
    "            metricas.append({\n",
    "                'Columna': col,\n",
    "                'Etapa': etapa,\n",
    "                'Registros con Datos': con_datos,\n",
    "                'Registros Vacíos': total_vacios,\n",
    "                '% Datos': round((con_datos / total) * 100, 2)\n",
    "            })\n",
    "    return pd.DataFrame(metricas)\n",
    "\n",
    "def validar_telefono_colombia(numero):\n",
    "    \"\"\"\n",
    "    Valida reglas de negocio para celulares en Colombia.\n",
    "    Retorna el número limpio o pd.NA si es inválido.\n",
    "    \"\"\"\n",
    "    # Manejo de nulos inicial\n",
    "    if pd.isna(numero) or numero == '':\n",
    "        return pd.NA  # Retornamos pd.NA directamente para uniformidad\n",
    "    \n",
    "    # Limpieza básica: convertimos a string y quitamos espacios\n",
    "    # OJO: Si hay puntos decimales (ej: 300.0) esto podría fallar, aseguramos int conversion si aplica\n",
    "    try:\n",
    "        if isinstance(numero, float) and numero.is_integer():\n",
    "             numero_str = str(int(numero))\n",
    "        else:\n",
    "             numero_str = str(numero).strip()\n",
    "    except:\n",
    "        return pd.NA\n",
    "\n",
    "    # Reglas de Negocio\n",
    "    # 1. Longitud exacta de 10\n",
    "    if len(numero_str) != 10:\n",
    "        return pd.NA\n",
    "    \n",
    "    # 2. Inicia con 3\n",
    "    if not numero_str.startswith('3'):\n",
    "        return pd.NA\n",
    "    \n",
    "    # 3. No todos los dígitos iguales (ej: 3333333333)\n",
    "    if len(set(numero_str)) == 1:\n",
    "        return pd.NA\n",
    "    \n",
    "    # 4. No patrón repetido después del 3 (ej: 3111111111)\n",
    "    if len(set(numero_str[1:])) == 1:\n",
    "        return pd.NA\n",
    "    \n",
    "    return numero_str\n",
    "\n",
    "# --- 2. Captura de Estado Inicial (ANTES) ---\n",
    "\n",
    "cols_objetivo = ['celular', 'telefono_1', 'telefono_2']\n",
    "# Filtramos solo las que existan en el DF para evitar errores\n",
    "cols_existentes = [c for c in cols_objetivo if c in df_ms_sie.columns]\n",
    "\n",
    "print(\"--- Iniciando proceso de limpieza ---\")\n",
    "stats_antes = obtener_estadisticas(df_ms_sie, cols_existentes, 'ANTES')\n",
    "\n",
    "# --- 3. Ejecución de la Limpieza ---\n",
    "\n",
    "for col in cols_existentes:\n",
    "    # Aplicamos la validación\n",
    "    df_ms_sie[col] = df_ms_sie[col].apply(validar_telefono_colombia)\n",
    "\n",
    "# --- 4. Captura de Estado Final (DESPUÉS) ---\n",
    "\n",
    "stats_despues = obtener_estadisticas(df_ms_sie, cols_existentes, 'DESPUÉS')\n",
    "\n",
    "# --- 5. Reporte Comparativo ---\n",
    "\n",
    "# Unimos los dataframes y calculamos la diferencia (pérdida de datos)\n",
    "reporte = pd.merge(stats_antes, stats_despues, on='Columna', suffixes=('_Antes', '_Despues'))\n",
    "\n",
    "# Calculamos cuántos datos se eliminaron por ser inválidos\n",
    "reporte['Datos Eliminados'] = reporte['Registros con Datos_Antes'] - reporte['Registros con Datos_Despues']\n",
    "\n",
    "# Reordenamos columnas para lectura fácil\n",
    "cols_finales = [\n",
    "    'Columna', \n",
    "    'Registros con Datos_Antes', 'Registros con Datos_Despues', \n",
    "    'Datos Eliminados',\n",
    "    'Registros Vacíos_Antes', 'Registros Vacíos_Despues'\n",
    "]\n",
    "\n",
    "print(\"\\n=== REPORTE DE CALIDAD DE DATOS (TELÉFONOS) ===\")\n",
    "# Usamos to_string para que pandas no oculte filas/columnas si es muy grande\n",
    "print(reporte[cols_finales].to_string(index=False))\n",
    "\n",
    "print(\"\\nProceso finalizado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla con conteos (enteros)\n",
    "campos = ['direccion', 'celular', 'telefono_1', 'telefono_2', 'correo_electronico']\n",
    "datos_conteos = []\n",
    "\n",
    "for campo in campos:\n",
    "    total = len(df_ms_sie)\n",
    "    con_datos = df_ms_sie[campo].notna().sum()\n",
    "    vacios = total - con_datos\n",
    "    datos_conteos.append({\n",
    "        'Campo': campo,\n",
    "        'Registros con Datos': con_datos,\n",
    "        'Registros Vacíos': vacios\n",
    "    })\n",
    "\n",
    "df_conteos = pd.DataFrame(datos_conteos)\n",
    "\n",
    "print(\"=== TABLA DE CONTEOS (ENTEROS) ===\")\n",
    "print(df_conteos.to_string(index=False))\n",
    "\n",
    "# Crear tabla con porcentajes\n",
    "datos_porcentajes = []\n",
    "\n",
    "for campo in campos:\n",
    "    total = len(df_ms_sie)\n",
    "    con_datos = df_ms_sie[campo].notna().sum()\n",
    "    vacios = total - con_datos\n",
    "    pct_con_datos = round((con_datos / total) * 100, 2)\n",
    "    pct_vacios = round((vacios / total) * 100, 2)\n",
    "    datos_porcentajes.append({\n",
    "        'Campo': campo,\n",
    "        'Registros con Datos (%)': pct_con_datos,\n",
    "        'Registros Vacíos (%)': pct_vacios\n",
    "    })\n",
    "\n",
    "df_porcentajes = pd.DataFrame(datos_porcentajes)\n",
    "\n",
    "print(\"\\n=== TABLA DE PORCENTAJES ===\")\n",
    "print(df_porcentajes.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generar_top_telefonos_validos(df):\n",
    "    \"\"\"\n",
    "    Cuenta frecuencias de teléfonos únicos por usuario, filtrando estrictamente\n",
    "    números que no cumplan con la longitud de 10 dígitos.\n",
    "    Optimizado vectorialmente (sin bucles for).\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. 'Derretimos' (melt) el DataFrame: pasamos de 3 columnas a 1 sola columna larga\n",
    "    # Esto pone todos los teléfonos en una sola columna llamada 'numero' manteniendo el índice original\n",
    "    df_long = df.melt(\n",
    "        value_vars=['celular', 'telefono_1', 'telefono_2'], \n",
    "        value_name='numero'\n",
    "    ).dropna(subset=['numero']) # Eliminamos nulos iniciales\n",
    "\n",
    "    # 2. Limpieza de seguridad y Conversión\n",
    "    # Convertimos a string, quitamos espacios y decimales raros (.0) si existen\n",
    "    df_long['numero'] = df_long['numero'].astype(str).str.replace(r'\\.0$', '', regex=True).str.strip()\n",
    "\n",
    "    # 3. FILTRO ESTRICTO (Aquí solucionamos lo del '300')\n",
    "    # Solo dejamos pasar lo que tenga exactamente 10 caracteres\n",
    "    df_long = df_long[df_long['numero'].str.len() == 10]\n",
    "\n",
    "    # 4. Eliminamos duplicados POR USUARIO (por índice)\n",
    "    # Si el usuario 1 tiene el número X en 'celular' y en 'telefono_1', \n",
    "    # aquí nos aseguramos de que solo cuente 1 vez.\n",
    "    # drop_duplicates() sin argumentos mira todas las columnas (índice original + numero)\n",
    "    df_unicos_por_usuario = df_long.loc[~df_long.index.duplicated(keep='first') | ~df_long.duplicated(subset=['numero'], keep=False)]\n",
    "    # Corrección lógica más simple para asegurar unicidad (Index + Valor):\n",
    "    # Reseteamos el index para que el ID del usuario sea una columna, y borramos duplicados de par (ID, Numero)\n",
    "    df_unicos = df_long.reset_index().drop_duplicates(subset=['index', 'numero'])\n",
    "\n",
    "    # 5. Conteo de frecuencias Globales\n",
    "    conteo = df_unicos['numero'].value_counts().reset_index()\n",
    "    conteo.columns = ['Número', 'Cantidad de Usuarios']\n",
    "    \n",
    "    return conteo\n",
    "\n",
    "# --- Ejecución ---\n",
    "\n",
    "print(\"--- Analizando números de teléfono más repetidos ---\")\n",
    "print(\"(Validando estrictamente longitud de 10 dígitos y unicidad por usuario)\")\n",
    "\n",
    "# Obtenemos el conteo global\n",
    "df_frecuencias = generar_top_telefonos_validos(df_ms_sie)\n",
    "\n",
    "# Ordenamos\n",
    "df_frecuencias = df_frecuencias.sort_values('Cantidad de Usuarios', ascending=False)\n",
    "\n",
    "# --- CORRECCIÓN DEL WARNING ---\n",
    "# Usamos .copy() para crear un objeto independiente, no una vista\n",
    "top_10 = df_frecuencias.head(10).copy()\n",
    "\n",
    "print(\"\\n=== TOP 10 NÚMEROS MÁS REPETIDOS ===\")\n",
    "print(top_10.to_string(index=False))\n",
    "\n",
    "# Calcular porcentaje\n",
    "# Ahora podemos modificar 'top_10' tranquilamente porque es una copia independiente\n",
    "total_registros = len(df_ms_sie)\n",
    "top_10['% del Total de Usuarios'] = (top_10['Cantidad de Usuarios'] / total_registros * 100).round(2)\n",
    "\n",
    "print(\"\\n=== TOP 10 CON PORCENTAJES ===\")\n",
    "print(top_10.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Corrreos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# --- 1. Definición de la Lógica de Limpieza ---\n",
    "\n",
    "def validar_correo_electronico(correo):\n",
    "    \"\"\"\n",
    "    Valida estructura y limpia correos.\n",
    "    Protege contra falsos positivos en la lista negra.\n",
    "    Versión mejorada con detección de correos institucionales y basura.\n",
    "    \"\"\"\n",
    "    # Manejo de nulos inicial\n",
    "    if pd.isna(correo) or str(correo).strip() == '':\n",
    "        return pd.NA\n",
    "    \n",
    "    # Normalización: minúsculas y sin espacios\n",
    "    correo_str = str(correo).strip().lower()\n",
    "    \n",
    "    # Lista de correos basura conocidos (Blacklist) - AMPLIADA\n",
    "    correos_basura_exactos = {\n",
    "        # Variantes de \"no tiene\"\n",
    "        'notiene@notiene.com', 'notiene@gmail.com', 'notienecorreo@gmail.com', \n",
    "        'notien@gmail.com', 'notiene@hotmail.com',\n",
    "        \n",
    "        # Variantes de \"sin correo\"\n",
    "        'sincorreo@sincorreo.com', 'sincorreo@gmail.com',\n",
    "        \n",
    "        # Variantes de \"no correo\"\n",
    "        'nocorreo@gmail.com', 'nocorreo@gmial.com', 'nocorreo@hotmail.com',\n",
    "        \n",
    "        # Variantes de \"actualizar\"\n",
    "        'actualizar@actualizar.com', 'actualizar@gmail.com', \n",
    "        'actualizar.actualizar@gmail.com',\n",
    "        \n",
    "        # Correo institucional genérico\n",
    "        'referenciacapresoca@capresoca-casanare.gov.co',\n",
    "        \n",
    "        # Otros comunes\n",
    "        'no tiene', 'sin correo', 'no@correo.com', 'sin@correo.com'\n",
    "    }\n",
    "    \n",
    "    # Prefijos sospechosos (más granular)\n",
    "    prefijos_basura = [\n",
    "        'notiene', 'nocorreo', 'sincorreo', 'no@', 'sin@', \n",
    "        'actualizar', 'notengo', 'referencia'\n",
    "    ]\n",
    "    \n",
    "    # Palabras clave en el usuario (parte antes del @)\n",
    "    palabras_basura_usuario = [\n",
    "        'notiene', 'nocorreo', 'sincorreo', 'actualizar', \n",
    "        'notengo', 'referencia', 'sinmail', 'nocuenta'\n",
    "    ]\n",
    "    \n",
    "    # 1. Chequeo de lista negra EXACTA\n",
    "    if correo_str in correos_basura_exactos:\n",
    "        return pd.NA\n",
    "    \n",
    "    # 2. Extraer usuario y dominio para análisis más profundo\n",
    "    try:\n",
    "        usuario, dominio = correo_str.split('@')\n",
    "    except ValueError:\n",
    "        return pd.NA  # No tiene @ o tiene más de uno\n",
    "    \n",
    "    # 3. Chequeo de palabras basura en el USUARIO\n",
    "    for palabra in palabras_basura_usuario:\n",
    "        if palabra in usuario:\n",
    "            return pd.NA\n",
    "    \n",
    "    # 4. Chequeo de PREFIJOS (más seguro que 'in')\n",
    "    for prefijo in prefijos_basura:\n",
    "        if correo_str.startswith(prefijo):\n",
    "            return pd.NA\n",
    "    \n",
    "    # 5. Validaciones de estructura\n",
    "    # No debe tener comas (error de digitación común)\n",
    "    if ',' in correo_str:\n",
    "        return pd.NA\n",
    "    \n",
    "    # Detectar dominios mal escritos comunes (typos)\n",
    "    dominios_typo = {\n",
    "        'gmial.com': 'gmail.com',  # typo común\n",
    "        'gmai.com': 'gmail.com',\n",
    "        'hotmial.com': 'hotmail.com'\n",
    "    }\n",
    "    \n",
    "    # Si el dominio es un typo conocido, lo marcamos como inválido\n",
    "    # (porque probablemente el correo no funciona)\n",
    "    if dominio in dominios_typo:\n",
    "        return pd.NA\n",
    "    \n",
    "    # 6. Patrón regex estándar (RFC 5322 simplificado)\n",
    "    patron_correo = r'^[a-zA-Z0-9._%-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n",
    "    \n",
    "    if not re.match(patron_correo, correo_str):\n",
    "        return pd.NA\n",
    "    \n",
    "    # 7. Verificación extra de dominio\n",
    "    if '.' not in dominio:\n",
    "        return pd.NA\n",
    "    \n",
    "    # 8. Usuario muy corto (menos de 3 caracteres es sospechoso)\n",
    "    if len(usuario) < 3:\n",
    "        return pd.NA\n",
    "    \n",
    "    return correo_str\n",
    "\n",
    "# --- 2. Captura de Estado Inicial (ANTES) ---\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"LIMPIEZA AVANZADA DE CORREOS ELECTRÓNICOS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n--- Iniciando proceso de limpieza ---\")\n",
    "\n",
    "# Estadísticas ANTES\n",
    "stats_correo_antes = obtener_estadisticas(df_ms_sie, ['correo_electronico'], 'ANTES')\n",
    "\n",
    "# Guardar una muestra de correos sospechosos ANTES de limpiar\n",
    "print(\"\\n--- MUESTRA DE CORREOS SOSPECHOSOS (ANTES DE LIMPIEZA) ---\")\n",
    "correos_actuales = df_ms_sie['correo_electronico'].dropna()\n",
    "if not correos_actuales.empty:\n",
    "    # Buscar correos que contengan palabras sospechosas\n",
    "    patron_sospechoso = r'(notiene|nocorreo|sincorreo|actualizar|referencia)'\n",
    "    correos_sospechosos = correos_actuales[\n",
    "        correos_actuales.str.lower().str.contains(patron_sospechoso, na=False)\n",
    "    ].value_counts().head(20)\n",
    "    \n",
    "    if not correos_sospechosos.empty:\n",
    "        print(f\"\\nSe encontraron {len(correos_sospechosos)} correos sospechosos únicos:\")\n",
    "        print(correos_sospechosos.to_string())\n",
    "    else:\n",
    "        print(\"No se encontraron correos con patrones sospechosos.\")\n",
    "\n",
    "# --- 3. Ejecución de la Limpieza ---\n",
    "\n",
    "print(\"\\n--- Aplicando validaciones y limpieza ---\")\n",
    "df_ms_sie['correo_electronico'] = df_ms_sie['correo_electronico'].apply(validar_correo_electronico)\n",
    "\n",
    "# --- 4. Captura de Estado Final (DESPUÉS) ---\n",
    "\n",
    "stats_correo_despues = obtener_estadisticas(df_ms_sie, ['correo_electronico'], 'DESPUÉS')\n",
    "\n",
    "# --- 5. Reporte Comparativo Detallado ---\n",
    "\n",
    "reporte_correo = pd.merge(\n",
    "    stats_correo_antes, \n",
    "    stats_correo_despues, \n",
    "    on='Columna', \n",
    "    suffixes=('_Antes', '_Despues')\n",
    ")\n",
    "\n",
    "reporte_correo['Datos Eliminados'] = (\n",
    "    reporte_correo['Registros con Datos_Antes'] - \n",
    "    reporte_correo['Registros con Datos_Despues']\n",
    ")\n",
    "\n",
    "# Calcular porcentajes\n",
    "total_registros = len(df_ms_sie)\n",
    "reporte_correo['% Eliminado'] = (\n",
    "    reporte_correo['Datos Eliminados'] / \n",
    "    reporte_correo['Registros con Datos_Antes'] * 100\n",
    ").round(2)\n",
    "\n",
    "# Columnas finales\n",
    "cols_finales_correo = [\n",
    "    'Columna', \n",
    "    'Registros con Datos_Antes', \n",
    "    'Registros con Datos_Despues', \n",
    "    'Datos Eliminados',\n",
    "    '% Eliminado',\n",
    "    'Registros Vacíos_Antes', \n",
    "    'Registros Vacíos_Despues'\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"REPORTE DE CALIDAD DE DATOS (CORREO ELECTRÓNICO)\")\n",
    "print(\"=\" * 70)\n",
    "print(reporte_correo[cols_finales_correo].to_string(index=False))\n",
    "\n",
    "# --- 6. Desglose de Tipos de Correos Eliminados ---\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RESUMEN DE NORMALIZACIÓN\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "datos_eliminados = reporte_correo['Datos Eliminados'].iloc[0]\n",
    "pct_eliminado = reporte_correo['% Eliminado'].iloc[0]\n",
    "\n",
    "print(f\"\\nCorreos eliminados/convertidos a vacío: {int(datos_eliminados):,}\")\n",
    "print(f\"Porcentaje de correos basura eliminados: {pct_eliminado:.2f}%\")\n",
    "\n",
    "# Categorías de correos eliminados (estimación basada en patrones)\n",
    "print(\"\\n--- CATEGORÍAS DE CORREOS ELIMINADOS ---\")\n",
    "categorias = {\n",
    "    'Variantes de \"no tiene/correo\"': ['notiene', 'nocorreo', 'notien'],\n",
    "    'Variantes de \"sin correo\"': ['sincorreo'],\n",
    "    'Variantes de \"actualizar\"': ['actualizar'],\n",
    "    'Correos institucionales genéricos': ['referencia', 'capresoca'],\n",
    "    'Dominios con typos': ['gmial', 'hotmial'],\n",
    "    'Formato inválido': ['sin @', 'sin dominio', 'muy corto']\n",
    "}\n",
    "\n",
    "for categoria, patrones in categorias.items():\n",
    "    print(f\"  - {categoria}: Incluye patrones como {', '.join(patrones[:2])}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Proceso finalizado exitosamente.\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generar_top_correos_validos(df):\n",
    "    \"\"\"\n",
    "    Cuenta frecuencias de correos electrónicos únicos por usuario.\n",
    "    Optimizado vectorialmente (sin bucles for).\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Extraemos solo la columna 'correo_electronico'\n",
    "    df_correos = df[['correo_electronico']].copy()\n",
    "    \n",
    "    # 2. Eliminamos nulos y valores vacíos\n",
    "    df_correos = df_correos.dropna(subset=['correo_electronico'])\n",
    "    \n",
    "    # 3. Normalización: convertimos a minúsculas y quitamos espacios extra\n",
    "    df_correos['correo_limpio'] = (\n",
    "        df_correos['correo_electronico']\n",
    "        .str.lower()\n",
    "        .str.strip()\n",
    "    )\n",
    "    \n",
    "    # 4. Filtramos correos vacíos después de la normalización\n",
    "    df_correos = df_correos[df_correos['correo_limpio'] != '']\n",
    "    \n",
    "    # 5. Conteo de frecuencias\n",
    "    conteo = df_correos['correo_limpio'].value_counts().reset_index()\n",
    "    conteo.columns = ['Correo Electrónico', 'Cantidad de Usuarios']\n",
    "    \n",
    "    return conteo\n",
    "\n",
    "# --- Ejecución ---\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ANÁLISIS DE CORREOS ELECTRÓNICOS MÁS REPETIDOS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Obtenemos el conteo global\n",
    "df_frecuencias_correo = generar_top_correos_validos(df_ms_sie)\n",
    "\n",
    "# --- CORRECCIÓN DEL WARNING ---\n",
    "# Usamos .copy() para crear un objeto independiente, no una vista\n",
    "top_10_correos = df_frecuencias_correo.head(10).copy()\n",
    "\n",
    "print(\"\\n=== TOP 10 CORREOS MÁS REPETIDOS ===\")\n",
    "print(top_10_correos.to_string(index=False))\n",
    "\n",
    "# Calcular porcentaje\n",
    "total_registros = len(df_ms_sie)\n",
    "top_10_correos['% del Total de Usuarios'] = (\n",
    "    top_10_correos['Cantidad de Usuarios'] / total_registros * 100\n",
    ").round(2)\n",
    "\n",
    "print(\"\\n=== TOP 10 CON PORCENTAJES ===\")\n",
    "print(top_10_correos.to_string(index=False))\n",
    "\n",
    "# Estadísticas adicionales\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ESTADÍSTICAS ADICIONALES\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total de registros en el dataset: {total_registros:,}\")\n",
    "print(f\"Correos únicos encontrados: {len(df_frecuencias_correo):,}\")\n",
    "print(f\"Registros con correo válido: {df_frecuencias_correo['Cantidad de Usuarios'].sum():,}\")\n",
    "print(f\"Registros sin correo: {total_registros - df_frecuencias_correo['Cantidad de Usuarios'].sum():,}\")\n",
    "\n",
    "# Análisis de dominios más comunes\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TOP 10 DOMINIOS MÁS USADOS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Extraer dominios de los correos\n",
    "df_frecuencias_correo['Dominio'] = df_frecuencias_correo['Correo Electrónico'].str.split('@').str[1]\n",
    "dominios_top = df_frecuencias_correo.groupby('Dominio')['Cantidad de Usuarios'].sum().sort_values(ascending=False).head(10)\n",
    "\n",
    "for i, (dominio, count) in enumerate(dominios_top.items(), 1):\n",
    "    pct = (count / total_registros) * 100\n",
    "    print(f\"{i:2d}. {dominio:30s} | {count:6,} usuarios ({pct:5.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Direcciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def limpiar_direcciones_ruido(df):\n",
    "    \"\"\"\n",
    "    Limpia direcciones que son ruido o información no útil.\n",
    "    Convierte a NaN las direcciones que no aportan valor.\n",
    "    \"\"\"\n",
    "    # Lista de valores que se consideran \"ruido\" o no informativos\n",
    "    valores_ruido = {\n",
    "        'ACTUALIZAR', 'CENTRO', 'NO TIENE', 'N', 'NO', 'SIN DIRECCION',\n",
    "        'SIN DIRECCIÓN', 'NINGUNA', 'NO REGISTRA', 'NO APLICA', 'N/A',\n",
    "        'NA', 'DESCONOCIDO', 'DESCONOCIDA', 'NO SABE', '.', '-', 'X'\n",
    "    }\n",
    "    \n",
    "    # Función para validar cada dirección\n",
    "    def validar_direccion(direccion):\n",
    "        # Si es nulo, mantener nulo\n",
    "        if pd.isna(direccion):\n",
    "            return pd.NA\n",
    "        \n",
    "        # Normalizar: mayúsculas y sin espacios extra\n",
    "        dir_limpia = str(direccion).strip().upper()\n",
    "        \n",
    "        # Si está vacío después de limpiar\n",
    "        if dir_limpia == '':\n",
    "            return pd.NA\n",
    "        \n",
    "        # Si está en la lista de ruido\n",
    "        if dir_limpia in valores_ruido:\n",
    "            return pd.NA\n",
    "        \n",
    "        # Si es muy corto (menos de 3 caracteres) probablemente no es una dirección real\n",
    "        if len(dir_limpia) < 3:\n",
    "            return pd.NA\n",
    "        \n",
    "        # Si solo contiene puntos, guiones o espacios\n",
    "        if all(c in '.- ' for c in dir_limpia):\n",
    "            return pd.NA\n",
    "        \n",
    "        # Si pasó todas las validaciones, mantener la dirección normalizada\n",
    "        return dir_limpia\n",
    "    \n",
    "    return df['direccion'].apply(validar_direccion)\n",
    "\n",
    "# --- ANÁLISIS ANTES DE LA LIMPIEZA ---\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"LIMPIEZA DE DIRECCIONES CON RUIDO\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Capturar estado inicial\n",
    "registros_totales = len(df_ms_sie)\n",
    "direcciones_antes = df_ms_sie['direccion'].notna().sum()\n",
    "direcciones_vacias_antes = df_ms_sie['direccion'].isna().sum()\n",
    "\n",
    "print(\"\\n--- ESTADO ANTES DE LA LIMPIEZA ---\")\n",
    "print(f\"Total de registros: {registros_totales:,}\")\n",
    "print(f\"Direcciones con datos: {direcciones_antes:,} ({direcciones_antes/registros_totales*100:.2f}%)\")\n",
    "print(f\"Direcciones vacías: {direcciones_vacias_antes:,} ({direcciones_vacias_antes/registros_totales*100:.2f}%)\")\n",
    "\n",
    "# Mostrar ejemplos de direcciones sospechosas (antes de limpiar)\n",
    "print(\"\\n--- MUESTRA DE DIRECCIONES SOSPECHOSAS (ANTES) ---\")\n",
    "direcciones_cortas = df_ms_sie[df_ms_sie['direccion'].str.len() < 10]['direccion'].value_counts().head(15)\n",
    "if not direcciones_cortas.empty:\n",
    "    print(direcciones_cortas.to_string())\n",
    "else:\n",
    "    print(\"No se encontraron direcciones cortas.\")\n",
    "\n",
    "# --- APLICAR LA LIMPIEZA ---\n",
    "\n",
    "df_ms_sie['direccion'] = limpiar_direcciones_ruido(df_ms_sie)\n",
    "\n",
    "# --- ANÁLISIS DESPUÉS DE LA LIMPIEZA ---\n",
    "\n",
    "direcciones_despues = df_ms_sie['direccion'].notna().sum()\n",
    "direcciones_vacias_despues = df_ms_sie['direccion'].isna().sum()\n",
    "direcciones_normalizadas = direcciones_antes - direcciones_despues\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"--- ESTADO DESPUÉS DE LA LIMPIEZA ---\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total de registros: {registros_totales:,}\")\n",
    "print(f\"Direcciones con datos: {direcciones_despues:,} ({direcciones_despues/registros_totales*100:.2f}%)\")\n",
    "print(f\"Direcciones vacías: {direcciones_vacias_despues:,} ({direcciones_vacias_despues/registros_totales*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"--- RESUMEN DE NORMALIZACIÓN ---\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Direcciones antes de limpiar:    {direcciones_antes:,}\")\n",
    "print(f\"Direcciones después de limpiar:  {direcciones_despues:,}\")\n",
    "print(f\"Direcciones convertidas a vacío: {direcciones_normalizadas:,}\")\n",
    "print(f\"Porcentaje de ruido eliminado:   {direcciones_normalizadas/direcciones_antes*100:.2f}%\" if direcciones_antes > 0 else \"N/A\")\n",
    "\n",
    "# Mostrar las 20 direcciones más comunes después de la limpieza\n",
    "print(\"\\n--- TOP 20 DIRECCIONES MÁS COMUNES (DESPUÉS DE LIMPIEZA) ---\")\n",
    "top_direcciones_limpias = df_ms_sie['direccion'].value_counts().head(20)\n",
    "if not top_direcciones_limpias.empty:\n",
    "    for i, (direccion, count) in enumerate(top_direcciones_limpias.items(), 1):\n",
    "        pct = (count / registros_totales) * 100\n",
    "        print(f\"{i:2d}. {direccion[:50]:50s} | {count:6,} ({pct:5.2f}%)\")\n",
    "else:\n",
    "    print(\"No hay direcciones válidas después de la limpieza.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generar_top_direcciones_validas(df):\n",
    "    \"\"\"\n",
    "    Cuenta frecuencias de direcciones únicas.\n",
    "    Optimizado vectorialmente (sin bucles for).\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Extraemos solo la columna 'direccion'\n",
    "    df_direcciones = df[['direccion']].copy()\n",
    "    \n",
    "    # 2. Eliminamos nulos y valores vacíos\n",
    "    df_direcciones = df_direcciones.dropna(subset=['direccion'])\n",
    "    df_direcciones = df_direcciones[df_direcciones['direccion'].str.strip() != '']\n",
    "    \n",
    "    # 3. Normalización básica (opcional pero recomendado)\n",
    "    # Convertimos a mayúsculas y quitamos espacios extra\n",
    "    df_direcciones['direccion_limpia'] = (\n",
    "        df_direcciones['direccion']\n",
    "        .str.upper()\n",
    "        .str.strip()\n",
    "        .str.replace(r'\\s+', ' ', regex=True)  # Múltiples espacios a uno solo\n",
    "    )\n",
    "    \n",
    "    # 4. Conteo de frecuencias\n",
    "    conteo = df_direcciones['direccion_limpia'].value_counts().reset_index()\n",
    "    conteo.columns = ['Dirección', 'Cantidad de Usuarios']\n",
    "    \n",
    "    return conteo\n",
    "\n",
    "# --- Ejecución ---\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ANÁLISIS DE DIRECCIONES MÁS REPETIDAS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Obtenemos el conteo global\n",
    "df_frecuencias_dir = generar_top_direcciones_validas(df_ms_sie)\n",
    "\n",
    "# --- CORRECCIÓN DEL WARNING ---\n",
    "# Usamos .copy() para crear un objeto independiente, no una vista\n",
    "top_10_direcciones = df_frecuencias_dir.head(10).copy()\n",
    "\n",
    "print(\"\\n=== TOP 10 DIRECCIONES MÁS REPETIDAS ===\")\n",
    "print(top_10_direcciones.to_string(index=False))\n",
    "\n",
    "# Calcular porcentaje\n",
    "total_registros = len(df_ms_sie)\n",
    "top_10_direcciones['% del Total de Usuarios'] = (\n",
    "    top_10_direcciones['Cantidad de Usuarios'] / total_registros * 100\n",
    ").round(2)\n",
    "\n",
    "print(\"\\n=== TOP 10 CON PORCENTAJES ===\")\n",
    "print(top_10_direcciones.to_string(index=False))\n",
    "\n",
    "# Estadísticas adicionales\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ESTADÍSTICAS ADICIONALES\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total de registros en el dataset: {total_registros:,}\")\n",
    "print(f\"Direcciones únicas encontradas: {len(df_frecuencias_dir):,}\")\n",
    "print(f\"Registros con dirección válida: {df_frecuencias_dir['Cantidad de Usuarios'].sum():,}\")\n",
    "print(f\"Registros sin dirección: {total_registros - df_frecuencias_dir['Cantidad de Usuarios'].sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "# Graficas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- Cálculo de datos ---\n",
    "campos = ['direccion', 'celular', 'telefono_1', 'telefono_2', 'correo_electronico']\n",
    "\n",
    "resumen = df_ms_sie[campos].notna().agg(['sum', 'count']).T\n",
    "resumen.columns = ['Con Datos', 'Total']\n",
    "resumen['Vacíos'] = resumen['Total'] - resumen['Con Datos']\n",
    "resumen['% Con Datos'] = (resumen['Con Datos'] / resumen['Total']) * 100\n",
    "resumen['% Vacíos'] = (resumen['Vacíos'] / resumen['Total']) * 100\n",
    "resumen = resumen.sort_values('% Con Datos', ascending=False)\n",
    "\n",
    "print(\"--- Resumen de Calidad ---\")\n",
    "print(resumen)\n",
    "\n",
    "# --- Visualización Mejorada ---\n",
    "\n",
    "def graficar_completitud(df_resumen):\n",
    "    \"\"\"\n",
    "    Genera un gráfico de barras apiladas mostrando la completitud de los datos\n",
    "    con valores enteros y porcentajes.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    \n",
    "    # Definimos los ejes\n",
    "    campos = df_resumen.index\n",
    "    con_datos = df_resumen['% Con Datos']\n",
    "    vacios = df_resumen['% Vacíos']\n",
    "    \n",
    "    # Valores enteros\n",
    "    con_datos_int = df_resumen['Con Datos']\n",
    "    vacios_int = df_resumen['Vacíos']\n",
    "    \n",
    "    # Colores semánticos\n",
    "    color_datos = '#2ecc71'  # Verde esmeralda\n",
    "    color_vacio = '#95a5a6'  # Gris concreto\n",
    "    \n",
    "    # Crear las barras\n",
    "    bar1 = ax.bar(campos, con_datos, label='Con Datos', color=color_datos, edgecolor='white', linewidth=2)\n",
    "    bar2 = ax.bar(campos, vacios, bottom=con_datos, label='Vacíos', color=color_vacio, edgecolor='white', linewidth=2)\n",
    "    \n",
    "    # Añadir etiquetas con valores enteros Y porcentajes\n",
    "    for i, (rect_datos, rect_vacios) in enumerate(zip(bar1, bar2)):\n",
    "        # Para la sección \"Con Datos\" (verde)\n",
    "        height_datos = rect_datos.get_height()\n",
    "        if height_datos > 5:\n",
    "            valor_int = int(con_datos_int.iloc[i])\n",
    "            pct = height_datos\n",
    "            label_text = f'{valor_int:,}\\n({pct:.1f}%)'\n",
    "            ax.text(\n",
    "                rect_datos.get_x() + rect_datos.get_width()/2,\n",
    "                rect_datos.get_y() + height_datos/2,\n",
    "                label_text,\n",
    "                ha='center', va='center',\n",
    "                color='white', fontweight='bold',\n",
    "                fontsize=10\n",
    "            )\n",
    "        \n",
    "        # Para la sección \"Vacíos\" (gris)\n",
    "        height_vacios = rect_vacios.get_height()\n",
    "        if height_vacios > 5:\n",
    "            valor_int = int(vacios_int.iloc[i])\n",
    "            pct = height_vacios\n",
    "            label_text = f'{valor_int:,}\\n({pct:.1f}%)'\n",
    "            ax.text(\n",
    "                rect_vacios.get_x() + rect_vacios.get_width()/2,\n",
    "                rect_vacios.get_y() + height_vacios/2,\n",
    "                label_text,\n",
    "                ha='center', va='center',\n",
    "                color='white', fontweight='bold',\n",
    "                fontsize=10\n",
    "            )\n",
    "\n",
    "    # Personalización del gráfico\n",
    "    ax.set_ylabel('Porcentaje de Completitud (%)', fontsize=11, fontweight='bold')\n",
    "    ax.set_xlabel('Campos de Contacto', fontsize=11, fontweight='bold')\n",
    "    ax.set_title('Calidad de Datos: Disponibilidad de Información por Campo', \n",
    "                 pad=20, fontweight='bold', fontsize=14)\n",
    "    \n",
    "    # Mejorar la leyenda\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.08), \n",
    "              ncol=2, frameon=True, shadow=True, fontsize=10)\n",
    "    \n",
    "    # Eliminar bordes innecesarios\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_color('#CCCCCC')\n",
    "    ax.spines['bottom'].set_color('#CCCCCC')\n",
    "    \n",
    "    # Cuadrícula suave\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.3, color='gray')\n",
    "    ax.set_axisbelow(True)\n",
    "    \n",
    "    # Ajustar límites del eje Y\n",
    "    ax.set_ylim(0, 105)\n",
    "    \n",
    "    # Rotar etiquetas del eje X si es necesario\n",
    "    plt.xticks(rotation=15, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Guardar o mostrar\n",
    "    # plt.savefig('calidad_datos_resumen_mejorado.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"\\nGráfico generado exitosamente.\")\n",
    "    plt.show()\n",
    "\n",
    "# Ejecutar la función\n",
    "graficar_completitud(resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## Top 10 telefonos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- VISUALIZACIÓN DE RESULTADOS ---\n",
    "\n",
    "# Validación de seguridad: Solo graficamos si hay datos\n",
    "if not top_10.empty:\n",
    "    \n",
    "    # Configuración del estilo para reporte profesional\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Crear el gráfico de barras horizontales\n",
    "    # Usamos viridis_r para que el #1 tenga el color más intenso\n",
    "    ax = sns.barplot(\n",
    "        data=top_10,\n",
    "        x='Cantidad de Usuarios',\n",
    "        y='Número',\n",
    "        palette='viridis_r'\n",
    "    )\n",
    "\n",
    "    # Títulos y Etiquetas\n",
    "    plt.title(f'Top 10 Números de Teléfono Más Repetidos\\n(Total Registros Analizados: {total_registros})', \n",
    "              fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Cantidad de Usuarios Únicos', fontsize=11)\n",
    "    plt.ylabel('Número Telefónico', fontsize=11)\n",
    "\n",
    "    # Añadir las anotaciones (Count y Porcentaje) al final de cada barra\n",
    "    for i, p in enumerate(ax.patches):\n",
    "        # Obtener el ancho de la barra (que es el valor de x)\n",
    "        width = p.get_width()\n",
    "        \n",
    "        # Recuperar el porcentaje correspondiente desde el DataFrame\n",
    "        pct = top_10.iloc[i]['% del Total de Usuarios']\n",
    "        \n",
    "        # Formatear el texto: \" 150 (5.2%)\"\n",
    "        etiqueta = f' {int(width)} ({pct}%)'\n",
    "        \n",
    "        # Colocar el texto un poco a la derecha del final de la barra\n",
    "        ax.text(width, p.get_y() + p.get_height() / 2, etiqueta, \n",
    "                ha='left', va='center', fontweight='bold', color='#333333')\n",
    "\n",
    "    # Ajustes finales de limpieza visual\n",
    "    sns.despine(left=True, bottom=True) # Quitar bordes innecesarios\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Guardar y Mostrar\n",
    "    #plt.savefig('top_10_telefonos_repetidos.png', dpi=300)\n",
    "    print(\"\\nGráfico generado exitosamente: 'top_10_telefonos_repetidos.png'\")\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"\\n[!] No hay datos para graficar. El DataFrame 'top_10' está vacío.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## % vacios por muniicpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- PREPARACIÓN DE DATOS PARA MAPA DE CALOR ---\n",
    "\n",
    "campos_analizar = ['direccion', 'celular', 'telefono_1', 'telefono_2', 'correo_electronico']\n",
    "\n",
    "# Crear DataFrame con CONTEOS de vacíos por municipio\n",
    "df_conteos = df_ms_sie.groupby('municipio').agg({\n",
    "    **{campo: lambda x: x.isna().sum() for campo in campos_analizar},\n",
    "    'municipio': 'count'\n",
    "}).rename(columns={'municipio': 'Total Registros'})\n",
    "\n",
    "# Crear DataFrame con PORCENTAJES de vacíos por municipio\n",
    "df_porcentajes = df_ms_sie.groupby('municipio').agg({\n",
    "    **{campo: lambda x: x.isna().mean() * 100 for campo in campos_analizar},\n",
    "}).round(1)\n",
    "\n",
    "# Ordenar por total de registros\n",
    "df_conteos = df_conteos.sort_values('Total Registros', ascending=False)\n",
    "df_porcentajes = df_porcentajes.loc[df_conteos.index]\n",
    "\n",
    "# Calcular totales por columna y fila\n",
    "totales_por_campo = df_conteos[campos_analizar].sum()\n",
    "pct_por_campo = (totales_por_campo / df_conteos['Total Registros'].sum() * 100).round(1)\n",
    "df_conteos['Total Vacíos'] = df_conteos[campos_analizar].sum(axis=1)\n",
    "df_conteos['Promedio %'] = df_porcentajes[campos_analizar].mean(axis=1).round(1)\n",
    "\n",
    "# Preparar matrices\n",
    "matriz_calor = df_porcentajes\n",
    "matriz_conteos = df_conteos[campos_analizar]\n",
    "\n",
    "# --- CREAR ANOTACIONES PERSONALIZADAS (PORCENTAJE + CONTEO) ---\n",
    "\n",
    "# Crear matriz de anotaciones con formato: \"66.5%\\n(36,123)\"\n",
    "anotaciones = np.empty(matriz_calor.shape, dtype=object)\n",
    "\n",
    "for i in range(matriz_calor.shape[0]):\n",
    "    for j in range(matriz_calor.shape[1]):\n",
    "        pct = matriz_calor.iloc[i, j]\n",
    "        count = int(matriz_conteos.iloc[i, j])\n",
    "        anotaciones[i, j] = f'{pct:.1f}%\\n({count:,})'\n",
    "\n",
    "# --- VISUALIZACIÓN ---\n",
    "\n",
    "altura = max(12, len(matriz_calor) * 0.5)\n",
    "fig, ax = plt.subplots(figsize=(18, altura))\n",
    "\n",
    "# Crear el mapa de calor con anotaciones personalizadas\n",
    "sns.heatmap(\n",
    "    matriz_calor,\n",
    "    annot=anotaciones,\n",
    "    fmt='',  # Importante: formato vacío porque usamos strings personalizados\n",
    "    cmap='RdYlGn_r',\n",
    "    cbar_kws={\n",
    "        'label': '% de Registros Vacíos',\n",
    "        'shrink': 0.8,\n",
    "        'aspect': 30\n",
    "    },\n",
    "    linewidths=1.5,\n",
    "    linecolor='white',\n",
    "    vmin=0,\n",
    "    vmax=100,\n",
    "    annot_kws={'fontsize': 7, 'fontweight': 'bold'},\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# --- COLUMNA DE TOTALES POR FILA ---\n",
    "for i, (idx, row) in enumerate(df_conteos.iterrows()):\n",
    "    total_registros = int(row['Total Registros'])\n",
    "    total_vacios = int(row['Total Vacíos'])\n",
    "    promedio_pct = row['Promedio %']\n",
    "    \n",
    "    texto = f'{total_registros:,}\\n({total_vacios:,})\\n{promedio_pct:.1f}%'\n",
    "    \n",
    "    ax.text(\n",
    "        len(campos_analizar) + 0.5, i + 0.5, texto,\n",
    "        ha='center', va='center', fontsize=7, fontweight='bold',\n",
    "        bbox=dict(boxstyle='round,pad=0.3', facecolor='lightgray', alpha=0.5)\n",
    "    )\n",
    "\n",
    "# Encabezado columna totales\n",
    "ax.text(\n",
    "    len(campos_analizar) + 0.5, -0.5,\n",
    "    'Total Registros\\n(Total Vacíos)\\nPromedio %',\n",
    "    ha='center', va='center', fontsize=8, fontweight='bold',\n",
    "    bbox=dict(boxstyle='round,pad=0.3', facecolor='lightblue', alpha=0.7)\n",
    ")\n",
    "\n",
    "# --- FILA DE TOTALES POR COLUMNA ---\n",
    "for j, campo in enumerate(campos_analizar):\n",
    "    total_vacios_campo = int(totales_por_campo[campo])\n",
    "    pct_campo = pct_por_campo[campo]\n",
    "    \n",
    "    texto = f'{total_vacios_campo:,}\\n({pct_campo:.1f}%)'\n",
    "    \n",
    "    ax.text(\n",
    "        j + 0.5, len(matriz_calor) + 0.5, texto,\n",
    "        ha='center', va='center', fontsize=8, fontweight='bold',\n",
    "        bbox=dict(boxstyle='round,pad=0.3', facecolor='lightyellow', alpha=0.5)\n",
    "    )\n",
    "\n",
    "# Etiqueta fila totales\n",
    "ax.text(\n",
    "    -0.5, len(matriz_calor) + 0.5,\n",
    "    'TOTAL POR CAMPO\\n(Vacíos y %)',\n",
    "    ha='right', va='center', fontsize=8, fontweight='bold',\n",
    "    bbox=dict(boxstyle='round,pad=0.3', facecolor='lightyellow', alpha=0.7)\n",
    ")\n",
    "\n",
    "# Celda resumen general\n",
    "total_general = df_conteos['Total Registros'].sum()\n",
    "total_vacios_general = df_conteos['Total Vacíos'].sum()\n",
    "pct_general = (total_vacios_general / (total_general * len(campos_analizar)) * 100).round(1)\n",
    "\n",
    "ax.text(\n",
    "    len(campos_analizar) + 0.5, len(matriz_calor) + 0.5,\n",
    "    f'TOTAL\\n{total_vacios_general:,}\\n({pct_general:.1f}%)',\n",
    "    ha='center', va='center', fontsize=8, fontweight='bold',\n",
    "    bbox=dict(boxstyle='round,pad=0.3', facecolor='lightcoral', alpha=0.5)\n",
    ")\n",
    "\n",
    "# Títulos y etiquetas\n",
    "plt.title(\n",
    "    'Mapa de Calor: Datos Vacíos por Municipio (Porcentaje y Cantidad)\\n' + \n",
    "    f'Total de Municipios: {len(matriz_calor)} | Total de Registros: {total_general:,}',\n",
    "    fontsize=14, fontweight='bold', pad=20\n",
    ")\n",
    "plt.xlabel('Campos de Contacto', fontsize=11, fontweight='bold')\n",
    "plt.ylabel('Municipio', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "plt.yticks(rotation=0, fontsize=9)\n",
    "\n",
    "ax.set_xlim(0, len(campos_analizar) + 1)\n",
    "ax.set_ylim(0, len(matriz_calor) + 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MAPA DE CALOR GENERADO CON PORCENTAJES Y CONTEOS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nEjemplo de lectura:\")\n",
    "print(\"Celda 'Yopal - correo_electronico': '66.5%\\\\n(36,123)'\")\n",
    "print(\"  → Significa: 66.5% de registros de Yopal no tienen correo\")\n",
    "print(\"  → Equivale a: 36,123 registros sin correo electrónico\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## % por Regimen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Preparación de Datos (Clean Code) ---\n",
    "campos_analizar = ['direccion', 'celular', 'telefono_1', 'telefono_2', 'correo_electronico']\n",
    "\n",
    "# Calculamos PORCENTAJES de vacíos\n",
    "df_resumen_pct = df_ms_sie.groupby('regimen')[campos_analizar].apply(\n",
    "    lambda x: x.isna().mean() * 100\n",
    ").reset_index()\n",
    "\n",
    "# Calculamos CONTEOS (enteros) de vacíos\n",
    "df_resumen_count = df_ms_sie.groupby('regimen')[campos_analizar].apply(\n",
    "    lambda x: x.isna().sum()\n",
    ").reset_index()\n",
    "\n",
    "# Obtener totales por régimen para referencia\n",
    "totales_por_regimen = df_ms_sie.groupby('regimen').size().to_dict()\n",
    "\n",
    "# Transformamos para gráfico\n",
    "df_melted_pct = df_resumen_pct.melt(\n",
    "    id_vars='regimen', \n",
    "    value_vars=campos_analizar, \n",
    "    var_name='Campo', \n",
    "    value_name='Porcentaje_Vacios'\n",
    ")\n",
    "\n",
    "df_melted_count = df_resumen_count.melt(\n",
    "    id_vars='regimen', \n",
    "    value_vars=campos_analizar, \n",
    "    var_name='Campo', \n",
    "    value_name='Cantidad_Vacios'\n",
    ")\n",
    "\n",
    "# Unimos ambos DataFrames\n",
    "df_melted = df_melted_pct.merge(df_melted_count, on=['regimen', 'Campo'])\n",
    "\n",
    "# --- 2. Visualización Profesional ---\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Creamos el Gráfico de Barras Agrupadas\n",
    "ax = sns.barplot(\n",
    "    data=df_melted,\n",
    "    x='Campo',\n",
    "    y='Porcentaje_Vacios',\n",
    "    hue='regimen',\n",
    "    palette='viridis',\n",
    "    edgecolor='white',\n",
    "    linewidth=1.5\n",
    ")\n",
    "\n",
    "# --- 3. Personalización y Etiquetas ---\n",
    "\n",
    "plt.title('Calidad de Datos: Comparativa de Vacíos por Régimen\\n(Porcentaje y Cantidad Absoluta)', \n",
    "          fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylabel('% de Registros Vacíos (Menos es Mejor)', fontsize=12)\n",
    "plt.xlabel('Campos de Contacto', fontsize=12)\n",
    "\n",
    "# Ajuste del eje Y\n",
    "plt.ylim(0, 115)\n",
    "\n",
    "# Leyenda\n",
    "plt.legend(title='Régimen', title_fontsize='11', fontsize='10', \n",
    "           loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=2, frameon=False)\n",
    "\n",
    "# --- 4. Etiquetas de Datos PERSONALIZADAS (Porcentaje + Conteo) ---\n",
    "\n",
    "# Iteramos sobre cada contenedor (cada régimen)\n",
    "for container in ax.containers:\n",
    "    # Obtenemos las etiquetas personalizadas\n",
    "    labels = []\n",
    "    \n",
    "    for bar in container:\n",
    "        # Obtenemos la altura de la barra (porcentaje)\n",
    "        height = bar.get_height()\n",
    "        \n",
    "        # Obtenemos la posición x de la barra\n",
    "        x_pos = bar.get_x() + bar.get_width() / 2\n",
    "        \n",
    "        # Determinamos el campo y régimen correspondiente\n",
    "        # (Seaborn organiza las barras en orden)\n",
    "        bar_index = container.index(bar)\n",
    "        \n",
    "        # Buscamos el conteo correspondiente en df_melted\n",
    "        # Filtramos por la posición relativa\n",
    "        try:\n",
    "            # Obtenemos el índice correcto del dataframe melted\n",
    "            regimen_idx = ax.containers.index(container)\n",
    "            campo_idx = bar_index\n",
    "            \n",
    "            # Calculamos el índice en df_melted\n",
    "            df_idx = regimen_idx * len(campos_analizar) + campo_idx\n",
    "            \n",
    "            if df_idx < len(df_melted):\n",
    "                cantidad = int(df_melted.iloc[df_idx]['Cantidad_Vacios'])\n",
    "                label = f'{height:.1f}%\\n({cantidad:,})'\n",
    "            else:\n",
    "                label = f'{height:.1f}%'\n",
    "        except:\n",
    "            label = f'{height:.1f}%'\n",
    "        \n",
    "        labels.append(label)\n",
    "    \n",
    "    # Aplicamos las etiquetas\n",
    "    ax.bar_label(container, labels=labels, padding=3, fontsize=8, fontweight='bold')\n",
    "\n",
    "# Limpieza final\n",
    "sns.despine(left=True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# --- 5. Reportes en Consola ---\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RESUMEN DE VACÍOS POR RÉGIMEN\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Mostrar tabla con porcentajes\n",
    "print(\"\\n--- PORCENTAJES DE VACÍOS (%) ---\")\n",
    "print(df_resumen_pct.to_string(index=False))\n",
    "\n",
    "# Mostrar tabla con conteos\n",
    "print(\"\\n--- CANTIDAD DE REGISTROS VACÍOS (Enteros) ---\")\n",
    "print(df_resumen_count.to_string(index=False))\n",
    "\n",
    "# Totales por régimen\n",
    "print(\"\\n--- TOTAL DE REGISTROS POR RÉGIMEN ---\")\n",
    "for regimen, total in totales_por_regimen.items():\n",
    "    print(f\"{regimen}: {total:,} registros\")\n",
    "\n",
    "# Análisis comparativo\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANÁLISIS COMPARATIVO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for campo in campos_analizar:\n",
    "    print(f\"\\n{campo.upper()}:\")\n",
    "    for regimen in df_resumen_pct['regimen'].unique():\n",
    "        pct = df_resumen_pct[df_resumen_pct['regimen'] == regimen][campo].values[0]\n",
    "        count = df_resumen_count[df_resumen_count['regimen'] == regimen][campo].values[0]\n",
    "        total = totales_por_regimen[regimen]\n",
    "        \n",
    "        print(f\"  {regimen:20s} | {pct:5.1f}% vacío | {int(count):6,} registros | de {total:,} total\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Gráfico generado exitosamente\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## top 10 dirección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- VISUALIZACIÓN DE DIRECCIONES MÁS REPETIDAS ---\n",
    "\n",
    "# Validación de seguridad: Solo graficamos si hay datos\n",
    "if not top_10_direcciones.empty:\n",
    "    \n",
    "    # Configuración del estilo para reporte profesional\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(14, 8))  # Más alto para direcciones largas\n",
    "\n",
    "    # Crear el gráfico de barras horizontales\n",
    "    ax = sns.barplot(\n",
    "        data=top_10_direcciones,\n",
    "        x='Cantidad de Usuarios',\n",
    "        y='Dirección',\n",
    "        palette='viridis_r',\n",
    "        orient='h'\n",
    "    )\n",
    "\n",
    "    # Títulos y Etiquetas\n",
    "    plt.title(f'Top 10 Direcciones Más Repetidas\\n(Total Registros Analizados: {total_registros:,})', \n",
    "              fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Cantidad de Usuarios', fontsize=11)\n",
    "    plt.ylabel('Dirección', fontsize=11)\n",
    "\n",
    "    # Añadir las anotaciones (Count y Porcentaje) al final de cada barra\n",
    "    for i, p in enumerate(ax.patches):\n",
    "        width = p.get_width()\n",
    "        pct = top_10_direcciones.iloc[i]['% del Total de Usuarios']\n",
    "        \n",
    "        # Formatear el texto: \" 150 (5.2%)\"\n",
    "        etiqueta = f' {int(width):,} ({pct}%)'\n",
    "        \n",
    "        ax.text(width, p.get_y() + p.get_height() / 2, etiqueta, \n",
    "                ha='left', va='center', fontweight='bold', color='#333333', fontsize=10)\n",
    "\n",
    "    # Ajustar el tamaño de las etiquetas del eje Y para direcciones largas\n",
    "    ax.tick_params(axis='y', labelsize=9)\n",
    "    \n",
    "    # Ajustes finales de limpieza visual\n",
    "    sns.despine(left=True, bottom=True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Guardar y Mostrar\n",
    "    #plt.savefig('top_10_direcciones_repetidas.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"\\nGráfico generado exitosamente: 'top_10_direcciones_repetidas.png'\")\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"\\n[!] No hay datos para graficar. El DataFrame 'top_10_direcciones' está vacío.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## Top 10 correos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- VISUALIZACIÓN DE CORREOS MÁS REPETIDOS ---\n",
    "\n",
    "# Validación de seguridad: Solo graficamos si hay datos\n",
    "if not top_10_correos.empty:\n",
    "    \n",
    "    # Configuración del estilo para reporte profesional\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(14, 8))  # Más alto para correos largos\n",
    "\n",
    "    # Crear el gráfico de barras horizontales\n",
    "    ax = sns.barplot(\n",
    "        data=top_10_correos,\n",
    "        x='Cantidad de Usuarios',\n",
    "        y='Correo Electrónico',\n",
    "        palette='viridis_r',\n",
    "        orient='h'\n",
    "    )\n",
    "\n",
    "    # Títulos y Etiquetas\n",
    "    plt.title(f'Top 10 Correos Electrónicos Más Repetidos\\n(Total Registros Analizados: {total_registros:,})', \n",
    "              fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Cantidad de Usuarios', fontsize=11)\n",
    "    plt.ylabel('Correo Electrónico', fontsize=11)\n",
    "\n",
    "    # Añadir las anotaciones (Count y Porcentaje) al final de cada barra\n",
    "    for i, p in enumerate(ax.patches):\n",
    "        width = p.get_width()\n",
    "        pct = top_10_correos.iloc[i]['% del Total de Usuarios']\n",
    "        \n",
    "        # Formatear el texto: \" 150 (5.2%)\"\n",
    "        etiqueta = f' {int(width):,} ({pct}%)'\n",
    "        \n",
    "        ax.text(width, p.get_y() + p.get_height() / 2, etiqueta, \n",
    "                ha='left', va='center', fontweight='bold', color='#333333', fontsize=10)\n",
    "\n",
    "    # Ajustar el tamaño de las etiquetas del eje Y para correos largos\n",
    "    ax.tick_params(axis='y', labelsize=9)\n",
    "    \n",
    "    # Ajustes finales de limpieza visual\n",
    "    sns.despine(left=True, bottom=True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Guardar y Mostrar\n",
    "    #plt.savefig('top_10_correos_repetidos.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"\\nGráfico generado exitosamente: 'top_10_correos_repetidos.png'\")\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"\\n[!] No hay datos para graficar. El DataFrame 'top_10_correos' está vacío.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_ms_sie['estado'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_ms_sie.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Definir la ruta de salida\n",
    "ruta_salida = Path(r\"C:\\Users\\osmarrincon\\Downloads\")\n",
    "nombre_archivo = \"SIE_Aseguramiento_Original_y_Procesado.xlsx\"\n",
    "archivo_completo = ruta_salida / nombre_archivo\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"EXPORTACIÓN DE DATOS A EXCEL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Cargar el DataFrame original desde el CSV\n",
    "print(\"\\n[1/3] Cargando datos originales desde el CSV...\")\n",
    "df_original = pd.read_csv(r_ms_sie, sep=';', dtype=str, encoding='latin-1')\n",
    "print(f\"✓ Datos originales cargados: {len(df_original):,} registros\")\n",
    "\n",
    "# Exportar ambos DataFrames a un archivo Excel con múltiples hojas\n",
    "print(\"\\n[2/3] Exportando a Excel con dos hojas...\")\n",
    "with pd.ExcelWriter(archivo_completo, engine='openpyxl') as writer:\n",
    "    # Hoja 1: Datos originales\n",
    "    df_original.to_excel(writer, sheet_name='Datos Originales', index=False)\n",
    "    \n",
    "    # Hoja 2: Datos procesados (limpios)\n",
    "    df_ms_sie.to_excel(writer, sheet_name='Datos Procesados', index=False)\n",
    "\n",
    "print(f\"✓ Archivo Excel creado exitosamente\")\n",
    "\n",
    "# Verificar que el archivo se creó\n",
    "if archivo_completo.exists():\n",
    "    tamaño_mb = archivo_completo.stat().st_size / (1024 * 1024)\n",
    "    print(\"\\n[3/3] Verificación completada\")\n",
    "    print(f\"✓ Archivo guardado en: {archivo_completo}\")\n",
    "    print(f\"✓ Tamaño del archivo: {tamaño_mb:.2f} MB\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"RESUMEN DE CONTENIDO\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\nHoja 1: 'Datos Originales'\")\n",
    "    print(f\"  - Registros: {len(df_original):,}\")\n",
    "    print(f\"  - Columnas: {len(df_original.columns)}\")\n",
    "    \n",
    "    print(f\"\\nHoja 2: 'Datos Procesados'\")\n",
    "    print(f\"  - Registros: {len(df_ms_sie):,}\")\n",
    "    print(f\"  - Columnas: {len(df_ms_sie.columns)}\")\n",
    "    print(f\"  - Registros eliminados: {len(df_original) - len(df_ms_sie):,}\")\n",
    "    print(f\"  - Porcentaje conservado: {(len(df_ms_sie)/len(df_original))*100:.2f}%\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"✓ EXPORTACIÓN COMPLETADA EXITOSAMENTE\")\n",
    "    print(\"=\" * 70)\n",
    "else:\n",
    "    print(\"\\n[!] ERROR: No se pudo crear el archivo\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
