{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 1. Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# 2. Rutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas de archivos a validar para cargar a SIE \n",
    "R_S1_Automatico = r\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Escritorio\\Yesid Rincón Z\\Traslados\\Procesos BDUA\\2025\\12_Diciembre\\02\\SIE\\AUTOMATICOS-S1EPS02502122025.VAL\"\n",
    "R_S1_Val = r\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Escritorio\\Yesid Rincón Z\\Traslados\\Procesos BDUA\\2025\\12_Diciembre\\02\\SIE\\S1EPS02502122025.VAL\"\n",
    "R_S3 = r\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Escritorio\\Yesid Rincón Z\\Traslados\\Procesos BDUA\\2025\\12_Diciembre\\02\\SIE\\S3EPS02502122025.TXT\"\n",
    "\n",
    "# Ruta de archivo de validación\n",
    "R_MS_SIE = r\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\SIE\\Aseguramiento\\ms_sie\\Reporte_Validación Archivos Maestro_2025_12_09.csv\"\n",
    "R_Expedientes_SIE = r\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\SIE\\Aseguramiento\\Expedientes\\Años\"\n",
    "R_Relaciones_Laborales = r\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\SIE\\Aseguramiento\\relaciones laborales\\Reporte_Afiliados Contributivo Relaciones Laborales_2025_12_09.csv\"\n",
    "\n",
    "# Ruta de archivo de salida\n",
    "N_Excel = \"Yesid-09-12-2025.xlsx\"\n",
    "R_Salida_Excel = fr\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Escritorio\\Yesid Rincón Z\\Traslados\\Procesos BDUA\\2025\\12_Diciembre\\02\\SIE\\{N_Excel}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas de archivos a validar para cargar a SIE \n",
    "#R_S1_Automatico = r\"C:\\Users\\crist\\OneDrive - 891856000_CAPRESOCA E P S\\Escritorio\\Yesid Rincón Z\\Traslados\\Procesos BDUA\\2025\\11_Noviembre\\11\\SIE\\AUTOMATICOS-S1EPS02511112025.VAL\"\n",
    "#R_S1_Val = r\"\\\\Servernas\\AYC2\\ASEGURAMIENTO\\ASEGURAMIENTO\\PROCESO_ASEGURAMIENTO\\REGIMEN SUBSIDIADO\\MUNICIPIOS 2025\\REPORTE RESOLUCION_0762_2023\\05_Mayo\\13\\Respuestas\\S1EPS02513052025.VAL\"\n",
    "#R_S3 = r\"\\\\Servernas\\AYC2\\ASEGURAMIENTO\\ASEGURAMIENTO\\PROCESO_ASEGURAMIENTO\\REGIMEN SUBSIDIADO\\MUNICIPIOS 2025\\REPORTE RESOLUCION_0762_2023\\05_Mayo\\13\\Respuestas\\S3EPS02513052025.TXT\"\n",
    "\n",
    "# Ruta de archivo de validación\n",
    "#R_MS_SIE = r\"C:\\Users\\crist\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\SIE\\Aseguramiento\\ms_sie\\Reporte_Validación Archivos Maestro_2025_11_13.csv\"\n",
    "#R_Expedientes_SIE = r\"C:\\Users\\crist\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\SIE\\Aseguramiento\\Expedientes\\Años\"\n",
    "#R_Relaciones_Laborales = r\"C:\\Users\\crist\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\SIE\\Aseguramiento\\relaciones laborales\\Reporte_Afiliados Contributivo Relaciones Laborales_2025_11_13.csv\"\n",
    "\n",
    "# Ruta de archivo de salida\n",
    "#N_Excel = \"Yesid-13-11-2025.xlsx\"\n",
    "#R_Salida_Excel = fr\"C:\\Users\\crist\\OneDrive - 891856000_CAPRESOCA E P S\\Escritorio\\Yesid Rincón Z\\Traslados\\Procesos BDUA\\2025\\11_Noviembre\\11\\SIE\\{N_Excel}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# 3. Cargue de Archivos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 3.1. Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los archivos a validar para subir al SIE\n",
    "df_S1_Automatico = pd.read_csv(R_S1_Automatico, delimiter=',', dtype=str, encoding='ansi', header=None)\n",
    "#df_S1_Val = pd.read_csv(R_S1_Val, delimiter=',', dtype=str, encoding='ansi', header=None)\n",
    "#df_S3 = pd.read_csv(R_S3, delimiter=',', dtype=str, encoding='ansi', header=None)\n",
    "\n",
    "# Cargar archivos que sirven para validación\n",
    "df_MS_SIE = pd.read_csv(R_MS_SIE, delimiter=';', dtype=str, encoding='ansi')\n",
    "df_Relaciones_Laborales = pd.read_csv(R_Relaciones_Laborales, delimiter=';', dtype=str, encoding='ansi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listar todos los archivos .TXT en la carpeta R_Expedientes_SIE\n",
    "txt_files = list(Path(R_Expedientes_SIE).glob(\"*.TXT\"))\n",
    "\n",
    "# Cargar cada archivo en un dataframe y luego concatenarlos\n",
    "df_list = [pd.read_csv(file, sep=\"|\", encoding=\"ANSI\", dtype=str) for file in txt_files]\n",
    "\n",
    "# Concatenar todos los dataframes en uno solo\n",
    "df_expedientes_SIE = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# 3.2. variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.basename(R_S1_Automatico)\n",
    "const_part = \"AUTOMATICOS-S1EPS025\"\n",
    "date_str = filename.replace(const_part, \"\")[:8]\n",
    "formatted_date = date_str[:2] + \"/\" + date_str[2:4] + \"/\" + date_str[4:]\n",
    "print(formatted_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# 4. Limpiar bases de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_expedientes_SIE.shape[0])\n",
    "# Filtrar el dataframe para eliminar registros donde \"Estado Expediente\" sea \"Cerrado\", \"Pendiente\" o \"Anulado\"\n",
    "df_expedientes_SIE = df_expedientes_SIE[~df_expedientes_SIE[\"Estado Expediente\"].isin([\"Pendiente\", \"Anulado\"])]\n",
    "procesos_validos = [\n",
    "    \"Ingreso Afiliado Contributivo Cotizante\",\n",
    "    \"Afiliación por Adición Relación Laboral\",\n",
    "    \"Ingreso Afiliado Contributivo Nacimiento\",\n",
    "    \"Ingreso Afiliado Contributivo Beneficiario\",\n",
    "    \"Actualización Beneficiario ó Adicional a Cotizante\",\n",
    "    \"Actualización Relación Laboral\"\n",
    "]\n",
    "\n",
    "df_expedientes_SIE = df_expedientes_SIE[df_expedientes_SIE[\"Proceso\"].isin(procesos_validos)]\n",
    "print(df_expedientes_SIE.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna 'Fecha Grabado' a datetime usando el formato \"yyyy/mm/dd hh:mm\"\n",
    "df_expedientes_SIE['Fecha Grabado_dt'] = pd.to_datetime(df_expedientes_SIE['Fecha Grabado'], format='%Y/%m/%d %H:%M')\n",
    "\n",
    "# Ordenar el dataframe de forma descendente según 'Fecha Grabado_dt'\n",
    "df_expedientes_SIE = df_expedientes_SIE.sort_values('Fecha Grabado_dt', ascending=False)\n",
    "\n",
    "# Eliminar duplicados en base a 'Tipo Documento' y 'Número Identificación', conservando el registro más reciente\n",
    "df_expedientes_SIE = df_expedientes_SIE.drop_duplicates(subset=['Tipo Documento', 'Número Identificación'], keep='first')\n",
    "\n",
    "# Convertir la fecha al formato \"dd/mm/yyyy\"\n",
    "df_expedientes_SIE['Fecha Grabado'] = df_expedientes_SIE['Fecha Grabado_dt'].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "# Eliminar la columna temporal\n",
    "df_expedientes_SIE = df_expedientes_SIE.drop(columns=['Fecha Grabado_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir número de registros antes del proceso\n",
    "print(\"Número de registros antes de eliminar duplicados:\", df_Relaciones_Laborales.shape[0])\n",
    "\n",
    "# Convertir la columna \"fecha_ingreso\" a datetime, asumiendo formato \"yyyy-mm-dd\"\n",
    "df_Relaciones_Laborales[\"fecha_ingreso_dt\"] = pd.to_datetime(df_Relaciones_Laborales[\"fecha_ingreso\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "# Ordenar por la fecha en forma descendente para que el más reciente quede primero\n",
    "df_Relaciones_Laborales = df_Relaciones_Laborales.sort_values(\"fecha_ingreso_dt\", ascending=False)\n",
    "\n",
    "# Eliminar duplicados manteniendo solo el registro con la fecha más reciente \n",
    "df_Relaciones_Laborales = df_Relaciones_Laborales.drop_duplicates(subset=[\"tipo_documento\", \"numero_identificacion\"], keep=\"first\")\n",
    "\n",
    "# Convertir la fecha al formato \"dd/mm/yyyy\"\n",
    "df_Relaciones_Laborales[\"fecha_ingreso\"] = df_Relaciones_Laborales[\"fecha_ingreso_dt\"].dt.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "# Eliminar la columna temporal usada para el manejo de fechas\n",
    "df_Relaciones_Laborales = df_Relaciones_Laborales.drop(columns=[\"fecha_ingreso_dt\"])\n",
    "\n",
    "# Imprimir número de registros después del proceso\n",
    "print(\"Número de registros después de eliminar duplicados:\", df_Relaciones_Laborales.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expedientes_SIE.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# 5. Validaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## 5.1 Validacion S1 automatico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero creamos dos columnas auxiliares en df_S1_Automatico para facilitar el cruce.\n",
    "df_S1_Automatico['tipo_documento'] = df_S1_Automatico.iloc[:, 1]\n",
    "df_S1_Automatico['numero_identificacion'] = df_S1_Automatico.iloc[:, 2]\n",
    "\n",
    "# Realizamos un merge izquierdo para traer la columna \"fecha_ingreso\" de df_Relaciones_Laborales\n",
    "df_S1_Automatico = df_S1_Automatico.merge(\n",
    "    df_Relaciones_Laborales[['tipo_documento', 'numero_identificacion', 'fecha_ingreso']],\n",
    "    on=['tipo_documento', 'numero_identificacion'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Creamos la columna \"Relacion Laboral\":\n",
    "# Si 'fecha_ingreso' tiene dato, asignamos \"SI\", de lo contrario \"No\"\n",
    "df_S1_Automatico['Relacion Laboral'] = df_S1_Automatico['fecha_ingreso'].apply(lambda x: 'SI' if pd.notnull(x) else 'No')\n",
    "\n",
    "# Extraemos las columnas clave y las que queremos agregar del df_expedientes_SIE\n",
    "df_temp = df_expedientes_SIE[['Tipo Documento', 'Número Identificación', 'Proceso', 'Fecha Grabado', 'Usuario Grabado']]\n",
    "\n",
    "# Hacemos merge para incorporar 'Proceso' y 'Fecha Grabado' en df_S1_Automatico usando los identificadores\n",
    "df_S1_Automatico = df_S1_Automatico.merge(\n",
    "    df_temp,\n",
    "    left_on=['tipo_documento', 'numero_identificacion'],\n",
    "    right_on=['Tipo Documento', 'Número Identificación'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Opcional: eliminamos las columnas duplicadas de llave del merge si no son necesarias\n",
    "df_S1_Automatico.drop(columns=['Tipo Documento', 'Número Identificación'], inplace=True)\n",
    "\n",
    "# Usar la columna 'Fecha Grabado' si existe; si no, se utiliza 'fecha_ingreso'\n",
    "fechas = df_S1_Automatico['Fecha Grabado'].fillna(df_S1_Automatico['fecha_ingreso'])\n",
    "# Convertir las fechas a datetime conservando el formato dd/mm/yyyy\n",
    "fecha_registro = pd.to_datetime(fechas, format='%d/%m/%Y', errors='coerce')\n",
    "# Referencia desde la columna en índice 20\n",
    "ref_col = pd.to_datetime(df_S1_Automatico.iloc[:, 20], format='%d/%m/%Y', errors='coerce')\n",
    "# Referencia desde la variable formatted_date\n",
    "ref_var = pd.to_datetime(formatted_date, format='%d/%m/%Y', errors='coerce')\n",
    "\n",
    "# Crear la nueva columna: si la fecha registrada es mayor o igual a cualquiera de las referencias, se asigna \"R1 no SIE\"\n",
    "df_S1_Automatico['Nueva Columna'] = np.where((fecha_registro >= ref_col) | (fecha_registro >= ref_var),\n",
    "                                              \"R1 no SIE\", \"S1 SIE\")\n",
    "df_S1_Automatico.loc[df_S1_Automatico['fecha_ingreso'].isnull() | (df_S1_Automatico['fecha_ingreso'] == ''), 'Nueva Columna'] = \"S1 SIE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar los registros que cumplen las condiciones adicionales\n",
    "condiciones_adicionales = (df_S1_Automatico['Usuario Grabado'].notnull()) & \\\n",
    "                          (df_S1_Automatico['Usuario Grabado'] != '') & \\\n",
    "                          (df_S1_Automatico['Usuario Grabado'] != 'Jhonatan.perez')\n",
    "\n",
    "# Máscara original de fechas y condiciones adicionales\n",
    "mask_fechas = (fecha_registro >= ref_col) | (fecha_registro >= ref_var)\n",
    "mask_adicionales = condiciones_adicionales\n",
    "\n",
    "# Nueva máscara: fecha_ingreso no nula ni vacía\n",
    "mask_fecha_ingreso = df_S1_Automatico['fecha_ingreso'].notna() & (df_S1_Automatico['fecha_ingreso'] != '')\n",
    "\n",
    "# Combinas todo\n",
    "mask_r1 = mask_fechas & mask_adicionales & mask_fecha_ingreso\n",
    "\n",
    "# Asignas la nueva columna\n",
    "df_S1_Automatico['Nueva Columna'] = np.where(\n",
    "    mask_r1,\n",
    "    \"R1 no SIE\",\n",
    "    \"S1 SIE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## 5.2. R1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "Df_R1 = df_S1_Automatico[\n",
    "    (df_S1_Automatico[\"Nueva Columna\"] == \"R1 no SIE\") & (df_S1_Automatico.iloc[:, 30] == \"F\")\n",
    "][[\"tipo_documento\", \"numero_identificacion\"]]\n",
    "\n",
    "# Realizamos un merge izquierdo para traer la columna \"fecha_ingreso\" de df_Relaciones_Laborales\n",
    "Df_R1 = Df_R1.merge(\n",
    "    df_Relaciones_Laborales[['tipo_documento', 'numero_identificacion', 'tipo_documento_aportante', 'numero_identificacion_aportante', 'fecha_ingreso']],\n",
    "    on=['tipo_documento', 'numero_identificacion'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "# 6. Guardar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(R_Salida_Excel) as writer:\n",
    "    df_S1_Automatico.to_excel(writer, index=False, sheet_name='S1Automatico')\n",
    "    Df_R1.to_excel(writer, index=False, sheet_name='Df_R1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
