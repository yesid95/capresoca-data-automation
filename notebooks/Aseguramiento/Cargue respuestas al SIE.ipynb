{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 1. Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# 2. Rutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ‚öôÔ∏è PAR√ÅMETROS DE CONFIGURACI√ìN MANUAL\n",
    "# ============================================================================\n",
    "# üîß ACTUALIZA ESTOS VALORES CADA MES:\n",
    "\n",
    "# 1. ESTRUCTURA DE CARPETAS (A√±o/Mes/D√≠a)\n",
    "CARPETA_ANO = \"2026\"\n",
    "CARPETA_MES = \"02_Febrero\"\n",
    "CARPETA_DIA = \"10\"\n",
    "\n",
    "# 2. ARCHIVOS SIE (con fecha YYYYMMDD en el nombre)\n",
    "FECHA_ARCHIVO = \"10022026\"  # Formato: DDMMYYYY\n",
    "ARCHIVO_S1_AUTOMATICO = f\"AUTOMATICOS-S1EPS025{FECHA_ARCHIVO}.VAL\"\n",
    "ARCHIVO_S1_VAL = f\"S1EPS025{FECHA_ARCHIVO}.VAL\"\n",
    "ARCHIVO_S3 = f\"S3EPS025{FECHA_ARCHIVO}.TXT\"\n",
    "\n",
    "# 3. ARCHIVOS DE VALIDACI√ìN\n",
    "FECHA_REPORTE = \"2026_02_12\"  # Formato: YYYY_MM_DD\n",
    "ARCHIVO_MS_SIE = f\"Reporte_Validaci√≥n Archivos Maestro_{FECHA_REPORTE}.csv\"\n",
    "ARCHIVO_RELACIONES_LABORALES = f\"Reporte_Afiliados Contributivo Relaciones Laborales_{FECHA_REPORTE}.csv\"\n",
    "\n",
    "# 4. ARCHIVO DE SALIDA\n",
    "NOMBRE_EXCEL = \"Yesid-12-02-2026.xlsx\"\n",
    "\n",
    "# ============================================================================\n",
    "# DETECCI√ìN AUTOM√ÅTICA DE RUTAS (UNIVERSAL)\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Obtener usuario del sistema\n",
    "usuario = os.environ.get('USERNAME') or os.environ.get('USER')\n",
    "user_home = os.path.expanduser(\"~\")  # C:\\Users\\{usuario}\n",
    "\n",
    "# Rutas base (estructura est√°ndar para todos los usuarios)\n",
    "ONEDRIVE_BASE = os.path.join(user_home, \"OneDrive - 891856000_CAPRESOCA E P S\")\n",
    "ESCRITORIO_BASE = os.path.join(ONEDRIVE_BASE, \"Escritorio\", \"Yesid Rinc√≥n Z\", \"Traslados\", \"Procesos BDUA\")\n",
    "CAPRESOCA_BASE = os.path.join(ONEDRIVE_BASE, \"Capresoca\", \"AlmostClear\", \"SIE\", \"Aseguramiento\")\n",
    "\n",
    "# ============================================================================\n",
    "# CONSTRUCCI√ìN DE RUTAS AUTOM√ÅTICAS\n",
    "# ============================================================================\n",
    "\n",
    "# Rutas de archivos a validar para cargar a SIE\n",
    "R_CARPETA_SIE = os.path.join(ESCRITORIO_BASE, CARPETA_ANO, CARPETA_MES, CARPETA_DIA, \"SIE\")\n",
    "R_S1_Automatico = os.path.join(R_CARPETA_SIE, ARCHIVO_S1_AUTOMATICO)\n",
    "R_S1_Val = os.path.join(R_CARPETA_SIE, ARCHIVO_S1_VAL)\n",
    "R_S3 = os.path.join(R_CARPETA_SIE, ARCHIVO_S3)\n",
    "\n",
    "# Rutas de archivos de validaci√≥n\n",
    "R_MS_SIE = os.path.join(CAPRESOCA_BASE, \"ms_sie\", ARCHIVO_MS_SIE)\n",
    "R_Expedientes_SIE = os.path.join(CAPRESOCA_BASE, \"Expedientes\", \"A√±os\")\n",
    "R_Relaciones_Laborales = os.path.join(CAPRESOCA_BASE, \"relaciones laborales\", ARCHIVO_RELACIONES_LABORALES)\n",
    "\n",
    "# Ruta de archivo de salida\n",
    "R_Salida_Excel = os.path.join(R_CARPETA_SIE, NOMBRE_EXCEL)\n",
    "\n",
    "# ============================================================================\n",
    "# VALIDACI√ìN Y RESUMEN\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"üë§ USUARIO: {usuario}\")\n",
    "print(f\"üìÅ OneDrive: {ONEDRIVE_BASE}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nüìã PAR√ÅMETROS CONFIGURADOS:\")\n",
    "print(f\"   üìÖ Carpeta fecha: {CARPETA_ANO}/{CARPETA_MES}/{CARPETA_DIA}\")\n",
    "print(f\"   üìÑ S1 Autom√°tico: {ARCHIVO_S1_AUTOMATICO}\")\n",
    "print(f\"   üìÑ S1 Val: {ARCHIVO_S1_VAL}\")\n",
    "print(f\"   üìÑ S3: {ARCHIVO_S3}\")\n",
    "print(f\"   üìä MS SIE: {ARCHIVO_MS_SIE}\")\n",
    "print(f\"   üìä Relaciones Laborales: {ARCHIVO_RELACIONES_LABORALES}\")\n",
    "print(f\"   üíæ Excel salida: {NOMBRE_EXCEL}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"üîç VALIDACI√ìN DE RUTAS:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "rutas_validar = {\n",
    "    \"üìÇ Carpeta SIE\": R_CARPETA_SIE,\n",
    "    \"üìÑ S1 Autom√°tico\": R_S1_Automatico,\n",
    "    \"üìÑ S1 Val\": R_S1_Val,\n",
    "    \"üìÑ S3\": R_S3,\n",
    "    \"üìä MS SIE\": R_MS_SIE,\n",
    "    \"üìÇ Expedientes SIE\": R_Expedientes_SIE,\n",
    "    \"üìä Relaciones Laborales\": R_Relaciones_Laborales\n",
    "}\n",
    "\n",
    "errores = []\n",
    "for nombre, ruta in rutas_validar.items():\n",
    "    existe = os.path.exists(ruta)\n",
    "    print(f\"{'‚úÖ' if existe else '‚ùå'} {nombre}\")\n",
    "    print(f\"   {ruta}\")\n",
    "    if not existe:\n",
    "        errores.append(nombre)\n",
    "\n",
    "if errores:\n",
    "    print(f\"\\n‚ö†Ô∏è {len(errores)} ruta(s) no encontrada(s)\")\n",
    "    print(\"\\nüí° Verifica:\")\n",
    "    print(\"   1. Que OneDrive est√© sincronizado\")\n",
    "    print(\"   2. Que los par√°metros al inicio est√©n actualizados\")\n",
    "    print(\"   3. Que los archivos existan en las carpetas\")\n",
    "    print(\"   4. Que las fechas en los nombres de archivo sean correctas\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Todas las rutas validadas correctamente\")\n",
    "\n",
    "print(\"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# 3. Cargue de Archivos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 3.1. Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los archivos a validar para subir al SIE\n",
    "df_S1_Automatico = pd.read_csv(R_S1_Automatico, delimiter=',', dtype=str, encoding='ansi', header=None)\n",
    "df_S1_Val = pd.read_csv(R_S1_Val, delimiter=',', dtype=str, encoding='ansi', header=None)\n",
    "df_S3 = pd.read_csv(R_S3, delimiter=',', dtype=str, encoding='ansi', header=None)\n",
    "\n",
    "# Cargar archivos que sirven para validaci√≥n\n",
    "df_MS_SIE = pd.read_csv(R_MS_SIE, delimiter=';', dtype=str, encoding='ansi')\n",
    "df_Relaciones_Laborales = pd.read_csv(R_Relaciones_Laborales, delimiter=';', dtype=str, encoding='ansi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listar todos los archivos .TXT en la carpeta R_Expedientes_SIE\n",
    "txt_files = list(Path(R_Expedientes_SIE).glob(\"*.TXT\"))\n",
    "\n",
    "# Cargar cada archivo en un dataframe y luego concatenarlos\n",
    "df_list = [pd.read_csv(file, sep=\"|\", encoding=\"ANSI\", dtype=str) for file in txt_files]\n",
    "\n",
    "# Concatenar todos los dataframes en uno solo\n",
    "df_expedientes_SIE = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# 3.2. variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.basename(R_S1_Automatico)\n",
    "const_part = \"AUTOMATICOS-S1EPS025\"\n",
    "date_str = filename.replace(const_part, \"\")[:8]\n",
    "formatted_date = date_str[:2] + \"/\" + date_str[2:4] + \"/\" + date_str[4:]\n",
    "print(formatted_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# 4. Limpiar bases de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_expedientes_SIE.shape[0])\n",
    "# Filtrar el dataframe para eliminar registros donde \"Estado Expediente\" sea \"Cerrado\", \"Pendiente\" o \"Anulado\"\n",
    "df_expedientes_SIE = df_expedientes_SIE[~df_expedientes_SIE[\"Estado Expediente\"].isin([\"Pendiente\", \"Anulado\"])]\n",
    "procesos_validos = [\n",
    "    \"Ingreso Afiliado Contributivo Cotizante\",\n",
    "    \"Afiliaci√≥n por Adici√≥n Relaci√≥n Laboral\",\n",
    "    \"Ingreso Afiliado Contributivo Nacimiento\",\n",
    "    \"Ingreso Afiliado Contributivo Beneficiario\",\n",
    "    \"Actualizaci√≥n Beneficiario √≥ Adicional a Cotizante\",\n",
    "    \"Actualizaci√≥n Relaci√≥n Laboral\"\n",
    "]\n",
    "\n",
    "df_expedientes_SIE = df_expedientes_SIE[df_expedientes_SIE[\"Proceso\"].isin(procesos_validos)]\n",
    "print(df_expedientes_SIE.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna 'Fecha Grabado' a datetime usando el formato \"yyyy/mm/dd hh:mm\"\n",
    "df_expedientes_SIE['Fecha Grabado_dt'] = pd.to_datetime(df_expedientes_SIE['Fecha Grabado'], format='%Y/%m/%d %H:%M')\n",
    "\n",
    "# Ordenar el dataframe de forma descendente seg√∫n 'Fecha Grabado_dt'\n",
    "df_expedientes_SIE = df_expedientes_SIE.sort_values('Fecha Grabado_dt', ascending=False)\n",
    "\n",
    "# Eliminar duplicados en base a 'Tipo Documento' y 'N√∫mero Identificaci√≥n', conservando el registro m√°s reciente\n",
    "df_expedientes_SIE = df_expedientes_SIE.drop_duplicates(subset=['Tipo Documento', 'N√∫mero Identificaci√≥n'], keep='first')\n",
    "\n",
    "# Convertir la fecha al formato \"dd/mm/yyyy\"\n",
    "df_expedientes_SIE['Fecha Grabado'] = df_expedientes_SIE['Fecha Grabado_dt'].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "# Eliminar la columna temporal\n",
    "df_expedientes_SIE = df_expedientes_SIE.drop(columns=['Fecha Grabado_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir n√∫mero de registros antes del proceso\n",
    "print(\"N√∫mero de registros antes de eliminar duplicados:\", df_Relaciones_Laborales.shape[0])\n",
    "\n",
    "# Convertir la columna \"fecha_ingreso\" a datetime, asumiendo formato \"yyyy-mm-dd\"\n",
    "df_Relaciones_Laborales[\"fecha_ingreso_dt\"] = pd.to_datetime(df_Relaciones_Laborales[\"fecha_ingreso\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "# Ordenar por la fecha en forma descendente para que el m√°s reciente quede primero\n",
    "df_Relaciones_Laborales = df_Relaciones_Laborales.sort_values(\"fecha_ingreso_dt\", ascending=False)\n",
    "\n",
    "# Eliminar duplicados manteniendo solo el registro con la fecha m√°s reciente \n",
    "df_Relaciones_Laborales = df_Relaciones_Laborales.drop_duplicates(subset=[\"tipo_documento\", \"numero_identificacion\"], keep=\"first\")\n",
    "\n",
    "# Convertir la fecha al formato \"dd/mm/yyyy\"\n",
    "df_Relaciones_Laborales[\"fecha_ingreso\"] = df_Relaciones_Laborales[\"fecha_ingreso_dt\"].dt.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "# Eliminar la columna temporal usada para el manejo de fechas\n",
    "df_Relaciones_Laborales = df_Relaciones_Laborales.drop(columns=[\"fecha_ingreso_dt\"])\n",
    "\n",
    "# Imprimir n√∫mero de registros despu√©s del proceso\n",
    "print(\"N√∫mero de registros despu√©s de eliminar duplicados:\", df_Relaciones_Laborales.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expedientes_SIE.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# 5. Validaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 5.1 Validacion S1 automatico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero creamos dos columnas auxiliares en df_S1_Automatico para facilitar el cruce.\n",
    "df_S1_Automatico['tipo_documento'] = df_S1_Automatico.iloc[:, 1]\n",
    "df_S1_Automatico['numero_identificacion'] = df_S1_Automatico.iloc[:, 2]\n",
    "\n",
    "# Realizamos un merge izquierdo para traer la columna \"fecha_ingreso\" de df_Relaciones_Laborales\n",
    "df_S1_Automatico = df_S1_Automatico.merge(\n",
    "    df_Relaciones_Laborales[['tipo_documento', 'numero_identificacion', 'fecha_ingreso']],\n",
    "    on=['tipo_documento', 'numero_identificacion'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Creamos la columna \"Relacion Laboral\":\n",
    "# Si 'fecha_ingreso' tiene dato, asignamos \"SI\", de lo contrario \"No\"\n",
    "df_S1_Automatico['Relacion Laboral'] = df_S1_Automatico['fecha_ingreso'].apply(lambda x: 'SI' if pd.notnull(x) else 'No')\n",
    "\n",
    "# Extraemos las columnas clave y las que queremos agregar del df_expedientes_SIE\n",
    "df_temp = df_expedientes_SIE[['Tipo Documento', 'N√∫mero Identificaci√≥n', 'Proceso', 'Fecha Grabado', 'Usuario Grabado']]\n",
    "\n",
    "# Hacemos merge para incorporar 'Proceso' y 'Fecha Grabado' en df_S1_Automatico usando los identificadores\n",
    "df_S1_Automatico = df_S1_Automatico.merge(\n",
    "    df_temp,\n",
    "    left_on=['tipo_documento', 'numero_identificacion'],\n",
    "    right_on=['Tipo Documento', 'N√∫mero Identificaci√≥n'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Opcional: eliminamos las columnas duplicadas de llave del merge si no son necesarias\n",
    "df_S1_Automatico.drop(columns=['Tipo Documento', 'N√∫mero Identificaci√≥n'], inplace=True)\n",
    "\n",
    "# Usar la columna 'Fecha Grabado' si existe; si no, se utiliza 'fecha_ingreso'\n",
    "fechas = df_S1_Automatico['Fecha Grabado'].fillna(df_S1_Automatico['fecha_ingreso'])\n",
    "# Convertir las fechas a datetime conservando el formato dd/mm/yyyy\n",
    "fecha_registro = pd.to_datetime(fechas, format='%d/%m/%Y', errors='coerce')\n",
    "# Referencia desde la columna en √≠ndice 20\n",
    "ref_col = pd.to_datetime(df_S1_Automatico.iloc[:, 20], format='%d/%m/%Y', errors='coerce')\n",
    "# Referencia desde la variable formatted_date\n",
    "ref_var = pd.to_datetime(formatted_date, format='%d/%m/%Y', errors='coerce')\n",
    "\n",
    "# Crear la nueva columna: si la fecha registrada es mayor o igual a cualquiera de las referencias, se asigna \"R1 no SIE\"\n",
    "df_S1_Automatico['Nueva Columna'] = np.where((fecha_registro >= ref_col) | (fecha_registro >= ref_var),\n",
    "                                              \"R1 no SIE\", \"S1 SIE\")\n",
    "df_S1_Automatico.loc[df_S1_Automatico['fecha_ingreso'].isnull() | (df_S1_Automatico['fecha_ingreso'] == ''), 'Nueva Columna'] = \"S1 SIE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar los registros que cumplen las condiciones adicionales\n",
    "condiciones_adicionales = (df_S1_Automatico['Usuario Grabado'].notnull()) & \\\n",
    "                          (df_S1_Automatico['Usuario Grabado'] != '') & \\\n",
    "                          (df_S1_Automatico['Usuario Grabado'] != 'Jhonatan.perez')\n",
    "\n",
    "# M√°scara original de fechas y condiciones adicionales\n",
    "mask_fechas = (fecha_registro >= ref_col) | (fecha_registro >= ref_var)\n",
    "mask_adicionales = condiciones_adicionales\n",
    "\n",
    "# Nueva m√°scara: fecha_ingreso no nula ni vac√≠a\n",
    "mask_fecha_ingreso = df_S1_Automatico['fecha_ingreso'].notna() & (df_S1_Automatico['fecha_ingreso'] != '')\n",
    "\n",
    "# Combinas todo\n",
    "mask_r1 = mask_fechas & mask_adicionales & mask_fecha_ingreso\n",
    "\n",
    "# Asignas la nueva columna\n",
    "df_S1_Automatico['Nueva Columna'] = np.where(\n",
    "    mask_r1,\n",
    "    \"R1 no SIE\",\n",
    "    \"S1 SIE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## 5.2. R1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "Df_R1 = df_S1_Automatico[\n",
    "    (df_S1_Automatico[\"Nueva Columna\"] == \"R1 no SIE\") & (df_S1_Automatico.iloc[:, 30] == \"F\")\n",
    "][[\"tipo_documento\", \"numero_identificacion\"]]\n",
    "\n",
    "# Realizamos un merge izquierdo para traer la columna \"fecha_ingreso\" de df_Relaciones_Laborales\n",
    "Df_R1 = Df_R1.merge(\n",
    "    df_Relaciones_Laborales[['tipo_documento', 'numero_identificacion', 'tipo_documento_aportante', 'numero_identificacion_aportante', 'fecha_ingreso']],\n",
    "    on=['tipo_documento', 'numero_identificacion'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "# 6. Guardar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(R_Salida_Excel) as writer:\n",
    "    df_S1_Automatico.to_excel(writer, index=False, sheet_name='S1Automatico')\n",
    "    Df_R1.to_excel(writer, index=False, sheet_name='Df_R1')\n",
    "    df_S1_Val.to_excel(writer, index=False, sheet_name='df_S1_Val')\n",
    "    df_S3.to_excel(writer, index=False, sheet_name='df_S3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
