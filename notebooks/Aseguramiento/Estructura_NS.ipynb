{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 1. Modulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from datetime import datetime, date, timedelta\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "import xlsxwriter\n",
    "import re  # Expresiones regulares para procesamiento de texto\n",
    "\n",
    "# A√±adir la carpeta ra√≠z del proyecto al sys.path para importar m√≥dulos personalizados\n",
    "sys.path.append(os.path.abspath(\"c:/Users/osmarrincon/Documents/capresoca-data-automation\"))\n",
    "#sys.path.append(os.path.abspath(r\"C:\\Users\\crist\\Documents\\Proyectos Python\\capresoca-data-automation\"))  # Ruta alternativa (comentada)\n",
    "\n",
    "# Importar funci√≥n y clase personalizada del proyecto\n",
    "from src.file_loader import cargar_maestros_ADRES  # Funci√≥n para cargar archivos maestros ADRES\n",
    "from src.data_cleaning import BduaReportProcessor      # Clase para limpiar y normalizar poblaci√≥n Maestro ADRES\n",
    "from src.data_cleaning import DataCleaner # Clase para limpiar y normalizar DataFrames de Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# 2. Rutas y variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Oficce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_Maestro__EPSC25 = r\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\Procesos BDUA\\Contributivo\\Maestro\\2026\\EPSC25MC0006012026.TXT\"\n",
    "R_Maestro__EPS025 = r\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\Procesos BDUA\\Subsidiados\\Maestro\\MS\\2026\\EPS025MS0006012026.TXT\"\n",
    "R_IPS = r\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\Constantes\\IPS_CODIGO.txt\"\n",
    "R_Dic_Nomenclaturas = r\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\Constantes\\NOMENCLATURA_DE_DIRECCIONES.xlsx\"\n",
    "\n",
    "# Crear el objeto de fecha\n",
    "fecha_reporte = dt.datetime(2026, 1, 9)\n",
    "fecha_archivo = \"09-01-2026\"\n",
    "\n",
    "Ruta_Salida = fr\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Escritorio\\Yesid Rinc√≥n Z\\Traslados\\Procesos BDUA\\2026\\01_Enero\\09\"\n",
    "\n",
    "S_Excel = fr\"C:\\Users\\osmarrincon\\OneDrive - 891856000_CAPRESOCA E P S\\Escritorio\\Yesid Rinc√≥n Z\\Traslados\\Procesos BDUA\\2026\\01_Enero\\09\\DataFrames_Activos 09012026.xlsx\"\n",
    "hoja = \"Df_NS_Envio\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#R_Maestro__EPSC25 = r\"C:\\Users\\crist\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\Procesos BDUA\\Contributivo\\Maestro\\2025-2\\EPSC25MC0010122025.TXT\"\n",
    "#R_Maestro__EPS025 = r\"C:\\Users\\crist\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\Procesos BDUA\\Subsidiados\\Maestro\\MS\\2025-02\\EPS025MS0010122025.TXT\"\n",
    "#R_IPS = r\"C:\\Users\\crist\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\Constantes\\IPS_CODIGO.txt\"\n",
    "\n",
    "#R_Dic_Nomenclaturas = r\"C:\\Users\\crist\\OneDrive - 891856000_CAPRESOCA E P S\\Capresoca\\AlmostClear\\Constantes\\NOMENCLATURA_DE_DIRECCIONES.xlsx\"\n",
    "# Crear el objeto de fecha\n",
    "#fecha_reporte = dt.datetime(2025, 12, 12)\n",
    "#fecha_archivo = \"12-12-2025\"\n",
    "\n",
    "#Ruta_Salida = fr\"C:\\Users\\crist\\OneDrive - 891856000_CAPRESOCA E P S\\Escritorio\\Yesid Rinc√≥n Z\\Traslados\\Procesos BDUA\\2025\\12_Diciembre\\12\"\n",
    "\n",
    "#S_Excel = fr\"C:\\Users\\crist\\OneDrive - 891856000_CAPRESOCA E P S\\Escritorio\\Yesid Rinc√≥n Z\\Traslados\\Procesos BDUA\\2025\\12_Diciembre\\12\\DataFrames_Activos 12122025.xlsx\"\n",
    "#hoja = \"Df_NS_Envio\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# 3. Cargue Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar y combinar los maestros\n",
    "maestro_ADRES = cargar_maestros_ADRES(R_Maestro__EPS025, R_Maestro__EPSC25)\n",
    "df_NS = pd.read_excel(S_Excel, hoja, header=0, dtype=str)\n",
    "df_Dic_Nomenclaturas = pd.read_excel(R_Dic_Nomenclaturas, \"NOMENCLATURA\", header=0, dtype=str)\n",
    "df_IPS = pd.read_csv(R_IPS, sep=None, engine='python', encoding='utf-8', header=None, dtype=str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# 4. Limpiar datos\n",
    "## 4.1. Listado censal o Sisben ADRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicar la columna \"MARCASISBENIV+MARCASISBENIII_2\" y nombrarla \"MARCASISBENIV+MARCASISBENIII\"\n",
    "maestro_ADRES[\"MARCASISBENIV+MARCASISBENIII_2\"] = \\\n",
    "    maestro_ADRES[\"MARCASISBENIV+MARCASISBENIII\"]\n",
    "\n",
    "# 1. Instanciar el procesador: Se crea un objeto pasando el DataFrame.\n",
    "#    La jerarqu√≠a de poblaci√≥n ya est√° definida por defecto dentro de la clase.\n",
    "processor = BduaReportProcessor(df=maestro_ADRES)\n",
    "\n",
    "# 2. Ejecutar la limpieza y asignarla de vuelta.\n",
    "#    El m√©todo retorna un DataFrame completamente nuevo con la columna actualizada.\n",
    "maestro_ADRES = processor.prioritize_population_markers(\n",
    "    col_name=\"MARCASISBENIV+MARCASISBENIII\"\n",
    ")\n",
    "\n",
    "# ¬°Listo! 'maestro_ADRES' ahora contiene los datos limpios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear las dos nuevas columnas basadas en la columna MARCASISBENIV+MARCASISBENIII\n",
    "def extraer_grupo_poblacional(valor):\n",
    "\t\"\"\"Extrae el grupo poblacional seg√∫n las reglas especificadas\"\"\"\n",
    "\tif pd.isna(valor) or valor == '' or str(valor).strip() == '':\n",
    "\t\treturn \"No sisben\"\n",
    "\telif valor == \"Sisben D\":\n",
    "\t\treturn \"34\"\n",
    "\telif \"LC(\" in str(valor):\n",
    "\t\t# Extraer n√∫mero entre par√©ntesis de LC(n√∫mero)\n",
    "\t\tmatch = re.search(r'LC\\((\\d+)\\)', str(valor))\n",
    "\t\treturn match.group(1) if match else \"No sisben\"\n",
    "\telif \"SIV(\" in str(valor):\n",
    "\t\treturn \"5\"\n",
    "\telse:\n",
    "\t\treturn \"No sisben\"\n",
    "\n",
    "def extraer_nivel_sisben(valor):\n",
    "\t\"\"\"Extrae el nivel de sisben para casos SIV\"\"\"\n",
    "\tif pd.notna(valor) and \"SIV(\" in str(valor):\n",
    "\t\t# Extraer c√≥digo entre par√©ntesis de SIV(c√≥digo)\n",
    "\t\tmatch = re.search(r'SIV\\(([^)]+)\\)', str(valor))\n",
    "\t\treturn match.group(1) if match else \"\"\n",
    "\telse:\n",
    "\t\treturn \"\"\n",
    "\n",
    "# Aplicar las funciones para crear las nuevas columnas\n",
    "maestro_ADRES['Gr_Poblacional_Actual'] = maestro_ADRES['MARCASISBENIV+MARCASISBENIII'].apply(extraer_grupo_poblacional)\n",
    "maestro_ADRES['N_Sisben_Actual'] = maestro_ADRES['MARCASISBENIV+MARCASISBENIII'].apply(extraer_nivel_sisben)\n",
    "\n",
    "# Mostrar algunas filas para verificar el resultado\n",
    "print(\"Verificaci√≥n de las nuevas columnas:\")\n",
    "print(maestro_ADRES[['MARCASISBENIV+MARCASISBENIII', 'Gr_Poblacional_Actual', 'N_Sisben_Actual']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### 4.1.1. ID Maestro ADRES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la columna ID_User en el dataframe maestro_ADRES\n",
    "print(\"üìù CREANDO COLUMNA ID_User PARA maestro_ADRES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear la columna ID_User concatenando TPS_IDN_ID + HST_IDN_NUMERO_IDENTIFICACION\n",
    "maestro_ADRES['ID_User'] = maestro_ADRES['TPS_IDN_ID'].astype(str) + maestro_ADRES['HST_IDN_NUMERO_IDENTIFICACION'].astype(str)\n",
    "\n",
    "# Verificaci√≥n de resultados\n",
    "print(f\"‚úÖ Columna ID_User creada exitosamente\")\n",
    "print(f\"üìä Total de registros: {len(maestro_ADRES):,}\")\n",
    "print(f\"üìã Ejemplos de ID_User:\")\n",
    "print(f\"   {maestro_ADRES['ID_User'].head(10).tolist()}\")\n",
    "\n",
    "# Verificar valores √∫nicos\n",
    "ids_unicos = maestro_ADRES['ID_User'].nunique()\n",
    "total_registros = len(maestro_ADRES)\n",
    "print(f\"\\nüìà Estad√≠sticas de ID_User:\")\n",
    "print(f\"   IDs √∫nicos: {ids_unicos:,}\")\n",
    "print(f\"   Total registros: {total_registros:,}\")\n",
    "print(f\"   IDs duplicados: {total_registros - ids_unicos:,}\")\n",
    "\n",
    "if ids_unicos < total_registros:\n",
    "    print(f\"‚ö†Ô∏è Se encontraron {total_registros - ids_unicos} IDs duplicados\")\n",
    "else:\n",
    "    print(f\"‚úÖ Todos los IDs son √∫nicos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### 4.1.2. MAestro EDAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la columna EDAD en maestro_ADRES\n",
    "print(\"üìù CREANDO COLUMNA EDAD EN maestro_ADRES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Obtener la fecha actual\n",
    "fecha_actual = datetime.now()\n",
    "print(f\"üìÖ Fecha actual: {fecha_actual.strftime('%d/%m/%Y')}\")\n",
    "\n",
    "def calcular_edad_exacta(fecha_nacimiento_str):\n",
    "    \"\"\"\n",
    "    Calcula la edad exacta en a√±os sin aproximaciones\n",
    "    \n",
    "    Args:\n",
    "        fecha_nacimiento_str: Fecha en formato DD/MM/YYYY como string\n",
    "    \n",
    "    Returns:\n",
    "        int: Edad en a√±os completos\n",
    "    \"\"\"\n",
    "    if pd.isna(fecha_nacimiento_str) or str(fecha_nacimiento_str).strip() == '':\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Convertir string a datetime\n",
    "        fecha_nacimiento = datetime.strptime(str(fecha_nacimiento_str), '%d/%m/%Y')\n",
    "        \n",
    "        # Calcular edad\n",
    "        edad = fecha_actual.year - fecha_nacimiento.year\n",
    "        \n",
    "        # Verificar si ya cumpli√≥ a√±os este a√±o\n",
    "        # Si el mes y d√≠a actual son menores al de nacimiento, restar 1 a√±o\n",
    "        if (fecha_actual.month, fecha_actual.day) < (fecha_nacimiento.month, fecha_nacimiento.day):\n",
    "            edad -= 1\n",
    "            \n",
    "        return edad\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è Error procesando fecha '{fecha_nacimiento_str}': {e}\")\n",
    "        return None\n",
    "\n",
    "# Aplicar el c√°lculo de edad\n",
    "print(f\"üìä Procesando {len(maestro_ADRES)} registros...\")\n",
    "\n",
    "maestro_ADRES['EDAD'] = maestro_ADRES['AFL_FECHA_NACIMIENTO'].apply(calcular_edad_exacta)\n",
    "\n",
    "# Verificaci√≥n de resultados\n",
    "edad_validas = maestro_ADRES['EDAD'].notna().sum()\n",
    "edad_invalidas = maestro_ADRES['EDAD'].isna().sum()\n",
    "\n",
    "print(f\"\\nüìà RESULTADOS:\")\n",
    "print(f\"   Total de registros: {len(maestro_ADRES):,}\")\n",
    "print(f\"   Edades calculadas: {edad_validas:,}\")\n",
    "print(f\"   Edades no calculadas: {edad_invalidas:,}\")\n",
    "print(f\"   Porcentaje exitoso: {(edad_validas/len(maestro_ADRES))*100:.2f}%\")\n",
    "\n",
    "# Estad√≠sticas de edades\n",
    "if edad_validas > 0:\n",
    "    edad_min = maestro_ADRES['EDAD'].min()\n",
    "    edad_max = maestro_ADRES['EDAD'].max()\n",
    "    edad_promedio = maestro_ADRES['EDAD'].mean()\n",
    "    \n",
    "    print(f\"\\nüìä ESTAD√çSTICAS DE EDAD:\")\n",
    "    print(f\"   Edad m√≠nima: {edad_min} a√±os\")\n",
    "    print(f\"   Edad m√°xima: {edad_max} a√±os\")\n",
    "    print(f\"   Edad promedio: {edad_promedio:.1f} a√±os\")\n",
    "    \n",
    "    # Mostrar ejemplos\n",
    "    print(f\"\\nüìã EJEMPLOS:\")\n",
    "    ejemplos = maestro_ADRES[['AFL_FECHA_NACIMIENTO', 'EDAD']].dropna().head(10)\n",
    "    for idx, row in ejemplos.iterrows():\n",
    "        print(f\"   Fecha nacimiento: {row['AFL_FECHA_NACIMIENTO']} ‚Üí Edad: {row['EDAD']} a√±os\")\n",
    "\n",
    "# Verificar casos problem√°ticos si los hay\n",
    "if edad_invalidas > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è REGISTROS PROBLEM√ÅTICOS:\")\n",
    "    problematicos = maestro_ADRES[maestro_ADRES['EDAD'].isna()]['AFL_FECHA_NACIMIENTO'].head(5)\n",
    "    print(f\"   Ejemplos de fechas problem√°ticas: {problematicos.tolist()}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Columna EDAD creada exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 4.2. Estructura general de NS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ordenar por la columna NOVEDAD (de menor a mayor)\n",
    "df_NS = df_NS.sort_values('NOVEDAD').reset_index(drop=True)\n",
    "\n",
    "# 2. Funci√≥n mejorada para formatear fechas con detecci√≥n autom√°tica de formato\n",
    "def format_date_column_with_diagnosis(df, column_name, target_format='%d/%m/%Y'):\n",
    "    \"\"\"Estandariza formato de fecha con diagn√≥stico completo y detecci√≥n de m√∫ltiples formatos\"\"\"\n",
    "    print(f\"\\n=== PROCESANDO COLUMNA: {column_name} ===\")\n",
    "    \n",
    "    # DIAGN√ìSTICO ANTES\n",
    "    original_total = len(df)\n",
    "    original_nulls = df[column_name].isna().sum()\n",
    "    original_not_nulls = df[column_name].notna().sum()\n",
    "    \n",
    "    print(f\"üìä ANTES DEL PROCESAMIENTO:\")\n",
    "    print(f\"   Total registros: {original_total}\")\n",
    "    print(f\"   Fechas vac√≠as/nulas: {original_nulls}\")\n",
    "    print(f\"   Fechas no vac√≠as: {original_not_nulls}\")\n",
    "    print(f\"   Porcentaje de vac√≠as: {(original_nulls/original_total)*100:.2f}%\")\n",
    "    \n",
    "    # Mostrar ejemplos de fechas originales\n",
    "    if original_not_nulls > 0:\n",
    "        print(f\"   Ejemplos de fechas originales: {df[column_name].dropna().head(5).tolist()}\")\n",
    "    \n",
    "    # Guardar valores originales para debugging\n",
    "    original_values = df[column_name].copy()\n",
    "    \n",
    "    try:\n",
    "        # ‚úÖ AN√ÅLISIS DE M√öLTIPLES FORMATOS EN LOS DATOS\n",
    "        sample_dates = df[column_name].dropna().astype(str).head(10).tolist()\n",
    "        \n",
    "        formato_iso_tiempo = any(\":\" in date and len(date) > 10 for date in sample_dates)\n",
    "        formato_iso_simple = any(\"-\" in date and date.count(\"-\") == 2 and \":\" not in date for date in sample_dates)\n",
    "        formato_barras = any(\"/\" in date for date in sample_dates)\n",
    "        \n",
    "        print(f\"   üîç FORMATOS DETECTADOS:\")\n",
    "        print(f\"     ISO con tiempo (YYYY-MM-DD HH:MM:SS): {formato_iso_tiempo}\")\n",
    "        print(f\"     ISO simple (YYYY-MM-DD): {formato_iso_simple}\")\n",
    "        print(f\"     Formato con barras (DD/MM/YYYY): {formato_barras}\")\n",
    "        \n",
    "        # ‚úÖ PROCESAMIENTO SECUENCIAL POR FORMATO\n",
    "        converted_dates = pd.Series([pd.NaT] * len(df), index=df.index)\n",
    "        \n",
    "        for idx, valor in df[column_name].items():\n",
    "            if pd.isna(valor) or str(valor).strip() == '':\n",
    "                continue\n",
    "                \n",
    "            valor_str = str(valor).strip()\n",
    "            \n",
    "            try:\n",
    "                # Intentar ISO con tiempo primero\n",
    "                if \":\" in valor_str and len(valor_str) > 10:\n",
    "                    converted_dates.loc[idx] = pd.to_datetime(valor_str)\n",
    "                # Intentar ISO simple\n",
    "                elif \"-\" in valor_str and valor_str.count(\"-\") == 2 and \":\" not in valor_str:\n",
    "                    converted_dates.loc[idx] = pd.to_datetime(valor_str)\n",
    "                # Intentar formato con barras (europeo)\n",
    "                elif \"/\" in valor_str:\n",
    "                    converted_dates.loc[idx] = pd.to_datetime(valor_str, dayfirst=True)\n",
    "                # √öltimo intento con detecci√≥n autom√°tica\n",
    "                else:\n",
    "                    converted_dates.loc[idx] = pd.to_datetime(valor_str)\n",
    "                    \n",
    "            except Exception:\n",
    "                # Si falla todo, intentar una vez m√°s con detecci√≥n autom√°tica sin dayfirst\n",
    "                try:\n",
    "                    converted_dates.loc[idx] = pd.to_datetime(valor_str)\n",
    "                except Exception:\n",
    "                    # Si sigue fallando, dejar como NaT\n",
    "                    pass\n",
    "        \n",
    "        # Aplicar formato de salida solo a fechas v√°lidas\n",
    "        mask_validas = converted_dates.notna()\n",
    "        df[column_name] = pd.Series([None] * len(df), index=df.index)\n",
    "        df.loc[mask_validas, column_name] = converted_dates.loc[mask_validas].dt.strftime(target_format)\n",
    "        \n",
    "        # DIAGN√ìSTICO DESPU√âS\n",
    "        final_nulls = df[column_name].isna().sum()\n",
    "        final_not_nulls = df[column_name].notna().sum()\n",
    "        dates_lost = original_not_nulls - final_not_nulls\n",
    "        \n",
    "        print(f\"üìà DESPU√âS DEL PROCESAMIENTO:\")\n",
    "        print(f\"   Fechas vac√≠as/nulas: {final_nulls}\")\n",
    "        print(f\"   Fechas no vac√≠as: {final_not_nulls}\")\n",
    "        print(f\"   Porcentaje de vac√≠as: {(final_nulls/original_total)*100:.2f}%\")\n",
    "        print(f\"   Fechas perdidas en el proceso: {dates_lost}\")\n",
    "        \n",
    "        if dates_lost > 0:\n",
    "            print(f\"   ‚ö†Ô∏è  SE PERDIERON {dates_lost} FECHAS EN EL PROCESO\")\n",
    "            # Mostrar ejemplos de fechas perdidas\n",
    "            lost_mask = converted_dates.isna() & original_values.notna()\n",
    "            if lost_mask.any():\n",
    "                print(f\"   Ejemplos de fechas perdidas: {original_values[lost_mask].head().tolist()}\")\n",
    "        else:\n",
    "            print(f\"   ‚úÖ NO SE PERDIERON FECHAS\")\n",
    "        \n",
    "        # Mostrar ejemplos de fechas finales\n",
    "        if final_not_nulls > 0:\n",
    "            print(f\"   Ejemplos de fechas finales: {df[column_name].dropna().head(5).tolist()}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al formatear la columna {column_name}: {e}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Validaci√≥n inicial de fechas vac√≠as\n",
    "print(\"üîç VALIDACI√ìN INICIAL DE FECHAS VAC√çAS:\")\n",
    "print(f\"AFL_FECHA_NACIMIENTO vac√≠as: {df_NS['AFL_FECHA_NACIMIENTO'].isna().sum()}\")\n",
    "print(f\"FECHA_NOVEDAD vac√≠as: {df_NS['FECHA_NOVEDAD'].isna().sum()}\")\n",
    "\n",
    "# Aplicar formateo de fechas con diagn√≥stico\n",
    "df_NS = format_date_column_with_diagnosis(df_NS, 'AFL_FECHA_NACIMIENTO')\n",
    "df_NS = format_date_column_with_diagnosis(df_NS, 'FECHA_NOVEDAD')\n",
    "\n",
    "# 3. Estandarizar DPR_ID a 2 d√≠gitos con ceros a la izquierda\n",
    "df_NS['DPR_ID'] = df_NS['DPR_ID'].astype(str).str.zfill(2)\n",
    "\n",
    "# 4. Estandarizar MNS_ID a 3 d√≠gitos con ceros a la izquierda\n",
    "df_NS['MNS_ID'] = df_NS['MNS_ID'].astype(str).str.zfill(3)\n",
    "\n",
    "# VERIFICACI√ìN FINAL COMPLETA\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìã VERIFICACI√ìN FINAL DE ESTANDARIZACI√ìN:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"NOVEDAD ordenada - Primeros 5 valores: {df_NS['NOVEDAD'].head().tolist()}\")\n",
    "print(f\"AFL_FECHA_NACIMIENTO - Muestra: {df_NS['AFL_FECHA_NACIMIENTO'].head().tolist()}\")\n",
    "print(f\"FECHA_NOVEDAD - Muestra: {df_NS['FECHA_NOVEDAD'].head().tolist()}\")\n",
    "print(f\"DPR_ID - Valores √∫nicos: {sorted(df_NS['DPR_ID'].unique())}\")\n",
    "print(f\"MNS_ID - Valores √∫nicos: {sorted(df_NS['MNS_ID'].unique())}\")\n",
    "\n",
    "# RESUMEN FINAL DE FECHAS VAC√çAS\n",
    "print(f\"\\nüéØ RESUMEN FINAL DE FECHAS VAC√çAS:\")\n",
    "print(f\"AFL_FECHA_NACIMIENTO vac√≠as: {df_NS['AFL_FECHA_NACIMIENTO'].isna().sum()}\")\n",
    "print(f\"FECHA_NOVEDAD vac√≠as: {df_NS['FECHA_NOVEDAD'].isna().sum()}\")\n",
    "print(f\"Total de registros: {len(df_NS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## 4.3. √ë"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n mejorada para corregir caracteres especiales con validaciones adicionales\n",
    "def corregir_caracteres_especiales(df, caracteres_problematicos=['¬•', '?', '√É‚Äò'], caracter_correcto='√ë'):\n",
    "    \"\"\"\n",
    "    Corrige caracteres especiales mal codificados en todas las columnas de texto del DataFrame\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a procesar\n",
    "        caracteres_problematicos: Lista de caracteres que se quieren reemplazar\n",
    "        caracter_correcto: Caracter por el cual se van a reemplazar\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame con caracteres corregidos\n",
    "    \"\"\"\n",
    "    print(f\"üîß INICIANDO CORRECCI√ìN DE CARACTERES ESPECIALES\")\n",
    "    print(f\"   Caracteres a corregir: {caracteres_problematicos} ‚Üí {caracter_correcto}\")\n",
    "    \n",
    "    # Validaci√≥n inicial\n",
    "    if df is None or df.empty:\n",
    "        print(\"   ‚ö†Ô∏è DataFrame vac√≠o o None\")\n",
    "        return df\n",
    "    \n",
    "    # Contadores\n",
    "    total_cambios = 0\n",
    "    cambios_por_columna = {}\n",
    "    filas_modificadas = set()  # Usar set para evitar duplicados\n",
    "    \n",
    "    # Obtener solo columnas de tipo object (texto)\n",
    "    columnas_texto = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    total_filas = len(df)\n",
    "    \n",
    "    print(f\"   DataFrame shape: {df.shape}\")\n",
    "    print(f\"   Procesando {len(columnas_texto)} columnas de texto en {total_filas} filas...\")\n",
    "    print(f\"   Columnas de texto: {columnas_texto[:5]}{'...' if len(columnas_texto) > 5 else ''}\")\n",
    "    \n",
    "    # Procesar cada columna de texto\n",
    "    for columna in columnas_texto:\n",
    "        # Validar que la columna existe\n",
    "        if columna not in df.columns:\n",
    "            print(f\"   ‚ö†Ô∏è Columna '{columna}' no encontrada, saltando...\")\n",
    "            continue\n",
    "            \n",
    "        cambios_columna = 0\n",
    "        \n",
    "        try:\n",
    "            # Para cada caracter problem√°tico\n",
    "            for char_problema in caracteres_problematicos:\n",
    "                # Obtener la serie de la columna y convertir a string\n",
    "                serie_columna = df[columna].astype(str)\n",
    "                \n",
    "                # Identificar filas con problemas ANTES del cambio\n",
    "                mask_problemas = serie_columna.str.contains(char_problema, na=False, regex=False)\n",
    "                ocurrencias_antes = mask_problemas.sum()\n",
    "                \n",
    "                if ocurrencias_antes > 0:\n",
    "                    # Agregar √≠ndices de filas modificadas al set\n",
    "                    indices_modificados = df[mask_problemas].index.tolist()\n",
    "                    filas_modificadas.update(indices_modificados)\n",
    "                    \n",
    "                    # Realizar el reemplazo\n",
    "                    df[columna] = serie_columna.str.replace(char_problema, caracter_correcto, regex=False)\n",
    "                    cambios_columna += ocurrencias_antes\n",
    "                    \n",
    "                    # Mostrar ejemplos de cambios\n",
    "                    if ocurrencias_antes > 0:\n",
    "                        ejemplos_antes = df.loc[indices_modificados[:3], columna].tolist()\n",
    "                        print(f\"     üìù {columna}: {ocurrencias_antes} ocurrencias de '{char_problema}' corregidas\")\n",
    "                        print(f\"        Ejemplos corregidos: {ejemplos_antes}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error procesando columna '{columna}': {e}\")\n",
    "            continue\n",
    "        \n",
    "        if cambios_columna > 0:\n",
    "            cambios_por_columna[columna] = cambios_columna\n",
    "            total_cambios += cambios_columna\n",
    "    \n",
    "    # Estad√≠sticas finales\n",
    "    total_filas_modificadas = len(filas_modificadas)\n",
    "    porcentaje_filas_modificadas = (total_filas_modificadas / total_filas) * 100 if total_filas > 0 else 0\n",
    "    \n",
    "    # Resumen final\n",
    "    print(f\"\\nüìä RESUMEN DE CORRECCIONES:\")\n",
    "    print(f\"   Total de cambios realizados: {total_cambios}\")\n",
    "    print(f\"   Total de filas modificadas: {total_filas_modificadas}\")\n",
    "    print(f\"   Porcentaje de filas modificadas: {porcentaje_filas_modificadas:.2f}%\")\n",
    "    print(f\"   Filas sin modificar: {total_filas - total_filas_modificadas}\")\n",
    "    \n",
    "    if cambios_por_columna:\n",
    "        print(f\"   üìà Columnas afectadas:\")\n",
    "        for col, cambios in cambios_por_columna.items():\n",
    "            print(f\"     - {col}: {cambios} cambios\")\n",
    "        \n",
    "        # Mostrar algunos √≠ndices de filas modificadas\n",
    "        if total_filas_modificadas > 0:\n",
    "            indices_muestra = sorted(list(filas_modificadas))[:10]\n",
    "            print(f\"   üìç Ejemplos de filas modificadas (√≠ndices): {indices_muestra}\")\n",
    "            if total_filas_modificadas > 10:\n",
    "                print(f\"      ... y {total_filas_modificadas - 10} filas m√°s\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ No se encontraron caracteres problem√°ticos\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Aplicar correcci√≥n a df_NS con conteo de filas\n",
    "print(\"=\"*60)\n",
    "print(\"CORRIGIENDO CARACTERES EN df_NS\")\n",
    "print(\"=\"*60)\n",
    "df_NS = corregir_caracteres_especiales(df_NS)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CORRIGIENDO CARACTERES EN maestro_ADRES\")\n",
    "print(\"=\"*60)\n",
    "maestro_ADRES = corregir_caracteres_especiales(maestro_ADRES)\n",
    "\n",
    "# Verificaci√≥n adicional mejorada con conteo\n",
    "print(\"\\nüîç VERIFICACI√ìN ESPEC√çFICA PARA PALABRAS COMUNES:\")\n",
    "palabras_verificar = ['NI√ëO', 'NI√ëA', 'A√ëO', 'PE√ëA', 'MONTA√ëA', 'ESPA√ëA']\n",
    "\n",
    "for df_name, df in [('df_NS', df_NS), ('maestro_ADRES', maestro_ADRES)]:\n",
    "    print(f\"\\n   üìã Verificando en {df_name} ({len(df)} filas):\")\n",
    "    columnas_texto = df.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    for palabra in palabras_verificar:\n",
    "        total_encontradas = 0\n",
    "        filas_con_palabra = set()\n",
    "        \n",
    "        for col in columnas_texto:\n",
    "            try:\n",
    "                # CORREGIDO: agregado regex=False tambi√©n en la verificaci√≥n\n",
    "                mask_palabra = df[col].astype(str).str.contains(palabra, case=False, na=False, regex=False)\n",
    "                count = mask_palabra.sum()\n",
    "                total_encontradas += count\n",
    "                \n",
    "                if count > 0:\n",
    "                    filas_con_palabra.update(df[mask_palabra].index.tolist())\n",
    "            except Exception as e:\n",
    "                print(f\"     ‚ö†Ô∏è Error verificando '{palabra}' en columna '{col}': {e}\")\n",
    "                continue\n",
    "        \n",
    "        if total_encontradas > 0:\n",
    "            print(f\"     ‚úÖ '{palabra}': {total_encontradas} ocurrencias en {len(filas_con_palabra)} filas\")\n",
    "        else:\n",
    "            print(f\"     ‚ùå '{palabra}': No encontrada\")\n",
    "\n",
    "# Resumen global final\n",
    "print(f\"\\nüéØ RESUMEN GLOBAL DE CORRECCIONES:\")\n",
    "print(f\"   df_NS: {len(df_NS)} registros procesados\")\n",
    "print(f\"   maestro_ADRES: {len(maestro_ADRES)} registros procesados\")\n",
    "print(f\"   ‚úÖ Proceso de correcci√≥n de caracteres completado\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## 4.4. Estado y EPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaciar las columnas ENT_ID_ADRES y TPS_EST_AFL_ID_from_adres\n",
    "print(\"üîß VACIANDO COLUMNAS ENT_ID_ADRES Y TPS_EST_AFL_ID_from_adres\")\n",
    "df_NS['ENT_ID_ADRES'] = ''\n",
    "df_NS['TPS_EST_AFL_ID_from_adres'] = ''\n",
    "\n",
    "# Crear la columna ID_User (concatenaci√≥n de TPS_IDN_ID + HST_IDN_NUMERO_IDENTIFICACION)\n",
    "print(\"üìù CREANDO COLUMNA ID_User\")\n",
    "df_NS['ID_User'] = df_NS['TPS_IDN_ID'].astype(str) + df_NS['HST_IDN_NUMERO_IDENTIFICACION'].astype(str)\n",
    "\n",
    "# Crear la columna ID_Register con l√≥gica condicional\n",
    "print(\"üìù CREANDO COLUMNA ID_Register\")\n",
    "\n",
    "# Para registros N39: TPS_IDN_ID + HST_IDN_NUMERO_IDENTIFICACION + NOVEDAD + COD_1_NOVEDAD\n",
    "mask_n39 = df_NS['NOVEDAD'] == 'N39'\n",
    "df_NS.loc[mask_n39, 'ID_Register'] = (\n",
    "    df_NS.loc[mask_n39, 'TPS_IDN_ID'].astype(str) + \n",
    "    df_NS.loc[mask_n39, 'HST_IDN_NUMERO_IDENTIFICACION'].astype(str) + \n",
    "    df_NS.loc[mask_n39, 'NOVEDAD'].astype(str) + \n",
    "    df_NS.loc[mask_n39, 'COD_1_NOVEDAD'].astype(str)\n",
    ")\n",
    "\n",
    "# Para todos los dem√°s registros: TPS_IDN_ID + HST_IDN_NUMERO_IDENTIFICACION + NOVEDAD\n",
    "mask_no_n39 = df_NS['NOVEDAD'] != 'N39'\n",
    "df_NS.loc[mask_no_n39, 'ID_Register'] = (\n",
    "    df_NS.loc[mask_no_n39, 'TPS_IDN_ID'].astype(str) + \n",
    "    df_NS.loc[mask_no_n39, 'HST_IDN_NUMERO_IDENTIFICACION'].astype(str) + \n",
    "    df_NS.loc[mask_no_n39, 'NOVEDAD'].astype(str)\n",
    ")\n",
    "\n",
    "# Verificaci√≥n de resultados\n",
    "print(\"\\nüìä VERIFICACI√ìN DE RESULTADOS:\")\n",
    "print(f\"Total de registros: {len(df_NS)}\")\n",
    "print(f\"Registros N39: {mask_n39.sum()}\")\n",
    "print(f\"Registros no N39: {mask_no_n39.sum()}\")\n",
    "\n",
    "print(f\"\\nColumnas vaciadas:\")\n",
    "print(f\"ENT_ID_ADRES valores √∫nicos: {df_NS['ENT_ID_ADRES'].unique()}\")\n",
    "print(f\"TPS_EST_AFL_ID_from_adres valores √∫nicos: {df_NS['TPS_EST_AFL_ID_from_adres'].unique()}\")\n",
    "\n",
    "print(f\"\\nEjemplos de ID_User: {df_NS['ID_User'].head().tolist()}\")\n",
    "print(f\"Ejemplos de ID_Register (N39): {df_NS[mask_n39]['ID_Register'].head().tolist()}\")\n",
    "print(f\"Ejemplos de ID_Register (no N39): {df_NS[mask_no_n39]['ID_Register'].head().tolist()}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Proceso completado exitosamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar el cruce con maestro_ADRES para traer ENT_ID y TPS_EST_AFL_ID\n",
    "print(\"üîÑ REALIZANDO CRUCE CON maestro_ADRES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear un DataFrame con solo las columnas necesarias del maestro_ADRES\n",
    "maestro_subset = maestro_ADRES[['ID_User', 'ENT_ID', 'TPS_EST_AFL_ID']].copy()\n",
    "\n",
    "# Renombrar las columnas para evitar conflictos\n",
    "maestro_subset = maestro_subset.rename(columns={\n",
    "    'ENT_ID': 'ENT_ID_ADRES_NEW',\n",
    "    'TPS_EST_AFL_ID': 'TPS_EST_AFL_ID_from_adres_NEW'\n",
    "})\n",
    "\n",
    "print(f\"üìä maestro_ADRES: {len(maestro_ADRES):,} registros\")\n",
    "print(f\"üìä df_NS: {len(df_NS):,} registros\")\n",
    "print(f\"üìä IDs √∫nicos en maestro_ADRES: {maestro_subset['ID_User'].nunique():,}\")\n",
    "print(f\"üìä IDs √∫nicos en df_NS: {df_NS['ID_User'].nunique():,}\")\n",
    "\n",
    "# Realizar el merge LEFT para mantener todos los registros de df_NS\n",
    "df_NS_merged = df_NS.merge(maestro_subset, on='ID_User', how='left')\n",
    "\n",
    "# Actualizar las columnas originales con los nuevos valores\n",
    "df_NS_merged['ENT_ID_ADRES'] = df_NS_merged['ENT_ID_ADRES_NEW']\n",
    "df_NS_merged['TPS_EST_AFL_ID_from_adres'] = df_NS_merged['TPS_EST_AFL_ID_from_adres_NEW']\n",
    "\n",
    "# Eliminar las columnas temporales\n",
    "df_NS = df_NS_merged.drop(columns=['ENT_ID_ADRES_NEW', 'TPS_EST_AFL_ID_from_adres_NEW'])\n",
    "\n",
    "print(f\"‚úÖ Cruce completado\")\n",
    "\n",
    "# AN√ÅLISIS DE RESULTADOS\n",
    "print(f\"\\nüìà AN√ÅLISIS DE RESULTADOS DEL CRUCE:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calcular estad√≠sticas generales\n",
    "total_registros = len(df_NS)\n",
    "print(f\"üìä Total de registros en df_NS: {total_registros:,}\")\n",
    "\n",
    "# ENT_ID_ADRES\n",
    "ent_id_vacios = df_NS['ENT_ID_ADRES'].isna().sum()\n",
    "ent_id_llenos = df_NS['ENT_ID_ADRES'].notna().sum()\n",
    "ent_id_porcentaje_vacios = (ent_id_vacios / total_registros) * 100\n",
    "\n",
    "print(f\"\\nüè¢ ENT_ID_ADRES:\")\n",
    "print(f\"   Registros con datos: {ent_id_llenos:,}\")\n",
    "print(f\"   Registros vac√≠os: {ent_id_vacios:,}\")\n",
    "print(f\"   Porcentaje vac√≠os: {ent_id_porcentaje_vacios:.2f}%\")\n",
    "\n",
    "# TPS_EST_AFL_ID_from_adres\n",
    "tps_est_vacios = df_NS['TPS_EST_AFL_ID_from_adres'].isna().sum()\n",
    "tps_est_llenos = df_NS['TPS_EST_AFL_ID_from_adres'].notna().sum()\n",
    "tps_est_porcentaje_vacios = (tps_est_vacios / total_registros) * 100\n",
    "\n",
    "print(f\"\\nüîë TPS_EST_AFL_ID_from_adres:\")\n",
    "print(f\"   Registros con datos: {tps_est_llenos:,}\")\n",
    "print(f\"   Registros vac√≠os: {tps_est_vacios:,}\")\n",
    "print(f\"   Porcentaje vac√≠os: {tps_est_porcentaje_vacios:.2f}%\")\n",
    "\n",
    "# AN√ÅLISIS POR TIPO DE NOVEDAD\n",
    "print(f\"\\nüìã AN√ÅLISIS POR TIPO DE NOVEDAD:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Obtener todos los tipos de novedad\n",
    "tipos_novedad = df_NS['NOVEDAD'].value_counts()\n",
    "print(f\"üìä Tipos de novedad encontrados: {len(tipos_novedad)}\")\n",
    "\n",
    "print(f\"\\nüîç DETALLE POR NOVEDAD - ENT_ID_ADRES:\")\n",
    "for novedad, total in tipos_novedad.items():\n",
    "    mask_novedad = df_NS['NOVEDAD'] == novedad\n",
    "    vacios_novedad = df_NS.loc[mask_novedad, 'ENT_ID_ADRES'].isna().sum()\n",
    "    llenos_novedad = df_NS.loc[mask_novedad, 'ENT_ID_ADRES'].notna().sum()\n",
    "    porcentaje_vacios = (vacios_novedad / total) * 100\n",
    "    \n",
    "    print(f\"   {novedad}: {total:,} registros\")\n",
    "    print(f\"     Con datos: {llenos_novedad:,} ({((llenos_novedad/total)*100):.1f}%)\")\n",
    "    print(f\"     Vac√≠os: {vacios_novedad:,} ({porcentaje_vacios:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüîç DETALLE POR NOVEDAD - TPS_EST_AFL_ID_from_adres:\")\n",
    "for novedad, total in tipos_novedad.items():\n",
    "    mask_novedad = df_NS['NOVEDAD'] == novedad\n",
    "    vacios_novedad = df_NS.loc[mask_novedad, 'TPS_EST_AFL_ID_from_adres'].isna().sum()\n",
    "    llenos_novedad = df_NS.loc[mask_novedad, 'TPS_EST_AFL_ID_from_adres'].notna().sum()\n",
    "    porcentaje_vacios = (vacios_novedad / total) * 100\n",
    "    \n",
    "    print(f\"   {novedad}: {total:,} registros\")\n",
    "    print(f\"     Con datos: {llenos_novedad:,} ({((llenos_novedad/total)*100):.1f}%)\")\n",
    "    print(f\"     Vac√≠os: {vacios_novedad:,} ({porcentaje_vacios:.1f}%)\")\n",
    "\n",
    "# MOSTRAR EJEMPLOS DE DATOS OBTENIDOS\n",
    "print(f\"\\nüìã EJEMPLOS DE DATOS OBTENIDOS:\")\n",
    "print(\"=\"*60)\n",
    "ejemplos_con_datos = df_NS[df_NS['ENT_ID_ADRES'].notna()][['ID_User', 'NOVEDAD', 'ENT_ID_ADRES', 'TPS_EST_AFL_ID_from_adres']].head(10)\n",
    "if len(ejemplos_con_datos) > 0:\n",
    "    print(\"Ejemplos de registros con datos:\")\n",
    "    print(ejemplos_con_datos.to_string(index=False))\n",
    "\n",
    "# IDENTIFICAR REGISTROS SIN MATCH\n",
    "print(f\"\\n‚ö†Ô∏è REGISTROS SIN MATCH EN MAESTRO_ADRES:\")\n",
    "ids_sin_match = df_NS[df_NS['ENT_ID_ADRES'].isna()]['ID_User'].unique()\n",
    "print(f\"   IDs √∫nicos sin match: {len(ids_sin_match):,}\")\n",
    "if len(ids_sin_match) > 0:\n",
    "    print(f\"   Ejemplos de IDs sin match: {ids_sin_match[:10].tolist()}\")\n",
    "\n",
    "print(f\"\\n‚úÖ PROCESO DE CRUCE COMPLETADO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un nuevo DataFrame con los registros donde ENT_ID_ADRES est√° vac√≠o\n",
    "df_NS_vacios = df_NS[df_NS['ENT_ID_ADRES'].isna()].copy()\n",
    "\n",
    "# Verificaci√≥n\n",
    "print(\"üìä NUEVO DATAFRAME: df_NS_vacios\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total de registros con ENT_ID_ADRES vac√≠o: {len(df_NS_vacios):,}\")\n",
    "print(f\"Total de columnas: {len(df_NS_vacios.columns)}\")\n",
    "\n",
    "if len(df_NS_vacios) > 0:\n",
    "    print(f\"\\nüìã Tipos de novedad en registros vac√≠os:\")\n",
    "    print(df_NS_vacios['NOVEDAD'].value_counts())\n",
    "    \n",
    "    print(f\"\\nüìã Primeros registros:\")\n",
    "    print(df_NS_vacios[['NUM_SOLICITUD_NOVEDAD', 'TPS_IDN_ID', 'HST_IDN_NUMERO_IDENTIFICACION', \n",
    "                        'NOVEDAD', 'ENT_ID_ADRES']].head())\n",
    "else:\n",
    "    print(\"‚úÖ No hay registros con ENT_ID_ADRES vac√≠o\")\n",
    "\n",
    "# Verificar que df_NS no fue alterado\n",
    "print(f\"\\n‚úÖ Verificaci√≥n: df_NS mantiene {len(df_NS):,} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_NS_vacios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîß PROCESANDO REGISTROS VAC√çOS EN ENT_ID_ADRES Y TPS_EST_AFL_ID_from_adres\")\n",
    "print(\"=\"*80)\n",
    "print(\"üìã OBJETIVO: Completar datos faltantes con merge de ADRES y l√≥gica de evoluciones\")\n",
    "\n",
    "# DIAGN√ìSTICO INICIAL\n",
    "registros_vacios_inicial = df_NS[\n",
    "    (df_NS['ENT_ID_ADRES'].isna()) | \n",
    "    (df_NS['TPS_EST_AFL_ID_from_adres'].isna())\n",
    "]\n",
    "total_vacios_inicial = len(registros_vacios_inicial)\n",
    "\n",
    "print(f\"\\nüìä DIAGN√ìSTICO INICIAL:\")\n",
    "print(f\"   Total registros en df_NS: {len(df_NS):,}\")\n",
    "print(f\"   Registros con datos vac√≠os: {total_vacios_inicial:,}\")\n",
    "print(f\"   Porcentaje vac√≠os: {(total_vacios_inicial/len(df_NS))*100:.2f}%\")\n",
    "\n",
    "if total_vacios_inicial == 0:\n",
    "    print(\"‚úÖ No hay registros vac√≠os para procesar\")\n",
    "else:\n",
    "    # Analizar tipos de novedad en registros vac√≠os\n",
    "    print(f\"\\nüîç AN√ÅLISIS DE REGISTROS VAC√çOS POR NOVEDAD:\")\n",
    "    vacios_por_novedad = registros_vacios_inicial['NOVEDAD'].value_counts()\n",
    "    for novedad, count in vacios_por_novedad.items():\n",
    "        print(f\"   {novedad}: {count} registros\")\n",
    "    \n",
    "    # ========== PASO 1: MERGE DIRECTO CON ADRES (L√ìGICA CORRECTA) ==========\n",
    "    print(f\"\\nüîç PASO 1: Completar desde maestro_ADRES\")\n",
    "    \n",
    "    # Crear DataFrame mini de ADRES con datos √∫nicos\n",
    "    df_adres_mini = (\n",
    "        maestro_ADRES[[\n",
    "            \"TPS_IDN_ID\", \n",
    "            \"HST_IDN_NUMERO_IDENTIFICACION\", \n",
    "            \"ENT_ID\", \n",
    "            \"TPS_EST_AFL_ID\"\n",
    "        ]]\n",
    "        .rename(columns={\n",
    "            \"ENT_ID\": \"ENT_ID_ADRES_from_maestro\",\n",
    "            \"TPS_EST_AFL_ID\": \"TPS_EST_AFL_ID_from_maestro\"\n",
    "        })\n",
    "        .drop_duplicates(subset=[\"TPS_IDN_ID\", \"HST_IDN_NUMERO_IDENTIFICACION\"])\n",
    "    )\n",
    "    \n",
    "    print(f\"   üìä Registros √∫nicos en maestro_ADRES: {len(df_adres_mini):,}\")\n",
    "    \n",
    "    # Hacer merge LEFT para mantener todos los registros de df_NS\n",
    "    df_NS_actualizado = df_NS.merge(\n",
    "        df_adres_mini,\n",
    "        on=[\"TPS_IDN_ID\", \"HST_IDN_NUMERO_IDENTIFICACION\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "    \n",
    "    # Rellenar solo donde faltaba\n",
    "    df_NS_actualizado[\"ENT_ID_ADRES\"] = df_NS_actualizado[\"ENT_ID_ADRES\"].fillna(\n",
    "        df_NS_actualizado[\"ENT_ID_ADRES_from_maestro\"]\n",
    "    )\n",
    "    df_NS_actualizado[\"TPS_EST_AFL_ID_from_adres\"] = df_NS_actualizado[\"TPS_EST_AFL_ID_from_adres\"].fillna(\n",
    "        df_NS_actualizado[\"TPS_EST_AFL_ID_from_maestro\"]\n",
    "    )\n",
    "    \n",
    "    # Contar actualizaciones del PASO 1\n",
    "    registros_vacios_despues_paso1 = df_NS_actualizado[\n",
    "        (df_NS_actualizado['ENT_ID_ADRES'].isna()) | \n",
    "        (df_NS_actualizado['TPS_EST_AFL_ID_from_adres'].isna())\n",
    "    ]\n",
    "    actualizados_por_adres = total_vacios_inicial - len(registros_vacios_despues_paso1)\n",
    "    \n",
    "    print(f\"   ‚úÖ Registros completados desde maestro_ADRES: {actualizados_por_adres:,}\")\n",
    "    print(f\"   üìä Registros a√∫n vac√≠os despu√©s del PASO 1: {len(registros_vacios_despues_paso1):,}\")\n",
    "    \n",
    "    # Eliminar columnas temporales\n",
    "    df_NS_actualizado.drop(columns=[\n",
    "        \"ENT_ID_ADRES_from_maestro\", \n",
    "        \"TPS_EST_AFL_ID_from_maestro\"\n",
    "    ], inplace=True)\n",
    "    \n",
    "    # ========== PASO 2: L√ìGICA CORRECTA DE EVOLUCIONES ==========\n",
    "    print(f\"\\nüîç PASO 2: Completar por evoluciones (L√ìGICA CORREGIDA)\")\n",
    "    \n",
    "    # ‚úÖ CREAR MAPA CORRECTO: N01 con datos completos ‚Üí beneficiarios\n",
    "    mapa_evoluciones = (\n",
    "        df_NS_actualizado.loc[\n",
    "            (df_NS_actualizado[\"NOVEDAD\"] == \"N01\") & \n",
    "            (df_NS_actualizado[\"ENT_ID_ADRES\"].notna()) &\n",
    "            (df_NS_actualizado[\"TPS_EST_AFL_ID_from_adres\"].notna()),\n",
    "            [\"COD_1_NOVEDAD\", \"COD_2_NOVEDAD\", \"ENT_ID_ADRES\", \"TPS_EST_AFL_ID_from_adres\"]\n",
    "        ]\n",
    "        .dropna(subset=[\"COD_1_NOVEDAD\", \"COD_2_NOVEDAD\"])  # Solo N01 con c√≥digos v√°lidos\n",
    "        .rename(columns={\n",
    "            \"COD_1_NOVEDAD\": \"TPS_IDN_ID\",  # ‚Üê CLAVE: Los c√≥digos de N01 se vuelven IDs principales\n",
    "            \"COD_2_NOVEDAD\": \"HST_IDN_NUMERO_IDENTIFICACION\",\n",
    "            \"ENT_ID_ADRES\": \"ENT_ID_from_evol\",\n",
    "            \"TPS_EST_AFL_ID_from_adres\": \"TPS_EST_AFL_ID_from_evol\"\n",
    "        })\n",
    "        .drop_duplicates(subset=[\"TPS_IDN_ID\", \"HST_IDN_NUMERO_IDENTIFICACION\"])\n",
    "    )\n",
    "    \n",
    "    print(f\"   üìã Registros N01 v√°lidos para mapeo: {len(mapa_evoluciones):,}\")\n",
    "    \n",
    "    if len(mapa_evoluciones) > 0:\n",
    "        # Hacer merge para traer datos de evoluciones\n",
    "        df_NS_actualizado = df_NS_actualizado.merge(\n",
    "            mapa_evoluciones,\n",
    "            on=[\"TPS_IDN_ID\", \"HST_IDN_NUMERO_IDENTIFICACION\"],\n",
    "            how=\"left\"\n",
    "        )\n",
    "        \n",
    "        # ‚úÖ APLICAR EVOLUCIONES SOLO A REGISTROS VAC√çOS QUE NO SEAN N01\n",
    "        mask_evol = (\n",
    "            df_NS_actualizado[\"ENT_ID_ADRES\"].isna() &\n",
    "            df_NS_actualizado[\"NOVEDAD\"].str.startswith(\"N0\") &\n",
    "            (df_NS_actualizado[\"NOVEDAD\"] != \"N01\")  # Excluir N01\n",
    "        )\n",
    "        \n",
    "        registros_completados_por_evol = mask_evol.sum()\n",
    "        \n",
    "        # Aplicar evoluciones\n",
    "        df_NS_actualizado.loc[mask_evol, \"ENT_ID_ADRES\"] = df_NS_actualizado.loc[mask_evol, \"ENT_ID_from_evol\"]\n",
    "        df_NS_actualizado.loc[mask_evol, \"TPS_EST_AFL_ID_from_adres\"] = df_NS_actualizado.loc[mask_evol, \"TPS_EST_AFL_ID_from_evol\"]\n",
    "        \n",
    "        print(f\"   ‚úÖ Registros completados por evoluciones: {registros_completados_por_evol:,}\")\n",
    "        \n",
    "        # Eliminar columnas temporales\n",
    "        df_NS_actualizado.drop(columns=[\n",
    "            \"ENT_ID_from_evol\", \n",
    "            \"TPS_EST_AFL_ID_from_evol\"\n",
    "        ], inplace=True, errors='ignore')\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è No hay registros N01 v√°lidos para crear mapeo de evoluciones\")\n",
    "        registros_completados_por_evol = 0\n",
    "    \n",
    "    # ========== PASO 3: B√öSQUEDA INTERNA ADICIONAL ==========\n",
    "    print(f\"\\nüîç PASO 3: B√∫squeda interna adicional por TPS_IDN_ID + HST_IDN_NUMERO_IDENTIFICACION\")\n",
    "    \n",
    "    # Crear referencia interna de registros con datos completos\n",
    "    df_referencia_interna = df_NS_actualizado[\n",
    "        (df_NS_actualizado['ENT_ID_ADRES'].notna()) & \n",
    "        (df_NS_actualizado['TPS_EST_AFL_ID_from_adres'].notna())\n",
    "    ][['TPS_IDN_ID', 'HST_IDN_NUMERO_IDENTIFICACION', 'ENT_ID_ADRES', 'TPS_EST_AFL_ID_from_adres']].drop_duplicates()\n",
    "    \n",
    "    print(f\"   üìä Registros de referencia interna: {len(df_referencia_interna):,}\")\n",
    "    \n",
    "    # Identificar registros a√∫n vac√≠os\n",
    "    registros_aun_vacios = df_NS_actualizado[\n",
    "        (df_NS_actualizado['ENT_ID_ADRES'].isna()) | \n",
    "        (df_NS_actualizado['TPS_EST_AFL_ID_from_adres'].isna())\n",
    "    ]\n",
    "    \n",
    "    actualizados_busqueda_interna = 0\n",
    "    \n",
    "    if len(registros_aun_vacios) > 0 and len(df_referencia_interna) > 0:\n",
    "        # Hacer merge para buscar coincidencias internas\n",
    "        merge_interno = registros_aun_vacios.merge(\n",
    "            df_referencia_interna,\n",
    "            on=['TPS_IDN_ID', 'HST_IDN_NUMERO_IDENTIFICACION'],\n",
    "            how='left',\n",
    "            suffixes=('', '_interno')\n",
    "        )\n",
    "        \n",
    "        # Aplicar valores encontrados\n",
    "        mask_encontrados = merge_interno['ENT_ID_ADRES_interno'].notna()\n",
    "        indices_encontrados = merge_interno[mask_encontrados].index\n",
    "        \n",
    "        df_NS_actualizado.loc[indices_encontrados, 'ENT_ID_ADRES'] = merge_interno.loc[indices_encontrados, 'ENT_ID_ADRES_interno']\n",
    "        df_NS_actualizado.loc[indices_encontrados, 'TPS_EST_AFL_ID_from_adres'] = merge_interno.loc[indices_encontrados, 'TPS_EST_AFL_ID_from_adres_interno']\n",
    "        \n",
    "        actualizados_busqueda_interna = mask_encontrados.sum()\n",
    "    \n",
    "    print(f\"   ‚úÖ Registros completados por b√∫squeda interna: {actualizados_busqueda_interna:,}\")\n",
    "    \n",
    "    # Actualizar el DataFrame principal\n",
    "    df_NS = df_NS_actualizado.copy()\n",
    "    \n",
    "    # ========== DIAGN√ìSTICO FINAL ==========\n",
    "    print(f\"\\nüìà DIAGN√ìSTICO FINAL:\")\n",
    "    registros_vacios_final = df_NS[\n",
    "        (df_NS['ENT_ID_ADRES'].isna()) | \n",
    "        (df_NS['TPS_EST_AFL_ID_from_adres'].isna())\n",
    "    ]\n",
    "    total_vacios_final = len(registros_vacios_final)\n",
    "    total_completados = actualizados_por_adres + registros_completados_por_evol + actualizados_busqueda_interna\n",
    "    \n",
    "    print(f\"   Registros vac√≠os antes: {total_vacios_inicial:,}\")\n",
    "    print(f\"   Registros vac√≠os despu√©s: {total_vacios_final:,}\")\n",
    "    print(f\"   Total registros completados: {total_completados:,}\")\n",
    "    print(f\"   Mejora: {total_vacios_inicial - total_vacios_final:,} registros completados\")\n",
    "    print(f\"   Porcentaje de mejora: {((total_vacios_inicial - total_vacios_final)/total_vacios_inicial)*100:.2f}%\" if total_vacios_inicial > 0 else \"0.00%\")\n",
    "    \n",
    "    # RESUMEN POR M√âTODO\n",
    "    print(f\"\\nüìã RESUMEN POR M√âTODO:\")\n",
    "    print(f\"   Por merge con maestro_ADRES: {actualizados_por_adres:,}\")\n",
    "    print(f\"   Por evoluciones (N01 ‚Üí N02,N03...): {registros_completados_por_evol:,}\")\n",
    "    print(f\"   Por b√∫squeda interna adicional: {actualizados_busqueda_interna:,}\")\n",
    "    print(f\"   Total completados: {total_completados:,}\")\n",
    "    \n",
    "    # AN√ÅLISIS DE REGISTROS QUE A√öN QUEDAN VAC√çOS\n",
    "    if total_vacios_final > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è REGISTROS QUE A√öN QUEDAN VAC√çOS: {total_vacios_final:,}\")\n",
    "        print(f\"   üìä Por tipo de novedad:\")\n",
    "        vacios_finales_por_novedad = registros_vacios_final['NOVEDAD'].value_counts()\n",
    "        for novedad, count in vacios_finales_por_novedad.items():\n",
    "            print(f\"     {novedad}: {count} registros\")\n",
    "        \n",
    "        # Mostrar ejemplos de registros que no se pudieron completar\n",
    "        print(f\"\\n   üìã Ejemplos de registros no completados:\")\n",
    "        ejemplos_vacios = registros_vacios_final[['NUM_SOLICITUD_NOVEDAD', 'TPS_IDN_ID', 'HST_IDN_NUMERO_IDENTIFICACION', \n",
    "                                                 'NOVEDAD', 'COD_1_NOVEDAD', 'COD_2_NOVEDAD']].head(5)\n",
    "        print(ejemplos_vacios.to_string(index=False))\n",
    "    else:\n",
    "        print(f\"\\nüéâ ¬°√âXITO! Todos los registros fueron completados\")\n",
    "    \n",
    "    # VERIFICACI√ìN DE INTEGRIDAD\n",
    "    print(f\"\\nüîç VERIFICACI√ìN DE INTEGRIDAD:\")\n",
    "    ent_id_vacios_final = df_NS['ENT_ID_ADRES'].isna().sum()\n",
    "    tps_est_vacios_final = df_NS['TPS_EST_AFL_ID_from_adres'].isna().sum()\n",
    "    \n",
    "    print(f\"   ENT_ID_ADRES vac√≠os: {ent_id_vacios_final:,}\")\n",
    "    print(f\"   TPS_EST_AFL_ID_from_adres vac√≠os: {tps_est_vacios_final:,}\")\n",
    "    print(f\"   Consistencia: {'‚úÖ' if ent_id_vacios_final == tps_est_vacios_final else '‚ùå'}\")\n",
    "\n",
    "print(f\"\\n‚úÖ PROCESO DE EVOLUCIONES COMPLETADO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## 4.5. validaci√≥n inical regimen y estado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame para registros que no cumplen criterios de env√≠o\n",
    "print(\"üîç CREANDO DATAFRAME DF_No_Envio - FILTROS DE VALIDACI√ìN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Inicializar DF_No_Envio como DataFrame vac√≠o con la misma estructura que df_NS m√°s columna 'motivo'\n",
    "DF_No_Envio = pd.DataFrame(columns=list(df_NS.columns) + ['motivo'])\n",
    "\n",
    "# Contador de registros movidos\n",
    "registros_movidos = 0\n",
    "conteo_por_motivo = {}\n",
    "\n",
    "# ========== VALIDACI√ìN 1: ENT_ID_ADRES vac√≠o o nulo ==========\n",
    "print(\"üîç VALIDACI√ìN 1: ENT_ID_ADRES vac√≠o o nulo\")\n",
    "\n",
    "# Identificar registros con ENT_ID_ADRES vac√≠o o nulo\n",
    "mask_vacios = df_NS['ENT_ID_ADRES'].isna() | (df_NS['ENT_ID_ADRES'] == '') | (df_NS['ENT_ID_ADRES'] == 'nan')\n",
    "registros_vacios = df_NS[mask_vacios].copy()\n",
    "count_vacios = len(registros_vacios)\n",
    "\n",
    "if count_vacios > 0:\n",
    "    # Agregar motivo\n",
    "    registros_vacios['motivo'] = 'Afiliado no pertenece a la EPS'\n",
    "    \n",
    "    # Agregar a DF_No_Envio\n",
    "    DF_No_Envio = pd.concat([DF_No_Envio, registros_vacios], ignore_index=True)\n",
    "    \n",
    "    # Eliminar de df_NS\n",
    "    df_NS = df_NS[~mask_vacios].reset_index(drop=True)\n",
    "    \n",
    "    registros_movidos += count_vacios\n",
    "    conteo_por_motivo['Afiliado no pertenece a la EPS'] = count_vacios\n",
    "\n",
    "print(f\"   üìä Registros con ENT_ID_ADRES vac√≠o: {count_vacios}\")\n",
    "print(f\"   ‚úÖ Movidos a DF_No_Envio: {count_vacios}\")\n",
    "\n",
    "# ========== VALIDACI√ìN 2: ENT_ID_ADRES igual a \"EPSC25\" ==========\n",
    "print(f\"\\nüîç VALIDACI√ìN 2: ENT_ID_ADRES igual a 'EPSC25'\")\n",
    "\n",
    "# Identificar registros con ENT_ID_ADRES igual a \"EPSC25\"\n",
    "mask_epsc25 = df_NS['ENT_ID_ADRES'] == 'EPSC25'\n",
    "registros_epsc25 = df_NS[mask_epsc25].copy()\n",
    "count_epsc25 = len(registros_epsc25)\n",
    "\n",
    "if count_epsc25 > 0:\n",
    "    # Agregar motivo\n",
    "    registros_epsc25['motivo'] = 'Afiliado del regimen contributivo'\n",
    "    \n",
    "    # Agregar a DF_No_Envio\n",
    "    DF_No_Envio = pd.concat([DF_No_Envio, registros_epsc25], ignore_index=True)\n",
    "    \n",
    "    # Eliminar de df_NS\n",
    "    df_NS = df_NS[~mask_epsc25].reset_index(drop=True)\n",
    "    \n",
    "    registros_movidos += count_epsc25\n",
    "    conteo_por_motivo['Afiliado del regimen contributivo'] = count_epsc25\n",
    "\n",
    "print(f\"   üìä Registros con ENT_ID_ADRES = 'EPSC25': {count_epsc25}\")\n",
    "print(f\"   ‚úÖ Movidos a DF_No_Envio: {count_epsc25}\")\n",
    "\n",
    "# ========== RESUMEN FINAL ==========\n",
    "print(f\"\\nüìà RESUMEN DE FILTROS APLICADOS:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üìä Total de registros movidos: {registros_movidos}\")\n",
    "print(f\"üìä Registros restantes en df_NS: {len(df_NS)}\")\n",
    "print(f\"üìä Registros en DF_No_Envio: {len(DF_No_Envio)}\")\n",
    "\n",
    "print(f\"\\nüìã DETALLE POR MOTIVO:\")\n",
    "for motivo, cantidad in conteo_por_motivo.items():\n",
    "    porcentaje = (cantidad / registros_movidos * 100) if registros_movidos > 0 else 0\n",
    "    print(f\"   ‚Ä¢ {motivo}: {cantidad} registros ({porcentaje:.2f}%)\")\n",
    "\n",
    "# Verificar integridad\n",
    "print(f\"\\nüîç VERIFICACI√ìN DE INTEGRIDAD:\")\n",
    "print(f\"   ENT_ID_ADRES √∫nicos en df_NS: {df_NS['ENT_ID_ADRES'].unique()}\")\n",
    "print(f\"   Motivos √∫nicos en DF_No_Envio: {DF_No_Envio['motivo'].unique() if len(DF_No_Envio) > 0 else 'N/A'}\")\n",
    "\n",
    "# Mostrar ejemplos si hay registros\n",
    "if len(DF_No_Envio) > 0:\n",
    "    print(f\"\\nüìã EJEMPLOS DE REGISTROS EN DF_No_Envio:\")\n",
    "    ejemplos = DF_No_Envio[['NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION', \n",
    "                           'NOVEDAD', 'ENT_ID_ADRES', 'motivo']].head(10)\n",
    "    print(ejemplos.to_string(index=False))\n",
    "else:\n",
    "    print(f\"\\n‚úÖ No hay registros en DF_No_Envio\")\n",
    "\n",
    "print(f\"\\n‚úÖ PROCESO DE FILTRADO COMPLETADO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "# 5. Procesar novedades\n",
    "## 5.1. N01 Actualizaci√≥n o correcci√≥n del tipo y n√∫mero de identificaci√≥n del afiliado y/o fecha de nacimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def validar_novedades_N01(df):\n",
    "    \"\"\"\n",
    "    Valida, corrige y filtra los registros con NOVEDAD = 'N01',\n",
    "    incluyendo la validaci√≥n de no-cambio.\n",
    "    \"\"\"\n",
    "    # Inicializaci√≥n de contadores y DataFrame de No Env√≠o\n",
    "    registros_iniciales_df = len(df)\n",
    "    DF_No_Envio = pd.DataFrame()\n",
    "    total_movidos = 0\n",
    "    \n",
    "    print(\"üîç INICIANDO VALIDACI√ìN DE NOVEDADES N01\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 1. Filtrar solo registros N01\n",
    "    mask_n01 = df['NOVEDAD'] == 'N01'\n",
    "    registros_n01 = df[mask_n01].copy()\n",
    "    total_n01_inicial = len(registros_n01)\n",
    "    \n",
    "    print(f\"üìä Total de registros N01 iniciales: {total_n01_inicial}\")\n",
    "    \n",
    "    if total_n01_inicial == 0:\n",
    "        print(\"‚ö†Ô∏è No se encontraron registros N01\")\n",
    "        # Devolver el DF original y un DF_No_Envio vac√≠o\n",
    "        return df, DF_No_Envio\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO CLAVE 1: PRE-PROCESAMIENTO Y CONVERSI√ìN DE COD_3_NOVEDAD\n",
    "    # (Necesario para tener un formato est√°ndar ANTES de la validaci√≥n de igualdad)\n",
    "    # =========================================================================\n",
    "\n",
    "    def convertir_fecha_cod3(valor):\n",
    "        \"\"\"Convierte diferentes formatos de fecha a DD/MM/YYYY\"\"\"\n",
    "        if pd.isna(valor) or str(valor).strip() == '':\n",
    "            return None\n",
    "        \n",
    "        valor_str = str(valor).strip()\n",
    "        \n",
    "        try:\n",
    "            # Si es un n√∫mero (formato Excel serializado)\n",
    "            if valor_str.isdigit() and len(valor_str) >= 5:\n",
    "                # Convertir n√∫mero Excel a fecha\n",
    "                fecha_excel = pd.to_datetime('1900-01-01') + pd.Timedelta(days=int(valor_str)-2)\n",
    "                return fecha_excel.strftime('%d/%m/%Y')\n",
    "            \n",
    "            # Si ya tiene formato de fecha\n",
    "            elif '/' in valor_str or '-' in valor_str:\n",
    "                # Intentar convertir con diferentes formatos\n",
    "                fecha_convertida = pd.to_datetime(valor_str, dayfirst=True, errors='coerce')\n",
    "                if pd.notna(fecha_convertida):\n",
    "                    return fecha_convertida.strftime('%d/%m/%Y')\n",
    "                else:\n",
    "                    return None\n",
    "            else:\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            return None\n",
    "    \n",
    "    # Aplicar conversi√≥n de fechas\n",
    "    registros_n01['COD_3_CONVERTIDA'] = registros_n01['COD_3_NOVEDAD'].apply(convertir_fecha_cod3)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO CLAVE 2: NUEVA VALIDACI√ìN DE NO-CAMBIO\n",
    "    # =========================================================================\n",
    "    print(\"\\nüîç VALIDANDO REGISTROS SIN CAMBIO DE DATOS\")\n",
    "    \n",
    "    # Estandarizar columnas para una comparaci√≥n justa (limpiar espacios y may√∫sculas/min√∫sculas)\n",
    "    registros_n01['COD_1_NOVEDAD_STR'] = registros_n01['COD_1_NOVEDAD'].astype(str).str.strip().str.upper()\n",
    "    registros_n01['TPS_IDN_ID_STR'] = registros_n01['TPS_IDN_ID'].astype(str).str.strip().str.upper()\n",
    "    \n",
    "    registros_n01['COD_2_NOVEDAD_STR'] = registros_n01['COD_2_NOVEDAD'].astype(str).str.strip().str.upper()\n",
    "    registros_n01['HST_IDN_NUMERO_IDENTIFICACION_STR'] = registros_n01['HST_IDN_NUMERO_IDENTIFICACION'].astype(str).str.strip().str.upper()\n",
    "\n",
    "    # Formatear AFL_FECHA_NACIMIENTO al formato DD/MM/YYYY para comparar con la columna convertida\n",
    "    registros_n01['AFL_FECHA_NACIMIENTO_STR'] = pd.to_datetime(\n",
    "        registros_n01['AFL_FECHA_NACIMIENTO'], errors='coerce'\n",
    "    ).dt.strftime('%d/%m/%Y')\n",
    "\n",
    "    # Crear una m√°scara donde todos los campos son iguales\n",
    "    mask_iguales = (\n",
    "        (registros_n01['COD_1_NOVEDAD_STR'] == registros_n01['TPS_IDN_ID_STR']) &\n",
    "        (registros_n01['COD_2_NOVEDAD_STR'] == registros_n01['HST_IDN_NUMERO_IDENTIFICACION_STR']) &\n",
    "        (registros_n01['COD_3_CONVERTIDA'].fillna('') == registros_n01['AFL_FECHA_NACIMIENTO_STR'].fillna(''))\n",
    "    )\n",
    "    \n",
    "    # Registros a mover\n",
    "    registros_a_mover = registros_n01[mask_iguales].copy()\n",
    "    total_movidos = len(registros_a_mover)\n",
    "    \n",
    "    print(f\"   Registros sin cambio de datos (a mover): {total_movidos}\")\n",
    "    \n",
    "    if total_movidos > 0:\n",
    "        # Mover al DF_No_Envio y agregar motivo\n",
    "        registros_a_mover['motivo'] = \"Datos a reportar iguales a los actuales\"\n",
    "        DF_No_Envio = pd.concat([DF_No_Envio, registros_a_mover.drop(columns=[\n",
    "            'COD_3_CONVERTIDA', 'COD_1_NOVEDAD_STR', 'TPS_IDN_ID_STR',\n",
    "            'COD_2_NOVEDAD_STR', 'HST_IDN_NUMERO_IDENTIFICACION_STR', \n",
    "            'AFL_FECHA_NACIMIENTO_STR'\n",
    "        ])], ignore_index=True)\n",
    "        \n",
    "        # Eliminar del lote de N01\n",
    "        registros_n01 = registros_n01[~mask_iguales].copy()\n",
    "        \n",
    "        # Actualizar la m√°scara N01 en el DF principal para reflejar la eliminaci√≥n\n",
    "        indices_a_eliminar = df.loc[mask_n01][mask_iguales].index\n",
    "        df = df.drop(indices_a_eliminar)\n",
    "        \n",
    "        # Actualizar la m√°scara despu√©s de la eliminaci√≥n\n",
    "        mask_n01 = df['NOVEDAD'] == 'N01'\n",
    "    \n",
    "    registros_n01_actuales = len(registros_n01)\n",
    "    print(f\"   Registros N01 restantes para validaci√≥n: {registros_n01_actuales}\")\n",
    "    \n",
    "    # Si no quedan registros N01 despu√©s del filtro de no-cambio\n",
    "    if registros_n01_actuales == 0:\n",
    "        print(\"‚ö†Ô∏è Todos los registros N01 fueron movidos por no-cambio.\")\n",
    "        # Devolver el DF original (reducido) y el DF_No_Envio\n",
    "        return df, DF_No_Envio\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 3: VALIDACIONES ORIGINALES (en el subconjunto restante)\n",
    "    # =========================================================================\n",
    "    \n",
    "    # ========== VALIDAR COD_2_NOVEDAD (debe ser entero) ==========\n",
    "    print(f\"\\nüîß VALIDANDO COD_2_NOVEDAD (debe ser entero)\")\n",
    "    \n",
    "    def es_entero_valido(valor):\n",
    "        # Mantenemos esta funci√≥n para la validaci√≥n de formato\n",
    "        if pd.isna(valor) or str(valor).strip() == '':\n",
    "            return False\n",
    "        try:\n",
    "            int(str(valor).strip())\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    # Aplicar validaci√≥n\n",
    "    registros_n01['COD_2_VALIDO'] = registros_n01['COD_2_NOVEDAD'].apply(es_entero_valido)\n",
    "    invalidos_cod2 = (~registros_n01['COD_2_VALIDO']).sum()\n",
    "    print(f\"   Valores inv√°lidos encontrados: {invalidos_cod2}\")\n",
    "    \n",
    "    # ========== VALIDAR COD_3_NOVEDAD (Fecha) ==========\n",
    "    print(f\"\\nüîß VALIDANDO COD_3_NOVEDAD (fecha DD/MM/YYYY)\")\n",
    "    # (Ya se aplic√≥ la conversi√≥n, solo se reporta)\n",
    "    fechas_validas = registros_n01['COD_3_CONVERTIDA'].notna().sum()\n",
    "    fechas_invalidas = registros_n01['COD_3_CONVERTIDA'].isna().sum()\n",
    "    print(f\"   Fechas v√°lidas despu√©s de conversi√≥n: {fechas_validas}\")\n",
    "    print(f\"   Fechas que no pudieron convertirse: {fechas_invalidas}\")\n",
    "    \n",
    "    # ========== VALIDAR COD_4_NOVEDAD (no puede estar vac√≠o) ==========\n",
    "    print(f\"\\nüîß VALIDANDO COD_4_NOVEDAD (no puede estar vac√≠o)\")\n",
    "    vacios_cod4_antes = registros_n01['COD_4_NOVEDAD'].isna().sum()\n",
    "    print(f\"   Valores vac√≠os: {vacios_cod4_antes}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 4: APLICAR CORRECCIONES Y RESUMEN FINAL\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîÑ APLICANDO CORRECCIONES AL DATAFRAME PRINCIPAL\")\n",
    "    \n",
    "    # Aplicar correcci√≥n de fechas (solo a los registros que quedan en el DF principal)\n",
    "    df.loc[mask_n01, 'COD_3_NOVEDAD'] = registros_n01['COD_3_CONVERTIDA']\n",
    "    \n",
    "    # Revalidar despu√©s de correcciones (en el DF principal ya reducido)\n",
    "    registros_n01_final = df[mask_n01].copy()\n",
    "\n",
    "    print(f\"\\nüìã RESUMEN FINAL DE VALIDACI√ìN N01:\")\n",
    "    \n",
    "    # Mostrar registros problem√°ticos finales (registros N01 que quedan en df)\n",
    "    problematicos = registros_n01_final[\n",
    "        registros_n01_final['COD_2_NOVEDAD'].isna() | \n",
    "        (~registros_n01['COD_2_VALIDO']) | # Usar el resultado de validaci√≥n\n",
    "        registros_n01_final['COD_3_NOVEDAD'].isna() | \n",
    "        registros_n01_final['COD_4_NOVEDAD'].isna()\n",
    "    ]\n",
    "    \n",
    "    if len(problematicos) > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è REGISTROS PROBLEM√ÅTICOS (PENDIENTES) ENCONTRADOS: {len(problematicos)}\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Todos los registros N01 restantes son v√°lidos\")\n",
    "    \n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 5: RESUMEN DE CONTEOS\n",
    "    # =========================================================================\n",
    "    \n",
    "    registros_finales_df = len(df)\n",
    "    registros_finales_n01_df = len(df[df['NOVEDAD'] == 'N01'])\n",
    "    registros_finales_no_envio = len(DF_No_Envio)\n",
    "    \n",
    "    print(\"\\n\\n=== RESUMEN DE MOVIMIENTO DE REGISTROS ===\")\n",
    "    print(f\"  Total registros en DF original (df): {registros_iniciales_df}\")\n",
    "    print(f\"  Total registros con NOVEDAD='N01' iniciales: {total_n01_inicial}\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"  ‚û°Ô∏è Registros movidos a DF_No_Envio (por No-Cambio): {total_movidos}\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"  Total registros N01 restantes en df_NS: {registros_finales_n01_df}\")\n",
    "    print(f\"  Total registros en DF final (df): {registros_finales_df}\")\n",
    "    print(f\"  Total registros en DF_No_Envio: {registros_finales_no_envio}\")\n",
    "    \n",
    "    # Devolver ambos DataFrames\n",
    "    return df, DF_No_Envio\n",
    "\n",
    "\n",
    "df_NS, DF_No_Envio = validar_novedades_N01(df_NS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## 5.2. N02 Actualizaci√≥n o correcci√≥n de nombres del afiliado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validar_novedades_N02(df, df_no_envio):\n",
    "    \"\"\"\n",
    "    Valida registros con NOVEDAD = 'N02' verificando que los nombres actuales\n",
    "    sean diferentes a los nombres que se quieren reportar.\n",
    "    Si son iguales, los mueve a DF_No_Envio.\n",
    "    \"\"\"\n",
    "    print(\"üîç INICIANDO VALIDACI√ìN DE NOVEDADES N02\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Filtrar solo registros N02\n",
    "    mask_n02 = df['NOVEDAD'] == 'N02'\n",
    "    registros_n02 = df[mask_n02].copy()\n",
    "    total_n02_inicial = len(registros_n02)\n",
    "    \n",
    "    print(f\"üìä Total de registros N02 iniciales: {total_n02_inicial}\")\n",
    "    \n",
    "    if total_n02_inicial == 0:\n",
    "        print(\"‚ö†Ô∏è No se encontraron registros N02\")\n",
    "        return df, df_no_envio\n",
    "    \n",
    "    # Estandarizar nombres para comparaci√≥n (quitar espacios y convertir a may√∫sculas)\n",
    "    def normalizar_nombre(nombre):\n",
    "        if pd.isna(nombre) or str(nombre).strip() == '':\n",
    "            return ''\n",
    "        return str(nombre).strip().upper()\n",
    "    \n",
    "    # Normalizar nombres actuales\n",
    "    registros_n02['AFL_PRIMER_NOMBRE_NORM'] = registros_n02['AFL_PRIMER_NOMBRE'].apply(normalizar_nombre)\n",
    "    registros_n02['AFL_SEGUNDO_NOMBRE_NORM'] = registros_n02['AFL_SEGUNDO_NOMBRE'].apply(normalizar_nombre)\n",
    "    \n",
    "    # Normalizar nombres nuevos (c√≥digos de novedad)\n",
    "    registros_n02['COD_1_NOVEDAD_NORM'] = registros_n02['COD_1_NOVEDAD'].apply(normalizar_nombre)\n",
    "    registros_n02['COD_2_NOVEDAD_NORM'] = registros_n02['COD_2_NOVEDAD'].apply(normalizar_nombre)\n",
    "    \n",
    "    # Crear m√°scara para identificar registros donde los nombres son iguales\n",
    "    mask_nombres_iguales = (\n",
    "        (registros_n02['AFL_PRIMER_NOMBRE_NORM'] == registros_n02['COD_1_NOVEDAD_NORM']) &\n",
    "        (registros_n02['AFL_SEGUNDO_NOMBRE_NORM'] == registros_n02['COD_2_NOVEDAD_NORM'])\n",
    "    )\n",
    "    \n",
    "    # Registros a mover (sin cambios)\n",
    "    registros_sin_cambios = registros_n02[mask_nombres_iguales].copy()\n",
    "    total_sin_cambios = len(registros_sin_cambios)\n",
    "    \n",
    "    print(f\"üìã AN√ÅLISIS DE NOMBRES:\")\n",
    "    print(f\"   Registros con nombres actuales = nombres nuevos: {total_sin_cambios}\")\n",
    "    print(f\"   Registros con cambios v√°lidos: {total_n02_inicial - total_sin_cambios}\")\n",
    "    \n",
    "    if total_sin_cambios > 0:\n",
    "        # Mostrar ejemplos de registros sin cambios\n",
    "        print(f\"\\nüìã EJEMPLOS DE REGISTROS SIN CAMBIOS:\")\n",
    "        ejemplos = registros_sin_cambios[['NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION', \n",
    "                                        'AFL_PRIMER_NOMBRE', 'AFL_SEGUNDO_NOMBRE', \n",
    "                                        'COD_1_NOVEDAD', 'COD_2_NOVEDAD']].head(5)\n",
    "        print(ejemplos.to_string(index=False))\n",
    "        \n",
    "        # Agregar motivo y mover a DF_No_Envio\n",
    "        registros_sin_cambios_clean = registros_sin_cambios.drop(columns=[\n",
    "            'AFL_PRIMER_NOMBRE_NORM', 'AFL_SEGUNDO_NOMBRE_NORM',\n",
    "            'COD_1_NOVEDAD_NORM', 'COD_2_NOVEDAD_NORM'\n",
    "        ])\n",
    "        registros_sin_cambios_clean['motivo'] = \"Afiliado sin cambios a reportar\"\n",
    "        \n",
    "        # Concatenar con DF_No_Envio existente\n",
    "        df_no_envio = pd.concat([df_no_envio, registros_sin_cambios_clean], ignore_index=True)\n",
    "        \n",
    "        # Obtener √≠ndices originales para eliminar del DataFrame principal\n",
    "        indices_a_eliminar = df.loc[mask_n02][mask_nombres_iguales].index\n",
    "        df = df.drop(indices_a_eliminar).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"‚úÖ Movidos {total_sin_cambios} registros a DF_No_Envio\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Todos los registros N02 tienen cambios v√°lidos\")\n",
    "    \n",
    "    # Estad√≠sticas finales\n",
    "    registros_n02_final = len(df[df['NOVEDAD'] == 'N02'])\n",
    "    \n",
    "    print(f\"\\nüìà RESUMEN FINAL:\")\n",
    "    print(f\"   Registros N02 iniciales: {total_n02_inicial}\")\n",
    "    print(f\"   Registros movidos (sin cambios): {total_sin_cambios}\")\n",
    "    print(f\"   Registros N02 restantes: {registros_n02_final}\")\n",
    "    print(f\"   Total en DF_No_Envio actual: {len(df_no_envio)}\")\n",
    "    \n",
    "    return df, df_no_envio\n",
    "\n",
    "# Aplicar validaci√≥n N02\n",
    "df_NS, DF_No_Envio = validar_novedades_N02(df_NS, DF_No_Envio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## 5.3. N03 Actualizaci√≥n o correcci√≥n de apellidos del afiliado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validar_novedades_N03(df, df_no_envio):\n",
    "    \"\"\"\n",
    "    Valida registros con NOVEDAD = 'N03' verificando que los apellidos actuales\n",
    "    sean diferentes a los apellidos que se quieren reportar.\n",
    "    Si son iguales, los mueve a DF_No_Envio.\n",
    "    \"\"\"\n",
    "    print(\"üîç INICIANDO VALIDACI√ìN DE NOVEDADES N03\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Filtrar solo registros N03\n",
    "    mask_n03 = df['NOVEDAD'] == 'N03'\n",
    "    registros_n03 = df[mask_n03].copy()\n",
    "    total_n03_inicial = len(registros_n03)\n",
    "    \n",
    "    print(f\"üìä Total de registros N03 iniciales: {total_n03_inicial}\")\n",
    "    \n",
    "    if total_n03_inicial == 0:\n",
    "        print(\"‚ö†Ô∏è No se encontraron registros N03\")\n",
    "        return df, df_no_envio\n",
    "    \n",
    "    # Estandarizar apellidos para comparaci√≥n (quitar espacios y convertir a may√∫sculas)\n",
    "    def normalizar_apellido(apellido):\n",
    "        if pd.isna(apellido) or str(apellido).strip() == '':\n",
    "            return ''\n",
    "        return str(apellido).strip().upper()\n",
    "    \n",
    "    # Normalizar apellidos actuales\n",
    "    registros_n03['AFL_PRIMER_APELLIDO_NORM'] = registros_n03['AFL_PRIMER_APELLIDO'].apply(normalizar_apellido)\n",
    "    registros_n03['AFL_SEGUNDO_APELLIDO_NORM'] = registros_n03['AFL_SEGUNDO_APELLIDO'].apply(normalizar_apellido)\n",
    "    \n",
    "    # Normalizar apellidos nuevos (c√≥digos de novedad)\n",
    "    registros_n03['COD_1_NOVEDAD_NORM'] = registros_n03['COD_1_NOVEDAD'].apply(normalizar_apellido)\n",
    "    registros_n03['COD_2_NOVEDAD_NORM'] = registros_n03['COD_2_NOVEDAD'].apply(normalizar_apellido)\n",
    "    \n",
    "    # Crear m√°scara para identificar registros donde los apellidos son iguales\n",
    "    mask_apellidos_iguales = (\n",
    "        (registros_n03['AFL_PRIMER_APELLIDO_NORM'] == registros_n03['COD_1_NOVEDAD_NORM']) &\n",
    "        (registros_n03['AFL_SEGUNDO_APELLIDO_NORM'] == registros_n03['COD_2_NOVEDAD_NORM'])\n",
    "    )\n",
    "    \n",
    "    # Registros a mover (sin cambios)\n",
    "    registros_sin_cambios = registros_n03[mask_apellidos_iguales].copy()\n",
    "    total_sin_cambios = len(registros_sin_cambios)\n",
    "    \n",
    "    print(f\"üìã AN√ÅLISIS DE APELLIDOS:\")\n",
    "    print(f\"   Registros con apellidos actuales = apellidos nuevos: {total_sin_cambios}\")\n",
    "    print(f\"   Registros con cambios v√°lidos: {total_n03_inicial - total_sin_cambios}\")\n",
    "    \n",
    "    if total_sin_cambios > 0:\n",
    "        # Mostrar ejemplos de registros sin cambios\n",
    "        print(f\"\\nüìã EJEMPLOS DE REGISTROS SIN CAMBIOS:\")\n",
    "        ejemplos = registros_sin_cambios[['NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION', \n",
    "                                        'AFL_PRIMER_APELLIDO', 'AFL_SEGUNDO_APELLIDO', \n",
    "                                        'COD_1_NOVEDAD', 'COD_2_NOVEDAD']].head(5)\n",
    "        print(ejemplos.to_string(index=False))\n",
    "        \n",
    "        # Agregar motivo y mover a DF_No_Envio\n",
    "        registros_sin_cambios_clean = registros_sin_cambios.drop(columns=[\n",
    "            'AFL_PRIMER_APELLIDO_NORM', 'AFL_SEGUNDO_APELLIDO_NORM',\n",
    "            'COD_1_NOVEDAD_NORM', 'COD_2_NOVEDAD_NORM'\n",
    "        ])\n",
    "        registros_sin_cambios_clean['motivo'] = \"Afiliado sin cambios a reportar\"\n",
    "        \n",
    "        # Concatenar con DF_No_Envio existente\n",
    "        df_no_envio = pd.concat([df_no_envio, registros_sin_cambios_clean], ignore_index=True)\n",
    "        \n",
    "        # Obtener √≠ndices originales para eliminar del DataFrame principal\n",
    "        indices_a_eliminar = df.loc[mask_n03][mask_apellidos_iguales].index\n",
    "        df = df.drop(indices_a_eliminar).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"‚úÖ Movidos {total_sin_cambios} registros a DF_No_Envio\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Todos los registros N03 tienen cambios v√°lidos\")\n",
    "    \n",
    "    # Estad√≠sticas finales\n",
    "    registros_n03_final = len(df[df['NOVEDAD'] == 'N03'])\n",
    "    \n",
    "    print(f\"\\nüìà RESUMEN FINAL:\")\n",
    "    print(f\"   Registros N03 iniciales: {total_n03_inicial}\")\n",
    "    print(f\"   Registros movidos (sin cambios): {total_sin_cambios}\")\n",
    "    print(f\"   Registros N03 restantes: {registros_n03_final}\")\n",
    "    print(f\"   Total en DF_No_Envio actual: {len(df_no_envio)}\")\n",
    "    \n",
    "    return df, df_no_envio\n",
    "\n",
    "# Aplicar validaci√≥n N03\n",
    "df_NS, DF_No_Envio = validar_novedades_N03(df_NS, DF_No_Envio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "## 5.4. N04 Actualizaci√≥n o cambio de departamento y municipio de afiliaci√≥n en la misma Entidad de Salud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validar_novedades_N04(df, df_no_envio, maestro_adres):\n",
    "    \"\"\"\n",
    "    Valida registros con NOVEDAD = 'N04' (cambio de departamento y municipio).\n",
    "    Proceso:\n",
    "    1. Actualizar DPR_ID y MNC_ID desde maestro_ADRES\n",
    "    2. Validar formato de c√≥digos (DPR_ID: 2 d√≠gitos, MNC_ID: 3 d√≠gitos)\n",
    "    3. Verificar que hay cambios reales en departamento/municipio\n",
    "    \"\"\"\n",
    "    print(\"üîç INICIANDO VALIDACI√ìN DE NOVEDADES N04\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Filtrar solo registros N04\n",
    "    mask_n04 = df['NOVEDAD'] == 'N04'\n",
    "    registros_n04 = df[mask_n04].copy()\n",
    "    total_n04_inicial = len(registros_n04)\n",
    "    \n",
    "    print(f\"üìä Total de registros N04 iniciales: {total_n04_inicial}\")\n",
    "    \n",
    "    if total_n04_inicial == 0:\n",
    "        print(\"‚ö†Ô∏è No se encontraron registros N04\")\n",
    "        return df, df_no_envio\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 1: VERIFICAR Y CORREGIR NOMBRES DE COLUMNAS\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîç PASO 1: Verificando estructura de columnas\")\n",
    "    \n",
    "    # Verificar qu√© columnas de municipio existen en df_NS\n",
    "    columna_municipio_df = None\n",
    "    if 'MNS_ID' in df.columns:\n",
    "        columna_municipio_df = 'MNS_ID'\n",
    "        print(f\"   üìä df_NS usa: MNS_ID\")\n",
    "    elif 'MNC_ID' in df.columns:\n",
    "        columna_municipio_df = 'MNC_ID'\n",
    "        print(f\"   üìä df_NS usa: MNC_ID\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå No se encontr√≥ columna de municipio en df_NS\")\n",
    "        return df, df_no_envio\n",
    "    \n",
    "    # Verificar qu√© columnas existen en maestro_adres\n",
    "    print(f\"   üìä maestro_ADRES tiene: DPR_ID={('DPR_ID' in maestro_adres.columns)}, MNC_ID={('MNC_ID' in maestro_adres.columns)}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 2: ACTUALIZAR DESDE MAESTRO_ADRES CON L√ìGICA CORREGIDA\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîÑ PASO 2: Actualizando ubicaci√≥n desde maestro_ADRES\")\n",
    "    \n",
    "    # Crear subset del maestro con nombres √∫nicos y renombrados para evitar conflictos\n",
    "    maestro_ubicacion = maestro_adres[['ID_User', 'DPR_ID', 'MNC_ID']].drop_duplicates(subset=['ID_User']).rename(columns={\n",
    "        'DPR_ID': 'DPR_ID_from_maestro',\n",
    "        'MNC_ID': 'MNC_ID_from_maestro'\n",
    "    })\n",
    "    \n",
    "    print(f\"   üìä Registros √∫nicos en maestro_ADRES: {len(maestro_ubicacion):,}\")\n",
    "    \n",
    "    # Hacer merge para traer datos del maestro\n",
    "    registros_n04_con_maestro = registros_n04.merge(\n",
    "        maestro_ubicacion,\n",
    "        on='ID_User',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # ‚úÖ ACTUALIZAR COLUMNAS CON DATOS DEL MAESTRO\n",
    "    print(f\"   üîÑ Actualizando columnas desde maestro...\")\n",
    "    \n",
    "    # Actualizar DPR_ID\n",
    "    registros_n04_con_maestro['DPR_ID'] = registros_n04_con_maestro['DPR_ID_from_maestro'].fillna(\n",
    "        registros_n04_con_maestro['DPR_ID']\n",
    "    )\n",
    "    \n",
    "    # Actualizar columna de municipio (usar el nombre correcto seg√∫n df_NS)\n",
    "    if columna_municipio_df == 'MNS_ID':\n",
    "        # df_NS usa MNS_ID, maestro_ADRES usa MNC_ID\n",
    "        registros_n04_con_maestro['MNS_ID'] = registros_n04_con_maestro['MNC_ID_from_maestro'].fillna(\n",
    "            registros_n04_con_maestro['MNS_ID']\n",
    "        )\n",
    "        columna_municipio_actual = 'MNS_ID'\n",
    "    else:\n",
    "        # df_NS usa MNC_ID\n",
    "        registros_n04_con_maestro['MNC_ID'] = registros_n04_con_maestro['MNC_ID_from_maestro'].fillna(\n",
    "            registros_n04_con_maestro['MNC_ID']\n",
    "        )\n",
    "        columna_municipio_actual = 'MNC_ID'\n",
    "    \n",
    "    # Limpiar columnas temporales\n",
    "    registros_n04_con_maestro = registros_n04_con_maestro.drop(columns=[\n",
    "        'DPR_ID_from_maestro', 'MNC_ID_from_maestro'\n",
    "    ])\n",
    "    \n",
    "    # Contar actualizaciones\n",
    "    actualizaciones_dpr = registros_n04_con_maestro['DPR_ID'].notna().sum()\n",
    "    actualizaciones_municipio = registros_n04_con_maestro[columna_municipio_actual].notna().sum()\n",
    "    print(f\"   ‚úÖ Registros con DPR_ID v√°lido: {actualizaciones_dpr}\")\n",
    "    print(f\"   ‚úÖ Registros con {columna_municipio_actual} v√°lido: {actualizaciones_municipio}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 3: VALIDAR Y ESTANDARIZAR FORMATOS\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîß PASO 3: Validando y estandarizando formatos de c√≥digos\")\n",
    "    \n",
    "    def validar_y_formatear_departamento(codigo):\n",
    "        if pd.isna(codigo) or str(codigo).strip() == '':\n",
    "            return None\n",
    "        try:\n",
    "            codigo_num = int(str(codigo).strip())\n",
    "            if 1 <= codigo_num <= 99:\n",
    "                return f\"{codigo_num:02d}\"\n",
    "            else:\n",
    "                return None\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def validar_y_formatear_municipio(codigo):\n",
    "        if pd.isna(codigo) or str(codigo).strip() == '':\n",
    "            return None\n",
    "        try:\n",
    "            codigo_num = int(str(codigo).strip())\n",
    "            if 1 <= codigo_num <= 999:\n",
    "                return f\"{codigo_num:03d}\"\n",
    "            else:\n",
    "                return None\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    # Aplicar formateo a c√≥digos actuales\n",
    "    registros_n04_con_maestro['DPR_ID_FORMATTED'] = registros_n04_con_maestro['DPR_ID'].apply(validar_y_formatear_departamento)\n",
    "    registros_n04_con_maestro['MUN_ID_FORMATTED'] = registros_n04_con_maestro[columna_municipio_actual].apply(validar_y_formatear_municipio)\n",
    "    \n",
    "    # Aplicar formateo a c√≥digos nuevos\n",
    "    registros_n04_con_maestro['COD_1_NOVEDAD_FORMATTED'] = registros_n04_con_maestro['COD_1_NOVEDAD'].apply(validar_y_formatear_departamento)\n",
    "    registros_n04_con_maestro['COD_2_NOVEDAD_FORMATTED'] = registros_n04_con_maestro['COD_2_NOVEDAD'].apply(validar_y_formatear_municipio)\n",
    "    \n",
    "    # Estad√≠sticas de validaci√≥n\n",
    "    dpr_actuales_validos = registros_n04_con_maestro['DPR_ID_FORMATTED'].notna().sum()\n",
    "    mun_actuales_validos = registros_n04_con_maestro['MUN_ID_FORMATTED'].notna().sum()\n",
    "    dpr_nuevos_validos = registros_n04_con_maestro['COD_1_NOVEDAD_FORMATTED'].notna().sum()\n",
    "    mun_nuevos_validos = registros_n04_con_maestro['COD_2_NOVEDAD_FORMATTED'].notna().sum()\n",
    "    \n",
    "    print(f\"   üìä C√≥digos actuales v√°lidos:\")\n",
    "    print(f\"     DPR_ID: {dpr_actuales_validos}/{total_n04_inicial}\")\n",
    "    print(f\"     {columna_municipio_actual}: {mun_actuales_validos}/{total_n04_inicial}\")\n",
    "    print(f\"   üìä C√≥digos nuevos v√°lidos:\")\n",
    "    print(f\"     COD_1_NOVEDAD (Dpto): {dpr_nuevos_validos}/{total_n04_inicial}\")\n",
    "    print(f\"     COD_2_NOVEDAD (Mpio): {mun_nuevos_validos}/{total_n04_inicial}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 4: IDENTIFICAR REGISTROS SIN CAMBIOS\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîç PASO 4: Identificando registros sin cambios de ubicaci√≥n\")\n",
    "    \n",
    "    # Crear m√°scara para registros donde no hay cambios\n",
    "    mask_sin_cambios = (\n",
    "        (registros_n04_con_maestro['DPR_ID_FORMATTED'] == registros_n04_con_maestro['COD_1_NOVEDAD_FORMATTED']) &\n",
    "        (registros_n04_con_maestro['MUN_ID_FORMATTED'] == registros_n04_con_maestro['COD_2_NOVEDAD_FORMATTED']) &\n",
    "        registros_n04_con_maestro['DPR_ID_FORMATTED'].notna() &\n",
    "        registros_n04_con_maestro['MUN_ID_FORMATTED'].notna() &\n",
    "        registros_n04_con_maestro['COD_1_NOVEDAD_FORMATTED'].notna() &\n",
    "        registros_n04_con_maestro['COD_2_NOVEDAD_FORMATTED'].notna()\n",
    "    )\n",
    "    \n",
    "    registros_sin_cambios = registros_n04_con_maestro[mask_sin_cambios].copy()\n",
    "    total_sin_cambios = len(registros_sin_cambios)\n",
    "    \n",
    "    print(f\"   üìã Registros sin cambios de ubicaci√≥n: {total_sin_cambios}\")\n",
    "    print(f\"   üìã Registros con cambios v√°lidos: {total_n04_inicial - total_sin_cambios}\")\n",
    "    \n",
    "    if total_sin_cambios > 0:\n",
    "        # Mostrar ejemplos\n",
    "        print(f\"\\nüìã EJEMPLOS DE REGISTROS SIN CAMBIOS:\")\n",
    "        ejemplos = registros_sin_cambios[[\n",
    "            'NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION', \n",
    "            'DPR_ID_FORMATTED', 'MUN_ID_FORMATTED', \n",
    "            'COD_1_NOVEDAD_FORMATTED', 'COD_2_NOVEDAD_FORMATTED'\n",
    "        ]].head(5)\n",
    "        print(ejemplos.to_string(index=False))\n",
    "        \n",
    "        # Limpiar y mover a DF_No_Envio\n",
    "        registros_sin_cambios_clean = registros_sin_cambios.drop(columns=[\n",
    "            'DPR_ID_FORMATTED', 'MUN_ID_FORMATTED',\n",
    "            'COD_1_NOVEDAD_FORMATTED', 'COD_2_NOVEDAD_FORMATTED'\n",
    "        ])\n",
    "        registros_sin_cambios_clean['motivo'] = \"Afiliado sin cambios a reportar\"\n",
    "        \n",
    "        # Concatenar con DF_No_Envio\n",
    "        df_no_envio = pd.concat([df_no_envio, registros_sin_cambios_clean], ignore_index=True)\n",
    "        \n",
    "        # Eliminar del DataFrame principal\n",
    "        indices_a_eliminar = registros_sin_cambios.index\n",
    "        df = df.drop(indices_a_eliminar).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"‚úÖ Movidos {total_sin_cambios} registros a DF_No_Envio\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 5: ACTUALIZAR DF PRINCIPAL CON DATOS CORREGIDOS\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîÑ PASO 5: Actualizando DataFrame principal\")\n",
    "    \n",
    "    # Filtrar registros restantes\n",
    "    registros_restantes = registros_n04_con_maestro[~mask_sin_cambios]\n",
    "    \n",
    "    if len(registros_restantes) > 0:\n",
    "        # Actualizar df_NS principal con los datos corregidos\n",
    "        for idx, row in registros_restantes.iterrows():\n",
    "            # Encontrar el √≠ndice correspondiente en df_NS\n",
    "            mask_update = (df['ID_User'] == row['ID_User']) & (df['NOVEDAD'] == 'N04')\n",
    "            if mask_update.any():\n",
    "                idx_df = df[mask_update].index[0]\n",
    "                \n",
    "                # Actualizar con valores formateados o originales\n",
    "                df.loc[idx_df, 'DPR_ID'] = row['DPR_ID_FORMATTED'] if pd.notna(row['DPR_ID_FORMATTED']) else row['DPR_ID']\n",
    "                df.loc[idx_df, columna_municipio_actual] = row['MUN_ID_FORMATTED'] if pd.notna(row['MUN_ID_FORMATTED']) else row[columna_municipio_actual]\n",
    "                df.loc[idx_df, 'COD_1_NOVEDAD'] = row['COD_1_NOVEDAD_FORMATTED'] if pd.notna(row['COD_1_NOVEDAD_FORMATTED']) else row['COD_1_NOVEDAD']\n",
    "                df.loc[idx_df, 'COD_2_NOVEDAD'] = row['COD_2_NOVEDAD_FORMATTED'] if pd.notna(row['COD_2_NOVEDAD_FORMATTED']) else row['COD_2_NOVEDAD']\n",
    "        \n",
    "        print(f\"   ‚úÖ Actualizados {len(registros_restantes)} registros en df_NS\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 6: ESTAD√çSTICAS FINALES\n",
    "    # =========================================================================\n",
    "    registros_n04_final = len(df[df['NOVEDAD'] == 'N04'])\n",
    "    \n",
    "    print(f\"\\nüìà RESUMEN FINAL:\")\n",
    "    print(f\"   Registros N04 iniciales: {total_n04_inicial}\")\n",
    "    print(f\"   Registros movidos (sin cambios): {total_sin_cambios}\")\n",
    "    print(f\"   Registros N04 restantes: {registros_n04_final}\")\n",
    "    print(f\"   Total en DF_No_Envio actual: {len(df_no_envio)}\")\n",
    "    \n",
    "    # Mostrar ejemplos finales\n",
    "    if registros_n04_final > 0:\n",
    "        print(f\"\\nüìã EJEMPLOS DE REGISTROS N04 V√ÅLIDOS RESTANTES:\")\n",
    "        ejemplos_finales = df[df['NOVEDAD'] == 'N04'][[\n",
    "            'NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION',\n",
    "            'DPR_ID', columna_municipio_actual, 'COD_1_NOVEDAD', 'COD_2_NOVEDAD'\n",
    "        ]].head(5)\n",
    "        print(ejemplos_finales.to_string(index=False))\n",
    "    \n",
    "    return df, df_no_envio\n",
    "\n",
    "# Aplicar validaci√≥n N04\n",
    "df_NS, DF_No_Envio = validar_novedades_N04(df_NS, DF_No_Envio, maestro_ADRES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "## 5.5 N09  Retiro por muerte. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validar_novedades_N09(df, df_no_envio):\n",
    "    \"\"\"\n",
    "    Valida registros con NOVEDAD = 'N09' (Retiro por muerte).\n",
    "    Si TPS_EST_AFL_ID_from_adres es 'AF' (ya fallecido en ADRES),\n",
    "    los mueve a DF_No_Envio porque no hay cambio a reportar.\n",
    "    \"\"\"\n",
    "    print(\"üîç INICIANDO VALIDACI√ìN DE NOVEDADES N09\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Filtrar solo registros N09\n",
    "    mask_n09 = df['NOVEDAD'] == 'N09'\n",
    "    registros_n09 = df[mask_n09].copy()\n",
    "    total_n09_inicial = len(registros_n09)\n",
    "    \n",
    "    print(f\"üìä Total de registros N09 iniciales: {total_n09_inicial}\")\n",
    "    \n",
    "    if total_n09_inicial == 0:\n",
    "        print(\"‚ö†Ô∏è No se encontraron registros N09\")\n",
    "        return df, df_no_envio\n",
    "    \n",
    "    # Identificar registros que ya est√°n como fallecidos (AF) en ADRES\n",
    "    mask_ya_fallecido = registros_n09['TPS_EST_AFL_ID_from_adres'] == 'AF'\n",
    "    registros_ya_fallecidos = registros_n09[mask_ya_fallecido].copy()\n",
    "    total_ya_fallecidos = len(registros_ya_fallecidos)\n",
    "    \n",
    "    print(f\"üìã AN√ÅLISIS DE ESTADO EN ADRES:\")\n",
    "    print(f\"   Registros ya marcados como fallecidos (AF) en ADRES: {total_ya_fallecidos}\")\n",
    "    print(f\"   Registros con cambio v√°lido (no AF): {total_n09_inicial - total_ya_fallecidos}\")\n",
    "    \n",
    "    if total_ya_fallecidos > 0:\n",
    "        # Mostrar ejemplos de registros ya fallecidos\n",
    "        print(f\"\\nüìã EJEMPLOS DE REGISTROS YA FALLECIDOS EN ADRES:\")\n",
    "        ejemplos = registros_ya_fallecidos[['NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION', \n",
    "                                           'TPS_EST_AFL_ID_from_adres', 'FECHA_NOVEDAD']].head(5)\n",
    "        print(ejemplos.to_string(index=False))\n",
    "        \n",
    "        # Agregar motivo y mover a DF_No_Envio\n",
    "        registros_ya_fallecidos['motivo'] = \"Afiliado sin cambios a reportar\"\n",
    "        \n",
    "        # Concatenar con DF_No_Envio existente\n",
    "        df_no_envio = pd.concat([df_no_envio, registros_ya_fallecidos], ignore_index=True)\n",
    "        \n",
    "        # Obtener √≠ndices originales para eliminar del DataFrame principal\n",
    "        indices_a_eliminar = df.loc[mask_n09][mask_ya_fallecido].index\n",
    "        df = df.drop(indices_a_eliminar).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"‚úÖ Movidos {total_ya_fallecidos} registros a DF_No_Envio\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Todos los registros N09 tienen cambios v√°lidos para reportar\")\n",
    "    \n",
    "    # Estad√≠sticas finales\n",
    "    registros_n09_final = len(df[df['NOVEDAD'] == 'N09'])\n",
    "    \n",
    "    print(f\"\\nüìà RESUMEN FINAL:\")\n",
    "    print(f\"   Registros N09 iniciales: {total_n09_inicial}\")\n",
    "    print(f\"   Registros movidos (ya fallecidos en ADRES): {total_ya_fallecidos}\")\n",
    "    print(f\"   Registros N09 restantes (v√°lidos): {registros_n09_final}\")\n",
    "    print(f\"   Total en DF_No_Envio actual: {len(df_no_envio)}\")\n",
    "    \n",
    "    # Mostrar distribuci√≥n de estados en registros restantes si hay\n",
    "    if registros_n09_final > 0:\n",
    "        print(f\"\\nüìã ESTADOS EN REGISTROS N09 RESTANTES:\")\n",
    "        estados_restantes = df[df['NOVEDAD'] == 'N09']['TPS_EST_AFL_ID_from_adres'].value_counts()\n",
    "        for estado, count in estados_restantes.items():\n",
    "            print(f\"   {estado}: {count} registros\")\n",
    "    \n",
    "    return df, df_no_envio\n",
    "\n",
    "# Aplicar validaci√≥n N09\n",
    "df_NS, DF_No_Envio = validar_novedades_N09(df_NS, DF_No_Envio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "## 5.6. N12 Actualizaci√≥n de condici√≥n de discapacidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validar_novedades_N12(df, df_no_envio, maestro_adres):\n",
    "    \"\"\"\n",
    "    Valida registros con NOVEDAD = 'N12' (Actualizaci√≥n de condici√≥n de discapacidad).\n",
    "    Proceso:\n",
    "    1. Validar que COD_1_NOVEDAD sea igual a 'D'\n",
    "    2. Verificar si el usuario ya est√° reportado con discapacidad en ADRES (TPS_CND_BNF_ID = 'D')\n",
    "    \"\"\"\n",
    "    print(\"üîç INICIANDO VALIDACI√ìN DE NOVEDADES N12\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Filtrar solo registros N12\n",
    "    mask_n12 = df['NOVEDAD'] == 'N12'\n",
    "    registros_n12 = df[mask_n12].copy()\n",
    "    total_n12_inicial = len(registros_n12)\n",
    "    \n",
    "    print(f\"üìä Total de registros N12 iniciales: {total_n12_inicial}\")\n",
    "    \n",
    "    if total_n12_inicial == 0:\n",
    "        print(\"‚ö†Ô∏è No se encontraron registros N12\")\n",
    "        return df, df_no_envio\n",
    "    \n",
    "    # =========================================================================\n",
    "    # VALIDACI√ìN 1: COD_1_NOVEDAD debe ser igual a 'D'\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîç VALIDACI√ìN 1: COD_1_NOVEDAD debe ser igual a 'D'\")\n",
    "    \n",
    "    # Normalizar valores (quitar espacios y convertir a may√∫sculas)\n",
    "    registros_n12['COD_1_NOVEDAD_NORM'] = registros_n12['COD_1_NOVEDAD'].astype(str).str.strip().str.upper()\n",
    "    \n",
    "    # Identificar registros con COD_1_NOVEDAD diferente de 'D'\n",
    "    mask_cod_invalido = registros_n12['COD_1_NOVEDAD_NORM'] != 'D'\n",
    "    registros_cod_invalido = registros_n12[mask_cod_invalido].copy()\n",
    "    total_cod_invalido = len(registros_cod_invalido)\n",
    "    \n",
    "    print(f\"   Registros con COD_1_NOVEDAD v√°lido ('D'): {total_n12_inicial - total_cod_invalido}\")\n",
    "    print(f\"   Registros con COD_1_NOVEDAD inv√°lido: {total_cod_invalido}\")\n",
    "    \n",
    "    if total_cod_invalido > 0:\n",
    "        # Mostrar ejemplos\n",
    "        print(f\"\\nüìã EJEMPLOS DE REGISTROS CON COD_1_NOVEDAD INV√ÅLIDO:\")\n",
    "        ejemplos_invalidos = registros_cod_invalido[['NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION', \n",
    "                                                     'COD_1_NOVEDAD', 'COD_1_NOVEDAD_NORM']].head(5)\n",
    "        print(ejemplos_invalidos.to_string(index=False))\n",
    "        \n",
    "        # Limpiar y mover a DF_No_Envio\n",
    "        registros_cod_invalido_clean = registros_cod_invalido.drop(columns=['COD_1_NOVEDAD_NORM'])\n",
    "        registros_cod_invalido_clean['motivo'] = \"Condici√≥n de discapacidad no v√°lida\"\n",
    "        \n",
    "        # Concatenar con DF_No_Envio\n",
    "        df_no_envio = pd.concat([df_no_envio, registros_cod_invalido_clean], ignore_index=True)\n",
    "        \n",
    "        # Eliminar del DataFrame principal\n",
    "        indices_a_eliminar = df.loc[mask_n12][mask_cod_invalido].index\n",
    "        df = df.drop(indices_a_eliminar).reset_index(drop=True)\n",
    "        \n",
    "        # Actualizar registros_n12 para la siguiente validaci√≥n\n",
    "        registros_n12 = registros_n12[~mask_cod_invalido].copy()\n",
    "        \n",
    "        print(f\"‚úÖ Movidos {total_cod_invalido} registros a DF_No_Envio por COD_1_NOVEDAD inv√°lido\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Todos los registros tienen COD_1_NOVEDAD = 'D'\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # VALIDACI√ìN 2: Verificar si ya est√° reportado con discapacidad en ADRES\n",
    "    # =========================================================================\n",
    "    registros_n12_restantes = len(registros_n12)\n",
    "    \n",
    "    if registros_n12_restantes == 0:\n",
    "        print(f\"\\n‚ö†Ô∏è No quedan registros N12 para validar\")\n",
    "        return df, df_no_envio\n",
    "    \n",
    "    print(f\"\\nüîç VALIDACI√ìN 2: Verificar si ya est√° reportado con discapacidad en ADRES\")\n",
    "    print(f\"   Registros a validar: {registros_n12_restantes}\")\n",
    "    \n",
    "    # Crear subset del maestro con TPS_CND_BNF_ID\n",
    "    maestro_discapacidad = maestro_adres[['ID_User', 'TPS_CND_BNF_ID']].drop_duplicates(subset=['ID_User'])\n",
    "    \n",
    "    # Normalizar TPS_CND_BNF_ID en el maestro\n",
    "    maestro_discapacidad['TPS_CND_BNF_ID_NORM'] = maestro_discapacidad['TPS_CND_BNF_ID'].astype(str).str.strip().str.upper()\n",
    "    \n",
    "    # Hacer merge para traer TPS_CND_BNF_ID del maestro\n",
    "    registros_n12_con_maestro = registros_n12.merge(\n",
    "        maestro_discapacidad[['ID_User', 'TPS_CND_BNF_ID_NORM']],\n",
    "        on='ID_User',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Identificar registros que ya tienen discapacidad reportada en ADRES\n",
    "    mask_ya_con_discapacidad = registros_n12_con_maestro['TPS_CND_BNF_ID_NORM'] == 'D'\n",
    "    registros_ya_con_discapacidad = registros_n12_con_maestro[mask_ya_con_discapacidad].copy()\n",
    "    total_ya_con_discapacidad = len(registros_ya_con_discapacidad)\n",
    "    \n",
    "    print(f\"   Registros ya con discapacidad en ADRES: {total_ya_con_discapacidad}\")\n",
    "    print(f\"   Registros con cambio v√°lido: {registros_n12_restantes - total_ya_con_discapacidad}\")\n",
    "    \n",
    "    if total_ya_con_discapacidad > 0:\n",
    "        # Mostrar ejemplos\n",
    "        print(f\"\\nüìã EJEMPLOS DE REGISTROS YA CON DISCAPACIDAD EN ADRES:\")\n",
    "        ejemplos_ya_discapacidad = registros_ya_con_discapacidad[['NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION', \n",
    "                                                                  'COD_1_NOVEDAD_NORM', 'TPS_CND_BNF_ID_NORM']].head(5)\n",
    "        print(ejemplos_ya_discapacidad.to_string(index=False))\n",
    "        \n",
    "        # Limpiar y mover a DF_No_Envio\n",
    "        registros_ya_con_discapacidad_clean = registros_ya_con_discapacidad.drop(columns=[\n",
    "            'COD_1_NOVEDAD_NORM', 'TPS_CND_BNF_ID_NORM'\n",
    "        ])\n",
    "        registros_ya_con_discapacidad_clean['motivo'] = \"Afiliado sin cambios a reportar\"\n",
    "        \n",
    "        # Concatenar con DF_No_Envio\n",
    "        df_no_envio = pd.concat([df_no_envio, registros_ya_con_discapacidad_clean], ignore_index=True)\n",
    "        \n",
    "        # Obtener √≠ndices originales para eliminar del DataFrame principal\n",
    "        # Necesitamos recalcular la m√°scara en el df original\n",
    "        mask_n12_original = df['NOVEDAD'] == 'N12'\n",
    "        registros_n12_original = df[mask_n12_original].copy()\n",
    "        \n",
    "        # Merge con el maestro en el df original\n",
    "        registros_n12_original_con_maestro = registros_n12_original.merge(\n",
    "            maestro_discapacidad[['ID_User', 'TPS_CND_BNF_ID_NORM']],\n",
    "            on='ID_User',\n",
    "            how='left'\n",
    "        )\n",
    "        registros_n12_original_con_maestro['COD_1_NOVEDAD_NORM'] = registros_n12_original_con_maestro['COD_1_NOVEDAD'].astype(str).str.strip().str.upper()\n",
    "        \n",
    "        # Identificar √≠ndices a eliminar\n",
    "        mask_eliminar_original = registros_n12_original_con_maestro['TPS_CND_BNF_ID_NORM'] == 'D'\n",
    "        indices_a_eliminar = df.loc[mask_n12_original][mask_eliminar_original].index\n",
    "        \n",
    "        df = df.drop(indices_a_eliminar).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"‚úÖ Movidos {total_ya_con_discapacidad} registros a DF_No_Envio por ya tener discapacidad en ADRES\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Todos los registros N12 son cambios v√°lidos para reportar\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # RESUMEN FINAL\n",
    "    # =========================================================================\n",
    "    registros_n12_final = len(df[df['NOVEDAD'] == 'N12'])\n",
    "    total_movidos = total_cod_invalido + total_ya_con_discapacidad\n",
    "    \n",
    "    print(f\"\\nüìà RESUMEN FINAL:\")\n",
    "    print(f\"   Registros N12 iniciales: {total_n12_inicial}\")\n",
    "    print(f\"   Registros movidos por COD_1_NOVEDAD inv√°lido: {total_cod_invalido}\")\n",
    "    print(f\"   Registros movidos por ya tener discapacidad en ADRES: {total_ya_con_discapacidad}\")\n",
    "    print(f\"   Total movidos: {total_movidos}\")\n",
    "    print(f\"   Registros N12 restantes (v√°lidos): {registros_n12_final}\")\n",
    "    print(f\"   Total en DF_No_Envio actual: {len(df_no_envio)}\")\n",
    "    \n",
    "    # Mostrar ejemplos de registros v√°lidos restantes si hay\n",
    "    if registros_n12_final > 0:\n",
    "        print(f\"\\nüìã EJEMPLOS DE REGISTROS N12 V√ÅLIDOS RESTANTES:\")\n",
    "        ejemplos_validos = df[df['NOVEDAD'] == 'N12'][['NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION', \n",
    "                                                       'COD_1_NOVEDAD']].head(5)\n",
    "        print(ejemplos_validos.to_string(index=False))\n",
    "    \n",
    "    return df, df_no_envio\n",
    "\n",
    "# Aplicar validaci√≥n N12\n",
    "df_NS, DF_No_Envio = validar_novedades_N12(df_NS, DF_No_Envio, maestro_ADRES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "## 5.7. N14 Actualizaci√≥n o cambio de estado de afiliaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validar_novedades_N14(df, df_no_envio):\n",
    "    \"\"\"\n",
    "    Valida registros con NOVEDAD = 'N14' (Actualizaci√≥n o cambio de estado de afiliaci√≥n).\n",
    "    \n",
    "    Proceso:\n",
    "    1. Validar y corregir formato de COD_2_NOVEDAD seg√∫n COD_1_NOVEDAD:\n",
    "       - Si COD_1_NOVEDAD es 'RE' o 'SM': COD_2_NOVEDAD debe ser num√©rico (1-9), sino asignar '7'\n",
    "       - Si COD_1_NOVEDAD es 'SD': COD_2_NOVEDAD debe estar vac√≠o\n",
    "    2. Verificar cambios reales: si COD_1_NOVEDAD == TPS_EST_AFL_ID_from_adres, mover a DF_No_Envio\n",
    "    \"\"\"\n",
    "    print(\"üîç INICIANDO VALIDACI√ìN DE NOVEDADES N14\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Filtrar solo registros N14\n",
    "    mask_n14 = df['NOVEDAD'] == 'N14'\n",
    "    registros_n14 = df[mask_n14].copy()\n",
    "    total_n14_inicial = len(registros_n14)\n",
    "    \n",
    "    print(f\"üìä Total de registros N14 iniciales: {total_n14_inicial}\")\n",
    "    \n",
    "    if total_n14_inicial == 0:\n",
    "        print(\"‚ö†Ô∏è No se encontraron registros N14\")\n",
    "        return df, df_no_envio\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 1: VALIDAR Y CORREGIR FORMATO DE COD_2_NOVEDAD\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîß PASO 1: Validando y corrigiendo formato de COD_2_NOVEDAD\")\n",
    "    \n",
    "    # Normalizar COD_1_NOVEDAD (quitar espacios y may√∫sculas)\n",
    "    registros_n14['COD_1_NOVEDAD_NORM'] = registros_n14['COD_1_NOVEDAD'].astype(str).str.strip().str.upper()\n",
    "    \n",
    "    # Mostrar distribuci√≥n de valores en COD_1_NOVEDAD\n",
    "    print(f\"\\nüìä Distribuci√≥n de COD_1_NOVEDAD:\")\n",
    "    distribucion_cod1 = registros_n14['COD_1_NOVEDAD_NORM'].value_counts()\n",
    "    for valor, count in distribucion_cod1.items():\n",
    "        print(f\"   {valor}: {count} registros\")\n",
    "    \n",
    "    # Funci√≥n para validar si es n√∫mero del 1 al 9\n",
    "    def es_numero_valido_1_a_9(valor):\n",
    "        if pd.isna(valor) or str(valor).strip() == '':\n",
    "            return False\n",
    "        try:\n",
    "            num = int(str(valor).strip())\n",
    "            return 1 <= num <= 9\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    # Contadores de correcciones\n",
    "    correcciones_re_sm = 0\n",
    "    correcciones_sd = 0\n",
    "    \n",
    "    # PROCESAR REGISTROS RE Y SM\n",
    "    mask_re_sm = registros_n14['COD_1_NOVEDAD_NORM'].isin(['RE', 'SM'])\n",
    "    registros_re_sm = registros_n14[mask_re_sm].copy()\n",
    "    \n",
    "    print(f\"\\nüîç Procesando registros RE y SM ({len(registros_re_sm)} registros):\")\n",
    "    \n",
    "    if len(registros_re_sm) > 0:\n",
    "        # Identificar registros sin valor v√°lido en COD_2_NOVEDAD\n",
    "        registros_re_sm['COD_2_VALIDO'] = registros_re_sm['COD_2_NOVEDAD'].apply(es_numero_valido_1_a_9)\n",
    "        invalidos_re_sm = (~registros_re_sm['COD_2_VALIDO']).sum()\n",
    "        \n",
    "        print(f\"   Registros con COD_2_NOVEDAD v√°lido (1-9): {registros_re_sm['COD_2_VALIDO'].sum()}\")\n",
    "        print(f\"   Registros sin COD_2_NOVEDAD v√°lido: {invalidos_re_sm}\")\n",
    "        \n",
    "        if invalidos_re_sm > 0:\n",
    "            # Mostrar ejemplos antes de corregir\n",
    "            print(f\"\\n   üìã Ejemplos de valores inv√°lidos a corregir:\")\n",
    "            ejemplos_invalidos = registros_re_sm[~registros_re_sm['COD_2_VALIDO']][\n",
    "                ['NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION', \n",
    "                 'COD_1_NOVEDAD_NORM', 'COD_2_NOVEDAD']\n",
    "            ].head(5)\n",
    "            print(ejemplos_invalidos.to_string(index=False))\n",
    "            \n",
    "            # Asignar '7' por defecto a los inv√°lidos\n",
    "            mask_corregir_re_sm = mask_re_sm & (~registros_re_sm['COD_2_VALIDO'])\n",
    "            df.loc[df[mask_n14][mask_corregir_re_sm].index, 'COD_2_NOVEDAD'] = '7'\n",
    "            correcciones_re_sm = invalidos_re_sm\n",
    "            \n",
    "            print(f\"   ‚úÖ Asignado '7' por defecto a {correcciones_re_sm} registros\")\n",
    "    \n",
    "    # PROCESAR REGISTROS SD\n",
    "    mask_sd = registros_n14['COD_1_NOVEDAD_NORM'] == 'SD'\n",
    "    registros_sd = registros_n14[mask_sd].copy()\n",
    "    \n",
    "    print(f\"\\nüîç Procesando registros SD ({len(registros_sd)} registros):\")\n",
    "    \n",
    "    if len(registros_sd) > 0:\n",
    "        # Identificar registros SD con valor en COD_2_NOVEDAD\n",
    "        registros_sd['COD_2_NO_VACIO'] = registros_sd['COD_2_NOVEDAD'].notna() & (registros_sd['COD_2_NOVEDAD'].astype(str).str.strip() != '')\n",
    "        con_valor_sd = registros_sd['COD_2_NO_VACIO'].sum()\n",
    "        \n",
    "        print(f\"   Registros SD con COD_2_NOVEDAD vac√≠o (correcto): {len(registros_sd) - con_valor_sd}\")\n",
    "        print(f\"   Registros SD con COD_2_NOVEDAD con valor (a limpiar): {con_valor_sd}\")\n",
    "        \n",
    "        if con_valor_sd > 0:\n",
    "            # Mostrar ejemplos antes de limpiar\n",
    "            print(f\"\\n   üìã Ejemplos de valores a limpiar:\")\n",
    "            ejemplos_sd = registros_sd[registros_sd['COD_2_NO_VACIO']][\n",
    "                ['NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION', \n",
    "                 'COD_1_NOVEDAD_NORM', 'COD_2_NOVEDAD']\n",
    "            ].head(5)\n",
    "            print(ejemplos_sd.to_string(index=False))\n",
    "            \n",
    "            # Limpiar COD_2_NOVEDAD para registros SD\n",
    "            mask_limpiar_sd = mask_sd & registros_sd['COD_2_NO_VACIO']\n",
    "            df.loc[df[mask_n14][mask_limpiar_sd].index, 'COD_2_NOVEDAD'] = ''\n",
    "            correcciones_sd = con_valor_sd\n",
    "            \n",
    "            print(f\"   ‚úÖ Limpiado COD_2_NOVEDAD en {correcciones_sd} registros SD\")\n",
    "    \n",
    "    # Resumen de correcciones de formato\n",
    "    total_correcciones_formato = correcciones_re_sm + correcciones_sd\n",
    "    print(f\"\\nüìà RESUMEN DE CORRECCIONES DE FORMATO:\")\n",
    "    print(f\"   Registros RE/SM corregidos (asignado '7'): {correcciones_re_sm}\")\n",
    "    print(f\"   Registros SD limpiados: {correcciones_sd}\")\n",
    "    print(f\"   Total correcciones de formato: {total_correcciones_formato}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 2: IDENTIFICAR REGISTROS SIN CAMBIOS\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîç PASO 2: Identificando registros sin cambios de estado\")\n",
    "    \n",
    "    # Recargar registros N14 con las correcciones aplicadas\n",
    "    registros_n14_actualizado = df[mask_n14].copy()\n",
    "    \n",
    "    # Normalizar TPS_EST_AFL_ID_from_adres para comparaci√≥n\n",
    "    registros_n14_actualizado['TPS_EST_AFL_ID_NORM'] = registros_n14_actualizado['TPS_EST_AFL_ID_from_adres'].astype(str).str.strip().str.upper()\n",
    "    registros_n14_actualizado['COD_1_NOVEDAD_NORM'] = registros_n14_actualizado['COD_1_NOVEDAD'].astype(str).str.strip().str.upper()\n",
    "    \n",
    "    # Crear m√°scara para registros sin cambios\n",
    "    mask_sin_cambios = registros_n14_actualizado['COD_1_NOVEDAD_NORM'] == registros_n14_actualizado['TPS_EST_AFL_ID_NORM']\n",
    "    registros_sin_cambios = registros_n14_actualizado[mask_sin_cambios].copy()\n",
    "    total_sin_cambios = len(registros_sin_cambios)\n",
    "    \n",
    "    print(f\"   Registros con COD_1_NOVEDAD = TPS_EST_AFL_ID_from_adres: {total_sin_cambios}\")\n",
    "    print(f\"   Registros con cambios v√°lidos: {total_n14_inicial - total_sin_cambios}\")\n",
    "    \n",
    "    if total_sin_cambios > 0:\n",
    "        # Mostrar ejemplos\n",
    "        print(f\"\\nüìã EJEMPLOS DE REGISTROS SIN CAMBIOS:\")\n",
    "        ejemplos_sin_cambios = registros_sin_cambios[[\n",
    "            'NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION',\n",
    "            'COD_1_NOVEDAD_NORM', 'TPS_EST_AFL_ID_NORM'\n",
    "        ]].head(5)\n",
    "        print(ejemplos_sin_cambios.to_string(index=False))\n",
    "        \n",
    "        # Limpiar y mover a DF_No_Envio\n",
    "        registros_sin_cambios_clean = registros_sin_cambios.drop(columns=[\n",
    "            'TPS_EST_AFL_ID_NORM', 'COD_1_NOVEDAD_NORM'\n",
    "        ])\n",
    "        registros_sin_cambios_clean['motivo'] = \"Afiliado sin cambios a reportar\"\n",
    "        \n",
    "        # Concatenar con DF_No_Envio\n",
    "        df_no_envio = pd.concat([df_no_envio, registros_sin_cambios_clean], ignore_index=True)\n",
    "        \n",
    "        # Eliminar del DataFrame principal\n",
    "        indices_a_eliminar = df.loc[mask_n14][mask_sin_cambios].index\n",
    "        df = df.drop(indices_a_eliminar).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"‚úÖ Movidos {total_sin_cambios} registros a DF_No_Envio\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Todos los registros N14 tienen cambios v√°lidos para reportar\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 3: ESTAD√çSTICAS FINALES\n",
    "    # =========================================================================\n",
    "    registros_n14_final = len(df[df['NOVEDAD'] == 'N14'])\n",
    "    \n",
    "    print(f\"\\nüìà RESUMEN FINAL:\")\n",
    "    print(f\"   Registros N14 iniciales: {total_n14_inicial}\")\n",
    "    print(f\"   Correcciones de formato aplicadas: {total_correcciones_formato}\")\n",
    "    print(f\"   Registros movidos (sin cambios): {total_sin_cambios}\")\n",
    "    print(f\"   Registros N14 restantes (v√°lidos): {registros_n14_final}\")\n",
    "    print(f\"   Total en DF_No_Envio actual: {len(df_no_envio)}\")\n",
    "    \n",
    "    # Mostrar ejemplos de registros v√°lidos restantes si hay\n",
    "    if registros_n14_final > 0:\n",
    "        print(f\"\\nüìã EJEMPLOS DE REGISTROS N14 V√ÅLIDOS RESTANTES:\")\n",
    "        ejemplos_validos = df[df['NOVEDAD'] == 'N14'][[\n",
    "            'NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION',\n",
    "            'COD_1_NOVEDAD', 'COD_2_NOVEDAD', 'TPS_EST_AFL_ID_from_adres'\n",
    "        ]].head(5)\n",
    "        print(ejemplos_validos.to_string(index=False))\n",
    "        \n",
    "        # Mostrar distribuci√≥n de estados en registros v√°lidos\n",
    "        print(f\"\\nüìä Distribuci√≥n de estados en registros v√°lidos:\")\n",
    "        distribucion_estados = df[df['NOVEDAD'] == 'N14']['COD_1_NOVEDAD'].value_counts()\n",
    "        for estado, count in distribucion_estados.items():\n",
    "            print(f\"   {estado}: {count} registros\")\n",
    "    \n",
    "    return df, df_no_envio\n",
    "\n",
    "# Aplicar validaci√≥n N14\n",
    "df_NS, DF_No_Envio = validar_novedades_N14(df_NS, DF_No_Envio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "### 5.7.1. N14 Masiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_retiros_masivos_N14(df_ns, maestro_adres, fecha_reporte):\n",
    "    \"\"\"\n",
    "    Aplica retiros masivos N14 (SD - Suspensi√≥n por Documento) para 3 casos espec√≠ficos:\n",
    "    1. Afiliados con PE activos\n",
    "    2. CN activos con edad >= 1 a√±o\n",
    "    3. Identificaciones alfanum√©ricas activas\n",
    "    \n",
    "    Args:\n",
    "        df_ns: DataFrame de novedades\n",
    "        maestro_adres: DataFrame maestro ADRES\n",
    "        fecha_reporte: fecha del reporte (datetime)\n",
    "    \n",
    "    Returns:\n",
    "        df_ns actualizado con las nuevas novedades N14\n",
    "    \"\"\"\n",
    "    print(\"üîç INICIANDO APLICACI√ìN DE RETIROS MASIVOS N14 (SD)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Convertir fecha_reporte a formato DD/MM/YYYY\n",
    "    fecha_novedad_str = fecha_reporte.strftime('%d/%m/%Y')\n",
    "    print(f\"üìÖ Fecha de novedad: {fecha_novedad_str}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CASO 1: PE ACTIVOS\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîç CASO 1: Afiliados con PE activos\")\n",
    "    \n",
    "    mask_pe = (\n",
    "        (maestro_adres['ENT_ID'] == 'EPS025') &\n",
    "        (maestro_adres['TPS_IDN_ID'] == 'PE') &\n",
    "        (maestro_adres['TPS_EST_AFL_ID'] == 'AC')\n",
    "    )\n",
    "    \n",
    "    registros_pe = maestro_adres[mask_pe].copy().reset_index(drop=True)  # ‚úÖ RESET INDEX\n",
    "    total_pe = len(registros_pe)\n",
    "    \n",
    "    print(f\"   üìä Registros PE activos encontrados: {total_pe}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CASO 2: CN ACTIVOS CON EDAD >= 1\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîç CASO 2: CN activos con edad >= 1 a√±o\")\n",
    "    \n",
    "    mask_cn = (\n",
    "        (maestro_adres['ENT_ID'] == 'EPS025') &\n",
    "        (maestro_adres['TPS_IDN_ID'] == 'CN') &\n",
    "        (maestro_adres['TPS_EST_AFL_ID'] == 'AC') &\n",
    "        (maestro_adres['EDAD'] >= 1)\n",
    "    )\n",
    "    \n",
    "    registros_cn = maestro_adres[mask_cn].copy().reset_index(drop=True)  # ‚úÖ RESET INDEX\n",
    "    total_cn = len(registros_cn)\n",
    "    \n",
    "    print(f\"   üìä Registros CN >= 1 a√±o encontrados: {total_cn}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CASO 3: IDENTIFICACIONES ALFANUM√âRICAS ACTIVAS\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîç CASO 3: Identificaciones alfanum√©ricas activas\")\n",
    "    \n",
    "    def es_alfanumerico(valor):\n",
    "        \"\"\"Verifica si un valor contiene letras y n√∫meros\"\"\"\n",
    "        if pd.isna(valor) or str(valor).strip() == '':\n",
    "            return False\n",
    "        \n",
    "        valor_str = str(valor).strip()\n",
    "        tiene_letras = any(c.isalpha() for c in valor_str)\n",
    "        tiene_numeros = any(c.isdigit() for c in valor_str)\n",
    "        \n",
    "        return tiene_letras and tiene_numeros\n",
    "    \n",
    "    # Aplicar validaci√≥n alfanum√©rica\n",
    "    maestro_adres_temp = maestro_adres.copy()\n",
    "    maestro_adres_temp['ES_ALFANUMERICO'] = maestro_adres_temp['HST_IDN_NUMERO_IDENTIFICACION'].apply(es_alfanumerico)\n",
    "    \n",
    "    mask_alfanum = (\n",
    "        (maestro_adres_temp['ENT_ID'] == 'EPS025') &\n",
    "        (maestro_adres_temp['ES_ALFANUMERICO'] == True) &\n",
    "        (maestro_adres_temp['TPS_EST_AFL_ID'] == 'AC')\n",
    "    )\n",
    "    \n",
    "    registros_alfanum = maestro_adres_temp[mask_alfanum].copy().reset_index(drop=True)  # ‚úÖ RESET INDEX\n",
    "    # Eliminar columna temporal\n",
    "    registros_alfanum = registros_alfanum.drop(columns=['ES_ALFANUMERICO'])\n",
    "    total_alfanum = len(registros_alfanum)\n",
    "    \n",
    "    print(f\"   üìä Registros alfanum√©ricos activos encontrados: {total_alfanum}\")\n",
    "    \n",
    "    if total_alfanum > 0:\n",
    "        print(f\"   üìã Ejemplos de identificaciones alfanum√©ricas:\")\n",
    "        ejemplos_alfanum = registros_alfanum['HST_IDN_NUMERO_IDENTIFICACION'].head(10).tolist()\n",
    "        print(f\"      {ejemplos_alfanum}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # COMBINAR TODOS LOS CASOS\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüìä RESUMEN DE REGISTROS A PROCESAR:\")\n",
    "    print(f\"   Caso 1 (PE activos): {total_pe}\")\n",
    "    print(f\"   Caso 2 (CN >= 1 a√±o): {total_cn}\")\n",
    "    print(f\"   Caso 3 (Alfanum√©ricos): {total_alfanum}\")\n",
    "    \n",
    "    total_registros = total_pe + total_cn + total_alfanum\n",
    "    print(f\"   TOTAL: {total_registros}\")\n",
    "    \n",
    "    if total_registros == 0:\n",
    "        print(f\"\\n‚ö†Ô∏è No se encontraron registros para aplicar retiros masivos\")\n",
    "        return df_ns\n",
    "    \n",
    "    # ‚úÖ COMBINAR CON MANEJO SEGURO DE DATAFRAMES VAC√çOS\n",
    "    dataframes_a_combinar = []\n",
    "    \n",
    "    if total_pe > 0:\n",
    "        dataframes_a_combinar.append(registros_pe)\n",
    "    if total_cn > 0:\n",
    "        dataframes_a_combinar.append(registros_cn)\n",
    "    if total_alfanum > 0:\n",
    "        dataframes_a_combinar.append(registros_alfanum)\n",
    "    \n",
    "    if len(dataframes_a_combinar) == 0:\n",
    "        print(f\"\\n‚ö†Ô∏è No hay DataFrames v√°lidos para combinar\")\n",
    "        return df_ns\n",
    "    \n",
    "    # Combinar todos los registros\n",
    "    try:\n",
    "        registros_combinados = pd.concat(dataframes_a_combinar, ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al concatenar DataFrames: {e}\")\n",
    "        print(f\"   DataFrames a combinar: {len(dataframes_a_combinar)}\")\n",
    "        for i, df_temp in enumerate(dataframes_a_combinar):\n",
    "            print(f\"   DF {i}: {len(df_temp)} filas, columnas: {list(df_temp.columns)[:5]}...\")\n",
    "        return df_ns\n",
    "    \n",
    "    # Eliminar duplicados por ID_User (por si hay casos que cumplan m√∫ltiples condiciones)\n",
    "    registros_combinados = registros_combinados.drop_duplicates(subset=['ID_User'])\n",
    "    total_unicos = len(registros_combinados)\n",
    "    \n",
    "    print(f\"\\n   üìä Total de registros √∫nicos (sin duplicados): {total_unicos}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CONSTRUIR NOVEDADES N14\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîß CONSTRUYENDO NOVEDADES N14 (SD)\")\n",
    "    \n",
    "    # Verificar que tenemos registros para procesar\n",
    "    if total_unicos == 0:\n",
    "        print(f\"‚ö†Ô∏è No hay registros √∫nicos para procesar\")\n",
    "        return df_ns\n",
    "    \n",
    "    # ‚úÖ VERIFICAR QUE EXISTEN LAS COLUMNAS NECESARIAS\n",
    "    columnas_requeridas = [\n",
    "        'ENT_ID', 'TPS_IDN_ID', 'HST_IDN_NUMERO_IDENTIFICACION',\n",
    "        'AFL_PRIMER_APELLIDO', 'AFL_SEGUNDO_APELLIDO', \n",
    "        'AFL_PRIMER_NOMBRE', 'AFL_SEGUNDO_NOMBRE',\n",
    "        'AFL_FECHA_NACIMIENTO', 'DPR_ID', 'MNC_ID', 'TPS_EST_AFL_ID'\n",
    "    ]\n",
    "    \n",
    "    columnas_faltantes = [col for col in columnas_requeridas if col not in registros_combinados.columns]\n",
    "    if columnas_faltantes:\n",
    "        print(f\"‚ùå Columnas faltantes en registros_combinados: {columnas_faltantes}\")\n",
    "        return df_ns\n",
    "    \n",
    "    # Mapear columnas de maestro_ADRES a df_NS\n",
    "    try:\n",
    "        nuevas_novedades = pd.DataFrame({\n",
    "            'ENT_ID': registros_combinados['ENT_ID'],\n",
    "            'TPS_IDN_ID': registros_combinados['TPS_IDN_ID'],\n",
    "            'HST_IDN_NUMERO_IDENTIFICACION': registros_combinados['HST_IDN_NUMERO_IDENTIFICACION'],\n",
    "            'AFL_PRIMER_APELLIDO': registros_combinados['AFL_PRIMER_APELLIDO'],\n",
    "            'AFL_SEGUNDO_APELLIDO': registros_combinados['AFL_SEGUNDO_APELLIDO'],\n",
    "            'AFL_PRIMER_NOMBRE': registros_combinados['AFL_PRIMER_NOMBRE'],\n",
    "            'AFL_SEGUNDO_NOMBRE': registros_combinados['AFL_SEGUNDO_NOMBRE'],\n",
    "            'AFL_FECHA_NACIMIENTO': registros_combinados['AFL_FECHA_NACIMIENTO'],\n",
    "            'DPR_ID': registros_combinados['DPR_ID'],\n",
    "            'MNS_ID': registros_combinados['MNC_ID'],  # Nota: MNC_ID -> MNS_ID\n",
    "            'NOVEDAD': 'N14',\n",
    "            'FECHA_NOVEDAD': fecha_novedad_str,\n",
    "            'COD_1_NOVEDAD': 'SD',\n",
    "            'ENT_ID_ADRES': registros_combinados['ENT_ID'],\n",
    "            'TPS_EST_AFL_ID_from_adres': registros_combinados['TPS_EST_AFL_ID'],\n",
    "            'Where': 'Novedad Masiva'\n",
    "        })\n",
    "        \n",
    "        # Crear ID_User e ID_Register\n",
    "        nuevas_novedades['ID_User'] = (\n",
    "            nuevas_novedades['TPS_IDN_ID'].astype(str) + \n",
    "            nuevas_novedades['HST_IDN_NUMERO_IDENTIFICACION'].astype(str)\n",
    "        )\n",
    "        \n",
    "        nuevas_novedades['ID_Register'] = (\n",
    "            nuevas_novedades['TPS_IDN_ID'].astype(str) + \n",
    "            nuevas_novedades['HST_IDN_NUMERO_IDENTIFICACION'].astype(str) + \n",
    "            nuevas_novedades['NOVEDAD'].astype(str)\n",
    "        )\n",
    "        \n",
    "        # Rellenar columnas faltantes con valores vac√≠os/None\n",
    "        columnas_faltantes = [col for col in df_ns.columns if col not in nuevas_novedades.columns]\n",
    "        for col in columnas_faltantes:\n",
    "            nuevas_novedades[col] = None\n",
    "        \n",
    "        # Ordenar columnas en el mismo orden que df_NS\n",
    "        nuevas_novedades = nuevas_novedades[df_ns.columns]\n",
    "        \n",
    "        print(f\"   ‚úÖ Novedades N14 construidas: {len(nuevas_novedades)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al construir nuevas_novedades: {e}\")\n",
    "        return df_ns\n",
    "    \n",
    "    # Mostrar ejemplos\n",
    "    if len(nuevas_novedades) > 0:\n",
    "        print(f\"\\nüìã EJEMPLOS DE NOVEDADES N14 CREADAS:\")\n",
    "        ejemplos_columnas = ['TPS_IDN_ID', 'HST_IDN_NUMERO_IDENTIFICACION', \n",
    "                           'AFL_PRIMER_NOMBRE', 'AFL_PRIMER_APELLIDO',\n",
    "                           'NOVEDAD', 'COD_1_NOVEDAD', 'FECHA_NOVEDAD', 'Where']\n",
    "        ejemplos_columnas_disponibles = [col for col in ejemplos_columnas if col in nuevas_novedades.columns]\n",
    "        ejemplos = nuevas_novedades[ejemplos_columnas_disponibles].head(10)\n",
    "        print(ejemplos.to_string(index=False))\n",
    "    \n",
    "    # =========================================================================\n",
    "    # AGREGAR AL DATAFRAME PRINCIPAL\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîÑ AGREGANDO NOVEDADES A df_NS\")\n",
    "    \n",
    "    try:\n",
    "        registros_antes = len(df_ns)\n",
    "        df_ns = pd.concat([df_ns, nuevas_novedades], ignore_index=True)\n",
    "        registros_despues = len(df_ns)\n",
    "        \n",
    "        print(f\"   üìä Registros antes: {registros_antes}\")\n",
    "        print(f\"   üìä Registros despu√©s: {registros_despues}\")\n",
    "        print(f\"   üìä Registros agregados: {registros_despues - registros_antes}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al agregar novedades a df_NS: {e}\")\n",
    "        return df_ns\n",
    "    \n",
    "    # =========================================================================\n",
    "    # ESTAD√çSTICAS FINALES POR TIPO DE DOCUMENTO\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüìà ESTAD√çSTICAS DE NOVEDADES N14 AGREGADAS:\")\n",
    "    \n",
    "    try:\n",
    "        if 'Where' in df_ns.columns:\n",
    "            novedades_n14_masivas = df_ns[df_ns['Where'] == 'Novedad Masiva']\n",
    "            if len(novedades_n14_masivas) > 0:\n",
    "                print(f\"   Por tipo de documento:\")\n",
    "                distribucion_tps = novedades_n14_masivas['TPS_IDN_ID'].value_counts()\n",
    "                \n",
    "                for tipo_doc, count in distribucion_tps.items():\n",
    "                    print(f\"     {tipo_doc}: {count} registros\")\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è No se encontraron novedades masivas en el DataFrame final\")\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è Columna 'Where' no encontrada en df_NS\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error al generar estad√≠sticas finales: {e}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ RETIROS MASIVOS N14 APLICADOS EXITOSAMENTE\")\n",
    "    \n",
    "    return df_ns\n",
    "\n",
    "# Aplicar retiros masivos\n",
    "df_NS = aplicar_retiros_masivos_N14(df_NS, maestro_ADRES, fecha_reporte)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "## 5.8 N17 Actualizaci√≥n de Sexo biol√≥gico del afiliado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validar_novedades_N17(df, df_no_envio, maestro_adres):\n",
    "    \"\"\"\n",
    "    Valida registros con NOVEDAD = 'N17' (Actualizaci√≥n de Sexo biol√≥gico del afiliado).\n",
    "    \n",
    "    Proceso:\n",
    "    1. Traer el sexo actual desde maestro_ADRES (AFL_SEXO_IDENTIFICACION)\n",
    "    2. Comparar con el sexo a reportar (COD_1_NOVEDAD)\n",
    "    3. Si son iguales, mover a DF_No_Envio\n",
    "    \"\"\"\n",
    "    print(\"üîç INICIANDO VALIDACI√ìN DE NOVEDADES N17\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Filtrar solo registros N17\n",
    "    mask_n17 = df['NOVEDAD'] == 'N17'\n",
    "    registros_n17 = df[mask_n17].copy()\n",
    "    total_n17_inicial = len(registros_n17)\n",
    "    \n",
    "    print(f\"üìä Total de registros N17 iniciales: {total_n17_inicial}\")\n",
    "    \n",
    "    if total_n17_inicial == 0:\n",
    "        print(\"‚ö†Ô∏è No se encontraron registros N17\")\n",
    "        return df, df_no_envio\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 1: TRAER SEXO ACTUAL DESDE MAESTRO_ADRES\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîç PASO 1: Obteniendo sexo actual desde maestro_ADRES\")\n",
    "    \n",
    "    # Crear subset del maestro con sexo actual\n",
    "    maestro_sexo = maestro_adres[['ID_User', 'AFL_SEXO_IDENTIFICACION']].drop_duplicates(subset=['ID_User'])\n",
    "    \n",
    "    print(f\"   üìä Registros √∫nicos en maestro_ADRES: {len(maestro_sexo):,}\")\n",
    "    \n",
    "    # Hacer merge para traer AFL_SEXO_IDENTIFICACION del maestro\n",
    "    registros_n17_con_maestro = registros_n17.merge(\n",
    "        maestro_sexo,\n",
    "        on='ID_User',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Verificar cu√°ntos registros tienen sexo en ADRES\n",
    "    registros_con_sexo_adres = registros_n17_con_maestro['AFL_SEXO_IDENTIFICACION'].notna().sum()\n",
    "    registros_sin_sexo_adres = registros_n17_con_maestro['AFL_SEXO_IDENTIFICACION'].isna().sum()\n",
    "    \n",
    "    print(f\"   ‚úÖ Registros con sexo en ADRES: {registros_con_sexo_adres}\")\n",
    "    print(f\"   ‚ö†Ô∏è Registros sin sexo en ADRES: {registros_sin_sexo_adres}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 2: NORMALIZAR Y COMPARAR SEXOS\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîß PASO 2: Normalizando y comparando valores de sexo\")\n",
    "    \n",
    "    # Normalizar valores (quitar espacios y convertir a may√∫sculas)\n",
    "    registros_n17_con_maestro['COD_1_NOVEDAD_NORM'] = registros_n17_con_maestro['COD_1_NOVEDAD'].astype(str).str.strip().str.upper()\n",
    "    registros_n17_con_maestro['AFL_SEXO_IDENTIFICACION_NORM'] = registros_n17_con_maestro['AFL_SEXO_IDENTIFICACION'].astype(str).str.strip().str.upper()\n",
    "    \n",
    "    # Mostrar distribuci√≥n de valores\n",
    "    print(f\"\\nüìä Distribuci√≥n de sexo a reportar (COD_1_NOVEDAD):\")\n",
    "    distribucion_nuevo = registros_n17_con_maestro['COD_1_NOVEDAD_NORM'].value_counts()\n",
    "    for sexo, count in distribucion_nuevo.items():\n",
    "        print(f\"   {sexo}: {count} registros\")\n",
    "    \n",
    "    print(f\"\\nüìä Distribuci√≥n de sexo actual en ADRES:\")\n",
    "    distribucion_actual = registros_n17_con_maestro['AFL_SEXO_IDENTIFICACION_NORM'].value_counts()\n",
    "    for sexo, count in distribucion_actual.items():\n",
    "        print(f\"   {sexo}: {count} registros\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 3: IDENTIFICAR REGISTROS SIN CAMBIOS\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîç PASO 3: Identificando registros sin cambios de sexo\")\n",
    "    \n",
    "    # Crear m√°scara para registros donde el sexo es igual\n",
    "    mask_sin_cambios = (\n",
    "        (registros_n17_con_maestro['COD_1_NOVEDAD_NORM'] == registros_n17_con_maestro['AFL_SEXO_IDENTIFICACION_NORM']) &\n",
    "        registros_n17_con_maestro['AFL_SEXO_IDENTIFICACION'].notna()  # Solo comparar si existe sexo en ADRES\n",
    "    )\n",
    "    \n",
    "    registros_sin_cambios = registros_n17_con_maestro[mask_sin_cambios].copy()\n",
    "    total_sin_cambios = len(registros_sin_cambios)\n",
    "    \n",
    "    print(f\"   Registros con mismo sexo en ADRES y a reportar: {total_sin_cambios}\")\n",
    "    print(f\"   Registros con cambios v√°lidos: {total_n17_inicial - total_sin_cambios}\")\n",
    "    \n",
    "    if total_sin_cambios > 0:\n",
    "        # Mostrar ejemplos\n",
    "        print(f\"\\nüìã EJEMPLOS DE REGISTROS SIN CAMBIOS:\")\n",
    "        ejemplos_sin_cambios = registros_sin_cambios[[\n",
    "            'NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION',\n",
    "            'COD_1_NOVEDAD_NORM', 'AFL_SEXO_IDENTIFICACION_NORM'\n",
    "        ]].head(5)\n",
    "        print(ejemplos_sin_cambios.to_string(index=False))\n",
    "        \n",
    "        # Limpiar y mover a DF_No_Envio\n",
    "        registros_sin_cambios_clean = registros_sin_cambios.drop(columns=[\n",
    "            'COD_1_NOVEDAD_NORM', 'AFL_SEXO_IDENTIFICACION_NORM', 'AFL_SEXO_IDENTIFICACION'\n",
    "        ])\n",
    "        registros_sin_cambios_clean['motivo'] = \"Afiliado sin cambios a reportar\"\n",
    "        \n",
    "        # Concatenar con DF_No_Envio\n",
    "        df_no_envio = pd.concat([df_no_envio, registros_sin_cambios_clean], ignore_index=True)\n",
    "        \n",
    "        # Obtener √≠ndices originales para eliminar del DataFrame principal\n",
    "        # Necesitamos recalcular la m√°scara en el df original\n",
    "        mask_n17_original = df['NOVEDAD'] == 'N17'\n",
    "        registros_n17_original = df[mask_n17_original].copy()\n",
    "        \n",
    "        # Merge con el maestro en el df original\n",
    "        registros_n17_original_con_maestro = registros_n17_original.merge(\n",
    "            maestro_sexo,\n",
    "            on='ID_User',\n",
    "            how='left'\n",
    "        )\n",
    "        registros_n17_original_con_maestro['COD_1_NOVEDAD_NORM'] = registros_n17_original_con_maestro['COD_1_NOVEDAD'].astype(str).str.strip().str.upper()\n",
    "        registros_n17_original_con_maestro['AFL_SEXO_IDENTIFICACION_NORM'] = registros_n17_original_con_maestro['AFL_SEXO_IDENTIFICACION'].astype(str).str.strip().str.upper()\n",
    "        \n",
    "        # Identificar √≠ndices a eliminar\n",
    "        mask_eliminar_original = (\n",
    "            (registros_n17_original_con_maestro['COD_1_NOVEDAD_NORM'] == registros_n17_original_con_maestro['AFL_SEXO_IDENTIFICACION_NORM']) &\n",
    "            registros_n17_original_con_maestro['AFL_SEXO_IDENTIFICACION'].notna()\n",
    "        )\n",
    "        #indices_a_eliminar = df.loc[mask_n17_original][mask_eliminar_original].index\n",
    "        #df = df.drop(indices_a_eliminar).reset_index(drop=True)\n",
    "        \n",
    "        # Identificar √≠ndices a eliminar\n",
    "        # CORRECCI√ìN: Usar ID_User para eliminar registros\n",
    "        ids_a_eliminar = registros_n17_original_con_maestro[mask_eliminar_original]['ID_User'].unique()\n",
    "        mask_eliminar_df = (df['NOVEDAD'] == 'N17') & (df['ID_User'].isin(ids_a_eliminar))\n",
    "        df = df[~mask_eliminar_df].reset_index(drop=True)\n",
    "        \n",
    "        print(f\"‚úÖ Movidos {total_sin_cambios} registros a DF_No_Envio\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Todos los registros N17 son cambios v√°lidos para reportar\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 4: AN√ÅLISIS DE REGISTROS SIN SEXO EN ADRES\n",
    "    # =========================================================================\n",
    "    if registros_sin_sexo_adres > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è REGISTROS SIN SEXO EN MAESTRO_ADRES:\")\n",
    "        registros_sin_match = registros_n17_con_maestro[registros_n17_con_maestro['AFL_SEXO_IDENTIFICACION'].isna()]\n",
    "        print(f\"   Total: {registros_sin_sexo_adres}\")\n",
    "        print(f\"   üìã Ejemplos de registros sin match:\")\n",
    "        ejemplos_sin_match = registros_sin_match[[\n",
    "            'NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION',\n",
    "            'COD_1_NOVEDAD', 'ID_User'\n",
    "        ]].head(5)\n",
    "        print(ejemplos_sin_match.to_string(index=False))\n",
    "        print(f\"   ‚ÑπÔ∏è Estos registros se mantendr√°n en df_NS (asumiendo que son cambios v√°lidos)\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 5: RESUMEN FINAL\n",
    "    # =========================================================================\n",
    "    registros_n17_final = len(df[df['NOVEDAD'] == 'N17'])\n",
    "    \n",
    "    print(f\"\\nüìà RESUMEN FINAL:\")\n",
    "    print(f\"   Registros N17 iniciales: {total_n17_inicial}\")\n",
    "    print(f\"   Registros movidos (sin cambios): {total_sin_cambios}\")\n",
    "    print(f\"   Registros N17 restantes (v√°lidos): {registros_n17_final}\")\n",
    "    print(f\"   Total en DF_No_Envio actual: {len(df_no_envio)}\")\n",
    "    \n",
    "    # Mostrar ejemplos de registros v√°lidos restantes si hay\n",
    "    if registros_n17_final > 0:\n",
    "        print(f\"\\nüìã EJEMPLOS DE REGISTROS N17 V√ÅLIDOS RESTANTES:\")\n",
    "        ejemplos_validos = df[df['NOVEDAD'] == 'N17'][[\n",
    "            'NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION',\n",
    "            'COD_1_NOVEDAD'\n",
    "        ]].head(5)\n",
    "        print(ejemplos_validos.to_string(index=False))\n",
    "        \n",
    "        # Mostrar distribuci√≥n de sexos a reportar en registros v√°lidos\n",
    "        print(f\"\\nüìä Distribuci√≥n de sexo a reportar en registros v√°lidos:\")\n",
    "        distribucion_validos = df[df['NOVEDAD'] == 'N17']['COD_1_NOVEDAD'].value_counts()\n",
    "        for sexo, count in distribucion_validos.items():\n",
    "            print(f\"   {sexo}: {count} registros\")\n",
    "    \n",
    "    return df, df_no_envio\n",
    "\n",
    "# Aplicar validaci√≥n N17\n",
    "df_NS, DF_No_Envio = validar_novedades_N17(df_NS, DF_No_Envio, maestro_ADRES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "## 5.9. N19 Actualizaci√≥n de zona de afiliaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validar_novedades_N19(df, df_no_envio, maestro_adres):\n",
    "    \"\"\"\n",
    "    Valida registros con NOVEDAD = 'N19' (Actualizaci√≥n de zona de afiliaci√≥n).\n",
    "    \n",
    "    Proceso:\n",
    "    1. Validar formato de COD_1_NOVEDAD: debe ser R1, R2, U1, U2, R, o U\n",
    "    2. Corregir formato: Si es \"R\" ‚Üí \"R1\", Si es \"U\" ‚Üí \"U1\" \n",
    "    3. Traer zona actual desde maestro_ADRES (ZNS_ID)\n",
    "    4. Verificar cambios reales: si COD_1_NOVEDAD == ZNS_ID, mover a DF_No_Envio\n",
    "    \"\"\"\n",
    "    print(\"üîç INICIANDO VALIDACI√ìN DE NOVEDADES N19\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Filtrar solo registros N19\n",
    "    mask_n19 = df['NOVEDAD'] == 'N19'\n",
    "    registros_n19 = df[mask_n19].copy()\n",
    "    total_n19_inicial = len(registros_n19)\n",
    "    \n",
    "    print(f\"üìä Total de registros N19 iniciales: {total_n19_inicial}\")\n",
    "    \n",
    "    if total_n19_inicial == 0:\n",
    "        print(\"‚ö†Ô∏è No se encontraron registros N19\")\n",
    "        return df, df_no_envio\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 1: VALIDAR Y CORREGIR FORMATO DE COD_1_NOVEDAD\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîß PASO 1: Validando y corrigiendo formato de COD_1_NOVEDAD\")\n",
    "    \n",
    "    # Normalizar COD_1_NOVEDAD (quitar espacios y may√∫sculas)\n",
    "    registros_n19['COD_1_NOVEDAD_NORM'] = registros_n19['COD_1_NOVEDAD'].astype(str).str.strip().str.upper()\n",
    "    \n",
    "    # Mostrar distribuci√≥n inicial de valores\n",
    "    print(f\"\\nüìä Distribuci√≥n inicial de COD_1_NOVEDAD:\")\n",
    "    distribucion_inicial = registros_n19['COD_1_NOVEDAD_NORM'].value_counts()\n",
    "    for valor, count in distribucion_inicial.items():\n",
    "        print(f\"   {valor}: {count} registros\")\n",
    "    \n",
    "    # Valores v√°lidos finales\n",
    "    valores_validos_finales = ['R1', 'R2', 'U1', 'U2']\n",
    "    valores_corregibles = ['R', 'U']\n",
    "    \n",
    "    # Funci√≥n para corregir formato\n",
    "    def corregir_zona(valor):\n",
    "        if pd.isna(valor) or str(valor).strip() == '':\n",
    "            return None\n",
    "        \n",
    "        valor_norm = str(valor).strip().upper()\n",
    "        \n",
    "        # Si ya es v√°lido, mantener\n",
    "        if valor_norm in valores_validos_finales:\n",
    "            return valor_norm\n",
    "        # Si es corregible, aplicar correcci√≥n por defecto\n",
    "        elif valor_norm == 'R':\n",
    "            return 'R1'\n",
    "        elif valor_norm == 'U':\n",
    "            return 'U1'\n",
    "        else:\n",
    "            return valor_norm  # Mantener para identificar como inv√°lido\n",
    "    \n",
    "    # Aplicar correcci√≥n\n",
    "    registros_n19['COD_1_NOVEDAD_CORREGIDO'] = registros_n19['COD_1_NOVEDAD_NORM'].apply(corregir_zona)\n",
    "    \n",
    "    # Contar correcciones aplicadas\n",
    "    correcciones_r = (registros_n19['COD_1_NOVEDAD_NORM'] == 'R').sum()\n",
    "    correcciones_u = (registros_n19['COD_1_NOVEDAD_NORM'] == 'U').sum()\n",
    "    total_correcciones = correcciones_r + correcciones_u\n",
    "    \n",
    "    print(f\"\\nüìà CORRECCIONES APLICADAS:\")\n",
    "    print(f\"   'R' ‚Üí 'R1': {correcciones_r} registros\")\n",
    "    print(f\"   'U' ‚Üí 'U1': {correcciones_u} registros\")\n",
    "    print(f\"   Total correcciones: {total_correcciones}\")\n",
    "    \n",
    "    # Mostrar distribuci√≥n despu√©s de correcciones\n",
    "    print(f\"\\nüìä Distribuci√≥n despu√©s de correcciones:\")\n",
    "    distribucion_corregida = registros_n19['COD_1_NOVEDAD_CORREGIDO'].value_counts()\n",
    "    for valor, count in distribucion_corregida.items():\n",
    "        print(f\"   {valor}: {count} registros\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 2: IDENTIFICAR Y MOVER VALORES INV√ÅLIDOS\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîç PASO 2: Identificando valores inv√°lidos\")\n",
    "    \n",
    "    # Identificar registros con valores inv√°lidos\n",
    "    mask_invalidos = ~registros_n19['COD_1_NOVEDAD_CORREGIDO'].isin(valores_validos_finales)\n",
    "    registros_invalidos = registros_n19[mask_invalidos].copy()\n",
    "    total_invalidos = len(registros_invalidos)\n",
    "    \n",
    "    print(f\"   Registros con valores v√°lidos: {total_n19_inicial - total_invalidos}\")\n",
    "    print(f\"   Registros con valores inv√°lidos: {total_invalidos}\")\n",
    "    \n",
    "    if total_invalidos > 0:\n",
    "        # Mostrar ejemplos de valores inv√°lidos\n",
    "        print(f\"\\nüìã EJEMPLOS DE VALORES INV√ÅLIDOS:\")\n",
    "        ejemplos_invalidos = registros_invalidos[[\n",
    "            'NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION',\n",
    "            'COD_1_NOVEDAD', 'COD_1_NOVEDAD_CORREGIDO'\n",
    "        ]].head(5)\n",
    "        print(ejemplos_invalidos.to_string(index=False))\n",
    "        \n",
    "        # Limpiar y mover a DF_No_Envio\n",
    "        registros_invalidos_clean = registros_invalidos.drop(columns=[\n",
    "            'COD_1_NOVEDAD_NORM', 'COD_1_NOVEDAD_CORREGIDO'\n",
    "        ])\n",
    "        registros_invalidos_clean['motivo'] = \"Valor no valido en la novedad\"\n",
    "        \n",
    "        # Concatenar con DF_No_Envio\n",
    "        df_no_envio = pd.concat([df_no_envio, registros_invalidos_clean], ignore_index=True)\n",
    "        \n",
    "        # ‚úÖ CORRECCI√ìN: Obtener los √≠ndices originales correctamente\n",
    "        indices_originales_invalidos = registros_n19[mask_invalidos].index\n",
    "        df = df.drop(indices_originales_invalidos).reset_index(drop=True)\n",
    "        \n",
    "        # Actualizar registros_n19 para la siguiente validaci√≥n\n",
    "        registros_n19 = registros_n19[~mask_invalidos].copy()\n",
    "        \n",
    "        print(f\"‚úÖ Movidos {total_invalidos} registros a DF_No_Envio por valores inv√°lidos\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Todos los registros tienen valores v√°lidos\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 3: APLICAR CORRECCIONES AL DATAFRAME PRINCIPAL\n",
    "    # =========================================================================\n",
    "    registros_n19_restantes = len(registros_n19)\n",
    "    \n",
    "    if registros_n19_restantes == 0:\n",
    "        print(f\"\\n‚ö†Ô∏è No quedan registros N19 para validar\")\n",
    "        return df, df_no_envio\n",
    "    \n",
    "    print(f\"\\nüîÑ PASO 3: Aplicando correcciones al DataFrame principal\")\n",
    "    print(f\"   Registros a actualizar: {registros_n19_restantes}\")\n",
    "    \n",
    "    # ‚úÖ CORRECCI√ìN: Aplicar correcciones usando los √≠ndices originales\n",
    "    for idx in registros_n19.index:\n",
    "        if idx in df.index and df.loc[idx, 'NOVEDAD'] == 'N19':\n",
    "            valor_corregido = registros_n19.loc[idx, 'COD_1_NOVEDAD_CORREGIDO']\n",
    "            if pd.notna(valor_corregido):\n",
    "                df.loc[idx, 'COD_1_NOVEDAD'] = valor_corregido\n",
    "    \n",
    "    print(f\"   ‚úÖ Correcciones aplicadas al DataFrame principal\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 4: TRAER ZONA ACTUAL DESDE MAESTRO_ADRES\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîç PASO 4: Obteniendo zona actual desde maestro_ADRES\")\n",
    "    \n",
    "    # Crear subset del maestro con zona actual\n",
    "    maestro_zona = maestro_adres[['ID_User', 'ZNS_ID']].drop_duplicates(subset=['ID_User'])\n",
    "    \n",
    "    print(f\"   üìä Registros √∫nicos en maestro_ADRES: {len(maestro_zona):,}\")\n",
    "    \n",
    "    # ‚úÖ CORRECCI√ìN: Recargar registros N19 desde el df actualizado\n",
    "    registros_n19_actualizado = df[df['NOVEDAD'] == 'N19'].copy()\n",
    "    \n",
    "    # Hacer merge para traer ZNS_ID del maestro\n",
    "    registros_n19_con_maestro = registros_n19_actualizado.merge(\n",
    "        maestro_zona,\n",
    "        on='ID_User',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Verificar cu√°ntos registros tienen zona en ADRES\n",
    "    registros_con_zona_adres = registros_n19_con_maestro['ZNS_ID'].notna().sum()\n",
    "    registros_sin_zona_adres = registros_n19_con_maestro['ZNS_ID'].isna().sum()\n",
    "    \n",
    "    print(f\"   ‚úÖ Registros con zona en ADRES: {registros_con_zona_adres}\")\n",
    "    print(f\"   ‚ö†Ô∏è Registros sin zona en ADRES: {registros_sin_zona_adres}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 5: IDENTIFICAR REGISTROS SIN CAMBIOS\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîç PASO 5: Identificando registros sin cambios de zona\")\n",
    "    \n",
    "    # Normalizar valores para comparaci√≥n\n",
    "    registros_n19_con_maestro['COD_1_NOVEDAD_NORM'] = registros_n19_con_maestro['COD_1_NOVEDAD'].astype(str).str.strip().str.upper()\n",
    "    registros_n19_con_maestro['ZNS_ID_NORM'] = registros_n19_con_maestro['ZNS_ID'].astype(str).str.strip().str.upper()\n",
    "    \n",
    "    # Crear m√°scara para registros sin cambios\n",
    "    mask_sin_cambios = (\n",
    "        (registros_n19_con_maestro['COD_1_NOVEDAD_NORM'] == registros_n19_con_maestro['ZNS_ID_NORM']) &\n",
    "        registros_n19_con_maestro['ZNS_ID'].notna()  # Solo comparar si existe zona en ADRES\n",
    "    )\n",
    "    \n",
    "    registros_sin_cambios = registros_n19_con_maestro[mask_sin_cambios].copy()\n",
    "    total_sin_cambios = len(registros_sin_cambios)\n",
    "    \n",
    "    print(f\"   Registros con misma zona en ADRES y a reportar: {total_sin_cambios}\")\n",
    "    print(f\"   Registros con cambios v√°lidos: {len(registros_n19_con_maestro) - total_sin_cambios}\")\n",
    "    \n",
    "    if total_sin_cambios > 0:\n",
    "        # Mostrar ejemplos\n",
    "        print(f\"\\nüìã EJEMPLOS DE REGISTROS SIN CAMBIOS:\")\n",
    "        ejemplos_sin_cambios = registros_sin_cambios[[\n",
    "            'NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION',\n",
    "            'COD_1_NOVEDAD_NORM', 'ZNS_ID_NORM'\n",
    "        ]].head(5)\n",
    "        print(ejemplos_sin_cambios.to_string(index=False))\n",
    "        \n",
    "        # Limpiar y mover a DF_No_Envio\n",
    "        registros_sin_cambios_clean = registros_sin_cambios.drop(columns=[\n",
    "            'COD_1_NOVEDAD_NORM', 'ZNS_ID_NORM', 'ZNS_ID'\n",
    "        ])\n",
    "        registros_sin_cambios_clean['motivo'] = \"Afiliado sin cambios a reportar\"\n",
    "        \n",
    "        # Concatenar con DF_No_Envio\n",
    "        df_no_envio = pd.concat([df_no_envio, registros_sin_cambios_clean], ignore_index=True)\n",
    "        \n",
    "        # ‚úÖ CORRECCI√ìN: Usar ID_User para identificar registros a eliminar\n",
    "        ids_a_eliminar = registros_sin_cambios['ID_User'].unique()\n",
    "        \n",
    "        # Crear m√°scara en el df original usando ID_User\n",
    "        mask_eliminar_df = (df['NOVEDAD'] == 'N19') & (df['ID_User'].isin(ids_a_eliminar))\n",
    "        \n",
    "        # Eliminar registros\n",
    "        df = df[~mask_eliminar_df].reset_index(drop=True)\n",
    "        \n",
    "        print(f\"‚úÖ Movidos {total_sin_cambios} registros a DF_No_Envio\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Todos los registros N19 son cambios v√°lidos para reportar\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 6: AN√ÅLISIS DE REGISTROS SIN ZONA EN ADRES\n",
    "    # =========================================================================\n",
    "    if registros_sin_zona_adres > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è REGISTROS SIN ZONA EN MAESTRO_ADRES:\")\n",
    "        registros_sin_match = registros_n19_con_maestro[registros_n19_con_maestro['ZNS_ID'].isna()]\n",
    "        print(f\"   Total: {registros_sin_zona_adres}\")\n",
    "        print(f\"   üìã Ejemplos de registros sin match:\")\n",
    "        ejemplos_sin_match = registros_sin_match[[\n",
    "            'NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION',\n",
    "            'COD_1_NOVEDAD', 'ID_User'\n",
    "        ]].head(5)\n",
    "        print(ejemplos_sin_match.to_string(index=False))\n",
    "        print(f\"   ‚ÑπÔ∏è Estos registros se mantendr√°n en df_NS (asumiendo que son cambios v√°lidos)\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 7: RESUMEN FINAL\n",
    "    # =========================================================================\n",
    "    registros_n19_final = len(df[df['NOVEDAD'] == 'N19'])\n",
    "    total_movidos = total_invalidos + total_sin_cambios\n",
    "    \n",
    "    print(f\"\\nüìà RESUMEN FINAL:\")\n",
    "    print(f\"   Registros N19 iniciales: {total_n19_inicial}\")\n",
    "    print(f\"   Correcciones de formato aplicadas: {total_correcciones}\")\n",
    "    print(f\"   Registros movidos por valores inv√°lidos: {total_invalidos}\")\n",
    "    print(f\"   Registros movidos por sin cambios: {total_sin_cambios}\")\n",
    "    print(f\"   Total movidos: {total_movidos}\")\n",
    "    print(f\"   Registros N19 restantes (v√°lidos): {registros_n19_final}\")\n",
    "    print(f\"   Total en DF_No_Envio actual: {len(df_no_envio)}\")\n",
    "    \n",
    "    # Mostrar ejemplos de registros v√°lidos restantes si hay\n",
    "    if registros_n19_final > 0:\n",
    "        print(f\"\\nüìã EJEMPLOS DE REGISTROS N19 V√ÅLIDOS RESTANTES:\")\n",
    "        ejemplos_validos = df[df['NOVEDAD'] == 'N19'][[\n",
    "            'NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION',\n",
    "            'COD_1_NOVEDAD'\n",
    "        ]].head(5)\n",
    "        print(ejemplos_validos.to_string(index=False))\n",
    "        \n",
    "        # Mostrar distribuci√≥n de zonas a reportar en registros v√°lidos\n",
    "        print(f\"\\nüìä Distribuci√≥n de zona a reportar en registros v√°lidos:\")\n",
    "        distribucion_validos = df[df['NOVEDAD'] == 'N19']['COD_1_NOVEDAD'].value_counts()\n",
    "        for zona, count in distribucion_validos.items():\n",
    "            print(f\"   {zona}: {count} registros\")\n",
    "    \n",
    "    return df, df_no_envio\n",
    "\n",
    "# Aplicar validaci√≥n N19\n",
    "df_NS, DF_No_Envio = validar_novedades_N19(df_NS, DF_No_Envio, maestro_ADRES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "### 5.9.1. N19 Masiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_actualizaciones_masivas_N19(df_ns, maestro_adres, fecha_reporte):\n",
    "    \"\"\"\n",
    "    Aplica actualizaciones masivas N19 (cambio de zona) para afiliados activos.\n",
    "    \n",
    "    Proceso:\n",
    "    1. Identificar afiliados activos (TPS_EST_AFL_ID = 'AC') en maestro_ADRES\n",
    "    2. Filtrar por zonas R o U\n",
    "    3. Convertir zonas: R ‚Üí R1, U ‚Üí U1\n",
    "    4. Construir novedades N19 con la nueva zona\n",
    "    \n",
    "    Args:\n",
    "        df_ns: DataFrame de novedades\n",
    "        maestro_adres: DataFrame maestro ADRES\n",
    "        fecha_reporte: fecha del reporte (datetime)\n",
    "    \n",
    "    Returns:\n",
    "        df_ns actualizado con las nuevas novedades N19\n",
    "    \"\"\"\n",
    "    print(\"üîç INICIANDO APLICACI√ìN DE ACTUALIZACIONES MASIVAS N19\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Convertir fecha_reporte a formato DD/MM/YYYY\n",
    "    fecha_novedad_str = fecha_reporte.strftime('%d/%m/%Y')\n",
    "    print(f\"üìÖ Fecha de novedad: {fecha_novedad_str}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 1: FILTRAR AFILIADOS ACTIVOS CON ZONAS R o U\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîç PASO 1: Identificando afiliados activos con zonas R o U\")\n",
    "    \n",
    "    mask_activos_zona_ru = (\n",
    "        (maestro_adres['ENT_ID'] == 'EPS025') &\n",
    "        (maestro_adres['TPS_EST_AFL_ID'] == 'AC') &\n",
    "        (maestro_adres['ZNS_ID'].isin(['R', 'U']))\n",
    "    )\n",
    "    \n",
    "    registros_zona_ru = maestro_adres[mask_activos_zona_ru].copy().reset_index(drop=True)\n",
    "    total_zona_ru = len(registros_zona_ru)\n",
    "    \n",
    "    print(f\"   üìä Registros activos con zona R o U encontrados: {total_zona_ru}\")\n",
    "    \n",
    "    if total_zona_ru == 0:\n",
    "        print(f\"\\n‚ö†Ô∏è No se encontraron registros para aplicar actualizaciones masivas N19\")\n",
    "        return df_ns\n",
    "    \n",
    "    # Mostrar distribuci√≥n de zonas\n",
    "    print(f\"\\nüìä Distribuci√≥n de zonas a actualizar:\")\n",
    "    distribucion_zonas = registros_zona_ru['ZNS_ID'].value_counts()\n",
    "    for zona, count in distribucion_zonas.items():\n",
    "        print(f\"   Zona {zona}: {count} registros\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 2: CONVERTIR ZONAS R ‚Üí R1, U ‚Üí U1\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîß PASO 2: Convirtiendo zonas al formato correcto\")\n",
    "    \n",
    "    def convertir_zona(zona):\n",
    "        \"\"\"Convierte R ‚Üí R1, U ‚Üí U1\"\"\"\n",
    "        if pd.isna(zona) or str(zona).strip() == '':\n",
    "            return None\n",
    "        \n",
    "        zona_norm = str(zona).strip().upper()\n",
    "        \n",
    "        if zona_norm == 'R':\n",
    "            return 'R1'\n",
    "        elif zona_norm == 'U':\n",
    "            return 'U1'\n",
    "        else:\n",
    "            return zona_norm  # Por si ya tiene el formato correcto\n",
    "    \n",
    "    # Aplicar conversi√≥n\n",
    "    registros_zona_ru['COD_1_NOVEDAD_CONVERTIDO'] = registros_zona_ru['ZNS_ID'].apply(convertir_zona)\n",
    "    \n",
    "    # Estad√≠sticas de conversi√≥n\n",
    "    conversiones_r = (registros_zona_ru['ZNS_ID'] == 'R').sum()\n",
    "    conversiones_u = (registros_zona_ru['ZNS_ID'] == 'U').sum()\n",
    "    \n",
    "    print(f\"   ‚úÖ Conversiones aplicadas:\")\n",
    "    print(f\"     R ‚Üí R1: {conversiones_r} registros\")\n",
    "    print(f\"     U ‚Üí U1: {conversiones_u} registros\")\n",
    "    \n",
    "    # Verificar que todas las conversiones son v√°lidas\n",
    "    zonas_convertidas_validas = registros_zona_ru['COD_1_NOVEDAD_CONVERTIDO'].isin(['R1', 'U1']).sum()\n",
    "    print(f\"   üìä Zonas convertidas v√°lidas: {zonas_convertidas_validas}/{total_zona_ru}\")\n",
    "    \n",
    "    if zonas_convertidas_validas < total_zona_ru:\n",
    "        print(f\"   ‚ö†Ô∏è Algunas zonas no se convirtieron correctamente\")\n",
    "        zonas_invalidas = registros_zona_ru[~registros_zona_ru['COD_1_NOVEDAD_CONVERTIDO'].isin(['R1', 'U1'])]['ZNS_ID'].unique()\n",
    "        print(f\"      Zonas problem√°ticas: {zonas_invalidas}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 3: CONSTRUIR NOVEDADES N19\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîß PASO 3: CONSTRUYENDO NOVEDADES N19\")\n",
    "    \n",
    "    # Verificar columnas necesarias\n",
    "    columnas_requeridas = [\n",
    "        'ENT_ID', 'TPS_IDN_ID', 'HST_IDN_NUMERO_IDENTIFICACION',\n",
    "        'AFL_PRIMER_APELLIDO', 'AFL_SEGUNDO_APELLIDO', \n",
    "        'AFL_PRIMER_NOMBRE', 'AFL_SEGUNDO_NOMBRE',\n",
    "        'AFL_FECHA_NACIMIENTO', 'DPR_ID', 'MNC_ID', 'TPS_EST_AFL_ID', 'ZNS_ID'\n",
    "    ]\n",
    "    \n",
    "    columnas_faltantes = [col for col in columnas_requeridas if col not in registros_zona_ru.columns]\n",
    "    if columnas_faltantes:\n",
    "        print(f\"‚ùå Columnas faltantes en registros_zona_ru: {columnas_faltantes}\")\n",
    "        return df_ns\n",
    "    \n",
    "    try:\n",
    "        # Mapear columnas de maestro_ADRES a df_NS\n",
    "        nuevas_novedades = pd.DataFrame({\n",
    "            'ENT_ID': registros_zona_ru['ENT_ID'],\n",
    "            'TPS_IDN_ID': registros_zona_ru['TPS_IDN_ID'],\n",
    "            'HST_IDN_NUMERO_IDENTIFICACION': registros_zona_ru['HST_IDN_NUMERO_IDENTIFICACION'],\n",
    "            'AFL_PRIMER_APELLIDO': registros_zona_ru['AFL_PRIMER_APELLIDO'],\n",
    "            'AFL_SEGUNDO_APELLIDO': registros_zona_ru['AFL_SEGUNDO_APELLIDO'],\n",
    "            'AFL_PRIMER_NOMBRE': registros_zona_ru['AFL_PRIMER_NOMBRE'],\n",
    "            'AFL_SEGUNDO_NOMBRE': registros_zona_ru['AFL_SEGUNDO_NOMBRE'],\n",
    "            'AFL_FECHA_NACIMIENTO': registros_zona_ru['AFL_FECHA_NACIMIENTO'],\n",
    "            'DPR_ID': registros_zona_ru['DPR_ID'],\n",
    "            'MNS_ID': registros_zona_ru['MNC_ID'],  # Nota: MNC_ID -> MNS_ID\n",
    "            'NOVEDAD': 'N19',\n",
    "            'FECHA_NOVEDAD': fecha_novedad_str,\n",
    "            'COD_1_NOVEDAD': registros_zona_ru['COD_1_NOVEDAD_CONVERTIDO'],  # Zona convertida (R1 o U1)\n",
    "            'ENT_ID_ADRES': registros_zona_ru['ENT_ID'],\n",
    "            'TPS_EST_AFL_ID_from_adres': registros_zona_ru['TPS_EST_AFL_ID'],\n",
    "            'Where': 'Novedad Masiva'\n",
    "        })\n",
    "        \n",
    "        # Crear ID_User e ID_Register\n",
    "        nuevas_novedades['ID_User'] = (\n",
    "            nuevas_novedades['TPS_IDN_ID'].astype(str) + \n",
    "            nuevas_novedades['HST_IDN_NUMERO_IDENTIFICACION'].astype(str)\n",
    "        )\n",
    "        \n",
    "        nuevas_novedades['ID_Register'] = (\n",
    "            nuevas_novedades['TPS_IDN_ID'].astype(str) + \n",
    "            nuevas_novedades['HST_IDN_NUMERO_IDENTIFICACION'].astype(str) + \n",
    "            nuevas_novedades['NOVEDAD'].astype(str)\n",
    "        )\n",
    "        \n",
    "        # Rellenar columnas faltantes con valores vac√≠os/None\n",
    "        columnas_faltantes_df = [col for col in df_ns.columns if col not in nuevas_novedades.columns]\n",
    "        for col in columnas_faltantes_df:\n",
    "            nuevas_novedades[col] = None\n",
    "        \n",
    "        # Ordenar columnas en el mismo orden que df_NS\n",
    "        nuevas_novedades = nuevas_novedades[df_ns.columns]\n",
    "        \n",
    "        print(f\"   ‚úÖ Novedades N19 construidas: {len(nuevas_novedades)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al construir nuevas_novedades: {e}\")\n",
    "        return df_ns\n",
    "    \n",
    "    # Mostrar ejemplos\n",
    "    if len(nuevas_novedades) > 0:\n",
    "        print(f\"\\nüìã EJEMPLOS DE NOVEDADES N19 CREADAS:\")\n",
    "        ejemplos_columnas = ['TPS_IDN_ID', 'HST_IDN_NUMERO_IDENTIFICACION', \n",
    "                           'AFL_PRIMER_NOMBRE', 'AFL_PRIMER_APELLIDO',\n",
    "                           'NOVEDAD', 'COD_1_NOVEDAD', 'FECHA_NOVEDAD', 'Where']\n",
    "        ejemplos_columnas_disponibles = [col for col in ejemplos_columnas if col in nuevas_novedades.columns]\n",
    "        ejemplos = nuevas_novedades[ejemplos_columnas_disponibles].head(10)\n",
    "        print(ejemplos.to_string(index=False))\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 4: AGREGAR AL DATAFRAME PRINCIPAL\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîÑ PASO 4: AGREGANDO NOVEDADES A df_NS\")\n",
    "    \n",
    "    try:\n",
    "        registros_antes = len(df_ns)\n",
    "        df_ns = pd.concat([df_ns, nuevas_novedades], ignore_index=True)\n",
    "        registros_despues = len(df_ns)\n",
    "        \n",
    "        print(f\"   üìä Registros antes: {registros_antes:,}\")\n",
    "        print(f\"   üìä Registros despu√©s: {registros_despues:,}\")\n",
    "        print(f\"   üìä Registros agregados: {registros_despues - registros_antes:,}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al agregar novedades a df_NS: {e}\")\n",
    "        return df_ns\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 5: ESTAD√çSTICAS FINALES\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüìà ESTAD√çSTICAS DE NOVEDADES N19 AGREGADAS:\")\n",
    "    \n",
    "    try:\n",
    "        if 'Where' in df_ns.columns:\n",
    "            novedades_n19_masivas = df_ns[\n",
    "                (df_ns['Where'] == 'Novedad Masiva') & \n",
    "                (df_ns['NOVEDAD'] == 'N19')\n",
    "            ]\n",
    "            \n",
    "            if len(novedades_n19_masivas) > 0:\n",
    "                print(f\"   üìä Total novedades N19 masivas: {len(novedades_n19_masivas):,}\")\n",
    "                \n",
    "                # Distribuci√≥n por zona convertida\n",
    "                print(f\"   üìä Por zona convertida:\")\n",
    "                distribucion_zona_final = novedades_n19_masivas['COD_1_NOVEDAD'].value_counts()\n",
    "                for zona, count in distribucion_zona_final.items():\n",
    "                    print(f\"     {zona}: {count:,} registros\")\n",
    "                \n",
    "                # Distribuci√≥n por tipo de documento\n",
    "                print(f\"\\n   üìä Por tipo de documento:\")\n",
    "                distribucion_tps = novedades_n19_masivas['TPS_IDN_ID'].value_counts()\n",
    "                for tipo_doc, count in distribucion_tps.items():\n",
    "                    print(f\"     {tipo_doc}: {count:,} registros\")\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è No se encontraron novedades N19 masivas en el DataFrame final\")\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è Columna 'Where' no encontrada en df_NS\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error al generar estad√≠sticas finales: {e}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 6: VERIFICACI√ìN DE CALIDAD\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîç VERIFICACI√ìN DE CALIDAD:\")\n",
    "    \n",
    "    try:\n",
    "        # Verificar que todas las zonas en N19 masivas son v√°lidas\n",
    "        novedades_n19_masivas = df_ns[\n",
    "            (df_ns['Where'] == 'Novedad Masiva') & \n",
    "            (df_ns['NOVEDAD'] == 'N19')\n",
    "        ]\n",
    "        \n",
    "        if len(novedades_n19_masivas) > 0:\n",
    "            zonas_validas = novedades_n19_masivas['COD_1_NOVEDAD'].isin(['R1', 'U1']).sum()\n",
    "            total_n19_masivas = len(novedades_n19_masivas)\n",
    "            \n",
    "            print(f\"   ‚úÖ Zonas v√°lidas (R1/U1): {zonas_validas}/{total_n19_masivas}\")\n",
    "            \n",
    "            if zonas_validas < total_n19_masivas:\n",
    "                print(f\"   ‚ö†Ô∏è Hay {total_n19_masivas - zonas_validas} novedades con zonas no v√°lidas\")\n",
    "                zonas_invalidas_final = novedades_n19_masivas[\n",
    "                    ~novedades_n19_masivas['COD_1_NOVEDAD'].isin(['R1', 'U1'])\n",
    "                ]['COD_1_NOVEDAD'].unique()\n",
    "                print(f\"      Zonas inv√°lidas encontradas: {zonas_invalidas_final}\")\n",
    "            \n",
    "            # Verificar que todos tienen estado AC\n",
    "            estados_activos = novedades_n19_masivas['TPS_EST_AFL_ID_from_adres'].eq('AC').sum()\n",
    "            print(f\"   ‚úÖ Registros con estado AC: {estados_activos}/{total_n19_masivas}\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è No hay novedades N19 masivas para verificar\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error en verificaci√≥n de calidad: {e}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ ACTUALIZACIONES MASIVAS N19 APLICADAS EXITOSAMENTE\")\n",
    "    \n",
    "    return df_ns\n",
    "\n",
    "# Aplicar actualizaciones masivas N19\n",
    "df_NS = aplicar_actualizaciones_masivas_N19(df_NS, maestro_ADRES, fecha_reporte)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "## 5.10. N21 Actualizaci√≥n condiciones Sisb√©n, etnia y comunidad ind√≠gena o resguardo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validar_novedades_N21(df, df_no_envio):\n",
    "    \"\"\"\n",
    "    Valida registros con NOVEDAD = 'N21' (Actualizaci√≥n condiciones Sisb√©n, etnia y comunidad ind√≠gena o resguardo).\n",
    "    \n",
    "    Proceso:\n",
    "    1. Si COD_3_NOVEDAD = 5:\n",
    "       - COD_2_NOVEDAD debe tener formato v√°lido (A01-C99)\n",
    "       - COD_1_NOVEDAD debe ser 2 (corregir si es diferente)\n",
    "       - COD_4_NOVEDAD: 1 para A/B, 2 para C\n",
    "    2. Si COD_3_NOVEDAD ‚â† 5:\n",
    "       - COD_2_NOVEDAD debe estar vac√≠o\n",
    "       - COD_1_NOVEDAD debe ser 3\n",
    "       - COD_4_NOVEDAD debe ser N\n",
    "    3. COD_5_NOVEDAD:\n",
    "       - Por defecto \"06\"\n",
    "       - Si COD_3_NOVEDAD = 17: \"01\" y COD_6_NOVEDAD = \"999\"\n",
    "    \"\"\"\n",
    "    print(\"üîç INICIANDO VALIDACI√ìN DE NOVEDADES N21\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Filtrar solo registros N21\n",
    "    mask_n21 = df['NOVEDAD'] == 'N21'\n",
    "    registros_n21 = df[mask_n21].copy()\n",
    "    total_n21_inicial = len(registros_n21)\n",
    "    \n",
    "    print(f\"üìä Total de registros N21 iniciales: {total_n21_inicial}\")\n",
    "    \n",
    "    if total_n21_inicial == 0:\n",
    "        print(\"‚ö†Ô∏è No se encontraron registros N21\")\n",
    "        return df, df_no_envio\n",
    "    \n",
    "    # Normalizar COD_3_NOVEDAD para comparaciones\n",
    "    registros_n21['COD_3_NOVEDAD_NORM'] = registros_n21['COD_3_NOVEDAD'].astype(str).str.strip()\n",
    "    \n",
    "    # Mostrar distribuci√≥n inicial de COD_3_NOVEDAD\n",
    "    print(f\"\\nüìä Distribuci√≥n de COD_3_NOVEDAD:\")\n",
    "    distribucion_cod3 = registros_n21['COD_3_NOVEDAD_NORM'].value_counts()\n",
    "    for valor, count in distribucion_cod3.items():\n",
    "        print(f\"   {valor}: {count} registros\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # VALIDACI√ìN 1: REGISTROS CON COD_3_NOVEDAD = 5\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîç VALIDACI√ìN 1: Registros con COD_3_NOVEDAD = 5\")\n",
    "    \n",
    "    mask_cod3_es_5 = registros_n21['COD_3_NOVEDAD_NORM'] == '5'\n",
    "    registros_cod3_5 = registros_n21[mask_cod3_es_5].copy()\n",
    "    total_cod3_5 = len(registros_cod3_5)\n",
    "    \n",
    "    print(f\"   üìä Registros con COD_3_NOVEDAD = 5: {total_cod3_5}\")\n",
    "    \n",
    "    registros_invalidos_cod3_5 = 0\n",
    "    \n",
    "    if total_cod3_5 > 0:\n",
    "        # Validar formato de COD_2_NOVEDAD para registros con COD_3_NOVEDAD = 5\n",
    "        def validar_formato_cod2_sisben(valor):\n",
    "            \"\"\"Valida formato A01-C99 para c√≥digos Sisb√©n\"\"\"\n",
    "            if pd.isna(valor) or str(valor).strip() == '':\n",
    "                return False\n",
    "            \n",
    "            valor_str = str(valor).strip().upper()\n",
    "            \n",
    "            # Debe tener exactamente 3 caracteres\n",
    "            if len(valor_str) != 3:\n",
    "                return False\n",
    "            \n",
    "            # Primer car√°cter debe ser A, B o C\n",
    "            if valor_str[0] not in ['A', 'B', 'C']:\n",
    "                return False\n",
    "            \n",
    "            # Los siguientes 2 caracteres deben ser d√≠gitos\n",
    "            if not valor_str[1:].isdigit():\n",
    "                return False\n",
    "            \n",
    "            # El n√∫mero debe estar entre 01 y 99\n",
    "            numero = int(valor_str[1:])\n",
    "            if not (1 <= numero <= 99):\n",
    "                return False\n",
    "            \n",
    "            return True\n",
    "        \n",
    "        # Aplicar validaci√≥n\n",
    "        registros_cod3_5['COD_2_VALIDO'] = registros_cod3_5['COD_2_NOVEDAD'].apply(validar_formato_cod2_sisben)\n",
    "        invalidos_cod2 = (~registros_cod3_5['COD_2_VALIDO']).sum()\n",
    "        \n",
    "        print(f\"   üìã COD_2_NOVEDAD con formato v√°lido: {registros_cod3_5['COD_2_VALIDO'].sum()}\")\n",
    "        print(f\"   üìã COD_2_NOVEDAD con formato inv√°lido: {invalidos_cod2}\")\n",
    "        \n",
    "        if invalidos_cod2 > 0:\n",
    "            # Mostrar ejemplos de valores inv√°lidos\n",
    "            print(f\"\\n   üìã Ejemplos de COD_2_NOVEDAD inv√°lidos:\")\n",
    "            ejemplos_invalidos = registros_cod3_5[~registros_cod3_5['COD_2_VALIDO']][\n",
    "                ['NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION', 'COD_2_NOVEDAD', 'COD_3_NOVEDAD']\n",
    "            ].head(5)\n",
    "            print(ejemplos_invalidos.to_string(index=False))\n",
    "            \n",
    "            # Mover registros inv√°lidos a DF_No_Envio\n",
    "            registros_invalidos = registros_cod3_5[~registros_cod3_5['COD_2_VALIDO']].copy()\n",
    "            registros_invalidos_clean = registros_invalidos.drop(columns=['COD_3_NOVEDAD_NORM', 'COD_2_VALIDO'])\n",
    "            registros_invalidos_clean['motivo'] = \"Datos incompletos en la novedad\"\n",
    "            \n",
    "            df_no_envio = pd.concat([df_no_envio, registros_invalidos_clean], ignore_index=True)\n",
    "            \n",
    "            # Eliminar del DataFrame principal\n",
    "            indices_invalidos = registros_n21[mask_cod3_es_5][~registros_cod3_5['COD_2_VALIDO']].index\n",
    "            df = df.drop(indices_invalidos).reset_index(drop=True)\n",
    "            \n",
    "            # Actualizar registros_n21 para siguientes validaciones\n",
    "            registros_n21 = registros_n21.drop(indices_invalidos)\n",
    "            \n",
    "            registros_invalidos_cod3_5 = invalidos_cod2\n",
    "            print(f\"   ‚úÖ Movidos {invalidos_cod2} registros a DF_No_Envio por COD_2_NOVEDAD inv√°lido\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CORRECCI√ìN 1: APLICAR CORRECCIONES PARA COD_3_NOVEDAD = 5\n",
    "    # =========================================================================\n",
    "    registros_n21_actualizados = df[df['NOVEDAD'] == 'N21'].copy()\n",
    "    mask_cod3_es_5_actualizado = registros_n21_actualizados['COD_3_NOVEDAD'].astype(str).str.strip() == '5'\n",
    "    \n",
    "    correcciones_cod1 = 0\n",
    "    correcciones_cod4 = 0\n",
    "    \n",
    "    if mask_cod3_es_5_actualizado.any():\n",
    "        print(f\"\\nüîß APLICANDO CORRECCIONES PARA COD_3_NOVEDAD = 5\")\n",
    "        \n",
    "        # Corregir COD_1_NOVEDAD a \"2\"\n",
    "        indices_cod3_5 = registros_n21_actualizados[mask_cod3_es_5_actualizado].index\n",
    "        cod1_diferentes = df.loc[indices_cod3_5, 'COD_1_NOVEDAD'].astype(str).str.strip() != '2'\n",
    "        correcciones_cod1 = cod1_diferentes.sum()\n",
    "        \n",
    "        df.loc[indices_cod3_5, 'COD_1_NOVEDAD'] = '2'\n",
    "        \n",
    "        print(f\"   üìã COD_1_NOVEDAD corregidos a '2': {correcciones_cod1}\")\n",
    "        \n",
    "        # Corregir COD_4_NOVEDAD basado en COD_2_NOVEDAD\n",
    "        for idx in indices_cod3_5:\n",
    "            cod2_valor = str(df.loc[idx, 'COD_2_NOVEDAD']).strip().upper()\n",
    "            if len(cod2_valor) >= 1:\n",
    "                primera_letra = cod2_valor[0]\n",
    "                if primera_letra in ['A', 'B']:\n",
    "                    nuevo_cod4 = '1'\n",
    "                elif primera_letra == 'C':\n",
    "                    nuevo_cod4 = '2'\n",
    "                else:\n",
    "                    nuevo_cod4 = '1'  # Por defecto\n",
    "                \n",
    "                if str(df.loc[idx, 'COD_4_NOVEDAD']).strip() != nuevo_cod4:\n",
    "                    correcciones_cod4 += 1\n",
    "                \n",
    "                df.loc[idx, 'COD_4_NOVEDAD'] = nuevo_cod4\n",
    "        \n",
    "        print(f\"   üìã COD_4_NOVEDAD corregidos: {correcciones_cod4}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CORRECCI√ìN 2: APLICAR CORRECCIONES PARA COD_3_NOVEDAD ‚â† 5\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîß APLICANDO CORRECCIONES PARA COD_3_NOVEDAD ‚â† 5\")\n",
    "    \n",
    "    registros_n21_actualizados = df[df['NOVEDAD'] == 'N21'].copy()\n",
    "    mask_cod3_no_es_5 = registros_n21_actualizados['COD_3_NOVEDAD'].astype(str).str.strip() != '5'\n",
    "    \n",
    "    correcciones_cod2_vacio = 0\n",
    "    correcciones_cod1_a_3 = 0\n",
    "    correcciones_cod4_a_n = 0\n",
    "    \n",
    "    if mask_cod3_no_es_5.any():\n",
    "        indices_cod3_no_5 = registros_n21_actualizados[mask_cod3_no_es_5].index\n",
    "        \n",
    "        # Vaciar COD_2_NOVEDAD\n",
    "        cod2_no_vacios = df.loc[indices_cod3_no_5, 'COD_2_NOVEDAD'].notna() & (df.loc[indices_cod3_no_5, 'COD_2_NOVEDAD'].astype(str).str.strip() != '')\n",
    "        correcciones_cod2_vacio = cod2_no_vacios.sum()\n",
    "        df.loc[indices_cod3_no_5, 'COD_2_NOVEDAD'] = ''\n",
    "        \n",
    "        # Corregir COD_1_NOVEDAD a \"3\"\n",
    "        cod1_diferentes = df.loc[indices_cod3_no_5, 'COD_1_NOVEDAD'].astype(str).str.strip() != '3'\n",
    "        correcciones_cod1_a_3 = cod1_diferentes.sum()\n",
    "        df.loc[indices_cod3_no_5, 'COD_1_NOVEDAD'] = '3'\n",
    "        \n",
    "        # Corregir COD_4_NOVEDAD a \"N\"\n",
    "        cod4_diferentes = df.loc[indices_cod3_no_5, 'COD_4_NOVEDAD'].astype(str).str.strip().str.upper() != 'N'\n",
    "        correcciones_cod4_a_n = cod4_diferentes.sum()\n",
    "        df.loc[indices_cod3_no_5, 'COD_4_NOVEDAD'] = 'N'\n",
    "        \n",
    "        print(f\"   üìã COD_2_NOVEDAD vaciados: {correcciones_cod2_vacio}\")\n",
    "        print(f\"   üìã COD_1_NOVEDAD corregidos a '3': {correcciones_cod1_a_3}\")\n",
    "        print(f\"   üìã COD_4_NOVEDAD corregidos a 'N': {correcciones_cod4_a_n}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CORRECCI√ìN 3: APLICAR CORRECCIONES PARA COD_5_NOVEDAD Y COD_6_NOVEDAD\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîß APLICANDO CORRECCIONES PARA COD_5_NOVEDAD Y COD_6_NOVEDAD\")\n",
    "    \n",
    "    registros_n21_final = df[df['NOVEDAD'] == 'N21'].copy()\n",
    "    correcciones_cod5 = 0\n",
    "    correcciones_cod6 = 0\n",
    "    \n",
    "    for idx in registros_n21_final.index:\n",
    "        cod3_valor = str(df.loc[idx, 'COD_3_NOVEDAD']).strip()\n",
    "        \n",
    "        if cod3_valor == '17':\n",
    "            # COD_5_NOVEDAD = \"01\" y COD_6_NOVEDAD = \"999\"\n",
    "            if str(df.loc[idx, 'COD_5_NOVEDAD']).strip() != '01':\n",
    "                correcciones_cod5 += 1\n",
    "            if str(df.loc[idx, 'COD_6_NOVEDAD']).strip() != '999':\n",
    "                correcciones_cod6 += 1\n",
    "            \n",
    "            df.loc[idx, 'COD_5_NOVEDAD'] = '01'\n",
    "            df.loc[idx, 'COD_6_NOVEDAD'] = '999'\n",
    "        else:\n",
    "            # COD_5_NOVEDAD = \"06\"\n",
    "            if str(df.loc[idx, 'COD_5_NOVEDAD']).strip() != '06':\n",
    "                correcciones_cod5 += 1\n",
    "            \n",
    "            df.loc[idx, 'COD_5_NOVEDAD'] = '06'\n",
    "    \n",
    "    print(f\"   üìã COD_5_NOVEDAD corregidos: {correcciones_cod5}\")\n",
    "    print(f\"   üìã COD_6_NOVEDAD corregidos: {correcciones_cod6}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # RESUMEN FINAL\n",
    "    # =========================================================================\n",
    "    registros_n21_final = len(df[df['NOVEDAD'] == 'N21'])\n",
    "    total_correcciones = (correcciones_cod1 + correcciones_cod4 + correcciones_cod2_vacio + \n",
    "                         correcciones_cod1_a_3 + correcciones_cod4_a_n + correcciones_cod5 + correcciones_cod6)\n",
    "    \n",
    "    print(f\"\\nüìà RESUMEN FINAL:\")\n",
    "    print(f\"   Registros N21 iniciales: {total_n21_inicial}\")\n",
    "    print(f\"   Registros movidos (datos incompletos): {registros_invalidos_cod3_5}\")\n",
    "    print(f\"   Registros N21 restantes: {registros_n21_final}\")\n",
    "    print(f\"   Total de correcciones aplicadas: {total_correcciones}\")\n",
    "    print(f\"   Total en DF_No_Envio actual: {len(df_no_envio)}\")\n",
    "    \n",
    "    # Desglose de correcciones\n",
    "    print(f\"\\nüìã DESGLOSE DE CORRECCIONES:\")\n",
    "    print(f\"   COD_1_NOVEDAD ‚Üí '2' (COD_3=5): {correcciones_cod1}\")\n",
    "    print(f\"   COD_4_NOVEDAD seg√∫n COD_2 (COD_3=5): {correcciones_cod4}\")\n",
    "    print(f\"   COD_2_NOVEDAD vaciados (COD_3‚â†5): {correcciones_cod2_vacio}\")\n",
    "    print(f\"   COD_1_NOVEDAD ‚Üí '3' (COD_3‚â†5): {correcciones_cod1_a_3}\")\n",
    "    print(f\"   COD_4_NOVEDAD ‚Üí 'N' (COD_3‚â†5): {correcciones_cod4_a_n}\")\n",
    "    print(f\"   COD_5_NOVEDAD corregidos: {correcciones_cod5}\")\n",
    "    print(f\"   COD_6_NOVEDAD corregidos: {correcciones_cod6}\")\n",
    "    \n",
    "    # Mostrar ejemplos de registros finales si hay\n",
    "    if registros_n21_final > 0:\n",
    "        print(f\"\\nüìã EJEMPLOS DE REGISTROS N21 PROCESADOS:\")\n",
    "        ejemplos_finales = df[df['NOVEDAD'] == 'N21'][[\n",
    "            'NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION',\n",
    "            'COD_1_NOVEDAD', 'COD_2_NOVEDAD', 'COD_3_NOVEDAD', \n",
    "            'COD_4_NOVEDAD', 'COD_5_NOVEDAD', 'COD_6_NOVEDAD'\n",
    "        ]].head(10)\n",
    "        print(ejemplos_finales.to_string(index=False))\n",
    "        \n",
    "        # Mostrar distribuci√≥n final de COD_3_NOVEDAD\n",
    "        print(f\"\\nüìä Distribuci√≥n final de COD_3_NOVEDAD:\")\n",
    "        distribucion_final = df[df['NOVEDAD'] == 'N21']['COD_3_NOVEDAD'].value_counts()\n",
    "        for valor, count in distribucion_final.items():\n",
    "            print(f\"   {valor}: {count} registros\")\n",
    "    \n",
    "    return df, df_no_envio\n",
    "\n",
    "# Aplicar validaci√≥n N21\n",
    "df_NS, DF_No_Envio = validar_novedades_N21(df_NS, DF_No_Envio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "### 5.10.1. N21 veracidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validar_veracidad_N21(df_ns, df_no_envio, maestro_adres):\n",
    "    \"\"\"\n",
    "    Valida la veracidad de las novedades N21 verificando:\n",
    "    1. Para COD_3_NOVEDAD = 5 (Sisb√©n):\n",
    "       - Que Gr_Poblacional_Actual sea 5 (no listado censal ni \"No sisben\")\n",
    "       - Que SUB_SISBEN_IV sea diferente a COD_2_NOVEDAD (hay cambio)\n",
    "       - Que N_Sisben_Actual sea igual a COD_2_NOVEDAD (coincide con tablas de referencia)\n",
    "    \n",
    "    2. Para COD_3_NOVEDAD ‚â† 5 (otros grupos poblacionales):\n",
    "       - Que CNT_AFL_TPS_GRP_PBL_ID sea diferente a COD_3_NOVEDAD (hay cambio)\n",
    "       - Que Gr_Poblacional_Actual sea igual a COD_3_NOVEDAD (coincide con tablas de referencia)\n",
    "    \n",
    "    Args:\n",
    "        df_ns: DataFrame con novedades\n",
    "        df_no_envio: DataFrame con registros rechazados\n",
    "        maestro_adres: DataFrame maestro ADRES\n",
    "    \n",
    "    Returns:\n",
    "        df_ns actualizado, df_no_envio actualizado\n",
    "    \"\"\"\n",
    "    print(\"üîç INICIANDO VALIDACI√ìN DE VERACIDAD N21\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Filtrar registros N21\n",
    "    mask_n21 = df_ns['NOVEDAD'] == 'N21'\n",
    "    registros_n21 = df_ns[mask_n21].copy()\n",
    "    total_n21_inicial = len(registros_n21)\n",
    "    \n",
    "    print(f\"üìä Total de registros N21 a validar: {total_n21_inicial}\")\n",
    "    \n",
    "    if total_n21_inicial == 0:\n",
    "        print(\"‚ö†Ô∏è No hay registros N21 para validar\")\n",
    "        return df_ns, df_no_envio\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 1: TRAER DATOS DEL MAESTRO ADRES\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîç PASO 1: Trayendo datos de veracidad desde maestro_ADRES\")\n",
    "    \n",
    "    maestro_veracidad = maestro_adres[[\n",
    "        'ID_User', 'Gr_Poblacional_Actual', 'N_Sisben_Actual', \n",
    "        'SUB_SISBEN_IV', 'CNT_AFL_TPS_GRP_PBL_ID'\n",
    "    ]].drop_duplicates(subset=['ID_User'])\n",
    "    \n",
    "    print(f\"   üìä Registros √∫nicos en maestro: {len(maestro_veracidad):,}\")\n",
    "    \n",
    "    # Hacer merge\n",
    "    registros_n21_con_adres = registros_n21.merge(\n",
    "        maestro_veracidad,\n",
    "        on='ID_User',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Verificar match\n",
    "    registros_con_match = registros_n21_con_adres['Gr_Poblacional_Actual'].notna().sum()\n",
    "    registros_sin_match = registros_n21_con_adres['Gr_Poblacional_Actual'].isna().sum()\n",
    "    \n",
    "    print(f\"   ‚úÖ Registros con match en maestro: {registros_con_match}\")\n",
    "    print(f\"   ‚ö†Ô∏è Registros sin match en maestro: {registros_sin_match}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 2: VALIDAR REGISTROS CON COD_3_NOVEDAD = 5 (SISB√âN)\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîç PASO 2: Validando registros Sisb√©n (COD_3_NOVEDAD = 5)\")\n",
    "    \n",
    "    mask_sisben = registros_n21_con_adres['COD_3_NOVEDAD'].astype(str).str.strip() == '5'\n",
    "    registros_sisben = registros_n21_con_adres[mask_sisben].copy()\n",
    "    total_sisben = len(registros_sisben)\n",
    "    \n",
    "    print(f\"   üìä Total registros Sisb√©n: {total_sisben}\")\n",
    "    \n",
    "    registros_rechazados_sisben = []\n",
    "    motivos_rechazo_sisben = {}\n",
    "    \n",
    "    if total_sisben > 0:\n",
    "        # VALIDACI√ìN 2.1: Verificar Gr_Poblacional_Actual\n",
    "        print(f\"\\n   üîç VALIDACI√ìN 2.1: Grupo poblacional en ADRES\")\n",
    "        \n",
    "        # Normalizar valores\n",
    "        registros_sisben['Gr_Poblacional_Actual_NORM'] = registros_sisben['Gr_Poblacional_Actual'].astype(str).str.strip()\n",
    "        \n",
    "        # Listado censal (diferente de 5 y diferente de \"No sisben\")\n",
    "        mask_listado_censal = (\n",
    "            (registros_sisben['Gr_Poblacional_Actual_NORM'] != '5') &\n",
    "            (registros_sisben['Gr_Poblacional_Actual_NORM'] != 'No sisben') &\n",
    "            registros_sisben['Gr_Poblacional_Actual'].notna()\n",
    "        )\n",
    "        \n",
    "        rechazados_listado = registros_sisben[mask_listado_censal].copy()\n",
    "        total_listado = len(rechazados_listado)\n",
    "        \n",
    "        # No sisben\n",
    "        mask_no_sisben = registros_sisben['Gr_Poblacional_Actual_NORM'] == 'No sisben'\n",
    "        rechazados_no_sisben = registros_sisben[mask_no_sisben].copy()\n",
    "        total_no_sisben = len(rechazados_no_sisben)\n",
    "        \n",
    "        print(f\"     Listado censal (Gr_Poblacional ‚â† 5): {total_listado}\")\n",
    "        print(f\"     No sisben en ADRES: {total_no_sisben}\")\n",
    "        print(f\"     V√°lidos (Gr_Poblacional = 5): {total_sisben - total_listado - total_no_sisben}\")\n",
    "        \n",
    "        # Agregar rechazados de listado censal\n",
    "        if total_listado > 0:\n",
    "            rechazados_listado['motivo'] = 'Novedad no efectiva, afiliado listado censal'\n",
    "            registros_rechazados_sisben.append(rechazados_listado)\n",
    "            motivos_rechazo_sisben['Listado censal'] = total_listado\n",
    "            \n",
    "            print(f\"\\n     üìã Ejemplos de listados censales:\")\n",
    "            ejemplos = rechazados_listado[[\n",
    "                'NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION',\n",
    "                'COD_2_NOVEDAD', 'Gr_Poblacional_Actual_NORM'\n",
    "            ]].head(5)\n",
    "            print(ejemplos.to_string(index=False))\n",
    "        \n",
    "        # Agregar rechazados sin sisben\n",
    "        if total_no_sisben > 0:\n",
    "            rechazados_no_sisben['motivo'] = 'Sisben no actualizado en tablas de referencia ADRES'\n",
    "            registros_rechazados_sisben.append(rechazados_no_sisben)\n",
    "            motivos_rechazo_sisben['No sisben en ADRES'] = total_no_sisben\n",
    "            \n",
    "            print(f\"\\n     üìã Ejemplos sin sisben en ADRES:\")\n",
    "            ejemplos = rechazados_no_sisben[[\n",
    "                'NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION',\n",
    "                'COD_2_NOVEDAD', 'Gr_Poblacional_Actual_NORM'\n",
    "            ]].head(5)\n",
    "            print(ejemplos.to_string(index=False))\n",
    "        \n",
    "        # VALIDACI√ìN 2.2: Para los que tienen Gr_Poblacional = 5, validar cambios\n",
    "        print(f\"\\n   üîç VALIDACI√ìN 2.2: Validando cambios en grupo Sisb√©n\")\n",
    "        \n",
    "        mask_gr_5 = registros_sisben['Gr_Poblacional_Actual_NORM'] == '5'\n",
    "        registros_sisben_validos_gr = registros_sisben[mask_gr_5].copy()\n",
    "        total_sisben_gr5 = len(registros_sisben_validos_gr)\n",
    "        \n",
    "        print(f\"     Registros con Gr_Poblacional = 5: {total_sisben_gr5}\")\n",
    "        \n",
    "        if total_sisben_gr5 > 0:\n",
    "            # Normalizar valores para comparaci√≥n\n",
    "            registros_sisben_validos_gr['COD_2_NOVEDAD_NORM'] = registros_sisben_validos_gr['COD_2_NOVEDAD'].astype(str).str.strip().str.upper()\n",
    "            registros_sisben_validos_gr['SUB_SISBEN_IV_NORM'] = registros_sisben_validos_gr['SUB_SISBEN_IV'].astype(str).str.strip().str.upper()\n",
    "            registros_sisben_validos_gr['N_Sisben_Actual_NORM'] = registros_sisben_validos_gr['N_Sisben_Actual'].astype(str).str.strip().str.upper()\n",
    "            \n",
    "            # Sin cambios: COD_2_NOVEDAD == SUB_SISBEN_IV\n",
    "            mask_sin_cambios = registros_sisben_validos_gr['COD_2_NOVEDAD_NORM'] == registros_sisben_validos_gr['SUB_SISBEN_IV_NORM']\n",
    "            rechazados_sin_cambios = registros_sisben_validos_gr[mask_sin_cambios].copy()\n",
    "            total_sin_cambios = len(rechazados_sin_cambios)\n",
    "            \n",
    "            # Diferente a tablas: COD_2_NOVEDAD != N_Sisben_Actual\n",
    "            mask_dif_tablas = (\n",
    "                (registros_sisben_validos_gr['COD_2_NOVEDAD_NORM'] != registros_sisben_validos_gr['N_Sisben_Actual_NORM']) &\n",
    "                (~mask_sin_cambios)  # Excluir los ya rechazados por sin cambios\n",
    "            )\n",
    "            rechazados_dif_tablas = registros_sisben_validos_gr[mask_dif_tablas].copy()\n",
    "            total_dif_tablas = len(rechazados_dif_tablas)\n",
    "            \n",
    "            print(f\"     Sin cambios (COD_2 = SUB_SISBEN_IV): {total_sin_cambios}\")\n",
    "            print(f\"     Diferente a tablas (COD_2 ‚â† N_Sisben_Actual): {total_dif_tablas}\")\n",
    "            print(f\"     V√°lidos: {total_sisben_gr5 - total_sin_cambios - total_dif_tablas}\")\n",
    "            \n",
    "            # Agregar rechazados sin cambios\n",
    "            if total_sin_cambios > 0:\n",
    "                rechazados_sin_cambios['motivo'] = 'Afiliado sin cambios a reportar'\n",
    "                registros_rechazados_sisben.append(rechazados_sin_cambios)\n",
    "                motivos_rechazo_sisben['Sin cambios Sisb√©n'] = total_sin_cambios\n",
    "                \n",
    "                print(f\"\\n     üìã Ejemplos sin cambios:\")\n",
    "                ejemplos = rechazados_sin_cambios[[\n",
    "                    'NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION',\n",
    "                    'COD_2_NOVEDAD_NORM', 'SUB_SISBEN_IV_NORM'\n",
    "                ]].head(5)\n",
    "                print(ejemplos.to_string(index=False))\n",
    "            \n",
    "            # Agregar rechazados diferente a tablas\n",
    "            if total_dif_tablas > 0:\n",
    "                rechazados_dif_tablas['motivo'] = 'Diferente a tablas de referencia ADRES'\n",
    "                registros_rechazados_sisben.append(rechazados_dif_tablas)\n",
    "                motivos_rechazo_sisben['Diferente a tablas Sisb√©n'] = total_dif_tablas\n",
    "                \n",
    "                print(f\"\\n     üìã Ejemplos diferentes a tablas:\")\n",
    "                ejemplos = rechazados_dif_tablas[[\n",
    "                    'NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION',\n",
    "                    'COD_2_NOVEDAD_NORM', 'N_Sisben_Actual_NORM'\n",
    "                ]].head(5)\n",
    "                print(ejemplos.to_string(index=False))\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 3: VALIDAR REGISTROS CON COD_3_NOVEDAD ‚â† 5 (OTROS GRUPOS)\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîç PASO 3: Validando otros grupos poblacionales (COD_3_NOVEDAD ‚â† 5)\")\n",
    "    \n",
    "    mask_otros_grupos = registros_n21_con_adres['COD_3_NOVEDAD'].astype(str).str.strip() != '5'\n",
    "    registros_otros = registros_n21_con_adres[mask_otros_grupos].copy()\n",
    "    total_otros = len(registros_otros)\n",
    "    \n",
    "    print(f\"   üìä Total otros grupos: {total_otros}\")\n",
    "    \n",
    "    registros_rechazados_otros = []\n",
    "    motivos_rechazo_otros = {}\n",
    "    \n",
    "    if total_otros > 0:\n",
    "        # Normalizar valores\n",
    "        registros_otros['COD_3_NOVEDAD_NORM'] = registros_otros['COD_3_NOVEDAD'].astype(str).str.strip()\n",
    "        registros_otros['CNT_AFL_TPS_GRP_PBL_ID_NORM'] = registros_otros['CNT_AFL_TPS_GRP_PBL_ID'].astype(str).str.strip()\n",
    "        registros_otros['Gr_Poblacional_Actual_NORM'] = registros_otros['Gr_Poblacional_Actual'].astype(str).str.strip()\n",
    "        \n",
    "        # Sin cambios: COD_3_NOVEDAD == CNT_AFL_TPS_GRP_PBL_ID\n",
    "        mask_sin_cambios_otros = registros_otros['COD_3_NOVEDAD_NORM'] == registros_otros['CNT_AFL_TPS_GRP_PBL_ID_NORM']\n",
    "        rechazados_sin_cambios_otros = registros_otros[mask_sin_cambios_otros].copy()\n",
    "        total_sin_cambios_otros = len(rechazados_sin_cambios_otros)\n",
    "        \n",
    "        # Diferente a tablas: COD_3_NOVEDAD != Gr_Poblacional_Actual\n",
    "        mask_dif_tablas_otros = (\n",
    "            (registros_otros['COD_3_NOVEDAD_NORM'] != registros_otros['Gr_Poblacional_Actual_NORM']) &\n",
    "            (~mask_sin_cambios_otros)  # Excluir ya rechazados\n",
    "        )\n",
    "        rechazados_dif_tablas_otros = registros_otros[mask_dif_tablas_otros].copy()\n",
    "        total_dif_tablas_otros = len(rechazados_dif_tablas_otros)\n",
    "        \n",
    "        print(f\"   Sin cambios (COD_3 = CNT_AFL_TPS_GRP_PBL_ID): {total_sin_cambios_otros}\")\n",
    "        print(f\"   Diferente a tablas (COD_3 ‚â† Gr_Poblacional_Actual): {total_dif_tablas_otros}\")\n",
    "        print(f\"   V√°lidos: {total_otros - total_sin_cambios_otros - total_dif_tablas_otros}\")\n",
    "        \n",
    "        # Agregar rechazados sin cambios\n",
    "        if total_sin_cambios_otros > 0:\n",
    "            rechazados_sin_cambios_otros['motivo'] = 'Afiliado sin cambios a reportar'\n",
    "            registros_rechazados_otros.append(rechazados_sin_cambios_otros)\n",
    "            motivos_rechazo_otros['Sin cambios grupo poblacional'] = total_sin_cambios_otros\n",
    "            \n",
    "            print(f\"\\n   üìã Ejemplos sin cambios:\")\n",
    "            ejemplos = rechazados_sin_cambios_otros[[\n",
    "                'NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION',\n",
    "                'COD_3_NOVEDAD_NORM', 'CNT_AFL_TPS_GRP_PBL_ID_NORM'\n",
    "            ]].head(5)\n",
    "            print(ejemplos.to_string(index=False))\n",
    "        \n",
    "        # Agregar rechazados diferente a tablas\n",
    "        if total_dif_tablas_otros > 0:\n",
    "            rechazados_dif_tablas_otros['motivo'] = 'Diferente a tablas de referencia ADRES'\n",
    "            registros_rechazados_otros.append(rechazados_dif_tablas_otros)\n",
    "            motivos_rechazo_otros['Diferente a tablas grupo poblacional'] = total_dif_tablas_otros\n",
    "            \n",
    "            print(f\"\\n   üìã Ejemplos diferentes a tablas:\")\n",
    "            ejemplos = rechazados_dif_tablas_otros[[\n",
    "                'NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION',\n",
    "                'COD_3_NOVEDAD_NORM', 'Gr_Poblacional_Actual_NORM'\n",
    "            ]].head(5)\n",
    "            print(ejemplos.to_string(index=False))\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 4: CONSOLIDAR Y MOVER RECHAZADOS\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîÑ PASO 4: Consolidando registros rechazados\")\n",
    "    \n",
    "    # Combinar todos los rechazados\n",
    "    todos_rechazados = []\n",
    "    \n",
    "    if registros_rechazados_sisben:\n",
    "        todos_rechazados.extend(registros_rechazados_sisben)\n",
    "    \n",
    "    if registros_rechazados_otros:\n",
    "        todos_rechazados.extend(registros_rechazados_otros)\n",
    "    \n",
    "    total_rechazados = 0\n",
    "    \n",
    "    if todos_rechazados:\n",
    "        # Combinar en un solo DataFrame\n",
    "        df_rechazados = pd.concat(todos_rechazados, ignore_index=True)\n",
    "        total_rechazados = len(df_rechazados)\n",
    "        \n",
    "        print(f\"   üìä Total de registros a rechazar: {total_rechazados}\")\n",
    "        \n",
    "        # Limpiar columnas temporales\n",
    "        columnas_temp = [\n",
    "            'Gr_Poblacional_Actual', 'N_Sisben_Actual', 'SUB_SISBEN_IV', 'CNT_AFL_TPS_GRP_PBL_ID',\n",
    "            'Gr_Poblacional_Actual_NORM', 'COD_2_NOVEDAD_NORM', 'SUB_SISBEN_IV_NORM', \n",
    "            'N_Sisben_Actual_NORM', 'COD_3_NOVEDAD_NORM', 'CNT_AFL_TPS_GRP_PBL_ID_NORM'\n",
    "        ]\n",
    "        \n",
    "        df_rechazados = df_rechazados.drop(columns=[col for col in columnas_temp if col in df_rechazados.columns])\n",
    "        \n",
    "        # Agregar a DF_No_Envio\n",
    "        df_no_envio = pd.concat([df_no_envio, df_rechazados], ignore_index=True)\n",
    "        \n",
    "        # Eliminar del DataFrame principal usando ID_User\n",
    "        ids_a_eliminar = df_rechazados['ID_User'].unique()\n",
    "        mask_eliminar = (df_ns['NOVEDAD'] == 'N21') & (df_ns['ID_User'].isin(ids_a_eliminar))\n",
    "        df_ns = df_ns[~mask_eliminar].reset_index(drop=True)\n",
    "        \n",
    "        print(f\"   ‚úÖ Registros movidos a DF_No_Envio: {total_rechazados}\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ No hay registros para rechazar\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 5: ESTAD√çSTICAS FINALES\n",
    "    # =========================================================================\n",
    "    registros_n21_final = len(df_ns[df_ns['NOVEDAD'] == 'N21'])\n",
    "    \n",
    "    print(f\"\\nüìà RESUMEN FINAL DE VERACIDAD N21:\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"   Registros N21 iniciales: {total_n21_inicial}\")\n",
    "    print(f\"   Registros rechazados: {total_rechazados}\")\n",
    "    print(f\"   Registros N21 v√°lidos finales: {registros_n21_final}\")\n",
    "    print(f\"   Total en DF_No_Envio: {len(df_no_envio)}\")\n",
    "    \n",
    "    # Desglose por motivo\n",
    "    if motivos_rechazo_sisben or motivos_rechazo_otros:\n",
    "        print(f\"\\nüìã DESGLOSE POR MOTIVO DE RECHAZO:\")\n",
    "        \n",
    "        if motivos_rechazo_sisben:\n",
    "            print(f\"   üîπ Registros Sisb√©n (COD_3 = 5):\")\n",
    "            for motivo, cantidad in motivos_rechazo_sisben.items():\n",
    "                print(f\"     ‚Ä¢ {motivo}: {cantidad}\")\n",
    "        \n",
    "        if motivos_rechazo_otros:\n",
    "            print(f\"   üîπ Otros grupos poblacionales (COD_3 ‚â† 5):\")\n",
    "            for motivo, cantidad in motivos_rechazo_otros.items():\n",
    "                print(f\"     ‚Ä¢ {motivo}: {cantidad}\")\n",
    "    \n",
    "    # Mostrar ejemplos finales v√°lidos\n",
    "    if registros_n21_final > 0:\n",
    "        print(f\"\\nüìã EJEMPLOS DE REGISTROS N21 V√ÅLIDOS FINALES:\")\n",
    "        ejemplos_validos = df_ns[df_ns['NOVEDAD'] == 'N21'][[\n",
    "            'NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION',\n",
    "            'COD_1_NOVEDAD', 'COD_2_NOVEDAD', 'COD_3_NOVEDAD'\n",
    "        ]].head(10)\n",
    "        print(ejemplos_validos.to_string(index=False))\n",
    "    \n",
    "    print(f\"\\n‚úÖ VALIDACI√ìN DE VERACIDAD N21 COMPLETADA\")\n",
    "    \n",
    "    return df_ns, df_no_envio\n",
    "\n",
    "# Aplicar validaci√≥n de veracidad N21\n",
    "df_NS, DF_No_Envio = validar_veracidad_N21(df_NS, DF_No_Envio, maestro_ADRES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "### 5.10.2. N21 masiva Listado censal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_actualizaciones_masivas_N21(df_ns, maestro_adres, fecha_reporte):\n",
    "    \"\"\"\n",
    "    Aplica actualizaciones masivas N21 (actualizaci√≥n de condiciones Sisb√©n, etnia y comunidad).\n",
    "    \n",
    "    Proceso:\n",
    "    1. CASO 1: Listado censal (Gr_Poblacional_Actual = 1, 2, 9, 16, 28)\n",
    "       - Afiliados con TPS_GRP_PBL_ID = 5 (o vac√≠o) en ADRES\n",
    "       - Pero con Gr_Poblacional_Actual de listado censal\n",
    "       - Reportar N21 para cambiar a listado censal\n",
    "    \n",
    "    2. CASO 2: Grupo poblacional 17 (ind√≠genas con c√≥digo especial)\n",
    "       - TPS_GRP_PBL_ID = 5 y Gr_Poblacional_Actual = 17\n",
    "       - Reportar con c√≥digos especiales (COD_5 = \"01\", COD_6 = \"999\")\n",
    "    \n",
    "    Args:\n",
    "        df_ns: DataFrame de novedades\n",
    "        maestro_adres: DataFrame maestro ADRES\n",
    "        fecha_reporte: fecha del reporte (datetime)\n",
    "    \n",
    "    Returns:\n",
    "        df_ns actualizado con las nuevas novedades N21\n",
    "    \"\"\"\n",
    "    print(\"üîç INICIANDO APLICACI√ìN DE ACTUALIZACIONES MASIVAS N21\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Convertir fecha_reporte a formato DD/MM/YYYY\n",
    "    fecha_novedad_str = fecha_reporte.strftime('%d/%m/%Y')\n",
    "    print(f\"üìÖ Fecha de novedad: {fecha_novedad_str}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 1: FILTRAR AFILIADOS ACTIVOS\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîç PASO 1: Identificando afiliados activos (AC) en EPS025\")\n",
    "    \n",
    "    mask_activos_eps025 = (\n",
    "        (maestro_adres['ENT_ID'] == 'EPS025') &\n",
    "        (maestro_adres['TPS_EST_AFL_ID'] == 'AC')\n",
    "    )\n",
    "    \n",
    "    registros_activos = maestro_adres[mask_activos_eps025].copy().reset_index(drop=True)\n",
    "    total_activos = len(registros_activos)\n",
    "    \n",
    "    print(f\"   üìä Registros activos en EPS025: {total_activos:,}\")\n",
    "    \n",
    "    if total_activos == 0:\n",
    "        print(f\"\\n‚ö†Ô∏è No se encontraron registros activos para procesar\")\n",
    "        return df_ns\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CASO 1: LISTADO CENSAL (Gr_Poblacional_Actual = 1, 2, 9, 16, 28)\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîç CASO 1: Procesando afiliados de listado censal\")\n",
    "    \n",
    "    # Filtrar por TPS_GRP_PBL_ID = 5 o vac√≠o/null\n",
    "    mask_sisben_o_vacio = (\n",
    "        (registros_activos['TPS_GRP_PBL_ID'].isna()) |\n",
    "        (registros_activos['TPS_GRP_PBL_ID'].astype(str).str.strip() == '') |\n",
    "        (registros_activos['TPS_GRP_PBL_ID'].astype(str).str.strip() == '5')\n",
    "    )\n",
    "    \n",
    "    # Filtrar por Gr_Poblacional_Actual de listado censal\n",
    "    grupos_listado_censal = ['1', '2', '9', '16', '28']\n",
    "    mask_listado_censal = registros_activos['Gr_Poblacional_Actual'].astype(str).str.strip().isin(grupos_listado_censal)\n",
    "    \n",
    "    # Combinar m√°scaras\n",
    "    mask_caso1 = mask_sisben_o_vacio & mask_listado_censal\n",
    "    registros_caso1 = registros_activos[mask_caso1].copy().reset_index(drop=True)\n",
    "    total_caso1 = len(registros_caso1)\n",
    "    \n",
    "    print(f\"   üìä Registros encontrados: {total_caso1:,}\")\n",
    "    \n",
    "    if total_caso1 > 0:\n",
    "        # Mostrar distribuci√≥n por grupo poblacional\n",
    "        print(f\"\\n   üìä Distribuci√≥n por grupo poblacional:\")\n",
    "        distribucion_gr_caso1 = registros_caso1['Gr_Poblacional_Actual'].value_counts()\n",
    "        for gr, count in distribucion_gr_caso1.items():\n",
    "            print(f\"     Grupo {gr}: {count:,} registros\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CASO 2: GRUPO POBLACIONAL 17 (IND√çGENAS CON C√ìDIGO ESPECIAL)\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîç CASO 2: Procesando grupo poblacional 17 (ind√≠genas)\")\n",
    "    \n",
    "    mask_caso2 = (\n",
    "        (registros_activos['TPS_GRP_PBL_ID'].astype(str).str.strip() == '5') &\n",
    "        (registros_activos['Gr_Poblacional_Actual'].astype(str).str.strip() == '17')\n",
    "    )\n",
    "    \n",
    "    registros_caso2 = registros_activos[mask_caso2].copy().reset_index(drop=True)\n",
    "    total_caso2 = len(registros_caso2)\n",
    "    \n",
    "    print(f\"   üìä Registros encontrados: {total_caso2:,}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 2: CONSTRUIR NOVEDADES N21 - CASO 1 (LISTADO CENSAL)\n",
    "    # =========================================================================\n",
    "    dataframes_nuevos = []\n",
    "    \n",
    "    if total_caso1 > 0:\n",
    "        print(f\"\\nüîß CONSTRUYENDO NOVEDADES N21 - CASO 1 (Listado Censal)\")\n",
    "        \n",
    "        # Verificar columnas necesarias\n",
    "        columnas_requeridas = [\n",
    "            'ENT_ID', 'TPS_IDN_ID', 'HST_IDN_NUMERO_IDENTIFICACION',\n",
    "            'AFL_PRIMER_APELLIDO', 'AFL_SEGUNDO_APELLIDO', \n",
    "            'AFL_PRIMER_NOMBRE', 'AFL_SEGUNDO_NOMBRE',\n",
    "            'AFL_FECHA_NACIMIENTO', 'DPR_ID', 'MNC_ID', \n",
    "            'TPS_EST_AFL_ID', 'Gr_Poblacional_Actual'\n",
    "        ]\n",
    "        \n",
    "        columnas_faltantes = [col for col in columnas_requeridas if col not in registros_caso1.columns]\n",
    "        if columnas_faltantes:\n",
    "            print(f\"‚ùå Columnas faltantes en registros_caso1: {columnas_faltantes}\")\n",
    "        else:\n",
    "            try:\n",
    "                # Construir DataFrame de novedades para CASO 1\n",
    "                nuevas_novedades_caso1 = pd.DataFrame({\n",
    "                    'ENT_ID': registros_caso1['ENT_ID'],\n",
    "                    'TPS_IDN_ID': registros_caso1['TPS_IDN_ID'],\n",
    "                    'HST_IDN_NUMERO_IDENTIFICACION': registros_caso1['HST_IDN_NUMERO_IDENTIFICACION'],\n",
    "                    'AFL_PRIMER_APELLIDO': registros_caso1['AFL_PRIMER_APELLIDO'],\n",
    "                    'AFL_SEGUNDO_APELLIDO': registros_caso1['AFL_SEGUNDO_APELLIDO'],\n",
    "                    'AFL_PRIMER_NOMBRE': registros_caso1['AFL_PRIMER_NOMBRE'],\n",
    "                    'AFL_SEGUNDO_NOMBRE': registros_caso1['AFL_SEGUNDO_NOMBRE'],\n",
    "                    'AFL_FECHA_NACIMIENTO': registros_caso1['AFL_FECHA_NACIMIENTO'],\n",
    "                    'DPR_ID': registros_caso1['DPR_ID'],\n",
    "                    'MNS_ID': registros_caso1['MNC_ID'],  # MNC_ID -> MNS_ID\n",
    "                    'NOVEDAD': 'N21',\n",
    "                    'FECHA_NOVEDAD': fecha_novedad_str,\n",
    "                    'COD_1_NOVEDAD': '3',  # Grupo poblacional\n",
    "                    'COD_2_NOVEDAD': '',   # Vac√≠o para listado censal\n",
    "                    'COD_3_NOVEDAD': registros_caso1['Gr_Poblacional_Actual'].astype(str).str.strip(),\n",
    "                    'COD_4_NOVEDAD': 'N',  # N para grupos no Sisb√©n\n",
    "                    'COD_5_NOVEDAD': '06', # C√≥digo de etnia por defecto\n",
    "                    'ENT_ID_ADRES': registros_caso1['ENT_ID'],\n",
    "                    'TPS_EST_AFL_ID_from_adres': registros_caso1['TPS_EST_AFL_ID'],\n",
    "                    'Where': 'Novedad Masiva'\n",
    "                })\n",
    "                \n",
    "                # Crear ID_User e ID_Register\n",
    "                nuevas_novedades_caso1['ID_User'] = (\n",
    "                    nuevas_novedades_caso1['TPS_IDN_ID'].astype(str) + \n",
    "                    nuevas_novedades_caso1['HST_IDN_NUMERO_IDENTIFICACION'].astype(str)\n",
    "                )\n",
    "                \n",
    "                nuevas_novedades_caso1['ID_Register'] = (\n",
    "                    nuevas_novedades_caso1['TPS_IDN_ID'].astype(str) + \n",
    "                    nuevas_novedades_caso1['HST_IDN_NUMERO_IDENTIFICACION'].astype(str) + \n",
    "                    nuevas_novedades_caso1['NOVEDAD'].astype(str)\n",
    "                )\n",
    "                \n",
    "                # Rellenar columnas faltantes\n",
    "                columnas_faltantes_df = [col for col in df_ns.columns if col not in nuevas_novedades_caso1.columns]\n",
    "                for col in columnas_faltantes_df:\n",
    "                    nuevas_novedades_caso1[col] = None\n",
    "                \n",
    "                # Ordenar columnas\n",
    "                nuevas_novedades_caso1 = nuevas_novedades_caso1[df_ns.columns]\n",
    "                \n",
    "                dataframes_nuevos.append(nuevas_novedades_caso1)\n",
    "                \n",
    "                print(f\"   ‚úÖ Novedades N21 CASO 1 construidas: {len(nuevas_novedades_caso1):,}\")\n",
    "                \n",
    "                # Mostrar ejemplos\n",
    "                print(f\"\\n   üìã Ejemplos de novedades CASO 1:\")\n",
    "                ejemplos_columnas = ['TPS_IDN_ID', 'HST_IDN_NUMERO_IDENTIFICACION', \n",
    "                                   'AFL_PRIMER_NOMBRE', 'AFL_PRIMER_APELLIDO',\n",
    "                                   'COD_1_NOVEDAD', 'COD_2_NOVEDAD', 'COD_3_NOVEDAD', \n",
    "                                   'COD_4_NOVEDAD', 'COD_5_NOVEDAD']\n",
    "                ejemplos_disponibles = [col for col in ejemplos_columnas if col in nuevas_novedades_caso1.columns]\n",
    "                ejemplos = nuevas_novedades_caso1[ejemplos_disponibles].head(10)\n",
    "                print(ejemplos.to_string(index=False))\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error al construir novedades CASO 1: {e}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 3: CONSTRUIR NOVEDADES N21 - CASO 2 (GRUPO 17)\n",
    "    # =========================================================================\n",
    "    if total_caso2 > 0:\n",
    "        print(f\"\\nüîß CONSTRUYENDO NOVEDADES N21 - CASO 2 (Grupo 17 - Ind√≠genas)\")\n",
    "        \n",
    "        # Verificar columnas necesarias\n",
    "        columnas_requeridas = [\n",
    "            'ENT_ID', 'TPS_IDN_ID', 'HST_IDN_NUMERO_IDENTIFICACION',\n",
    "            'AFL_PRIMER_APELLIDO', 'AFL_SEGUNDO_APELLIDO', \n",
    "            'AFL_PRIMER_NOMBRE', 'AFL_SEGUNDO_NOMBRE',\n",
    "            'AFL_FECHA_NACIMIENTO', 'DPR_ID', 'MNC_ID', \n",
    "            'TPS_EST_AFL_ID', 'Gr_Poblacional_Actual'\n",
    "        ]\n",
    "        \n",
    "        columnas_faltantes = [col for col in columnas_requeridas if col not in registros_caso2.columns]\n",
    "        if columnas_faltantes:\n",
    "            print(f\"‚ùå Columnas faltantes en registros_caso2: {columnas_faltantes}\")\n",
    "        else:\n",
    "            try:\n",
    "                # Construir DataFrame de novedades para CASO 2\n",
    "                nuevas_novedades_caso2 = pd.DataFrame({\n",
    "                    'ENT_ID': registros_caso2['ENT_ID'],\n",
    "                    'TPS_IDN_ID': registros_caso2['TPS_IDN_ID'],\n",
    "                    'HST_IDN_NUMERO_IDENTIFICACION': registros_caso2['HST_IDN_NUMERO_IDENTIFICACION'],\n",
    "                    'AFL_PRIMER_APELLIDO': registros_caso2['AFL_PRIMER_APELLIDO'],\n",
    "                    'AFL_SEGUNDO_APELLIDO': registros_caso2['AFL_SEGUNDO_APELLIDO'],\n",
    "                    'AFL_PRIMER_NOMBRE': registros_caso2['AFL_PRIMER_NOMBRE'],\n",
    "                    'AFL_SEGUNDO_NOMBRE': registros_caso2['AFL_SEGUNDO_NOMBRE'],\n",
    "                    'AFL_FECHA_NACIMIENTO': registros_caso2['AFL_FECHA_NACIMIENTO'],\n",
    "                    'DPR_ID': registros_caso2['DPR_ID'],\n",
    "                    'MNS_ID': registros_caso2['MNC_ID'],  # MNC_ID -> MNS_ID\n",
    "                    'NOVEDAD': 'N21',\n",
    "                    'FECHA_NOVEDAD': fecha_novedad_str,\n",
    "                    'COD_1_NOVEDAD': '3',  # Grupo poblacional\n",
    "                    'COD_2_NOVEDAD': '',   # Vac√≠o para grupo 17\n",
    "                    'COD_3_NOVEDAD': '17', # Grupo ind√≠gena\n",
    "                    'COD_4_NOVEDAD': 'N',  # N para grupos no Sisb√©n\n",
    "                    'COD_5_NOVEDAD': '01', # C√≥digo especial para grupo 17\n",
    "                    'COD_6_NOVEDAD': '999',# C√≥digo especial para grupo 17\n",
    "                    'ENT_ID_ADRES': registros_caso2['ENT_ID'],\n",
    "                    'TPS_EST_AFL_ID_from_adres': registros_caso2['TPS_EST_AFL_ID'],\n",
    "                    'Where': 'Novedad Masiva'\n",
    "                })\n",
    "                \n",
    "                # Crear ID_User e ID_Register\n",
    "                nuevas_novedades_caso2['ID_User'] = (\n",
    "                    nuevas_novedades_caso2['TPS_IDN_ID'].astype(str) + \n",
    "                    nuevas_novedades_caso2['HST_IDN_NUMERO_IDENTIFICACION'].astype(str)\n",
    "                )\n",
    "                \n",
    "                nuevas_novedades_caso2['ID_Register'] = (\n",
    "                    nuevas_novedades_caso2['TPS_IDN_ID'].astype(str) + \n",
    "                    nuevas_novedades_caso2['HST_IDN_NUMERO_IDENTIFICACION'].astype(str) + \n",
    "                    nuevas_novedades_caso2['NOVEDAD'].astype(str)\n",
    "                )\n",
    "                \n",
    "                # Rellenar columnas faltantes\n",
    "                columnas_faltantes_df = [col for col in df_ns.columns if col not in nuevas_novedades_caso2.columns]\n",
    "                for col in columnas_faltantes_df:\n",
    "                    nuevas_novedades_caso2[col] = None\n",
    "                \n",
    "                # Ordenar columnas\n",
    "                nuevas_novedades_caso2 = nuevas_novedades_caso2[df_ns.columns]\n",
    "                \n",
    "                dataframes_nuevos.append(nuevas_novedades_caso2)\n",
    "                \n",
    "                print(f\"   ‚úÖ Novedades N21 CASO 2 construidas: {len(nuevas_novedades_caso2):,}\")\n",
    "                \n",
    "                # Mostrar ejemplos\n",
    "                print(f\"\\n   üìã Ejemplos de novedades CASO 2:\")\n",
    "                ejemplos_columnas = ['TPS_IDN_ID', 'HST_IDN_NUMERO_IDENTIFICACION', \n",
    "                                   'AFL_PRIMER_NOMBRE', 'AFL_PRIMER_APELLIDO',\n",
    "                                   'COD_1_NOVEDAD', 'COD_3_NOVEDAD', \n",
    "                                   'COD_4_NOVEDAD', 'COD_5_NOVEDAD', 'COD_6_NOVEDAD']\n",
    "                ejemplos_disponibles = [col for col in ejemplos_columnas if col in nuevas_novedades_caso2.columns]\n",
    "                ejemplos = nuevas_novedades_caso2[ejemplos_disponibles].head(10)\n",
    "                print(ejemplos.to_string(index=False))\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error al construir novedades CASO 2: {e}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 4: AGREGAR AL DATAFRAME PRINCIPAL\n",
    "    # =========================================================================\n",
    "    if len(dataframes_nuevos) == 0:\n",
    "        print(f\"\\n‚ö†Ô∏è No se generaron novedades N21 masivas\")\n",
    "        return df_ns\n",
    "    \n",
    "    print(f\"\\nüîÑ PASO 4: AGREGANDO NOVEDADES A df_NS\")\n",
    "    \n",
    "    try:\n",
    "        # Combinar todos los casos\n",
    "        todas_nuevas_novedades = pd.concat(dataframes_nuevos, ignore_index=True)\n",
    "        total_nuevas_novedades = len(todas_nuevas_novedades)\n",
    "        \n",
    "        print(f\"   üìä Total de novedades N21 masivas a agregar: {total_nuevas_novedades:,}\")\n",
    "        \n",
    "        # Agregar al DataFrame principal\n",
    "        registros_antes = len(df_ns)\n",
    "        df_ns = pd.concat([df_ns, todas_nuevas_novedades], ignore_index=True)\n",
    "        registros_despues = len(df_ns)\n",
    "        \n",
    "        print(f\"   üìä Registros antes: {registros_antes:,}\")\n",
    "        print(f\"   üìä Registros despu√©s: {registros_despues:,}\")\n",
    "        print(f\"   üìä Registros agregados: {registros_despues - registros_antes:,}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al agregar novedades a df_NS: {e}\")\n",
    "        return df_ns\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 5: ESTAD√çSTICAS FINALES\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüìà ESTAD√çSTICAS DE NOVEDADES N21 AGREGADAS:\")\n",
    "    \n",
    "    try:\n",
    "        if 'Where' in df_ns.columns:\n",
    "            novedades_n21_masivas = df_ns[\n",
    "                (df_ns['Where'] == 'Novedad Masiva') & \n",
    "                (df_ns['NOVEDAD'] == 'N21')\n",
    "            ]\n",
    "            \n",
    "            if len(novedades_n21_masivas) > 0:\n",
    "                print(f\"   üìä Total novedades N21 masivas: {len(novedades_n21_masivas):,}\")\n",
    "                \n",
    "                # Distribuci√≥n por COD_3_NOVEDAD (grupo poblacional)\n",
    "                print(f\"\\n   üìä Por grupo poblacional (COD_3_NOVEDAD):\")\n",
    "                distribucion_cod3 = novedades_n21_masivas['COD_3_NOVEDAD'].value_counts()\n",
    "                for cod3, count in distribucion_cod3.items():\n",
    "                    print(f\"     Grupo {cod3}: {count:,} registros\")\n",
    "                \n",
    "                # Distribuci√≥n por tipo de documento\n",
    "                print(f\"\\n   üìä Por tipo de documento:\")\n",
    "                distribucion_tps = novedades_n21_masivas['TPS_IDN_ID'].value_counts().head(10)\n",
    "                for tipo_doc, count in distribucion_tps.items():\n",
    "                    print(f\"     {tipo_doc}: {count:,} registros\")\n",
    "                \n",
    "                # Casos con COD_6_NOVEDAD (grupo 17)\n",
    "                casos_cod6 = novedades_n21_masivas['COD_6_NOVEDAD'].notna().sum()\n",
    "                if casos_cod6 > 0:\n",
    "                    print(f\"\\n   üìä Registros con COD_6_NOVEDAD (Grupo 17): {casos_cod6:,}\")\n",
    "                \n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è No se encontraron novedades N21 masivas en el DataFrame final\")\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è Columna 'Where' no encontrada en df_NS\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error al generar estad√≠sticas finales: {e}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 6: VERIFICACI√ìN DE CALIDAD\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîç VERIFICACI√ìN DE CALIDAD:\")\n",
    "    \n",
    "    try:\n",
    "        novedades_n21_masivas = df_ns[\n",
    "            (df_ns['Where'] == 'Novedad Masiva') & \n",
    "            (df_ns['NOVEDAD'] == 'N21')\n",
    "        ]\n",
    "        \n",
    "        if len(novedades_n21_masivas) > 0:\n",
    "            # Verificar COD_1_NOVEDAD = '3'\n",
    "            cod1_correctos = novedades_n21_masivas['COD_1_NOVEDAD'].eq('3').sum()\n",
    "            print(f\"   ‚úÖ COD_1_NOVEDAD = '3': {cod1_correctos}/{len(novedades_n21_masivas)}\")\n",
    "            \n",
    "            # Verificar COD_2_NOVEDAD vac√≠o\n",
    "            cod2_vacios = (novedades_n21_masivas['COD_2_NOVEDAD'].isna() | \n",
    "                          (novedades_n21_masivas['COD_2_NOVEDAD'] == '')).sum()\n",
    "            print(f\"   ‚úÖ COD_2_NOVEDAD vac√≠o: {cod2_vacios}/{len(novedades_n21_masivas)}\")\n",
    "            \n",
    "            # Verificar COD_4_NOVEDAD = 'N'\n",
    "            cod4_correctos = novedades_n21_masivas['COD_4_NOVEDAD'].eq('N').sum()\n",
    "            print(f\"   ‚úÖ COD_4_NOVEDAD = 'N': {cod4_correctos}/{len(novedades_n21_masivas)}\")\n",
    "            \n",
    "            # Verificar COD_5_NOVEDAD\n",
    "            cod5_validos = novedades_n21_masivas['COD_5_NOVEDAD'].isin(['06', '01']).sum()\n",
    "            print(f\"   ‚úÖ COD_5_NOVEDAD v√°lido ('06' o '01'): {cod5_validos}/{len(novedades_n21_masivas)}\")\n",
    "            \n",
    "            # Verificar estado AC\n",
    "            estados_activos = novedades_n21_masivas['TPS_EST_AFL_ID_from_adres'].eq('AC').sum()\n",
    "            print(f\"   ‚úÖ Estado AC: {estados_activos}/{len(novedades_n21_masivas)}\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è No hay novedades N21 masivas para verificar\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error en verificaci√≥n de calidad: {e}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ ACTUALIZACIONES MASIVAS N21 APLICADAS EXITOSAMENTE\")\n",
    "    \n",
    "    return df_ns\n",
    "\n",
    "# Aplicar actualizaciones masivas N21 Listado censal\n",
    "df_NS = aplicar_actualizaciones_masivas_N21(df_NS, maestro_ADRES, fecha_reporte)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "## 5.10.3. N21 Masiva sisben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_actualizaciones_sisben_N21(df_ns, maestro_adres, fecha_reporte):\n",
    "    \"\"\"\n",
    "    Aplica actualizaciones masivas N21 para corregir el Sisb√©n IV desactualizado \n",
    "    en ADRES (SUB_SISBEN_IV) utilizando el valor local (N_Sisben_Actual).\n",
    "    \n",
    "    Proceso:\n",
    "    1. Filtra afiliados Activos (AC) en EPS025.\n",
    "    2. Identifica registros que cumplen las condiciones de Sisb√©n desactualizado:\n",
    "        - TPS_GRP_PBL_ID = '5' o vac√≠o/null (Reg√≠menes Subsidiados/No clasificados)\n",
    "        - N_Sisben_Actual NO est√° vac√≠o (Sisb√©n local v√°lido)\n",
    "        - N_Sisben_Actual es DIFERENTE a SUB_SISBEN_IV (Valor desactualizado en ADRES)\n",
    "    3. Construye la novedad N21 con los c√≥digos Sisb√©n correctos.\n",
    "        - COD_1_NOVEDAD = '5' (C√≥digo Sisb√©n)\n",
    "        - COD_3_NOVEDAD = N_Sisben_Actual\n",
    "        - COD_4_NOVEDAD: '1' (Grupos A y B) o '2' (Grupo C)\n",
    "    \n",
    "    Args:\n",
    "        df_ns: DataFrame de novedades existente (donde se a√±adir√°n las nuevas novedades)\n",
    "        maestro_adres: DataFrame maestro con la informaci√≥n de afiliados y Sisb√©n.\n",
    "        fecha_reporte: fecha del reporte (datetime)\n",
    "    \n",
    "    Returns:\n",
    "        df_ns actualizado con las nuevas novedades N21\n",
    "    \"\"\"\n",
    "    print(\"üîç INICIANDO APLICACI√ìN DE ACTUALIZACIONES SISB√âN N21\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Convertir fecha_reporte a formato DD/MM/YYYY\n",
    "    fecha_novedad_str = fecha_reporte.strftime('%d/%m/%Y')\n",
    "    print(f\"üìÖ Fecha de novedad: {fecha_novedad_str}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 1: FILTRAR AFILIADOS ACTIVOS EN EPS025\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîç PASO 1: Identificando afiliados activos (AC) en EPS025\")\n",
    "    \n",
    "    # Asegurar que las columnas de Sisb√©n sean strings para evitar errores de comparaci√≥n\n",
    "    maestro_adres['TPS_GRP_PBL_ID'] = maestro_adres['TPS_GRP_PBL_ID'].astype(str).str.strip()\n",
    "    maestro_adres['N_Sisben_Actual'] = maestro_adres['N_Sisben_Actual'].astype(str).str.strip().str.upper()\n",
    "    maestro_adres['SUB_SISBEN_IV'] = maestro_adres['SUB_SISBEN_IV'].astype(str).str.strip().str.upper()\n",
    "    \n",
    "    mask_activos_eps025 = (\n",
    "        (maestro_adres['ENT_ID'] == 'EPS025') &\n",
    "        (maestro_adres['TPS_EST_AFL_ID'] == 'AC')\n",
    "    )\n",
    "    \n",
    "    registros_activos = maestro_adres[mask_activos_eps025].copy().reset_index(drop=True)\n",
    "    total_activos = len(registros_activos)\n",
    "    \n",
    "    print(f\" ¬† üìä Registros activos en EPS025: {total_activos:,}\")\n",
    "    \n",
    "    if total_activos == 0:\n",
    "        print(f\"\\n‚ö†Ô∏è No se encontraron registros activos para procesar\")\n",
    "        return df_ns\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CASO √öNICO: SISB√âN DESACTUALIZADO\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîç CASO SISB√âN: Identificando afiliados con Sisb√©n desactualizado\")\n",
    "    \n",
    "    # Condici√≥n 1: TPS_GRP_PBL_ID = '5' o vac√≠o/nulo\n",
    "    mask_regimen_sisben = (\n",
    "        (registros_activos['TPS_GRP_PBL_ID'].isna()) |\n",
    "        (registros_activos['TPS_GRP_PBL_ID'] == '') |\n",
    "        (registros_activos['TPS_GRP_PBL_ID'] == '5')\n",
    "    )\n",
    "    \n",
    "    # Condici√≥n 2: N_Sisben_Actual NO est√° vac√≠o (tiene valor local)\n",
    "    mask_sisben_local_valido = (registros_activos['N_Sisben_Actual'] != '')\n",
    "    \n",
    "    # Condici√≥n 3: N_Sisben_Actual es DIFERENTE a SUB_SISBEN_IV (ADRES desactualizado)\n",
    "    # Rellenamos los vac√≠os de SUB_SISBEN_IV con un valor de control (ej: 'VacioADRES') para que la comparaci√≥n funcione\n",
    "    mask_sisben_desactualizado = (\n",
    "        registros_activos['N_Sisben_Actual'] != registros_activos['SUB_SISBEN_IV'].fillna('VacioADRES')\n",
    "    )\n",
    "    \n",
    "    # Combinar todas las m√°scaras\n",
    "    mask_caso_sisben = mask_regimen_sisben & mask_sisben_local_valido & mask_sisben_desactualizado\n",
    "    \n",
    "    registros_caso_sisben = registros_activos[mask_caso_sisben].copy().reset_index(drop=True)\n",
    "    total_caso_sisben = len(registros_caso_sisben)\n",
    "    \n",
    "    print(f\" ¬† üìä Registros con Sisb√©n desactualizado a corregir: {total_caso_sisben:,}\")\n",
    "    \n",
    "    if total_caso_sisben == 0:\n",
    "        print(f\"\\n‚ö†Ô∏è No se encontraron registros con Sisb√©n desactualizado para generar N21\")\n",
    "        return df_ns\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 2: CONSTRUIR NOVEDADES N21 - SISB√âN DESACTUALIZADO\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîß CONSTRUYENDO NOVEDADES N21 - SISB√âN DESACTUALIZADO\")\n",
    "    \n",
    "    # Funci√≥n auxiliar para determinar COD_2_NOVEDAD\n",
    "    def determinar_cod2_sisben(sisben_actual):\n",
    "        if pd.isna(sisben_actual) or sisben_actual == '':\n",
    "            return None\n",
    "        \n",
    "        grupo = sisben_actual[0].upper()\n",
    "        \n",
    "        # Grupos A y B asignan '1'\n",
    "        if grupo in ('A', 'B'):\n",
    "            return '1'\n",
    "        # Grupo C asigna '2'\n",
    "        elif grupo == 'C':\n",
    "            return '2'\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # Aplicar la l√≥gica para COD_2_NOVEDAD\n",
    "    registros_caso_sisben['COD_2_NOVEDAD_CALC'] = registros_caso_sisben['N_Sisben_Actual'].apply(determinar_cod2_sisben)\n",
    "    \n",
    "    # Verificar columnas necesarias\n",
    "    columnas_requeridas = [\n",
    "        'ENT_ID', 'TPS_IDN_ID', 'HST_IDN_NUMERO_IDENTIFICACION',\n",
    "        'AFL_PRIMER_APELLIDO', 'AFL_SEGUNDO_APELLIDO', \n",
    "        'AFL_PRIMER_NOMBRE', 'AFL_SEGUNDO_NOMBRE',\n",
    "        'AFL_FECHA_NACIMIENTO', 'DPR_ID', 'MNC_ID', \n",
    "        'TPS_EST_AFL_ID'\n",
    "    ]\n",
    "    \n",
    "    columnas_faltantes = [col for col in columnas_requeridas if col not in registros_caso_sisben.columns]\n",
    "    if columnas_faltantes:\n",
    "        print(f\"‚ùå Columnas faltantes para construir novedad N21: {columnas_faltantes}\")\n",
    "        return df_ns\n",
    "    \n",
    "    try:\n",
    "        # Construir DataFrame de novedades\n",
    "        nuevas_novedades_sisben = pd.DataFrame({\n",
    "            'ENT_ID': registros_caso_sisben['ENT_ID'],\n",
    "            'TPS_IDN_ID': registros_caso_sisben['TPS_IDN_ID'],\n",
    "            'HST_IDN_NUMERO_IDENTIFICACION': registros_caso_sisben['HST_IDN_NUMERO_IDENTIFICACION'],\n",
    "            'AFL_PRIMER_APELLIDO': registros_caso_sisben['AFL_PRIMER_APELLIDO'],\n",
    "            'AFL_SEGUNDO_APELLIDO': registros_caso_sisben['AFL_SEGUNDO_APELLIDO'],\n",
    "            'AFL_PRIMER_NOMBRE': registros_caso_sisben['AFL_PRIMER_NOMBRE'],\n",
    "            'AFL_SEGUNDO_NOMBRE': registros_caso_sisben['AFL_SEGUNDO_NOMBRE'],\n",
    "            'AFL_FECHA_NACIMIENTO': registros_caso_sisben['AFL_FECHA_NACIMIENTO'],\n",
    "            'DPR_ID': registros_caso_sisben['DPR_ID'],\n",
    "            'MNS_ID': registros_caso_sisben['MNC_ID'],  # MNC_ID -> MNS_ID\n",
    "            'NOVEDAD': 'N21',\n",
    "            'FECHA_NOVEDAD': fecha_novedad_str,\n",
    "            'COD_1_NOVEDAD': '2',                                            # C√≥digo fijo para Sisb√©n\n",
    "            'COD_2_NOVEDAD': registros_caso_sisben['N_Sisben_Actual'],        # Valor del Sisb√©n Local                                            # Subcategor√≠a Sisb√©n IV\n",
    "            'COD_3_NOVEDAD': '5',\n",
    "            'COD_4_NOVEDAD': registros_caso_sisben['COD_2_NOVEDAD_CALC'],     # Categoria 1 (A/B) o 2 (C)\n",
    "            'COD_5_NOVEDAD': '06',                                           # C√≥digo de etnia por defecto\n",
    "            'ENT_ID_ADRES': registros_caso_sisben['ENT_ID'],\n",
    "            'TPS_EST_AFL_ID_from_adres': registros_caso_sisben['TPS_EST_AFL_ID'],\n",
    "            'Where': 'Novedad Masiva Sisben'\n",
    "        })\n",
    "        \n",
    "        # Crear ID_User e ID_Register\n",
    "        nuevas_novedades_sisben['ID_User'] = (\n",
    "            nuevas_novedades_sisben['TPS_IDN_ID'].astype(str) + \n",
    "            nuevas_novedades_sisben['HST_IDN_NUMERO_IDENTIFICACION'].astype(str)\n",
    "        )\n",
    "        \n",
    "        nuevas_novedades_sisben['ID_Register'] = (\n",
    "            nuevas_novedades_sisben['TPS_IDN_ID'].astype(str) + \n",
    "            nuevas_novedades_sisben['HST_IDN_NUMERO_IDENTIFICACION'].astype(str) + \n",
    "            nuevas_novedades_sisben['NOVEDAD'].astype(str)\n",
    "        )\n",
    "        \n",
    "        # Rellenar columnas faltantes del DF de destino (df_ns)\n",
    "        columnas_faltantes_df = [col for col in df_ns.columns if col not in nuevas_novedades_sisben.columns]\n",
    "        for col in columnas_faltantes_df:\n",
    "            nuevas_novedades_sisben[col] = None\n",
    "        \n",
    "        # Ordenar columnas\n",
    "        nuevas_novedades_sisben = nuevas_novedades_sisben[df_ns.columns]\n",
    "        \n",
    "        print(f\" ¬† ‚úÖ Novedades N21 Sisb√©n construidas: {len(nuevas_novedades_sisben):,}\")\n",
    "        \n",
    "        # Mostrar ejemplos\n",
    "        print(f\"\\n ¬† üìã Ejemplos de novedades Sisb√©n:\")\n",
    "        ejemplos_columnas = [\n",
    "            'TPS_IDN_ID', 'HST_IDN_NUMERO_IDENTIFICACION', 'AFL_PRIMER_APELLIDO',\n",
    "            'COD_1_NOVEDAD', 'COD_2_NOVEDAD', 'COD_3_NOVEDAD', \n",
    "            'COD_4_NOVEDAD', 'N_Sisben_Actual', 'SUB_SISBEN_IV' # Columnas de contexto\n",
    "        ]\n",
    "        ejemplos_disponibles = [col for col in ejemplos_columnas if col in nuevas_novedades_sisben.columns]\n",
    "        \n",
    "        # A√±adir las columnas de Sisben del maestro para contexto\n",
    "        columnas_contexto = ['N_Sisben_Actual', 'SUB_SISBEN_IV']\n",
    "        \n",
    "        # Unir las nuevas novedades con las columnas de Sisb√©n del maestro para el ejemplo\n",
    "        ejemplos_mostrar = nuevas_novedades_sisben.merge(\n",
    "            registros_caso_sisben[['HST_IDN_NUMERO_IDENTIFICACION'] + columnas_contexto],\n",
    "            on='HST_IDN_NUMERO_IDENTIFICACION',\n",
    "            how='left'\n",
    "        )[ejemplos_columnas].drop_duplicates(subset=['HST_IDN_NUMERO_IDENTIFICACION']).head(10)\n",
    "        \n",
    "        print(ejemplos_mostrar.to_string(index=False))\n",
    "\n",
    "        # =========================================================================\n",
    "        # PASO 3: AGREGAR AL DATAFRAME PRINCIPAL\n",
    "        # =========================================================================\n",
    "        print(f\"\\nüîÑ PASO 3: AGREGANDO NOVEDADES A df_NS\")\n",
    "        \n",
    "        registros_antes = len(df_ns)\n",
    "        df_ns = pd.concat([df_ns, nuevas_novedades_sisben], ignore_index=True)\n",
    "        registros_despues = len(df_ns)\n",
    "        \n",
    "        print(f\" ¬† üìä Total de novedades Sisb√©n agregadas: {len(nuevas_novedades_sisben):,}\")\n",
    "        print(f\" ¬† üìä Registros agregados: {registros_despues - registros_antes:,}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al construir o agregar novedades Sisb√©n: {e}\")\n",
    "        return df_ns\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 4: ESTAD√çSTICAS FINALES\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüìà ESTAD√çSTICAS DE NOVEDADES N21 SISB√âN AGREGADAS:\")\n",
    "    \n",
    "    novedades_n21_masivas = df_ns[\n",
    "        (df_ns['Where'] == 'Novedad Masiva Sisben') & \n",
    "        (df_ns['NOVEDAD'] == 'N21')\n",
    "    ]\n",
    "    \n",
    "    if len(novedades_n21_masivas) > 0:\n",
    "        print(f\" ¬† üìä Total novedades N21 Sisb√©n masivas: {len(novedades_n21_masivas):,}\")\n",
    "        \n",
    "        # Distribuci√≥n por Sisb√©n (COD_3_NOVEDAD)\n",
    "        print(f\"\\n ¬† üìä Por Sisb√©n (COD_3_NOVEDAD):\")\n",
    "        distribucion_cod3 = novedades_n21_masivas['COD_3_NOVEDAD'].value_counts().head(10)\n",
    "        for cod3, count in distribucion_cod3.items():\n",
    "            print(f\" ¬† ¬† Sisb√©n {cod3}: {count:,} registros\")\n",
    "        \n",
    "        # Distribuci√≥n por Categor√≠a (COD_4_NOVEDAD)\n",
    "        print(f\"\\n ¬† üìä Por Categor√≠a (COD_4_NOVEDAD):\")\n",
    "        distribucion_cod4 = novedades_n21_masivas['COD_4_NOVEDAD'].value_counts()\n",
    "        for cod4, count in distribucion_cod4.items():\n",
    "            print(f\" ¬† ¬† Categor√≠a {cod4}: {count:,} registros\")\n",
    "\n",
    "    else:\n",
    "        print(f\" ¬† ‚ö†Ô∏è No se encontraron novedades N21 Sisb√©n masivas en el DataFrame final\")\n",
    "\n",
    "    print(f\"\\n‚úÖ ACTUALIZACIONES MASIVAS SISB√âN N21 APLICADAS EXITOSAMENTE\")\n",
    "    \n",
    "    return df_ns\n",
    "\n",
    "# Aplicar actualizaciones masivas N21 Sisb√©n\n",
    "df_NS = aplicar_actualizaciones_sisben_N21(df_NS, maestro_ADRES, fecha_reporte)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "## 5.11. N25 Actualizaci√≥n de IPS Primaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validar_novedades_N25(df, df_no_envio, df_ips):\n",
    "    \"\"\"\n",
    "    Valida registros con NOVEDAD = 'N25' (Actualizaci√≥n de IPS Primaria).\n",
    "    \n",
    "    Proceso:\n",
    "    1. Filtrar solo registros del departamento de Casanare (DPR_ID = 85)\n",
    "    2. Traer c√≥digo de IPS v√°lido desde df_IPS seg√∫n municipio (MNS_ID)\n",
    "    3. Asignar el c√≥digo de IPS a COD_1_NOVEDAD y COD_2_NOVEDAD\n",
    "    4. Vaciar columnas COD_4_NOVEDAD hasta COD_7_NOVEDAD\n",
    "    5. Mover registros de otros departamentos a DF_No_Envio\n",
    "    \"\"\"\n",
    "    print(\"üîç INICIANDO VALIDACI√ìN DE NOVEDADES N25\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Filtrar solo registros N25\n",
    "    mask_n25 = df['NOVEDAD'] == 'N25'\n",
    "    registros_n25 = df[mask_n25].copy()\n",
    "    total_n25_inicial = len(registros_n25)\n",
    "    \n",
    "    print(f\"üìä Total de registros N25 iniciales: {total_n25_inicial}\")\n",
    "    \n",
    "    if total_n25_inicial == 0:\n",
    "        print(\"‚ö†Ô∏è No se encontraron registros N25\")\n",
    "        return df, df_no_envio\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 1: FILTRAR POR DEPARTAMENTO DE CASANARE (DPR_ID = 85)\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîç PASO 1: Validando departamento\")\n",
    "    \n",
    "    # Normalizar DPR_ID\n",
    "    registros_n25['DPR_ID_NORM'] = registros_n25['DPR_ID'].astype(str).str.strip()\n",
    "    \n",
    "    # Identificar registros de Casanare vs otros departamentos\n",
    "    mask_casanare = registros_n25['DPR_ID_NORM'] == '85'\n",
    "    registros_casanare = registros_n25[mask_casanare].copy()\n",
    "    registros_otros_dpto = registros_n25[~mask_casanare].copy()\n",
    "    \n",
    "    total_casanare = len(registros_casanare)\n",
    "    total_otros_dpto = len(registros_otros_dpto)\n",
    "    \n",
    "    print(f\"   üìä Registros de Casanare (DPR_ID = 85): {total_casanare}\")\n",
    "    print(f\"   üìä Registros de otros departamentos: {total_otros_dpto}\")\n",
    "    \n",
    "    # Mostrar distribuci√≥n de departamentos si hay otros\n",
    "    if total_otros_dpto > 0:\n",
    "        print(f\"\\n   üìä Distribuci√≥n de otros departamentos:\")\n",
    "        distribucion_dpto = registros_otros_dpto['DPR_ID_NORM'].value_counts()\n",
    "        for dpto, count in distribucion_dpto.items():\n",
    "            print(f\"     DPR_ID {dpto}: {count} registros\")\n",
    "        \n",
    "        # Mostrar ejemplos\n",
    "        print(f\"\\n   üìã Ejemplos de registros de otros departamentos:\")\n",
    "        ejemplos_otros = registros_otros_dpto[['NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION', \n",
    "                                              'DPR_ID_NORM', 'MNS_ID']].head(5)\n",
    "        print(ejemplos_otros.to_string(index=False))\n",
    "        \n",
    "        # Mover a DF_No_Envio\n",
    "        registros_otros_clean = registros_otros_dpto.drop(columns=['DPR_ID_NORM'])\n",
    "        registros_otros_clean['motivo'] = 'Registro de otro departamento'\n",
    "        \n",
    "        df_no_envio = pd.concat([df_no_envio, registros_otros_clean], ignore_index=True)\n",
    "        \n",
    "        # Eliminar del DataFrame principal\n",
    "        indices_otros_dpto = df.loc[mask_n25][~mask_casanare].index\n",
    "        df = df.drop(indices_otros_dpto).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"   ‚úÖ Movidos {total_otros_dpto} registros a DF_No_Envio\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 2: PROCESAR df_IPS PARA CREAR MAPEO\n",
    "    # =========================================================================\n",
    "    if total_casanare == 0:\n",
    "        print(f\"\\n‚ö†Ô∏è No quedan registros N25 de Casanare para procesar\")\n",
    "        return df, df_no_envio\n",
    "    \n",
    "    print(f\"\\nüîç PASO 2: Procesando datos de IPS\")\n",
    "    \n",
    "    # Verificar estructura de df_IPS\n",
    "    print(f\"   üìä df_IPS shape: {df_ips.shape}\")\n",
    "    print(f\"   üìã Primeras filas de df_IPS:\")\n",
    "    print(df_ips.head().to_string(index=False, header=False))\n",
    "    \n",
    "    # Asignar nombres a las columnas (asumiendo que columna 0 = municipio, columna 1 = c√≥digo IPS)\n",
    "    df_ips_procesado = df_ips.copy()\n",
    "    df_ips_procesado.columns = ['MNS_ID', 'COD_IPS']\n",
    "    \n",
    "    # Normalizar c√≥digos de municipio (asegurar formato de 3 d√≠gitos)\n",
    "    df_ips_procesado['MNS_ID_NORM'] = df_ips_procesado['MNS_ID'].astype(str).str.strip().str.zfill(3)\n",
    "    df_ips_procesado['COD_IPS_NORM'] = df_ips_procesado['COD_IPS'].astype(str).str.strip()\n",
    "    \n",
    "    # Mostrar mapeo de IPS\n",
    "    print(f\"\\n   üìä Municipios con IPS v√°lidas: {df_ips_procesado['MNS_ID_NORM'].nunique()}\")\n",
    "    print(f\"   üìã Ejemplos de mapeo:\")\n",
    "    ejemplos_ips = df_ips_procesado[['MNS_ID_NORM', 'COD_IPS_NORM']].head(10)\n",
    "    print(ejemplos_ips.to_string(index=False))\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 3: TRAER C√ìDIGOS DE IPS PARA REGISTROS DE CASANARE\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîç PASO 3: Asignando c√≥digos de IPS\")\n",
    "    \n",
    "    # Normalizar MNS_ID en registros de Casanare\n",
    "    registros_casanare['MNS_ID_NORM'] = registros_casanare['MNS_ID'].astype(str).str.strip().str.zfill(3)\n",
    "    \n",
    "    # Hacer merge para traer c√≥digos de IPS\n",
    "    registros_con_ips = registros_casanare.merge(\n",
    "        df_ips_procesado[['MNS_ID_NORM', 'COD_IPS_NORM']],\n",
    "        on='MNS_ID_NORM',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Verificar match\n",
    "    registros_con_match = registros_con_ips['COD_IPS_NORM'].notna().sum()\n",
    "    registros_sin_match = registros_con_ips['COD_IPS_NORM'].isna().sum()\n",
    "    \n",
    "    print(f\"   ‚úÖ Registros con IPS v√°lida encontrada: {registros_con_match}\")\n",
    "    print(f\"   ‚ö†Ô∏è Registros sin IPS v√°lida: {registros_sin_match}\")\n",
    "    \n",
    "    if registros_sin_match > 0:\n",
    "        print(f\"\\n   üìã Municipios sin IPS v√°lida:\")\n",
    "        municipios_sin_ips = registros_con_ips[registros_con_ips['COD_IPS_NORM'].isna()]['MNS_ID_NORM'].unique()\n",
    "        print(f\"      {municipios_sin_ips}\")\n",
    "        \n",
    "        # Mostrar ejemplos\n",
    "        ejemplos_sin_ips = registros_con_ips[registros_con_ips['COD_IPS_NORM'].isna()][\n",
    "            ['NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION', 'MNS_ID_NORM']\n",
    "        ].head(5)\n",
    "        print(f\"\\n   üìã Ejemplos de registros sin IPS:\")\n",
    "        print(ejemplos_sin_ips.to_string(index=False))\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 4: APLICAR CAMBIOS AL DATAFRAME PRINCIPAL\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîÑ PASO 4: Aplicando cambios al DataFrame principal\")\n",
    "    \n",
    "    # Actualizar registros en df_NS que son N25 y de Casanare\n",
    "    mask_n25_casanare = (df['NOVEDAD'] == 'N25') & (df['DPR_ID'].astype(str).str.strip() == '85')\n",
    "    \n",
    "    if mask_n25_casanare.any():\n",
    "        # Crear mapeo temporal para actualizaci√≥n\n",
    "        mapeo_ips = dict(zip(registros_con_ips['ID_User'], registros_con_ips['COD_IPS_NORM']))\n",
    "        \n",
    "        # Contadores de actualizaciones\n",
    "        actualizaciones_cod1 = 0\n",
    "        actualizaciones_cod2 = 0\n",
    "        vaciado_cod4_7 = 0\n",
    "        \n",
    "        for idx in df[mask_n25_casanare].index:\n",
    "            id_user = df.loc[idx, 'ID_User']\n",
    "            \n",
    "            if id_user in mapeo_ips and pd.notna(mapeo_ips[id_user]):\n",
    "                # Asignar c√≥digo de IPS a COD_1_NOVEDAD y COD_2_NOVEDAD\n",
    "                codigo_ips = mapeo_ips[id_user]\n",
    "                \n",
    "                if str(df.loc[idx, 'COD_1_NOVEDAD']).strip() != codigo_ips:\n",
    "                    actualizaciones_cod1 += 1\n",
    "                if str(df.loc[idx, 'COD_2_NOVEDAD']).strip() != codigo_ips:\n",
    "                    actualizaciones_cod2 += 1\n",
    "                \n",
    "                df.loc[idx, 'COD_1_NOVEDAD'] = codigo_ips\n",
    "                df.loc[idx, 'COD_2_NOVEDAD'] = codigo_ips\n",
    "            \n",
    "            # Vaciar columnas COD_4_NOVEDAD hasta COD_7_NOVEDAD\n",
    "            columnas_a_vaciar = ['COD_4_NOVEDAD', 'COD_5_NOVEDAD', 'COD_6_NOVEDAD', 'COD_7_NOVEDAD']\n",
    "            for columna in columnas_a_vaciar:\n",
    "                if pd.notna(df.loc[idx, columna]) and str(df.loc[idx, columna]).strip() != '':\n",
    "                    vaciado_cod4_7 += 1\n",
    "                df.loc[idx, columna] = ''\n",
    "        \n",
    "        print(f\"   ‚úÖ COD_1_NOVEDAD actualizados: {actualizaciones_cod1}\")\n",
    "        print(f\"   ‚úÖ COD_2_NOVEDAD actualizados: {actualizaciones_cod2}\")\n",
    "        print(f\"   ‚úÖ Columnas COD_4-COD_7 vaciadas: {vaciado_cod4_7}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 5: ESTAD√çSTICAS FINALES\n",
    "    # =========================================================================\n",
    "    registros_n25_final = len(df[df['NOVEDAD'] == 'N25'])\n",
    "    \n",
    "    print(f\"\\nüìà RESUMEN FINAL:\")\n",
    "    print(f\"   Registros N25 iniciales: {total_n25_inicial}\")\n",
    "    print(f\"   Registros movidos (otros departamentos): {total_otros_dpto}\")\n",
    "    print(f\"   Registros N25 restantes (Casanare): {registros_n25_final}\")\n",
    "    print(f\"   Total en DF_No_Envio actual: {len(df_no_envio)}\")\n",
    "    \n",
    "    # Mostrar ejemplos de registros procesados\n",
    "    if registros_n25_final > 0:\n",
    "        print(f\"\\nüìã EJEMPLOS DE REGISTROS N25 PROCESADOS:\")\n",
    "        ejemplos_finales = df[df['NOVEDAD'] == 'N25'][[\n",
    "            'NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION',\n",
    "            'DPR_ID', 'MNS_ID', 'COD_1_NOVEDAD', 'COD_2_NOVEDAD'\n",
    "        ]].head(10)\n",
    "        print(ejemplos_finales.to_string(index=False))\n",
    "        \n",
    "        # Verificar que COD_4-COD_7 est√°n vac√≠as\n",
    "        registros_n25_actuales = df[df['NOVEDAD'] == 'N25']\n",
    "        columnas_vacias = ['COD_4_NOVEDAD', 'COD_5_NOVEDAD', 'COD_6_NOVEDAD', 'COD_7_NOVEDAD']\n",
    "        \n",
    "        print(f\"\\nüîç VERIFICACI√ìN DE COLUMNAS VAC√çAS:\")\n",
    "        for columna in columnas_vacias:\n",
    "            vacios = (registros_n25_actuales[columna].isna() | \n",
    "                     (registros_n25_actuales[columna] == '')).sum()\n",
    "            total = len(registros_n25_actuales)\n",
    "            print(f\"   {columna}: {vacios}/{total} vac√≠as\")\n",
    "        \n",
    "        # Mostrar distribuci√≥n de c√≥digos IPS asignados\n",
    "        print(f\"\\nüìä C√ìDIGOS IPS ASIGNADOS:\")\n",
    "        distribucion_ips = df[df['NOVEDAD'] == 'N25']['COD_1_NOVEDAD'].value_counts().head(10)\n",
    "        for codigo, count in distribucion_ips.items():\n",
    "            print(f\"   {codigo}: {count} registros\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ VALIDACI√ìN N25 COMPLETADA\")\n",
    "    \n",
    "    return df, df_no_envio\n",
    "\n",
    "# Aplicar validaci√≥n N25\n",
    "df_NS, DF_No_Envio = validar_novedades_N25(df_NS, DF_No_Envio, df_IPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "## 5.11. N32 Correcci√≥n de parentesco. - Discapacidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validar_novedades_N32(df, df_no_envio, maestro_adres):\n",
    "    \"\"\"\n",
    "    Valida registros con NOVEDAD = 'N32' (Correcci√≥n de parentesco - Discapacidad).\n",
    "    \n",
    "    Proceso:\n",
    "    1. Estandarizaci√≥n:\n",
    "       - COD_3_NOVEDAD: Se fuerza a \"B\".\n",
    "       - COD_5_NOVEDAD: Si tiene valor, se fuerza a \"D\". Si est√° vac√≠o, se deja vac√≠o.\n",
    "    2. Validaci√≥n de formato:\n",
    "       - COD_4_NOVEDAD: Debe ser uno de [1, 2, 3, 4, 5, 8, 9, 10, 11].\n",
    "    3. Validaci√≥n de No-Cambio (ADRES):\n",
    "       - Se compara COD_1_NOVEDAD (Tipo Doc CF) y COD_2_NOVEDAD (Num Doc CF)\n",
    "         con TPS_IDN_ID_CF y HST_IDN_NUMERO_IDENTIFICACION_CF del maestro.\n",
    "       - Si son iguales, se mueve a DF_No_Envio.\n",
    "    \"\"\"\n",
    "    print(\"üîç INICIANDO VALIDACI√ìN DE NOVEDADES N32\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Filtrar solo registros N32\n",
    "    mask_n32 = df['NOVEDAD'] == 'N32'\n",
    "    registros_n32 = df[mask_n32].copy()\n",
    "    total_n32_inicial = len(registros_n32)\n",
    "    \n",
    "    print(f\"üìä Total de registros N32 iniciales: {total_n32_inicial}\")\n",
    "    \n",
    "    if total_n32_inicial == 0:\n",
    "        print(\"‚ö†Ô∏è No se encontraron registros N32\")\n",
    "        return df, df_no_envio\n",
    "\n",
    "    # =========================================================================\n",
    "    # PASO 1: ESTANDARIZACI√ìN (COD_3 y COD_5)\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîß PASO 1: Estandarizando COD_3 (Parentesco) y COD_5 (Discapacidad)\")\n",
    "    \n",
    "    # 1.1 COD_3_NOVEDAD siempre debe ser \"B\"\n",
    "    correcciones_cod3 = (registros_n32['COD_3_NOVEDAD'] != 'B').sum()\n",
    "    registros_n32['COD_3_NOVEDAD'] = 'B'\n",
    "    print(f\"   ‚úÖ COD_3_NOVEDAD forzado a 'B' en {correcciones_cod3} registros\")\n",
    "\n",
    "    # 1.2 COD_5_NOVEDAD: Si tiene valor -> \"D\", si no -> vac√≠o\n",
    "    def corregir_discapacidad(valor):\n",
    "        if pd.isna(valor) or str(valor).strip() == '':\n",
    "            return ''\n",
    "        return 'D'\n",
    "\n",
    "    registros_n32['COD_5_NOVEDAD'] = registros_n32['COD_5_NOVEDAD'].apply(corregir_discapacidad)\n",
    "    print(f\"   ‚úÖ COD_5_NOVEDAD estandarizado (D o vac√≠o)\")\n",
    "\n",
    "    # Aplicar correcciones al DataFrame principal (para los registros que pasen la validaci√≥n)\n",
    "    df.loc[mask_n32, 'COD_3_NOVEDAD'] = registros_n32['COD_3_NOVEDAD']\n",
    "    df.loc[mask_n32, 'COD_5_NOVEDAD'] = registros_n32['COD_5_NOVEDAD']\n",
    "\n",
    "    # =========================================================================\n",
    "    # PASO 2: VALIDACI√ìN DE FORMATO COD_4 (C√ìDIGO PARENTESCO)\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîß PASO 2: Validando COD_4_NOVEDAD (C√≥digo Parentesco)\")\n",
    "    \n",
    "    valores_validos_cod4 = ['1', '2', '3', '4', '5', '8', '9', '10', '11']\n",
    "    \n",
    "    # Normalizar para comparar\n",
    "    registros_n32['COD_4_NORM'] = registros_n32['COD_4_NOVEDAD'].astype(str).str.strip()\n",
    "    \n",
    "    mask_cod4_invalido = ~registros_n32['COD_4_NORM'].isin(valores_validos_cod4)\n",
    "    registros_cod4_invalido = registros_n32[mask_cod4_invalido].copy()\n",
    "    total_cod4_invalido = len(registros_cod4_invalido)\n",
    "    \n",
    "    if total_cod4_invalido > 0:\n",
    "        print(f\"   ‚ö†Ô∏è Se encontraron {total_cod4_invalido} registros con COD_4 inv√°lido\")\n",
    "        print(f\"      Valores permitidos: {valores_validos_cod4}\")\n",
    "        \n",
    "        # Mostrar ejemplos\n",
    "        print(f\"      Ejemplos inv√°lidos: {registros_cod4_invalido['COD_4_NOVEDAD'].unique()}\")\n",
    "        \n",
    "        # Mover a DF_No_Envio\n",
    "        registros_cod4_invalido_clean = registros_cod4_invalido.drop(columns=['COD_4_NORM'])\n",
    "        registros_cod4_invalido_clean['motivo'] = \"C√≥digo de parentesco (COD_4) inv√°lido\"\n",
    "        \n",
    "        df_no_envio = pd.concat([df_no_envio, registros_cod4_invalido_clean], ignore_index=True)\n",
    "        \n",
    "        # Eliminar del set de trabajo actual\n",
    "        registros_n32 = registros_n32[~mask_cod4_invalido].copy()\n",
    "        \n",
    "        # Eliminar del DF principal\n",
    "        ids_eliminar = registros_cod4_invalido['ID_User'].unique()\n",
    "        mask_eliminar = (df['NOVEDAD'] == 'N32') & (df['ID_User'].isin(ids_eliminar))\n",
    "        df = df[~mask_eliminar].reset_index(drop=True)\n",
    "        \n",
    "        print(f\"   ‚úÖ Movidos {total_cod4_invalido} registros a DF_No_Envio\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Todos los registros tienen COD_4 v√°lido\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # PASO 3: VALIDACI√ìN DE NO-CAMBIO CON MAESTRO ADRES\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîç PASO 3: Verificando si el Cabeza de Familia ya est√° actualizado en ADRES\")\n",
    "    \n",
    "    if len(registros_n32) == 0:\n",
    "        print(\"   ‚ö†Ô∏è No quedan registros para validar contra ADRES\")\n",
    "        return df, df_no_envio\n",
    "\n",
    "    # Verificar si existen las columnas de Cabeza de Familia en el maestro\n",
    "    cols_cf = ['TPS_IDN_ID_CF', 'HST_IDN_NUMERO_IDENTIFICACION_CF']\n",
    "    cols_existentes = [c for c in cols_cf if c in maestro_adres.columns]\n",
    "    \n",
    "    if len(cols_existentes) < 2:\n",
    "        print(f\"   ‚ùå Faltan columnas de Cabeza de Familia en maestro_ADRES: {cols_cf}\")\n",
    "        print(\"   ‚ö†Ô∏è Saltando validaci√≥n de cruce ADRES\")\n",
    "        return df, df_no_envio\n",
    "\n",
    "    # Preparar subset del maestro\n",
    "    maestro_cf = maestro_adres[['ID_User'] + cols_cf].drop_duplicates(subset=['ID_User'])\n",
    "    \n",
    "    # Merge\n",
    "    registros_n32_con_adres = registros_n32.merge(maestro_cf, on='ID_User', how='left')\n",
    "    \n",
    "    # Normalizar para comparaci√≥n\n",
    "    registros_n32_con_adres['COD_1_NORM'] = registros_n32_con_adres['COD_1_NOVEDAD'].astype(str).str.strip().str.upper()\n",
    "    registros_n32_con_adres['COD_2_NORM'] = registros_n32_con_adres['COD_2_NOVEDAD'].astype(str).str.strip()\n",
    "    \n",
    "    registros_n32_con_adres['CF_TIPO_ADRES'] = registros_n32_con_adres['TPS_IDN_ID_CF'].astype(str).str.strip().str.upper()\n",
    "    registros_n32_con_adres['CF_NUM_ADRES'] = registros_n32_con_adres['HST_IDN_NUMERO_IDENTIFICACION_CF'].astype(str).str.strip()\n",
    "    \n",
    "    # L√≥gica: Si Tipo Y N√∫mero son iguales a lo que hay en ADRES -> Rechazar\n",
    "    mask_sin_cambios = (\n",
    "        (registros_n32_con_adres['COD_1_NORM'] == registros_n32_con_adres['CF_TIPO_ADRES']) &\n",
    "        (registros_n32_con_adres['COD_2_NORM'] == registros_n32_con_adres['CF_NUM_ADRES']) &\n",
    "        (registros_n32_con_adres['TPS_IDN_ID_CF'].notna()) # Solo si existe dato en ADRES\n",
    "    )\n",
    "    \n",
    "    registros_sin_cambios = registros_n32_con_adres[mask_sin_cambios].copy()\n",
    "    total_sin_cambios = len(registros_sin_cambios)\n",
    "    \n",
    "    print(f\"   Registros con Cabeza de Familia id√©ntico en ADRES: {total_sin_cambios}\")\n",
    "    print(f\"   Registros con cambio v√°lido: {len(registros_n32) - total_sin_cambios}\")\n",
    "    \n",
    "    if total_sin_cambios > 0:\n",
    "        print(f\"\\n   üìã Ejemplos sin cambios (Rechazados):\")\n",
    "        ejemplos = registros_sin_cambios[[\n",
    "            'NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION',\n",
    "            'COD_1_NOVEDAD', 'COD_2_NOVEDAD', 'CF_TIPO_ADRES', 'CF_NUM_ADRES'\n",
    "        ]].head(5)\n",
    "        print(ejemplos.to_string(index=False))\n",
    "        \n",
    "        # Limpiar y mover a DF_No_Envio\n",
    "        cols_temp = ['COD_4_NORM', 'COD_1_NORM', 'COD_2_NORM', 'CF_TIPO_ADRES', 'CF_NUM_ADRES', 'TPS_IDN_ID_CF', 'HST_IDN_NUMERO_IDENTIFICACION_CF']\n",
    "        registros_sin_cambios_clean = registros_sin_cambios.drop(columns=[c for c in cols_temp if c in registros_sin_cambios.columns])\n",
    "        registros_sin_cambios_clean['motivo'] = \"Cabeza de familia ya actualizado en ADRES\"\n",
    "        \n",
    "        df_no_envio = pd.concat([df_no_envio, registros_sin_cambios_clean], ignore_index=True)\n",
    "        \n",
    "        # Eliminar del DataFrame principal\n",
    "        ids_eliminar = registros_sin_cambios['ID_User'].unique()\n",
    "        mask_eliminar = (df['NOVEDAD'] == 'N32') & (df['ID_User'].isin(ids_eliminar))\n",
    "        df = df[~mask_eliminar].reset_index(drop=True)\n",
    "        \n",
    "        print(f\"   ‚úÖ Movidos {total_sin_cambios} registros a DF_No_Envio\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # RESUMEN FINAL\n",
    "    # =========================================================================\n",
    "    registros_n32_final = len(df[df['NOVEDAD'] == 'N32'])\n",
    "    \n",
    "    print(f\"\\nüìà RESUMEN FINAL N32:\")\n",
    "    print(f\"   Registros iniciales: {total_n32_inicial}\")\n",
    "    print(f\"   Rechazados por formato COD_4: {total_cod4_invalido}\")\n",
    "    print(f\"   Rechazados por sin cambios (ADRES): {total_sin_cambios}\")\n",
    "    print(f\"   Registros v√°lidos finales: {registros_n32_final}\")\n",
    "    print(f\"   Total en DF_No_Envio: {len(df_no_envio)}\")\n",
    "    \n",
    "    if registros_n32_final > 0:\n",
    "        print(f\"\\nüìã EJEMPLOS FINALES V√ÅLIDOS:\")\n",
    "        print(df[df['NOVEDAD'] == 'N32'][[\n",
    "            'HST_IDN_NUMERO_IDENTIFICACION', 'COD_1_NOVEDAD', 'COD_2_NOVEDAD', \n",
    "            'COD_3_NOVEDAD', 'COD_4_NOVEDAD', 'COD_5_NOVEDAD'\n",
    "        ]].head().to_string(index=False))\n",
    "\n",
    "    return df, df_no_envio\n",
    "\n",
    "# Aplicar validaci√≥n N32\n",
    "df_NS, DF_No_Envio = validar_novedades_N32(df_NS, DF_No_Envio, maestro_ADRES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "## 5.12.N43 Municipio de nacimiento o recidencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "### 5.12.1. Validaci√≥n de Novedades N43 Existentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validar_novedades_N43(df, df_no_envio, maestro_adres):\n",
    "    \"\"\"\n",
    "    Valida registros con NOVEDAD = 'N43' (Municipio de nacimiento o residencia).\n",
    "    \n",
    "    Proceso:\n",
    "    1. Validar formato de COD_1_NOVEDAD (debe ser de 5 d√≠gitos).\n",
    "    2. Comparar con el valor actual en ADRES (AFL_MUNICIPIO_NACIMIENTO).\n",
    "    3. Si son iguales y el afiliado es Activo y Subsidiado (EPS025), mover a DF_No_Envio.\n",
    "    \"\"\"\n",
    "    print(\"üîç INICIANDO VALIDACI√ìN DE NOVEDADES N43\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Filtrar solo registros N43\n",
    "    mask_n43 = df['NOVEDAD'] == 'N43'\n",
    "    registros_n43 = df[mask_n43].copy()\n",
    "    total_n43_inicial = len(registros_n43)\n",
    "    \n",
    "    print(f\"üìä Total de registros N43 iniciales: {total_n43_inicial}\")\n",
    "    \n",
    "    if total_n43_inicial == 0:\n",
    "        print(\"‚ö†Ô∏è No se encontraron registros N43\")\n",
    "        return df, df_no_envio\n",
    "\n",
    "    # =========================================================================\n",
    "    # PASO 1: VALIDAR FORMATO (5 D√çGITOS)\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîß PASO 1: Validando formato de COD_1_NOVEDAD (5 d√≠gitos)\")\n",
    "    \n",
    "    def validar_formato_municipio(valor):\n",
    "        if pd.isna(valor) or str(valor).strip() == '':\n",
    "            return False\n",
    "        valor_str = str(valor).strip()\n",
    "        return len(valor_str) == 5 and valor_str.isdigit()\n",
    "\n",
    "    registros_n43['FORMATO_VALIDO'] = registros_n43['COD_1_NOVEDAD'].apply(validar_formato_municipio)\n",
    "    invalidos_formato = (~registros_n43['FORMATO_VALIDO']).sum()\n",
    "    \n",
    "    if invalidos_formato > 0:\n",
    "        print(f\"   ‚ö†Ô∏è Se encontraron {invalidos_formato} registros con formato inv√°lido\")\n",
    "        # Aqu√≠ podr√≠as decidir moverlos a No_Envio si quisieras ser estricto, \n",
    "        # por ahora solo advertimos.\n",
    "\n",
    "    # =========================================================================\n",
    "    # PASO 2: TRAER DATOS DE MAESTRO ADRES\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîç PASO 2: Comparando con datos actuales en ADRES\")\n",
    "    \n",
    "    # Columnas necesarias del maestro\n",
    "    cols_maestro = ['ID_User', 'AFL_MUNICIPIO_NACIMIENTO', 'ENT_ID', 'TPS_EST_AFL_ID']\n",
    "    \n",
    "    # Asegurar que existan en el maestro (AFL_MUNICIPIO_NACIMIENTO a veces tiene otros nombres)\n",
    "    if 'AFL_MUNICIPIO_NACIMIENTO' not in maestro_adres.columns:\n",
    "        print(\"‚ùå Columna 'AFL_MUNICIPIO_NACIMIENTO' no encontrada en maestro_ADRES. Saltando validaci√≥n de igualdad.\")\n",
    "        return df, df_no_envio\n",
    "\n",
    "    maestro_subset = maestro_adres[cols_maestro].drop_duplicates(subset=['ID_User'])\n",
    "    \n",
    "    # Merge\n",
    "    registros_n43_con_maestro = registros_n43.merge(\n",
    "        maestro_subset,\n",
    "        on='ID_User',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PASO 3: IDENTIFICAR REGISTROS SIN CAMBIOS (IGUALES A ADRES)\n",
    "    # =========================================================================\n",
    "    \n",
    "    # Normalizar para comparaci√≥n\n",
    "    registros_n43_con_maestro['COD_1_NORM'] = registros_n43_con_maestro['COD_1_NOVEDAD'].astype(str).str.strip()\n",
    "    registros_n43_con_maestro['MUNI_ADRES_NORM'] = registros_n43_con_maestro['AFL_MUNICIPIO_NACIMIENTO'].astype(str).str.strip()\n",
    "    \n",
    "    # L√≥gica de rechazo:\n",
    "    # 1. El c√≥digo nuevo es IGUAL al actual.\n",
    "    # 2. El afiliado es EPS025 (Subsidiado).\n",
    "    # 3. El afiliado est√° Activo (AC).\n",
    "    mask_sin_cambios = (\n",
    "        (registros_n43_con_maestro['COD_1_NORM'] == registros_n43_con_maestro['MUNI_ADRES_NORM']) &\n",
    "        (registros_n43_con_maestro['ENT_ID_y'] == 'EPS025') & # _y viene del maestro\n",
    "        (registros_n43_con_maestro['TPS_EST_AFL_ID'] == 'AC') &\n",
    "        (registros_n43_con_maestro['MUNI_ADRES_NORM'] != '') & \n",
    "        (registros_n43_con_maestro['MUNI_ADRES_NORM'] != 'nan')\n",
    "    )\n",
    "    \n",
    "    registros_rechazados = registros_n43_con_maestro[mask_sin_cambios].copy()\n",
    "    total_rechazados = len(registros_rechazados)\n",
    "    \n",
    "    print(f\"   Registros N43 totales: {total_n43_inicial}\")\n",
    "    print(f\"   Registros rechazados (Dato ya actualizado en ADRES): {total_rechazados}\")\n",
    "    print(f\"   Registros v√°lidos: {total_n43_inicial - total_rechazados}\")\n",
    "    \n",
    "    if total_rechazados > 0:\n",
    "        # Mostrar ejemplos\n",
    "        print(f\"\\nüìã EJEMPLOS DE REGISTROS RECHAZADOS (YA ACTUALIZADOS):\")\n",
    "        ejemplos = registros_rechazados[[\n",
    "            'NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION', \n",
    "            'COD_1_NORM', 'MUNI_ADRES_NORM'\n",
    "        ]].head(5)\n",
    "        print(ejemplos.to_string(index=False))\n",
    "        \n",
    "        # Preparar para mover a DF_No_Envio\n",
    "        # Limpiar columnas temporales del merge\n",
    "        cols_temp = ['FORMATO_VALIDO', 'AFL_MUNICIPIO_NACIMIENTO', 'ENT_ID_y', 'TPS_EST_AFL_ID', 'COD_1_NORM', 'MUNI_ADRES_NORM']\n",
    "        registros_rechazados_clean = registros_rechazados.drop(columns=[c for c in cols_temp if c in registros_rechazados.columns])\n",
    "        \n",
    "        # Restaurar nombre original de ENT_ID si se renombr√≥ en el merge (ENT_ID_x)\n",
    "        if 'ENT_ID_x' in registros_rechazados_clean.columns:\n",
    "            registros_rechazados_clean = registros_rechazados_clean.rename(columns={'ENT_ID_x': 'ENT_ID'})\n",
    "            \n",
    "        registros_rechazados_clean['motivo'] = \"Dato de municipio ya actualizado en ADRES\"\n",
    "        \n",
    "        # Concatenar\n",
    "        df_no_envio = pd.concat([df_no_envio, registros_rechazados_clean], ignore_index=True)\n",
    "        \n",
    "        # Eliminar del DataFrame principal usando ID_User\n",
    "        ids_rechazados = registros_rechazados['ID_User'].unique()\n",
    "        mask_eliminar = (df['NOVEDAD'] == 'N43') & (df['ID_User'].isin(ids_rechazados))\n",
    "        df = df[~mask_eliminar].reset_index(drop=True)\n",
    "        \n",
    "        print(f\"‚úÖ Movidos {total_rechazados} registros a DF_No_Envio\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Todos los registros N43 son cambios v√°lidos o necesarios\")\n",
    "\n",
    "    return df, df_no_envio\n",
    "\n",
    "# Aplicar validaci√≥n N43\n",
    "df_NS, DF_No_Envio = validar_novedades_N43(df_NS, DF_No_Envio, maestro_ADRES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "### 5.12.2. Construcci√≥n Masiva de N43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_actualizaciones_masivas_N43(df_ns, maestro_adres, fecha_reporte):\n",
    "    \"\"\"\n",
    "    Aplica actualizaciones masivas N43 (Municipio de nacimiento/residencia) para afiliados\n",
    "    del r√©gimen subsidiado (EPS025) activos que tienen este dato vac√≠o en ADRES.\n",
    "    \n",
    "    L√≥gica:\n",
    "    1. Filtrar EPS025 + Activos (AC).\n",
    "    2. Filtrar quienes tengan AFL_MUNICIPIO_NACIMIENTO vac√≠o.\n",
    "    3. Excluir quienes ya tengan una N43 reportada en df_ns.\n",
    "    4. Construir el c√≥digo (COD_1_NOVEDAD) usando DPR_ID + MNC_ID (residencia actual).\n",
    "    \"\"\"\n",
    "    print(\"üîç INICIANDO APLICACI√ìN DE ACTUALIZACIONES MASIVAS N43\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    fecha_novedad_str = fecha_reporte.strftime('%d/%m/%Y')\n",
    "    print(f\"üìÖ Fecha de novedad: {fecha_novedad_str}\")\n",
    "    \n",
    "    # Verificar existencia de columna en maestro\n",
    "    col_muni_nac = 'AFL_MUNICIPIO_NACIMIENTO'\n",
    "    if col_muni_nac not in maestro_adres.columns:\n",
    "        print(f\"‚ùå Columna '{col_muni_nac}' no encontrada en maestro_ADRES. No se puede procesar.\")\n",
    "        return df_ns\n",
    "\n",
    "    # =========================================================================\n",
    "    # PASO 1: IDENTIFICAR CANDIDATOS (EPS025 + AC + MUNICIPIO VAC√çO)\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîç PASO 1: Identificando candidatos sin municipio de nacimiento\")\n",
    "    \n",
    "    # Normalizar columna para verificar vac√≠os\n",
    "    maestro_adres[col_muni_nac] = maestro_adres[col_muni_nac].fillna('').astype(str).str.strip()\n",
    "    \n",
    "    mask_candidatos = (\n",
    "        (maestro_adres['ENT_ID'] == 'EPS025') &\n",
    "        (maestro_adres['TPS_EST_AFL_ID'] == 'AC') &\n",
    "        ((maestro_adres[col_muni_nac] == '') | (maestro_adres[col_muni_nac] == 'nan')) &\n",
    "        (maestro_adres['DPR_ID'].notna()) & # Deben tener datos de residencia para construir\n",
    "        (maestro_adres['MNC_ID'].notna())\n",
    "    )\n",
    "    \n",
    "    registros_candidatos = maestro_adres[mask_candidatos].copy().reset_index(drop=True)\n",
    "    total_candidatos = len(registros_candidatos)\n",
    "    \n",
    "    print(f\"   üìä Registros activos EPS025 sin municipio nacimiento: {total_candidatos:,}\")\n",
    "    \n",
    "    if total_candidatos == 0:\n",
    "        print(\"‚ö†Ô∏è No hay registros para procesar\")\n",
    "        return df_ns\n",
    "\n",
    "    # =========================================================================\n",
    "    # PASO 2: EXCLUIR LOS QUE YA EST√ÅN EN df_NS (COMO N43)\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîç PASO 2: Excluyendo afiliados que ya tienen N43 en proceso\")\n",
    "    \n",
    "    ids_con_n43 = df_ns[df_ns['NOVEDAD'] == 'N43']['ID_User'].unique()\n",
    "    \n",
    "    registros_finales = registros_candidatos[~registros_candidatos['ID_User'].isin(ids_con_n43)].copy()\n",
    "    total_finales = len(registros_finales)\n",
    "    \n",
    "    print(f\"   Excluidos (ya en df_NS): {total_candidatos - total_finales}\")\n",
    "    print(f\"   Total a generar: {total_finales}\")\n",
    "    \n",
    "    if total_finales == 0:\n",
    "        return df_ns\n",
    "\n",
    "    # =========================================================================\n",
    "    # PASO 3: CONSTRUIR C√ìDIGO DE MUNICIPIO (DPR + MNC)\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîß PASO 3: Construyendo c√≥digo de municipio (5 d√≠gitos)\")\n",
    "    \n",
    "    def limpiar_codigo(valor, relleno):\n",
    "        \"\"\"Limpia y formatea c√≥digos num√©ricos eliminando decimales si existen\"\"\"\n",
    "        try:\n",
    "            # Convertir a float primero para manejar strings como \"5.0\" y luego a int\n",
    "            val_int = int(float(str(valor).strip()))\n",
    "            return str(val_int).zfill(relleno)\n",
    "        except:\n",
    "            return str(valor).strip().zfill(relleno)\n",
    "\n",
    "    # Asegurar formato: DPR (2 d√≠gitos) + MNC (3 d√≠gitos)\n",
    "    registros_finales['DPR_STR'] = registros_finales['DPR_ID'].apply(lambda x: limpiar_codigo(x, 2))\n",
    "    registros_finales['MNC_STR'] = registros_finales['MNC_ID'].apply(lambda x: limpiar_codigo(x, 3))\n",
    "    \n",
    "    registros_finales['COD_MUNICIPIO_CALC'] = registros_finales['DPR_STR'] + registros_finales['MNC_STR']\n",
    "    \n",
    "    # Validar que haya quedado de 5 d√≠gitos\n",
    "    mask_validos = registros_finales['COD_MUNICIPIO_CALC'].str.len() == 5\n",
    "    registros_finales = registros_finales[mask_validos].copy()\n",
    "    \n",
    "    print(f\"   Registros con c√≥digo v√°lido construido: {len(registros_finales)}\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # PASO 4: CREAR DATAFRAME DE NOVEDADES\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîß PASO 4: Construyendo estructura N43\")\n",
    "    \n",
    "    try:\n",
    "        nuevas_novedades = pd.DataFrame({\n",
    "            'ENT_ID': registros_finales['ENT_ID'],\n",
    "            'TPS_IDN_ID': registros_finales['TPS_IDN_ID'],\n",
    "            'HST_IDN_NUMERO_IDENTIFICACION': registros_finales['HST_IDN_NUMERO_IDENTIFICACION'],\n",
    "            'AFL_PRIMER_APELLIDO': registros_finales['AFL_PRIMER_APELLIDO'],\n",
    "            'AFL_SEGUNDO_APELLIDO': registros_finales['AFL_SEGUNDO_APELLIDO'],\n",
    "            'AFL_PRIMER_NOMBRE': registros_finales['AFL_PRIMER_NOMBRE'],\n",
    "            'AFL_SEGUNDO_NOMBRE': registros_finales['AFL_SEGUNDO_NOMBRE'],\n",
    "            'AFL_FECHA_NACIMIENTO': registros_finales['AFL_FECHA_NACIMIENTO'],\n",
    "            'DPR_ID': registros_finales['DPR_ID'],\n",
    "            'MNS_ID': registros_finales['MNC_ID'], # MNC_ID -> MNS_ID\n",
    "            'NOVEDAD': 'N43',\n",
    "            'FECHA_NOVEDAD': fecha_novedad_str,\n",
    "            'COD_1_NOVEDAD': registros_finales['COD_MUNICIPIO_CALC'], # C√≥digo construido\n",
    "            'ENT_ID_ADRES': registros_finales['ENT_ID'],\n",
    "            'TPS_EST_AFL_ID_from_adres': registros_finales['TPS_EST_AFL_ID'],\n",
    "            'Where': 'Novedad Masiva N43'\n",
    "        })\n",
    "        \n",
    "        # Crear IDs\n",
    "        nuevas_novedades['ID_User'] = (\n",
    "            nuevas_novedades['TPS_IDN_ID'].astype(str) + \n",
    "            nuevas_novedades['HST_IDN_NUMERO_IDENTIFICACION'].astype(str)\n",
    "        )\n",
    "        \n",
    "        nuevas_novedades['ID_Register'] = (\n",
    "            nuevas_novedades['TPS_IDN_ID'].astype(str) + \n",
    "            nuevas_novedades['HST_IDN_NUMERO_IDENTIFICACION'].astype(str) + \n",
    "            nuevas_novedades['NOVEDAD'].astype(str)\n",
    "        )\n",
    "        \n",
    "        # Rellenar columnas faltantes\n",
    "        for col in df_ns.columns:\n",
    "            if col not in nuevas_novedades.columns:\n",
    "                nuevas_novedades[col] = None\n",
    "                \n",
    "        # Ordenar columnas\n",
    "        nuevas_novedades = nuevas_novedades[df_ns.columns]\n",
    "        \n",
    "        print(f\"   ‚úÖ Novedades N43 construidas: {len(nuevas_novedades):,}\")\n",
    "        \n",
    "        # Mostrar ejemplos\n",
    "        print(f\"\\n   üìã Ejemplos de N43 Masivas:\")\n",
    "        print(nuevas_novedades[['HST_IDN_NUMERO_IDENTIFICACION', 'COD_1_NOVEDAD', 'DPR_ID', 'MNS_ID']].head().to_string(index=False))\n",
    "\n",
    "        # Agregar al DF principal\n",
    "        registros_antes = len(df_ns)\n",
    "        df_ns = pd.concat([df_ns, nuevas_novedades], ignore_index=True)\n",
    "        print(f\"\\n   üìä Registros agregados a df_NS: {len(df_ns) - registros_antes:,}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al construir novedades N43: {e}\")\n",
    "        \n",
    "    print(f\"\\n‚úÖ ACTUALIZACIONES MASIVAS N43 APLICADAS EXITOSAMENTE\")\n",
    "    return df_ns\n",
    "\n",
    "# Aplicar actualizaciones masivas N43\n",
    "df_NS = aplicar_actualizaciones_masivas_N43(df_NS, maestro_ADRES, fecha_reporte)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "## üö© N46 Reporte de datos de contacto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Se agrega import de pandas\n",
    "\n",
    "def validar_novedades_N46(df, df_no_envio):\n",
    "    \"\"\"\n",
    "    Valida registros con NOVEDAD = 'N46' (Reporte de datos de contacto).\n",
    "    \n",
    "    Proceso:\n",
    "    1. COD_1_NOVEDAD: Si no inicia con \"BRR \", se corrige anteponi√©ndolo. (MODIFICADO)\n",
    "    2. COD_2_NOVEDAD: Debe tener 5 d√≠gitos (DDMMM), si no tiene formato correcto se construye con DPR_ID + MNS_ID\n",
    "    3. COD_3_NOVEDAD: Debe ser un tel√©fono v√°lido colombiano (inicia con 3, 10 d√≠gitos), si no cumple se vac√≠a\n",
    "    4. COD_4_NOVEDAD: Debe ser un email v√°lido, si no cumple se vac√≠a\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con novedades\n",
    "        df_no_envio: DataFrame con registros rechazados\n",
    "    \n",
    "    Returns:\n",
    "        df actualizado, df_no_envio actualizado\n",
    "    \"\"\"\n",
    "    print(\"üîç INICIANDO VALIDACI√ìN DE NOVEDADES N46\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Filtrar solo registros N46\n",
    "    mask_n46 = df['NOVEDAD'] == 'N46'\n",
    "    registros_n46 = df[mask_n46].copy()\n",
    "    total_n46_inicial = len(registros_n46)\n",
    "    \n",
    "    print(f\"üìä Total de registros N46 iniciales: {total_n46_inicial}\")\n",
    "    \n",
    "    if total_n46_inicial == 0:\n",
    "        print(\"‚ö†Ô∏è No se encontraron registros N46\")\n",
    "        return df, df_no_envio\n",
    "    \n",
    "    # Inicializar contadores de correcci√≥n\n",
    "    correcciones_cod1 = 0\n",
    "    total_invalidos_cod1 = 0 # Se mantiene en 0 porque ya no se rechazan en este punto\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CORRECCI√ìN 1: COD_1_NOVEDAD DEBE INICIAR CON \"BRR \" (L√≥gica de correcci√≥n)\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîß CORRECCI√ìN 1: Estandarizando COD_1_NOVEDAD para que inicie con 'BRR '\")\n",
    "    \n",
    "    # Normalizar y verificar\n",
    "    registros_n46['COD_1_NOVEDAD_NORM'] = registros_n46['COD_1_NOVEDAD'].astype(str).str.strip()\n",
    "    mask_valido_cod1 = registros_n46['COD_1_NOVEDAD_NORM'].str.upper().str.startswith('BRR ')\n",
    "    \n",
    "    mask_a_corregir = ~mask_valido_cod1\n",
    "    \n",
    "    if mask_a_corregir.any():\n",
    "        \n",
    "        # Guardar solo la parte que sigue a 'BRR ' (el contenido original)\n",
    "        contenido_original = registros_n46.loc[mask_a_corregir, 'COD_1_NOVEDAD_NORM']\n",
    "        \n",
    "        # Aplicar la correcci√≥n: anteponer 'BRR ' al contenido original\n",
    "        nuevo_valor_cod1 = 'BRR ' + contenido_original\n",
    "        \n",
    "        # Contar las correcciones\n",
    "        correcciones_cod1 = mask_a_corregir.sum()\n",
    "        \n",
    "        # 1. Actualizar el DataFrame principal (df) con los valores corregidos\n",
    "        indices_a_corregir_df = df.loc[mask_n46][mask_a_corregir].index\n",
    "        df.loc[indices_a_corregir_df, 'COD_1_NOVEDAD'] = nuevo_valor_cod1.values\n",
    "        \n",
    "        # 2. Actualizar el DataFrame temporal (registros_n46)\n",
    "        registros_n46.loc[mask_a_corregir, 'COD_1_NOVEDAD'] = nuevo_valor_cod1\n",
    "        \n",
    "        print(f\" ¬† üîß Registros corregidos (se les antepuso 'BRR '): {correcciones_cod1}\")\n",
    "        \n",
    "        if correcciones_cod1 > 0:\n",
    "            print(f\"\\n ¬† üìã Ejemplo de COD_1_NOVEDAD corregido:\")\n",
    "            ejemplo_corregido = df.loc[indices_a_corregir_df, ['NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION', 'COD_1_NOVEDAD']].head(1)\n",
    "            print(ejemplo_corregido.to_string(index=False))\n",
    "\n",
    "    else:\n",
    "        print(\" ¬† ‚úÖ Todos los registros N46 ya iniciaban con 'BRR '.\")\n",
    "    \n",
    "    # Actualizar registros_n46 (ya se hizo en el paso 2, solo quitamos la columna temporal y re-filtramos)\n",
    "    registros_n46 = df[df['NOVEDAD'] == 'N46'].copy() \n",
    "    \n",
    "    # =========================================================================\n",
    "    # VALIDACI√ìN 2: COD_2_NOVEDAD DEBE TENER 5 D√çGITOS (DDMMM)\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîß VALIDACI√ìN 2: Validando y corrigiendo COD_2_NOVEDAD (c√≥digo de municipio)\")\n",
    "    \n",
    "    def validar_codigo_municipio(valor):\n",
    "        \"\"\"Valida si es un c√≥digo de 5 d√≠gitos\"\"\"\n",
    "        if pd.isna(valor) or str(valor).strip() == '':\n",
    "            return False\n",
    "        \n",
    "        valor_str = str(valor).strip()\n",
    "        \n",
    "        # Debe tener exactamente 5 d√≠gitos\n",
    "        if len(valor_str) != 5 or not valor_str.isdigit():\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    # Aplicar validaci√≥n\n",
    "    registros_n46['COD_2_VALIDO'] = registros_n46['COD_2_NOVEDAD'].apply(validar_codigo_municipio)\n",
    "    invalidos_cod2 = (~registros_n46['COD_2_VALIDO']).sum()\n",
    "    \n",
    "    print(f\" ¬† ‚úÖ Registros con COD_2_NOVEDAD v√°lido (5 d√≠gitos): {registros_n46['COD_2_VALIDO'].sum()}\")\n",
    "    print(f\" ¬† üîß Registros que requieren correcci√≥n: {invalidos_cod2}\")\n",
    "    \n",
    "    # Corregir los inv√°lidos construyendo con DPR_ID + MNS_ID\n",
    "    correcciones_cod2 = 0\n",
    "    \n",
    "    for idx in registros_n46[~registros_n46['COD_2_VALIDO']].index:\n",
    "        # Obtener DPR_ID (2 d√≠gitos) y MNS_ID (3 d√≠gitos)\n",
    "        # Importante: se usa df.loc[idx] para obtener DPR_ID/MNS_ID del dataframe principal.\n",
    "        dpr_id = str(df.loc[idx, 'DPR_ID']).strip().zfill(2)\n",
    "        mns_id = str(df.loc[idx, 'MNS_ID']).strip().zfill(3)\n",
    "        \n",
    "        # Validar que sean num√©ricos\n",
    "        if dpr_id.isdigit() and mns_id.isdigit():\n",
    "            codigo_municipio = dpr_id + mns_id\n",
    "            df.loc[idx, 'COD_2_NOVEDAD'] = codigo_municipio\n",
    "            correcciones_cod2 += 1\n",
    "    \n",
    "    print(f\" ¬† ‚úÖ COD_2_NOVEDAD corregidos: {correcciones_cod2}\")\n",
    "    \n",
    "    # Mostrar ejemplos de correcciones\n",
    "    if correcciones_cod2 > 0:\n",
    "        print(f\"\\n ¬† üìã Ejemplos de COD_2_NOVEDAD corregidos:\")\n",
    "        registros_actualizados = df[df['NOVEDAD'] == 'N46'][[\n",
    "            'NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION', \n",
    "            'DPR_ID', 'MNS_ID', 'COD_2_NOVEDAD'\n",
    "        ]].tail(5) # Usamos tail para mostrar correcciones recientes\n",
    "        print(registros_actualizados.to_string(index=False))\n",
    "    \n",
    "    # =========================================================================\n",
    "    # VALIDACI√ìN 3: COD_3_NOVEDAD DEBE SER UN TEL√âFONO V√ÅLIDO\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîß VALIDACI√ìN 3: Validando y limpiando COD_3_NOVEDAD (tel√©fono)\")\n",
    "    \n",
    "    def validar_telefono_colombia(valor):\n",
    "        \"\"\"\n",
    "        Valida si es un tel√©fono v√°lido colombiano:\n",
    "        - Inicia con 3\n",
    "        - Tiene exactamente 10 d√≠gitos\n",
    "        - Solo n√∫meros, sin espacios\n",
    "        \"\"\"\n",
    "        if pd.isna(valor) or str(valor).strip() == '':\n",
    "            return None\n",
    "        \n",
    "        # Limpiar: solo n√∫meros\n",
    "        valor_limpio = ''.join(filter(str.isdigit, str(valor)))\n",
    "        \n",
    "        # Validar formato\n",
    "        if len(valor_limpio) == 10 and valor_limpio.startswith('3'):\n",
    "            return valor_limpio\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    # Aplicar validaci√≥n y correcci√≥n\n",
    "    telefonos_validos_antes = df[df['NOVEDAD'] == 'N46']['COD_3_NOVEDAD'].notna().sum()\n",
    "    \n",
    "    for idx in df[df['NOVEDAD'] == 'N46'].index:\n",
    "        valor_actual = df.loc[idx, 'COD_3_NOVEDAD']\n",
    "        telefono_validado = validar_telefono_colombia(valor_actual)\n",
    "        \n",
    "        df.loc[idx, 'COD_3_NOVEDAD'] = telefono_validado if telefono_validado else ''\n",
    "    \n",
    "    telefonos_validos_despues = (df[df['NOVEDAD'] == 'N46']['COD_3_NOVEDAD'] != '').sum()\n",
    "    telefonos_limpiados = telefonos_validos_antes - telefonos_validos_despues\n",
    "    \n",
    "    print(f\" ¬† ‚úÖ Tel√©fonos v√°lidos: {telefonos_validos_despues}\")\n",
    "    print(f\" ¬† üßπ Tel√©fonos inv√°lidos limpiados: {telefonos_limpiados}\")\n",
    "    \n",
    "    # Mostrar ejemplos\n",
    "    registros_con_telefono = df[(df['NOVEDAD'] == 'N46') & (df['COD_3_NOVEDAD'] != '')]\n",
    "    if len(registros_con_telefono) > 0:\n",
    "        print(f\"\\n ¬† üìã Ejemplos de tel√©fonos v√°lidos:\")\n",
    "        ejemplos_telefonos = registros_con_telefono[[\n",
    "            'NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION', 'COD_3_NOVEDAD'\n",
    "        ]].head(5)\n",
    "        print(ejemplos_telefonos.to_string(index=False))\n",
    "    \n",
    "    # =========================================================================\n",
    "    # VALIDACI√ìN 4: COD_4_NOVEDAD DEBE SER UN EMAIL V√ÅLIDO\n",
    "    # =========================================================================\n",
    "    print(f\"\\nüîß VALIDACI√ìN 4: Validando y limpiando COD_4_NOVEDAD (email)\")\n",
    "    \n",
    "    \n",
    "    def validar_email(valor):\n",
    "        \"\"\"\n",
    "        Valida si es un email v√°lido usando expresi√≥n regular\n",
    "        \"\"\"\n",
    "        if pd.isna(valor) or str(valor).strip() == '':\n",
    "            return None\n",
    "        \n",
    "        valor_limpio = str(valor).strip()\n",
    "        \n",
    "        # Patr√≥n b√°sico de email\n",
    "        patron_email = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n",
    "        \n",
    "        if re.match(patron_email, valor_limpio):\n",
    "            return valor_limpio\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    # Aplicar validaci√≥n y correcci√≥n\n",
    "    emails_validos_antes = df[df['NOVEDAD'] == 'N46']['COD_4_NOVEDAD'].notna().sum()\n",
    "    \n",
    "    for idx in df[df['NOVEDAD'] == 'N46'].index:\n",
    "        valor_actual = df.loc[idx, 'COD_4_NOVEDAD']\n",
    "        email_validado = validar_email(valor_actual)\n",
    "        \n",
    "        df.loc[idx, 'COD_4_NOVEDAD'] = email_validado if email_validado else ''\n",
    "    \n",
    "    emails_validos_despues = (df[df['NOVEDAD'] == 'N46']['COD_4_NOVEDAD'] != '').sum()\n",
    "    emails_limpiados = emails_validos_antes - emails_validos_despues\n",
    "    \n",
    "    print(f\" ¬† ‚úÖ Emails v√°lidos: {emails_validos_despues}\")\n",
    "    print(f\" ¬† üßπ Emails inv√°lidos limpiados: {emails_limpiados}\")\n",
    "    \n",
    "    # Mostrar ejemplos\n",
    "    registros_con_email = df[(df['NOVEDAD'] == 'N46') & (df['COD_4_NOVEDAD'] != '')]\n",
    "    if len(registros_con_email) > 0:\n",
    "        print(f\"\\n ¬† üìã Ejemplos de emails v√°lidos:\")\n",
    "        ejemplos_emails = registros_con_email[[\n",
    "            'NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION', 'COD_4_NOVEDAD'\n",
    "        ]].head(5)\n",
    "        print(ejemplos_emails.to_string(index=False))\n",
    "    \n",
    "    # =========================================================================\n",
    "    # RESUMEN FINAL\n",
    "    # =========================================================================\n",
    "    registros_n46_final = len(df[df['NOVEDAD'] == 'N46'])\n",
    "    \n",
    "    print(f\"\\nüìà RESUMEN FINAL:\")\n",
    "    print(f\" ¬† Registros N46 iniciales: {total_n46_inicial}\")\n",
    "    # Nota: total_invalidos_cod1 es 0 porque ya no se rechazan por el COD_1, se corrigen.\n",
    "    print(f\" ¬† Registros rechazados (COD_1 inv√°lido): {total_invalidos_cod1} (fueron corregidos)\") \n",
    "    print(f\" ¬† Registros N46 restantes: {registros_n46_final}\")\n",
    "    print(f\" ¬† Total en DF_No_Envio actual: {len(df_no_envio)}\")\n",
    "    \n",
    "    print(f\"\\nüìã CORRECCIONES APLICADAS:\")\n",
    "    print(f\" ¬† COD_1_NOVEDAD estandarizados (anteponiendo 'BRR '): {correcciones_cod1}\")\n",
    "    print(f\" ¬† COD_2_NOVEDAD corregidos (construidos con DPR_ID + MNS_ID): {correcciones_cod2}\")\n",
    "    print(f\" ¬† COD_3_NOVEDAD limpiados (tel√©fonos inv√°lidos): {telefonos_limpiados}\")\n",
    "    print(f\" ¬† COD_4_NOVEDAD limpiados (emails inv√°lidos): {emails_limpiados}\")\n",
    "    \n",
    "    # Mostrar estad√≠sticas finales\n",
    "    if registros_n46_final > 0:\n",
    "        registros_finales = df[df['NOVEDAD'] == 'N46']\n",
    "        \n",
    "        print(f\"\\nüìä ESTAD√çSTICAS DE DATOS DE CONTACTO:\")\n",
    "        print(f\" ¬† Registros con tel√©fono v√°lido: {(registros_finales['COD_3_NOVEDAD'] != '').sum()}\")\n",
    "        print(f\" ¬† Registros con email v√°lido: {(registros_finales['COD_4_NOVEDAD'] != '').sum()}\")\n",
    "        print(f\" ¬† Registros con ambos datos: {((registros_finales['COD_3_NOVEDAD'] != '') & (registros_finales['COD_4_NOVEDAD'] != '')).sum()}\")\n",
    "        print(f\" ¬† Registros sin ning√∫n dato de contacto: {((registros_finales['COD_3_NOVEDAD'] == '') & (registros_finales['COD_4_NOVEDAD'] == '')).sum()}\")\n",
    "        \n",
    "        print(f\"\\nüìã EJEMPLOS DE REGISTROS N46 FINALES:\")\n",
    "        ejemplos_finales = registros_finales[[\n",
    "            'NUM_SOLICITUD_NOVEDAD', 'HST_IDN_NUMERO_IDENTIFICACION',\n",
    "            'COD_1_NOVEDAD', 'COD_2_NOVEDAD', 'COD_3_NOVEDAD', 'COD_4_NOVEDAD'\n",
    "        ]].head(10)\n",
    "        print(ejemplos_finales.to_string(index=False))\n",
    "    \n",
    "    print(f\"\\n‚úÖ VALIDACI√ìN N46 COMPLETADA\")\n",
    "    \n",
    "    return df, df_no_envio\n",
    "\n",
    "# Aplicar validaci√≥n N46\n",
    "df_NS, DF_No_Envio = validar_novedades_N46(df_NS, DF_No_Envio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "# Limpiar nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpiar valores NaN en df_NS reemplaz√°ndolos por cadenas vac√≠as\n",
    "print(\"üßπ LIMPIANDO VALORES NaN EN df_NS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Mostrar informaci√≥n antes de la limpieza\n",
    "total_registros = len(df_NS)\n",
    "total_celdas = df_NS.size\n",
    "nan_antes = df_NS.isna().sum().sum()\n",
    "\n",
    "print(f\"üìä Registros totales: {total_registros:,}\")\n",
    "print(f\"üìä Celdas totales: {total_celdas:,}\")\n",
    "print(f\"üìä Valores NaN antes: {nan_antes:,}\")\n",
    "\n",
    "# Reemplazar todos los valores NaN por cadenas vac√≠as\n",
    "df_NS = df_NS.fillna('')\n",
    "\n",
    "# Verificar despu√©s de la limpieza\n",
    "nan_despues = df_NS.isna().sum().sum()\n",
    "\n",
    "print(f\"üìä Valores NaN despu√©s: {nan_despues:,}\")\n",
    "print(f\"‚úÖ Se limpiaron {nan_antes:,} valores NaN\")\n",
    "\n",
    "# Mostrar ejemplo de primeras filas despu√©s de la limpieza\n",
    "print(f\"\\nüìã Ejemplo de datos despu√©s de la limpieza:\")\n",
    "print(f\"Shape: {df_NS.shape}\")\n",
    "print(\"\\nPrimeras 3 filas y primeras 10 columnas:\")\n",
    "print(df_NS.iloc[:3, :10].to_string())\n",
    "\n",
    "print(f\"\\n‚úÖ LIMPIEZA DE NaN COMPLETADA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "# üö©üö©Estandarizar N21 SIE 4 y 06\n",
    "## N32 Parentesco SIE\n",
    "14535,EPS025,RC,1115870139,SILVA,NI√ëO,LISBETH,SAMARA,07/07/2022,85,250,N32,10/11/2025,CC,1115864791,*A*,2,,,,GE0030\n",
    "14551,EPS025,CC,1067031533,BENAVIDES,MORA,YINETH,CAROLINA,20/10/2005,85,125,N32,10/11/2025,CC,1066086055,B,*9,4*,,,GE0204\n",
    "## N36\n",
    "14566,EPS025,RC,1115869036,VALOR,SOLANO,ALAN,,23/09/2020,85,250,N36,11/11/2025,F,4,B01,5,1,06,,GE0200\n",
    "14567,EPS025,TI,1157963502,ENDES,FANDI√ëO,AUDRY,STHEFANY,24/02/2010,85,001,N36,12/11/2025,F,5,,9,N,06,,GE0201;GE0202\n",
    "14568,EPS025,CC,1006450245,BARRETO,CALDERON,ANA,VICTORIA,04/01/1991,85,001,N36,11/11/2025,1,4,C06,5,2,06,,GE0060;GE0200\n",
    "14569,EPS025,TI,1118704349,NARANJO,VELANDIA,KELLY,JOHANNA,24/12/2007,85,250,N36,11/11/2025,F,4,A02,5,1,06,,GE0200\n",
    "14570,EPS025,CC,1115862059,SIBO,CORREDOR,PAULA,ANDREA,02/09/1995,85,250,N36,13/11/2025,1,,,9,,06,,GE0060;GE0201;GE0202;GE0200\n",
    "14571,EPS025,TI,1118650729,SEGUA,ALBARRACIN,CLARIS,ZAMANTHA,03/05/2016,85,125,N36,07/11/2025,1,4,A03,5,1,06,,GE0060;GE0200\n",
    "14572,EPS025,TI,1029658524,ALBARRACIN,ROMERO,VALERIN,YELENYS,20/10/2011,85,125,N36,07/11/2025,1,4,A03,5,1,06,,GE0060;GE0200\n",
    "14573,EPS025,CC,1006636098,ALBARRACIN,ROMERO,MILDRED,ROCIO,26/08/1991,85,125,N36,07/11/2025,1,4,A03,5,1,06,,GE0060;GE0200\n",
    "14574,EPS025,RC,1118651668,SEGUA,ALBARRACIN,ASLY,ADARA,05/08/2022,85,125,N36,07/11/2025,1,4,A03,5,1,06,,GE0060;GE0200\n",
    "\n",
    "## N39\n",
    "14660,EPS025,CC,1193519273,GONZALEZ,BELLO,ESNEYDER,ALBERTO,22/09/1998,85,125,N39,30/07/2026,0,85,001,,,,,GE0079\n",
    "14661,EPS025,CC,1116544784,SALAMANCA,CORREA,YEISON,HERNEY,11/10/2003,85,010,N39,14/02/2026,0,85,001,,,,,GE0079\n",
    "## N41\n",
    "14680,EPS025,CC,33646632,VEGA,SANABRIA,JENNY,LISEDT,21/02/1983,85,010,N41,11/11/2025,5,,,,,,,GE0305\n",
    "14681,EPS025,TI,1115917869,PAEZ,NU√ëEZ,PAMELA,DENISE,18/10/2015,85,410,N41,08/11/2025,3,,,,,,,GE0305\n",
    "14682,EPS025,CC,51958092,DOMINGUEZ,VERA,SONIA,ISABEL,22/05/1965,85,010,N41,10/11/2025,4,,,,,,,GE0305\n",
    "14683,EPS025,CC,1006783781,MORENO,BOHORQUEZ,MIGUEL,ESTEBAN,10/07/1996,85,162,N41,10/11/2025,5,,,,,,,GE0305\n",
    "## N46\n",
    "15008,EPS025,RC,1116044816,PIDIACHE,DEDIOS,XAVIER  ,SNEIDER,21/05/2024,85,263,N46,11/11/2025,BRR CARRERA 9  03 50,85263,3223764941,,,,,GE0085\n",
    "15870,EPS025,CC,1029644056,BELTRAN,ALVAREZ,JUAN,SEBASTIAN,28/04/2006,85,001,N46,12/11/2025,BRR N,85001,3000000000,actualizar@actualizar.com,,,,GE0314\n",
    "16530,EPS025,CC,17555227,RODRIGUEZ,GUTIERREZ,OLIVERIO,,22/07/1957,85,410,N46,10/11/2025,BRR Actualizar,85410,3000000000,actualizar@actualizar.com,,,,GE0314\n",
    "16557,EPS025,CC,4184360,GUINA,GUANARO,ALFONSO,,02/01/1963,85,225,N46,09/11/2025,BRR Actualizar,85225,3000000000,actualizar@actualizar.com,,,,GE0314\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NS.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "maestro_ADRES.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "# GUARDAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Valores √∫nicos en la columna NOVEDAD:\") \n",
    "print(df_NS['NOVEDAD'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "maestro_ADRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar con nombres de hojas m√°s descriptivos\n",
    "output_file = os.path.join(Ruta_Salida, f\"Datos_Procesados_{fecha_archivo}.xlsx\")\n",
    "\n",
    "print(f\"üíæ GUARDANDO DATAFRAMES PROCESADOS\")\n",
    "print(f\"üìÅ Archivo: {output_file}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "        # Guardar maestro_ADRES\n",
    "        maestro_ADRES.to_excel(writer, sheet_name='Maestro_ADRES_Limpio', index=False)\n",
    "        print(f\"‚úÖ Maestro ADRES guardado:\")\n",
    "        print(f\"   üìä Filas: {len(maestro_ADRES):,}\")\n",
    "        print(f\"   üìä Columnas: {len(maestro_ADRES.columns)}\")\n",
    "        \n",
    "        # Guardar df_NS\n",
    "        df_NS.to_excel(writer, sheet_name='NS_Validado', index=False)\n",
    "        print(f\"‚úÖ DataFrame NS guardado:\")\n",
    "        print(f\"   üìä Filas: {len(df_NS):,}\")\n",
    "        print(f\"   üìä Columnas: {len(df_NS.columns)}\")\n",
    "        \n",
    "        # Guardar DF_No_Envio\n",
    "        DF_No_Envio.to_excel(writer, sheet_name='NS_No_Envio', index=False)\n",
    "        print(f\"‚úÖ DataFrame No Env√≠o guardado:\")\n",
    "        print(f\"   üìä Filas: {len(DF_No_Envio):,}\")\n",
    "        print(f\"   üìä Columnas: {len(DF_No_Envio.columns)}\")\n",
    "        \n",
    "        # Guardar df_IPS\n",
    "        df_IPS.to_excel(writer, sheet_name='IPS', index=False)\n",
    "        print(f\"‚úÖ DataFrame IPS guardado:\")\n",
    "        print(f\"   üìä Filas: {len(df_IPS):,}\")\n",
    "        print(f\"   üìä Columnas: {len(df_IPS.columns)}\")\n",
    "        \n",
    "        # Resumen de novedades en df_NS\n",
    "        if 'NOVEDAD' in df_NS.columns:\n",
    "            print(f\"   üìã Tipos de novedad v√°lidas: {df_NS['NOVEDAD'].value_counts().to_dict()}\")\n",
    "        \n",
    "        # Resumen de motivos de rechazo en DF_No_Envio\n",
    "        if 'motivo' in DF_No_Envio.columns and len(DF_No_Envio) > 0:\n",
    "            print(f\"   üìã Motivos de rechazo: {DF_No_Envio['motivo'].value_counts().to_dict()}\")\n",
    "    \n",
    "    print(f\"\\nüéâ GUARDADO EXITOSO\")\n",
    "    print(f\"üìÇ Ubicaci√≥n: {output_file}\")\n",
    "    print(f\"üìã Hojas creadas: 'Maestro_ADRES_Limpio', 'NS_Validado', 'NS_No_Envio'\")\n",
    "    \n",
    "    # Mostrar estad√≠sticas finales\n",
    "    print(f\"\\nüìä ESTAD√çSTICAS FINALES:\")\n",
    "    print(f\"   Total registros procesados: {len(df_NS) + len(DF_No_Envio):,}\")\n",
    "    print(f\"   Registros v√°lidos para env√≠o: {len(df_NS):,}\")\n",
    "    print(f\"   Registros rechazados: {len(DF_No_Envio):,}\")\n",
    "    if len(df_NS) + len(DF_No_Envio) > 0:\n",
    "        porcentaje_validos = (len(df_NS) / (len(df_NS) + len(DF_No_Envio))) * 100\n",
    "        print(f\"   Porcentaje de validez: {porcentaje_validos:.2f}%\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error al guardar: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
